<!doctype html><html class="theme-next mist use-motion" lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="deep learning,machine learning,cs231n,"><link rel="alternate" href="/atom.xml" title="Abracadabra" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="Software PackagesCaffehttp://caffe.berkeleyvision.orgOverviewFrom U.C. BerkeleyWritten in C++Has Python and Matlab bindingsGood for training or finetuning feedforward modelsTipDon’t be afraid to read"><meta property="og:type" content="article"><meta property="og:title" content="cs231n Software Packages notes"><meta property="og:url" content="http://yoursite.com/2017/04/13/cs231n-Software-Packages-notes/index.html"><meta property="og:site_name" content="Abracadabra"><meta property="og:description" content="Software PackagesCaffehttp://caffe.berkeleyvision.orgOverviewFrom U.C. BerkeleyWritten in C++Has Python and Matlab bindingsGood for training or finetuning feedforward modelsTipDon’t be afraid to read"><meta property="og:updated_time" content="2017-04-13T10:24:48.739Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="cs231n Software Packages notes"><meta name="twitter:description" content="Software PackagesCaffehttp://caffe.berkeleyvision.orgOverviewFrom U.C. BerkeleyWritten in C++Has Python and Matlab bindingsGood for training or finetuning feedforward modelsTipDon’t be afraid to read"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post"},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/2017/04/13/cs231n-Software-Packages-notes/"><title>cs231n Software Packages notes | Abracadabra</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?dc405a79ad500922134d14cdf288f646";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container one-collumn sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Abracadabra</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Do it yourself</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/13/cs231n-Software-Packages-notes/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline">cs231n Software Packages notes</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-13T17:22:10+08:00">2017-04-13 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/13/cs231n-Software-Packages-notes/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/13/cs231n-Software-Packages-notes/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/13/cs231n-Software-Packages-notes/" class="leancloud_visitors" data-flag-title="cs231n Software Packages notes"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="Software-Packages"><a href="#Software-Packages" class="headerlink" title="Software Packages"></a>Software Packages</h1><h2 id="Caffe"><a href="#Caffe" class="headerlink" title="Caffe"></a>Caffe</h2><p><a href="http://caffe.berkeleyvision.org" target="_blank" rel="external">http://caffe.berkeleyvision.org</a></p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><ul><li>From U.C. Berkeley</li><li>Written in C++</li><li>Has Python and Matlab bindings</li><li>Good for training or finetuning feedforward models</li></ul><h3 id="Tip"><a href="#Tip" class="headerlink" title="Tip"></a>Tip</h3><p>Don’t be afraid to read the code!</p><h3 id="Main-classes"><a href="#Main-classes" class="headerlink" title="Main classes"></a>Main classes</h3><ul><li>Blob: Stores data and derivatives</li><li>Layer: Transforms bottom blobs to top blobs</li><li>Net:<ul><li>Many layers</li><li>Computes gradients via forward / backward</li></ul></li><li>Solver: Uses gradients to update weights</li></ul><h3 id="Protocol-Buffers"><a href="#Protocol-Buffers" class="headerlink" title="Protocol Buffers"></a>Protocol Buffers</h3><ul><li><p>“Typed JSON” from Google</p></li><li><p>Define “message types” in .proto files</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">message Person &#123;</div><div class="line">  required <span class="built_in">string</span> name = <span class="number">1</span>;</div><div class="line">  required int32 id = <span class="number">2</span>;</div><div class="line">  optional <span class="built_in">string</span> email = <span class="number">3</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></li><li><p>Serialize instances to text files (.prototxt)</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">name: <span class="string">"John Doe"</span></div><div class="line">id: <span class="number">1234</span></div><div class="line">email: <span class="string">"jdoe@example.com"</span></div></pre></td></tr></table></figure></li><li><p>Compile classes for different languages</p></li></ul><h3 id="Training-Finetuning"><a href="#Training-Finetuning" class="headerlink" title="Training / Finetuning"></a>Training / Finetuning</h3><ol><li>Convert data (run a script)</li><li>Define net (edit prototxt)</li><li>Define solver (edit prototxt)</li><li>Train (with pretrained weights) (run a script)</li></ol><h4 id="Step1-Convert-Data"><a href="#Step1-Convert-Data" class="headerlink" title="Step1: Convert Data"></a>Step1: Convert Data</h4><ul><li>DataLayer reading from LMDB is the easiest</li><li>Create LMDB using <a href="https://github.com/BVLC/caffe/blob/85bb397acfd383a676c125c75d877642d6b39ff6/tools/convert_imageset.cpp" target="_blank" rel="external">convert_imageset</a></li><li>Need text file where each line is<ul><li>“[path/to/image.jpeg][label]”</li></ul></li><li>Create HDF5 file yourself using h5py</li><li>[extras] some methods:<ul><li>ImageDataLayer: Read from image files</li><li>WindowDataLayer: For detection</li><li>HDF5Layer: Read from HDF5 file</li><li>From memory, using Python interface</li><li>All of these are harder to use (except Python)</li></ul></li></ul><h4 id="Step2-Define-Net"><a href="#Step2-Define-Net" class="headerlink" title="Step2: Define Net"></a>Step2: Define Net</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div></pre></td><td class="code"><pre><div class="line">name: <span class="string">"ResNet-152"</span></div><div class="line">input: <span class="string">"data"</span></div><div class="line">input_dim: <span class="number">1</span></div><div class="line">input_dim: <span class="number">3</span></div><div class="line">input_dim: <span class="number">224</span></div><div class="line">input_dim: <span class="number">224</span></div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"data"</span></div><div class="line">	top: <span class="string">"conv1"</span></div><div class="line">	name: <span class="string">"conv1"</span></div><div class="line">	type: <span class="string">"Convolution"</span></div><div class="line">	convolution_param &#123;</div><div class="line">		num_output: <span class="number">64</span></div><div class="line">		kernel_size: <span class="number">7</span></div><div class="line">		pad: <span class="number">3</span></div><div class="line">		stride: <span class="number">2</span></div><div class="line">		bias_term: <span class="literal">false</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"conv1"</span></div><div class="line">	top: <span class="string">"conv1"</span></div><div class="line">	name: <span class="string">"bn_conv1"</span></div><div class="line">	type: <span class="string">"BatchNorm"</span></div><div class="line">	batch_norm_param &#123;</div><div class="line">		use_global_stats: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"conv1"</span></div><div class="line">	top: <span class="string">"conv1"</span></div><div class="line">	name: <span class="string">"scale_conv1"</span></div><div class="line">	type: <span class="string">"Scale"</span></div><div class="line">	scale_param &#123;</div><div class="line">		bias_term: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	top: <span class="string">"conv1"</span></div><div class="line">	bottom: <span class="string">"conv1"</span></div><div class="line">	name: <span class="string">"conv1_relu"</span></div><div class="line">	type: <span class="string">"ReLU"</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"conv1"</span></div><div class="line">	top: <span class="string">"pool1"</span></div><div class="line">	name: <span class="string">"pool1"</span></div><div class="line">	type: <span class="string">"Pooling"</span></div><div class="line">	pooling_param &#123;</div><div class="line">		kernel_size: <span class="number">3</span></div><div class="line">		stride: <span class="number">2</span></div><div class="line">		pool: MAX</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"pool1"</span></div><div class="line">	top: <span class="string">"res2a_branch1"</span></div><div class="line">	name: <span class="string">"res2a_branch1"</span></div><div class="line">	type: <span class="string">"Convolution"</span></div><div class="line">	convolution_param &#123;</div><div class="line">		num_output: <span class="number">256</span></div><div class="line">		kernel_size: <span class="number">1</span></div><div class="line">		pad: <span class="number">0</span></div><div class="line">		stride: <span class="number">1</span></div><div class="line">		bias_term: <span class="literal">false</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"res2a_branch1"</span></div><div class="line">	top: <span class="string">"res2a_branch1"</span></div><div class="line">	name: <span class="string">"bn2a_branch1"</span></div><div class="line">	type: <span class="string">"BatchNorm"</span></div><div class="line">	batch_norm_param &#123;</div><div class="line">		use_global_stats: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"res2a_branch1"</span></div><div class="line">	top: <span class="string">"res2a_branch1"</span></div><div class="line">	name: <span class="string">"scale2a_branch1"</span></div><div class="line">	type: <span class="string">"Scale"</span></div><div class="line">	scale_param &#123;</div><div class="line">		bias_term: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"pool1"</span></div><div class="line">	top: <span class="string">"res2a_branch2a"</span></div><div class="line">	name: <span class="string">"res2a_branch2a"</span></div><div class="line">	type: <span class="string">"Convolution"</span></div><div class="line">	convolution_param &#123;</div><div class="line">		num_output: <span class="number">64</span></div><div class="line">		kernel_size: <span class="number">1</span></div><div class="line">		pad: <span class="number">0</span></div><div class="line">		stride: <span class="number">1</span></div><div class="line">		bias_term: <span class="literal">false</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"res2a_branch2a"</span></div><div class="line">	top: <span class="string">"res2a_branch2a"</span></div><div class="line">	name: <span class="string">"bn2a_branch2a"</span></div><div class="line">	type: <span class="string">"BatchNorm"</span></div><div class="line">	batch_norm_param &#123;</div><div class="line">		use_global_stats: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"res2a_branch2a"</span></div><div class="line">	top: <span class="string">"res2a_branch2a"</span></div><div class="line">	name: <span class="string">"scale2a_branch2a"</span></div><div class="line">	type: <span class="string">"Scale"</span></div><div class="line">	scale_param &#123;</div><div class="line">		bias_term: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><ul><li>.prototxt can get ugly for big models</li><li><a href="https://github.com/KaimingHe/deep-residual-networks/blob/master/prototxt/ResNet-152-deploy.prototxt" target="_blank" rel="external">ResNet-152 prototxt</a> is 6775 lines long!</li><li>Not “compositional”; can’t easily define a residual block and reuse</li></ul><h4 id="Step2-Define-Net-finetuning"><a href="#Step2-Define-Net-finetuning" class="headerlink" title="Step2: Define Net (finetuning)"></a>Step2: Define Net (finetuning)</h4><ul><li>Same name: weights copied</li><li>Different name: weights reinitialized</li></ul><h4 id="Step3-Define-Solver"><a href="#Step3-Define-Solver" class="headerlink" title="Step3: Define Solver"></a>Step3: Define Solver</h4><ul><li><p>Write a prototxt file defining a <a href="https://github.com/BVLC/caffe/blob/85bb397acfd383a676c125c75d877642d6b39ff6/src/caffe/proto/caffe.proto#L92" target="_blank" rel="external">SolverParameter</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div></pre></td><td class="code"><pre><div class="line">message SolverParameter &#123;</div><div class="line">  <span class="comment">//////////////////////////////////////////////////////////////////////////////</span></div><div class="line">  <span class="comment">// Specifying the train and test networks</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// Exactly one train net must be specified using one of the following fields:</span></div><div class="line">  <span class="comment">//     train_net_param, train_net, net_param, net</span></div><div class="line">  <span class="comment">// One or more test nets may be specified using any of the following fields:</span></div><div class="line">  <span class="comment">//     test_net_param, test_net, net_param, net</span></div><div class="line">  <span class="comment">// If more than one test net field is specified (e.g., both net and</span></div><div class="line">  <span class="comment">// test_net are specified), they will be evaluated in the field order given</span></div><div class="line">  <span class="comment">// above: (1) test_net_param, (2) test_net, (3) net_param/net.</span></div><div class="line">  <span class="comment">// A test_iter must be specified for each test_net.</span></div><div class="line">  <span class="comment">// A test_level and/or a test_stage may also be specified for each test_net.</span></div><div class="line">  <span class="comment">//////////////////////////////////////////////////////////////////////////////</span></div><div class="line"></div><div class="line">  <span class="comment">// Proto filename for the train net, possibly combined with one or more</span></div><div class="line">  <span class="comment">// test nets.</span></div><div class="line">  optional <span class="built_in">string</span> net = <span class="number">24</span>;</div><div class="line">  <span class="comment">// Inline train net param, possibly combined with one or more test nets.</span></div><div class="line">  optional NetParameter net_param = <span class="number">25</span>;</div><div class="line"></div><div class="line">  optional <span class="built_in">string</span> train_net = <span class="number">1</span>; <span class="comment">// Proto filename for the train net.</span></div><div class="line">  repeated <span class="built_in">string</span> test_net = <span class="number">2</span>; <span class="comment">// Proto filenames for the test nets.</span></div><div class="line">  optional NetParameter train_net_param = <span class="number">21</span>; <span class="comment">// Inline train net params.</span></div><div class="line">  repeated NetParameter test_net_param = <span class="number">22</span>; <span class="comment">// Inline test net params.</span></div><div class="line"></div><div class="line">  <span class="comment">// The states for the train/test nets. Must be unspecified or</span></div><div class="line">  <span class="comment">// specified once per net.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// By default, all states will have solver = true;</span></div><div class="line">  <span class="comment">// train_state will have phase = TRAIN,</span></div><div class="line">  <span class="comment">// and all test_state's will have phase = TEST.</span></div><div class="line">  <span class="comment">// Other defaults are set according to the NetState defaults.</span></div><div class="line">  optional NetState train_state = <span class="number">26</span>;</div><div class="line">  repeated NetState test_state = <span class="number">27</span>;</div><div class="line"></div><div class="line">  <span class="comment">// The number of iterations for each test net.</span></div><div class="line">  repeated int32 test_iter = <span class="number">3</span>;</div><div class="line"></div><div class="line">  <span class="comment">// The number of iterations between two testing phases.</span></div><div class="line">  optional int32 test_interval = <span class="number">4</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line">  optional <span class="keyword">bool</span> test_compute_loss = <span class="number">19</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line">  <span class="comment">// If true, run an initial test pass before the first iteration,</span></div><div class="line">  <span class="comment">// ensuring memory availability and printing the starting value of the loss.</span></div><div class="line">  optional <span class="keyword">bool</span> test_initialization = <span class="number">32</span> [<span class="keyword">default</span> = <span class="literal">true</span>];</div><div class="line">  optional <span class="keyword">float</span> base_lr = <span class="number">5</span>; <span class="comment">// The base learning rate</span></div><div class="line">  <span class="comment">// the number of iterations between displaying info. If display = 0, no info</span></div><div class="line">  <span class="comment">// will be displayed.</span></div><div class="line">  optional int32 display = <span class="number">6</span>;</div><div class="line">  <span class="comment">// Display the loss averaged over the last average_loss iterations</span></div><div class="line">  optional int32 average_loss = <span class="number">33</span> [<span class="keyword">default</span> = <span class="number">1</span>];</div><div class="line">  optional int32 max_iter = <span class="number">7</span>; <span class="comment">// the maximum number of iterations</span></div><div class="line">  optional <span class="built_in">string</span> lr_policy = <span class="number">8</span>; <span class="comment">// The learning rate decay policy.</span></div><div class="line">  optional <span class="keyword">float</span> gamma = <span class="number">9</span>; <span class="comment">// The parameter to compute the learning rate.</span></div><div class="line">  optional <span class="keyword">float</span> power = <span class="number">10</span>; <span class="comment">// The parameter to compute the learning rate.</span></div><div class="line">  optional <span class="keyword">float</span> momentum = <span class="number">11</span>; <span class="comment">// The momentum value.</span></div><div class="line">  optional <span class="keyword">float</span> weight_decay = <span class="number">12</span>; <span class="comment">// The weight decay.</span></div><div class="line">  <span class="comment">// regularization types supported: L1 and L2</span></div><div class="line">  <span class="comment">// controlled by weight_decay</span></div><div class="line">  optional <span class="built_in">string</span> regularization_type = <span class="number">29</span> [<span class="keyword">default</span> = <span class="string">"L2"</span>];</div><div class="line">  <span class="comment">// the stepsize for learning rate policy "step"</span></div><div class="line">  optional int32 stepsize = <span class="number">13</span>;</div><div class="line">  <span class="comment">// the stepsize for learning rate policy "multistep"</span></div><div class="line">  repeated int32 stepvalue = <span class="number">34</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Set clip_gradients to &gt;= 0 to clip parameter gradients to that L2 norm,</span></div><div class="line">  <span class="comment">// whenever their actual L2 norm is larger.</span></div><div class="line">  optional <span class="keyword">float</span> clip_gradients = <span class="number">35</span> [<span class="keyword">default</span> = <span class="number">-1</span>];</div><div class="line"></div><div class="line">  optional int32 snapshot = <span class="number">14</span> [<span class="keyword">default</span> = <span class="number">0</span>]; <span class="comment">// The snapshot interval</span></div><div class="line">  optional <span class="built_in">string</span> snapshot_prefix = <span class="number">15</span>; <span class="comment">// The prefix for the snapshot.</span></div><div class="line">  <span class="comment">// whether to snapshot diff in the results or not. Snapshotting diff will help</span></div><div class="line">  <span class="comment">// debugging but the final protocol buffer size will be much larger.</span></div><div class="line">  optional <span class="keyword">bool</span> snapshot_diff = <span class="number">16</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line">  <span class="comment">// the mode solver will use: 0 for CPU and 1 for GPU. Use GPU in default.</span></div><div class="line">  <span class="keyword">enum</span> SolverMode &#123;</div><div class="line">    CPU = <span class="number">0</span>;</div><div class="line">    GPU = <span class="number">1</span>;</div><div class="line">  &#125;</div><div class="line">  optional SolverMode solver_mode = <span class="number">17</span> [<span class="keyword">default</span> = GPU];</div><div class="line">  <span class="comment">// the device_id will that be used in GPU mode. Use device_id = 0 in default.</span></div><div class="line">  optional int32 device_id = <span class="number">18</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line">  <span class="comment">// If non-negative, the seed with which the Solver will initialize the Caffe</span></div><div class="line">  <span class="comment">// random number generator -- useful for reproducible results. Otherwise,</span></div><div class="line">  <span class="comment">// (and by default) initialize using a seed derived from the system clock.</span></div><div class="line">  optional int64 random_seed = <span class="number">20</span> [<span class="keyword">default</span> = <span class="number">-1</span>];</div><div class="line"></div><div class="line">  <span class="comment">// Solver type</span></div><div class="line">  <span class="keyword">enum</span> SolverType &#123;</div><div class="line">    SGD = <span class="number">0</span>;</div><div class="line">    NESTEROV = <span class="number">1</span>;</div><div class="line">    ADAGRAD = <span class="number">2</span>;</div><div class="line">  &#125;</div><div class="line">  optional SolverType solver_type = <span class="number">30</span> [<span class="keyword">default</span> = SGD];</div><div class="line">  <span class="comment">// numerical stability for AdaGrad</span></div><div class="line">  optional <span class="keyword">float</span> delta = <span class="number">31</span> [<span class="keyword">default</span> = <span class="number">1e-8</span>];</div><div class="line"></div><div class="line">  <span class="comment">// If true, print information about the state of the net that may help with</span></div><div class="line">  <span class="comment">// debugging learning problems.</span></div><div class="line">  optional <span class="keyword">bool</span> debug_info = <span class="number">23</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line"></div><div class="line">  <span class="comment">// If false, don't save a snapshot after training finishes.</span></div><div class="line">  optional <span class="keyword">bool</span> snapshot_after_train = <span class="number">28</span> [<span class="keyword">default</span> = <span class="literal">true</span>];</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A message that stores the solver snapshots</span></div><div class="line">message SolverState &#123;</div><div class="line">  optional int32 iter = <span class="number">1</span>; <span class="comment">// The current iteration</span></div><div class="line">  optional <span class="built_in">string</span> learned_net = <span class="number">2</span>; <span class="comment">// The file that stores the learned net.</span></div><div class="line">  repeated BlobProto history = <span class="number">3</span>; <span class="comment">// The history for sgd solvers</span></div><div class="line">  optional int32 current_step = <span class="number">4</span> [<span class="keyword">default</span> = <span class="number">0</span>]; <span class="comment">// The current step for learning rate</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">enum</span> Phase &#123;</div><div class="line">   TRAIN = <span class="number">0</span>;</div><div class="line">   TEST = <span class="number">1</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line">message NetState &#123;</div><div class="line">  optional Phase phase = <span class="number">1</span> [<span class="keyword">default</span> = TEST];</div><div class="line">  optional int32 level = <span class="number">2</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line">  repeated <span class="built_in">string</span> stage = <span class="number">3</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line">message NetStateRule &#123;</div><div class="line">  <span class="comment">// Set phase to require the NetState have a particular phase (TRAIN or TEST)</span></div><div class="line">  <span class="comment">// to meet this rule.</span></div><div class="line">  optional Phase phase = <span class="number">1</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Set the minimum and/or maximum levels in which the layer should be used.</span></div><div class="line">  <span class="comment">// Leave undefined to meet the rule regardless of level.</span></div><div class="line">  optional int32 min_level = <span class="number">2</span>;</div><div class="line">  optional int32 max_level = <span class="number">3</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Customizable sets of stages to include or exclude.</span></div><div class="line">  <span class="comment">// The net must have ALL of the specified stages and NONE of the specified</span></div><div class="line">  <span class="comment">// "not_stage"s to meet the rule.</span></div><div class="line">  <span class="comment">// (Use multiple NetStateRules to specify conjunctions of stages.)</span></div><div class="line">  repeated <span class="built_in">string</span> stage = <span class="number">4</span>;</div><div class="line">  repeated <span class="built_in">string</span> not_stage = <span class="number">5</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// Specifies training parameters (multipliers on global learning constants,</span></div><div class="line"><span class="comment">// and the name and other settings used for weight sharing).</span></div><div class="line">message ParamSpec &#123;</div><div class="line">  <span class="comment">// The names of the parameter blobs -- useful for sharing parameters among</span></div><div class="line">  <span class="comment">// layers, but never required otherwise.  To share a parameter between two</span></div><div class="line">  <span class="comment">// layers, give it a (non-empty) name.</span></div><div class="line">  optional <span class="built_in">string</span> name = <span class="number">1</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Whether to require shared weights to have the same shape, or just the same</span></div><div class="line">  <span class="comment">// count -- defaults to STRICT if unspecified.</span></div><div class="line">  optional DimCheckMode share_mode = <span class="number">2</span>;</div><div class="line">  <span class="keyword">enum</span> DimCheckMode &#123;</div><div class="line">    <span class="comment">// STRICT (default) requires that num, channels, height, width each match.</span></div><div class="line">    STRICT = <span class="number">0</span>;</div><div class="line">    <span class="comment">// PERMISSIVE requires only the count (num*channels*height*width) to match.</span></div><div class="line">    PERMISSIVE = <span class="number">1</span>;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// The multiplier on the global learning rate for this parameter.</span></div><div class="line">  optional <span class="keyword">float</span> lr_mult = <span class="number">3</span> [<span class="keyword">default</span> = <span class="number">1.0</span>];</div><div class="line"></div><div class="line">  <span class="comment">// The multiplier on the global weight decay for this parameter.</span></div><div class="line">  optional <span class="keyword">float</span> decay_mult = <span class="number">4</span> [<span class="keyword">default</span> = <span class="number">1.0</span>];</div><div class="line">&#125;</div></pre></td></tr></table></figure></li><li><p>If finetuning, copy existing solver.prototxt file</p><ul><li>Change net to be your net</li><li>Change snapshot_prefix to your output</li><li>Reduce base learning rate (divide by 100)</li><li>Maybe change max_iter and snapshot</li></ul></li></ul><h4 id="Step-4-Train"><a href="#Step-4-Train" class="headerlink" title="Step 4: Train"></a>Step 4: Train</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">./build/tools/caffe train \</div><div class="line"> -gpu 0 \</div><div class="line"> -model path/to/trainval.prototxt \</div><div class="line"> -solver path/to/solver.prototxt \</div><div class="line"> -weights path/to/pretrained_weights.caffemodel</div><div class="line"> </div><div class="line"> # -gpu -1 for CPU mode</div><div class="line"> # -gpu all for multi-GPU data parallelism</div></pre></td></tr></table></figure><h3 id="Model-Zoo"><a href="#Model-Zoo" class="headerlink" title="Model Zoo"></a>Model Zoo</h3><p><a href="https://github.com/BVLC/caffe/wiki/Model-Zoo" target="_blank" rel="external">https://github.com/BVLC/caffe/wiki/Model-Zoo</a></p><h3 id="Python-Interface"><a href="#Python-Interface" class="headerlink" title="Python Interface"></a>Python Interface</h3><p>Read the code! Two most important files:</p><ul><li><a href="https://github.com/BVLC/caffe/blob/master/python/caffe/_caffe.cpp" target="_blank" rel="external">caffe/python/caffe/_caffe.cpp</a><ul><li>Exports Blob, Layer, Net, and Solver classes</li></ul></li><li><a href="https://github.com/BVLC/caffe/blob/master/python/caffe/pycaffe.py" target="_blank" rel="external">caffe/python/caffe/pycaffe.py</a><ul><li>Adds extra methods to Net class</li></ul></li></ul><p>Good for:</p><ul><li>Interfacing with numpy</li><li>Extract features: Run net forward</li><li>Compute gradients: Run net backward (DeepDream, etc)</li><li>Define layers in Python with numpy (CPU only)</li></ul><h3 id="Pros-Cons"><a href="#Pros-Cons" class="headerlink" title="Pros / Cons"></a>Pros / Cons</h3><ul><li>(+) Good for feedforward networks</li><li>(+) Good for finetuning existing networks</li><li>(+) Train models without writing any code!</li><li>(+) Python interface is pretty useful!</li><li>(-) Need to write C++ / CUDA for new GPU layers</li><li>(-) Not good for recurrent networks</li><li>(-) Cumbersome for big networks (GoogLeNet, ResNet)</li></ul><h2 id="Torch"><a href="#Torch" class="headerlink" title="Torch"></a>Torch</h2><p><a href="http://torch.ch" target="_blank" rel="external">http://torch.ch</a></p><h3 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a>Overview</h3><ul><li>From NYU + IDIAP</li><li>Written in C and Lua</li><li>Used a lot a Facebook, DeepMind</li></ul><h3 id="Lua"><a href="#Lua" class="headerlink" title="Lua"></a>Lua</h3><p><a href="http://tylerneylon.com/a/learn-lua/" target="_blank" rel="external">Learn Lua in 15 Minutes</a></p><ul><li>High level scripting language, easy to interface with C</li><li>Similar to Javascript:<ul><li>One data structure: table == JS object</li><li>Prototypical inheritance: metatable == JS prototype</li><li>First-class functions</li></ul></li><li>Some gotchas:<ul><li>1-indexed =(</li><li>Variables global by default =(</li><li>Small standard library</li></ul></li></ul><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><p>Torch tensors are just like numpy arrays</p><p>Documentation on GitHub:</p><ul><li><a href="https://github.com/torch/torch7/blob/master/doc/tensor.md" target="_blank" rel="external">https://github.com/torch/torch7/blob/master/doc/tensor.md</a></li><li><a href="https://github.com/torch/torch7/blob/master/doc/maths.md" target="_blank" rel="external">https://github.com/torch/torch7/blob/master/doc/maths.md</a></li></ul><h3 id="nn"><a href="#nn" class="headerlink" title="nn"></a>nn</h3><p>nn module lets you easily build and train neural nets</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- our optimization procedure will iterate over the modules, so only share</span></div><div class="line"><span class="comment">-- the parameters</span></div><div class="line">mlp = nn.Sequential()</div><div class="line">linear = nn.Linear(<span class="number">2</span>,<span class="number">2</span>)</div><div class="line">linear_clone = linear:clone(<span class="string">'weight'</span>,<span class="string">'bias'</span>) <span class="comment">-- clone sharing the parameters</span></div><div class="line">mlp:add(linear)</div><div class="line">mlp:add(linear_clone)</div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">gradUpdate</span><span class="params">(mlp, x, y, criterion, learningRate)</span></span> </div><div class="line">  <span class="keyword">local</span> pred = mlp:forward(x)</div><div class="line">  <span class="keyword">local</span> err = criterion:forward(pred, y)</div><div class="line">  <span class="keyword">local</span> gradCriterion = criterion:backward(pred, y)</div><div class="line">  mlp:zeroGradParameters()</div><div class="line">  mlp:backward(x, gradCriterion)</div><div class="line">  mlp:updateParameters(learningRate)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- our optimization procedure will use all the parameters at once, because</span></div><div class="line"><span class="comment">-- it requires the flattened parameters and gradParameters Tensors. Thus,</span></div><div class="line"><span class="comment">-- we need to share both the parameters and the gradParameters</span></div><div class="line">mlp = nn.Sequential()</div><div class="line">linear = nn.Linear(<span class="number">2</span>,<span class="number">2</span>)</div><div class="line"><span class="comment">-- need to share the parameters and the gradParameters as well</span></div><div class="line">linear_clone = linear:clone(<span class="string">'weight'</span>,<span class="string">'bias'</span>,<span class="string">'gradWeight'</span>,<span class="string">'gradBias'</span>)</div><div class="line">mlp:add(linear)</div><div class="line">mlp:add(linear_clone)</div><div class="line">params, gradParams = mlp:getParameters()</div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">gradUpdate</span><span class="params">(mlp, x, y, criterion, learningRate, params, gradParams)</span></span></div><div class="line">  <span class="keyword">local</span> pred = mlp:forward(x)</div><div class="line">  <span class="keyword">local</span> err = criterion:forward(pred, y)</div><div class="line">  <span class="keyword">local</span> gradCriterion = criterion:backward(pred, y)</div><div class="line">  mlp:zeroGradParameters()</div><div class="line">  mlp:backward(x, gradCriterion)</div><div class="line">  <span class="comment">-- adds the gradients to all the parameters at once</span></div><div class="line">  params:add(-learningRate, gradParams)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><h3 id="cunn"><a href="#cunn" class="headerlink" title="cunn"></a>cunn</h3><p>Running on GPU is easy</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">local</span> model = nn.Sequential()</div><div class="line">model:add(nn.Linear(<span class="number">2</span>,<span class="number">2</span>))</div><div class="line">model:add(nn.LogSoftMax())</div><div class="line"></div><div class="line">model:cuda()  <span class="comment">-- convert model to CUDA</span></div><div class="line"></div><div class="line"><span class="keyword">local</span> input = torch.Tensor(<span class="number">32</span>,<span class="number">2</span>):uniform()</div><div class="line">input = input:cuda()</div><div class="line"><span class="keyword">local</span> output = model:forward(input)</div><div class="line"></div><div class="line"><span class="keyword">local</span> input = torch.CudaTensor(<span class="number">32</span>,<span class="number">2</span>):uniform()</div><div class="line"><span class="keyword">local</span> output = model:forward(input)</div></pre></td></tr></table></figure><h3 id="optim"><a href="#optim" class="headerlink" title="optim"></a>optim</h3><p>optim package implements different update rules: momentum, Adam, etc</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">require</span> <span class="string">'optim'</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> epoch = <span class="number">1</span>, <span class="number">50</span> <span class="keyword">do</span></div><div class="line">   <span class="comment">-- local function we give to optim</span></div><div class="line">   <span class="comment">-- it takes current weights as input, and outputs the loss</span></div><div class="line">   <span class="comment">-- and the gradient of the loss with respect to the weights</span></div><div class="line">   <span class="comment">-- gradParams is calculated implicitly by calling 'backward',</span></div><div class="line">   <span class="comment">-- because the model's weight and bias gradient tensors</span></div><div class="line">   <span class="comment">-- are simply views onto gradParams</span></div><div class="line">   <span class="function"><span class="keyword">function</span> <span class="title">feval</span><span class="params">(params)</span></span></div><div class="line">      gradParams:zero()</div><div class="line"></div><div class="line">      <span class="keyword">local</span> outputs = model:forward(batchInputs)</div><div class="line">      <span class="keyword">local</span> loss = criterion:forward(outputs, batchLabels)</div><div class="line">      <span class="keyword">local</span> dloss_doutputs = criterion:backward(outputs, batchLabels)</div><div class="line">      model:backward(batchInputs, dloss_doutputs)</div><div class="line"></div><div class="line">      <span class="keyword">return</span> loss, gradParams</div><div class="line">   <span class="keyword">end</span></div><div class="line">   optim.sgd(feval, params, optimState)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><h3 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h3><ul><li>Caffe has Nets and Layers; Torch just has Modules</li><li>Modules are classes written in Lua; easy to read and write</li><li>Forward / backward written in Lua using Tensor methods</li><li>Same code runs on CPU / GPU</li></ul><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">local</span> Linear, parent = torch.class(<span class="string">'nn.Linear'</span>, <span class="string">'nn.Module'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:__init</span><span class="params">(inputSize, outputSize, bias)</span></span></div><div class="line">   parent.__init(self)</div><div class="line">   <span class="keyword">local</span> bias = ((bias == <span class="keyword">nil</span>) <span class="keyword">and</span> <span class="keyword">true</span>) <span class="keyword">or</span> bias</div><div class="line">   self.weight = torch.Tensor(outputSize, inputSize)</div><div class="line">   self.gradWeight = torch.Tensor(outputSize, inputSize)</div><div class="line">   <span class="keyword">if</span> bias <span class="keyword">then</span></div><div class="line">      self.bias = torch.Tensor(outputSize)</div><div class="line">      self.gradBias = torch.Tensor(outputSize)</div><div class="line">   <span class="keyword">end</span></div><div class="line">   self:reset()</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:noBias</span><span class="params">()</span></span></div><div class="line">   self.bias = <span class="keyword">nil</span></div><div class="line">   self.gradBias = <span class="keyword">nil</span></div><div class="line">   <span class="keyword">return</span> self</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:reset</span><span class="params">(stdv)</span></span></div><div class="line">   <span class="keyword">if</span> stdv <span class="keyword">then</span></div><div class="line">      stdv = stdv * <span class="built_in">math</span>.sqrt(<span class="number">3</span>)</div><div class="line">   <span class="keyword">else</span></div><div class="line">      stdv = <span class="number">1.</span>/<span class="built_in">math</span>.sqrt(self.weight:size(<span class="number">2</span>))</div><div class="line">   <span class="keyword">end</span></div><div class="line">   <span class="keyword">if</span> nn.oldSeed <span class="keyword">then</span></div><div class="line">      <span class="keyword">for</span> i=<span class="number">1</span>,self.weight:size(<span class="number">1</span>) <span class="keyword">do</span></div><div class="line">         self.weight:<span class="built_in">select</span>(<span class="number">1</span>, i):apply(<span class="function"><span class="keyword">function</span><span class="params">()</span></span></div><div class="line">            <span class="keyword">return</span> torch.uniform(-stdv, stdv)</div><div class="line">         <span class="keyword">end</span>)</div><div class="line">      <span class="keyword">end</span></div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span></div><div class="line">         <span class="keyword">for</span> i=<span class="number">1</span>,self.bias:nElement() <span class="keyword">do</span></div><div class="line">            self.bias[i] = torch.uniform(-stdv, stdv)</div><div class="line">         <span class="keyword">end</span></div><div class="line">      <span class="keyword">end</span></div><div class="line">   <span class="keyword">else</span></div><div class="line">      self.weight:uniform(-stdv, stdv)</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span> self.bias:uniform(-stdv, stdv) <span class="keyword">end</span></div><div class="line">   <span class="keyword">end</span></div><div class="line">   <span class="keyword">return</span> self</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">updateAddBuffer</span><span class="params">(self, input)</span></span></div><div class="line">   <span class="keyword">local</span> nframe = input:size(<span class="number">1</span>)</div><div class="line">   self.addBuffer = self.addBuffer <span class="keyword">or</span> input.new()</div><div class="line">   <span class="keyword">if</span> self.addBuffer:nElement() ~= nframe <span class="keyword">then</span></div><div class="line">      self.addBuffer:resize(nframe):fill(<span class="number">1</span>)</div><div class="line">   <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:updateOutput</span><span class="params">(input)</span></span></div><div class="line">   <span class="keyword">if</span> input:dim() == <span class="number">1</span> <span class="keyword">then</span></div><div class="line">      self.output:resize(self.weight:size(<span class="number">1</span>))</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span> self.output:copy(self.bias) <span class="keyword">else</span> self.output:zero() <span class="keyword">end</span></div><div class="line">      self.output:addmv(<span class="number">1</span>, self.weight, input)</div><div class="line">   <span class="keyword">elseif</span> input:dim() == <span class="number">2</span> <span class="keyword">then</span></div><div class="line">      <span class="keyword">local</span> nframe = input:size(<span class="number">1</span>)</div><div class="line">      <span class="keyword">local</span> nElement = self.output:nElement()</div><div class="line">      self.output:resize(nframe, self.weight:size(<span class="number">1</span>))</div><div class="line">      <span class="keyword">if</span> self.output:nElement() ~= nElement <span class="keyword">then</span></div><div class="line">         self.output:zero()</div><div class="line">      <span class="keyword">end</span></div><div class="line">      updateAddBuffer(self, input)</div><div class="line">      self.output:addmm(<span class="number">0</span>, self.output, <span class="number">1</span>, input, self.weight:t())</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span> self.output:addr(<span class="number">1</span>, self.addBuffer, self.bias) <span class="keyword">end</span></div><div class="line">   <span class="keyword">else</span></div><div class="line">      <span class="built_in">error</span>(<span class="string">'input must be vector or matrix'</span>)</div><div class="line">   <span class="keyword">end</span></div><div class="line"></div><div class="line">   <span class="keyword">return</span> self.output</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:updateGradInput</span><span class="params">(input, gradOutput)</span></span></div><div class="line">   <span class="keyword">if</span> self.gradInput <span class="keyword">then</span></div><div class="line"></div><div class="line">      <span class="keyword">local</span> nElement = self.gradInput:nElement()</div><div class="line">      self.gradInput:resizeAs(input)</div><div class="line">      <span class="keyword">if</span> self.gradInput:nElement() ~= nElement <span class="keyword">then</span></div><div class="line">         self.gradInput:zero()</div><div class="line">      <span class="keyword">end</span></div><div class="line">      <span class="keyword">if</span> input:dim() == <span class="number">1</span> <span class="keyword">then</span></div><div class="line">         self.gradInput:addmv(<span class="number">0</span>, <span class="number">1</span>, self.weight:t(), gradOutput)</div><div class="line">      <span class="keyword">elseif</span> input:dim() == <span class="number">2</span> <span class="keyword">then</span></div><div class="line">         self.gradInput:addmm(<span class="number">0</span>, <span class="number">1</span>, gradOutput, self.weight)</div><div class="line">      <span class="keyword">end</span></div><div class="line"></div><div class="line">      <span class="keyword">return</span> self.gradInput</div><div class="line">   <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:accGradParameters</span><span class="params">(input, gradOutput, scale)</span></span></div><div class="line">   scale = scale <span class="keyword">or</span> <span class="number">1</span></div><div class="line">   <span class="keyword">if</span> input:dim() == <span class="number">1</span> <span class="keyword">then</span></div><div class="line">      self.gradWeight:addr(scale, gradOutput, input)</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span> self.gradBias:add(scale, gradOutput) <span class="keyword">end</span></div><div class="line">   <span class="keyword">elseif</span> input:dim() == <span class="number">2</span> <span class="keyword">then</span></div><div class="line">      self.gradWeight:addmm(scale, gradOutput:t(), input)</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span></div><div class="line">         <span class="comment">-- update the size of addBuffer if the input is not the same size as the one we had in last updateGradInput</span></div><div class="line">         updateAddBuffer(self, input)</div><div class="line">         self.gradBias:addmv(scale, gradOutput:t(), self.addBuffer)</div><div class="line">      <span class="keyword">end</span></div><div class="line">   <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:sharedAccUpdateGradParameters</span><span class="params">(input, gradOutput, lr)</span></span></div><div class="line">   <span class="comment">-- we do not need to accumulate parameters when sharing:</span></div><div class="line">   self:defaultAccUpdateGradParameters(input, gradOutput, lr)</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:clearState</span><span class="params">()</span></span></div><div class="line">   <span class="keyword">if</span> self.addBuffer <span class="keyword">then</span> self.addBuffer:set() <span class="keyword">end</span></div><div class="line">   <span class="keyword">return</span> parent.clearState(self)</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:__tostring__</span><span class="params">()</span></span></div><div class="line">  <span class="keyword">return</span> torch.<span class="built_in">type</span>(self) ..</div><div class="line">      <span class="built_in">string</span>.format(<span class="string">'(%d -&gt; %d)'</span>, self.weight:size(<span class="number">2</span>), self.weight:size(<span class="number">1</span>)) ..</div><div class="line">      (self.bias == <span class="keyword">nil</span> <span class="keyword">and</span> <span class="string">' without bias'</span> <span class="keyword">or</span> <span class="string">''</span>)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>Tons of built-in modules and loss functions</p><p><a href="https://github.com/torch/nn" target="_blank" rel="external">https://github.com/torch/nn</a></p><h4 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h4><p>Container modules allow you to combine multiple modules</p><h3 id="nngraph"><a href="#nngraph" class="headerlink" title="nngraph"></a>nngraph</h3><p>A multi-layer network where each layer takes output of previous two layers as input.</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">input = nn.Identity()()</div><div class="line">L1 = nn.Tanh()(nn.Linear(<span class="number">10</span>, <span class="number">20</span>)(input))</div><div class="line">L2 = nn.Tanh()(nn.Linear(<span class="number">30</span>, <span class="number">60</span>)(nn.JoinTable(<span class="number">1</span>)(&#123;input, L1&#125;)))</div><div class="line">L3 = nn.Tanh()(nn.Linear(<span class="number">80</span>, <span class="number">160</span>)(nn.JoinTable(<span class="number">1</span>)(&#123;L1, L2&#125;)))</div><div class="line"></div><div class="line">g = nn.gModule(&#123;input&#125;, &#123;L3&#125;)</div><div class="line"></div><div class="line">indata = torch.rand(<span class="number">10</span>)</div><div class="line">gdata = torch.rand(<span class="number">160</span>)</div><div class="line">g:forward(indata)</div><div class="line">g:backward(indata, gdata)</div><div class="line"></div><div class="line">graph.dot(g.fg, <span class="string">'Forward Graph'</span>)</div><div class="line">graph.dot(g.bg, <span class="string">'Backward Graph'</span>)</div></pre></td></tr></table></figure><p><a href="https://github.com/torch/nngraph" target="_blank" rel="external">More Info</a></p><h3 id="Pretrained-Models"><a href="#Pretrained-Models" class="headerlink" title="Pretrained Models"></a>Pretrained Models</h3><ul><li>loadcaffe: Load pretrained Caffe models: AlexNet, VGG, some others<ul><li><a href="https://github.com/szagoruyko/loadcaffe" target="_blank" rel="external">https://github.com/szagoruyko/loadcaffe</a></li></ul></li><li>GoogLeNet v1: <a href="https://github.com/soumith/inception.torch" target="_blank" rel="external">https://github.com/soumith/inception.torch</a></li><li>GoogLeNet v3: <a href="https://github.com/Moodstocks/inception-v3.torch" target="_blank" rel="external">https://github.com/Moodstocks/inception-v3.torch</a></li><li>ResNet: <a href="https://github.com/facebook/fb.resnet.torch" target="_blank" rel="external">https://github.com/facebook/fb.resnet.torch</a></li></ul><h3 id="Package-Management"><a href="#Package-Management" class="headerlink" title="Package Management"></a>Package Management</h3><p>After installing torch, use luarocks to install or update Lua packages</p><p>(Similar to pip install from Python)</p><h3 id="Other-useful-packages"><a href="#Other-useful-packages" class="headerlink" title="Other useful packages"></a>Other useful packages</h3><ul><li>torch.cudnn: Bindings for NVIDIA cuDNN kernels<ul><li><a href="https://github.com/soumith/cudnn.torch" target="_blank" rel="external">https://github.com/soumith/cudnn.torch</a></li></ul></li><li>torch-hdf5: Read and write HDF5 files from Torch<ul><li><a href="https://github.com/deepmind/torch-hdf5" target="_blank" rel="external">https://github.com/deepmind/torch-hdf5</a></li></ul></li><li>lua-cjson: Read and write JSON files from Lua<ul><li><a href="https://luarocks.org/modules/luarocks/lua-cjson" target="_blank" rel="external">https://luarocks.org/modules/luarocks/lua-cjson</a></li></ul></li><li>cltorch, clnn: OpenCL backend for Torch, and port of nn<ul><li><a href="https://github.com/hughperkins/cltorch" target="_blank" rel="external">https://github.com/hughperkins/cltorch</a>, <a href="https://github.com/hughperkins/clnn" target="_blank" rel="external">https://github.com/hughperkins/clnn</a></li></ul></li><li>torch-autograd: Automatic differentiation; sort of like more powerful nngraph, similar to Theano or TensorFlow<ul><li><a href="https://github.com/twitter/torch-autograd" target="_blank" rel="external">https://github.com/twitter/torch-autograd</a></li></ul></li><li>fbcunn: Facebook: FFT conv, multi-GPU (DataParallel, ModelParallel)<ul><li><a href="https://github.com/facebook/fbcunn" target="_blank" rel="external">https://github.com/facebook/fbcunn</a></li></ul></li></ul><h3 id="Typical-Workflow"><a href="#Typical-Workflow" class="headerlink" title="Typical Workflow"></a>Typical Workflow</h3><ol><li>Preprocess data; usually use a Python script to dump data to HDF5</li><li>Train a model in Lua / Torch; read from HDF5 datafile, save trained model to disk</li><li>Use trained model for something, often with an evaluation script</li></ol><p>Example: <a href="https://github.com/jcjohnson/torch-rnn" target="_blank" rel="external">https://github.com/jcjohnson/torch-rnn</a></p><p>Step 1: Preprocess data; usually use a Python script to dump data to HDF5 (<a href="https://github.com/jcjohnson/torch-rnn/blob/master/scripts/preprocess.py" target="_blank" rel="external">https://github.com/jcjohnson/torch-rnn/blob/master/scripts/preprocess.py</a>)<br>Step 2: Train a model in Lua / Torch; read from HDF5 datafile, save trained model to disk (<a href="https://github.com/jcjohnson/torch-rnn/blob/master/train.lua" target="_blank" rel="external">https://github.com/jcjohnson/torch-rnn/blob/master/train.lua</a> )<br>Step 3: Use trained model for something, often with an evaluation script (<a href="https://github.com/jcjohnson/torch-rnn/blob/master/sample.lua" target="_blank" rel="external">https://github.com/jcjohnson/torch-rnn/blob/master/sample.lua</a>)</p><h3 id="Pros-Cons-1"><a href="#Pros-Cons-1" class="headerlink" title="Pros / Cons"></a>Pros / Cons</h3><ul><li>(-) Lua</li><li>(-) Less plug-and-play than Caffe<ul><li>You usually write your own training code</li></ul></li><li>(+) Lots of modular pieces that are easy to combine</li><li>(+) Easy to write your own layer types and run on GPU</li><li>(+) Most of the library code is in Lua, easy to read</li><li>(+) Lots of pretrained models!</li><li>(-) Not great for RNNs</li></ul><h2 id="Theano"><a href="#Theano" class="headerlink" title="Theano"></a>Theano</h2><p><a href="http://deeplearning.net/software/theano/" target="_blank" rel="external">http://deeplearning.net/software/theano/</a></p><h3 id="Overview-2"><a href="#Overview-2" class="headerlink" title="Overview"></a>Overview</h3><ul><li>From Yoshua Bengio’s group at University of Montreal</li><li>Embracing computation graphs, symbolic computation</li><li>High-level wrappers: Keras, Lasagne</li></ul><h3 id="Other-Topics"><a href="#Other-Topics" class="headerlink" title="Other Topics"></a>Other Topics</h3><p><strong>Conditionals</strong>: The <strong>ifelse</strong> and <strong>switch</strong> functions allow conditional control flow in the graph</p><p><strong>Loops</strong>: The <strong>scan</strong> function allows for (some types) of loops in the computational graph; good for RNNs</p><p><strong>Derivatives</strong>: Efficient Jacobian / vector products with R and L operators, symbolic hessians (gradient of gradient)</p><p><strong>Sparse matrices, optimizations, etc</strong></p><h3 id="Multi-GPU"><a href="#Multi-GPU" class="headerlink" title="Multi-GPU"></a>Multi-GPU</h3><p>Experimental model parallelism:<br><a href="http://deeplearning.net/software/theano/tutorial/using_multi_gpu.html" target="_blank" rel="external">http://deeplearning.net/software/theano/tutorial/using_multi_gpu.html</a></p><p>Data parallelism using platoon:<br><a href="https://github.com/mila-udem/platoon" target="_blank" rel="external">https://github.com/mila-udem/platoon</a></p><h3 id="High-level-wrapper"><a href="#High-level-wrapper" class="headerlink" title="High level wrapper"></a>High level wrapper</h3><ul><li>Lasagne</li><li>Keras</li></ul><h3 id="Pretrained-Models-1"><a href="#Pretrained-Models-1" class="headerlink" title="Pretrained Models"></a>Pretrained Models</h3><p><strong>Lasagne Model Zoo</strong> has pretrained common architectures:<br><a href="https://github.com/Lasagne/Recipes/tree/master/modelzoo" target="_blank" rel="external">https://github.com/Lasagne/Recipes/tree/master/modelzoo</a><br><strong>AlexNet with weights</strong>: <a href="https://github.com/uoguelph-mlrg/theano_alexnet" target="_blank" rel="external">https://github.com/uoguelph-mlrg/theano_alexnet</a><br><strong>sklearn-theano</strong>: Run OverFeat and GoogLeNet forward, but no fine-tuning? <a href="http://sklearn-theano.github.io" target="_blank" rel="external">http://sklearn-theano.github.io</a><br><strong>caffe-theano-conversion</strong>: CS 231n project from last year: load models and weights from caffe! Not sure if full-featured <a href="https://github.com/kitofans/caffe-theano-conversion" target="_blank" rel="external">https://github.com/kitofans/caffe-theano-conversion</a></p><h3 id="Pros-Cons-2"><a href="#Pros-Cons-2" class="headerlink" title="Pros / Cons"></a>Pros / Cons</h3><ul><li>(+) Python + numpy</li><li>(+) Computational graph is nice abstraction</li><li>(+) RNNs fit nicely in computational graph</li><li>(-) Raw Theano is somewhat low-level</li><li>(+) High level wrappers (Keras, Lasagne) ease the pain</li><li>(-) Error messages can be unhelpful</li><li>(-) Large models can have long compile times</li><li>(-) Much “fatter” than Torch; more magic</li><li>(-) Patchy support for pretrained models</li></ul><h2 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h2><p><a href="https://www.tensorflow.org" target="_blank" rel="external">https://www.tensorflow.org</a></p><h3 id="Overview-3"><a href="#Overview-3" class="headerlink" title="Overview"></a>Overview</h3><ul><li>From Google</li><li>Very similar to Theano - all about computation graphs</li><li>Easy visualizations (TensorBoard)</li><li>Multi-GPU and multi-node training</li></ul><h3 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h3><p>Tensorboard makes it easy to visualize what’s happening inside your models</p><h3 id="Multi-GPU-1"><a href="#Multi-GPU-1" class="headerlink" title="Multi-GPU"></a>Multi-GPU</h3><h3 id="Distributed"><a href="#Distributed" class="headerlink" title="Distributed"></a>Distributed</h3><h3 id="Pretrained-Models-2"><a href="#Pretrained-Models-2" class="headerlink" title="Pretrained Models"></a>Pretrained Models</h3><p>You can get a pretrained version of Inception here:<br><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md" target="_blank" rel="external">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md</a></p><p>(In an Android example?? Very well-hidden)</p><p>The only one I could find =(</p><h3 id="Pros-Cons-3"><a href="#Pros-Cons-3" class="headerlink" title="Pros / Cons"></a>Pros / Cons</h3><ul><li>(+) Python + numpy</li><li>(+) Computational graph abstraction, like Theano; great for RNNs</li><li>(+) Much faster compile times than Theano</li><li>(+) Slightly more convenient than raw Theano?</li><li>(+) TensorBoard for visualization</li><li>(+) Data AND model parallelism; best of all frameworks</li><li>(+/-) Distributed models, but not open-source yet</li><li>(-) Slower than other frameworks right now</li><li>(-) Much “fatter” than Torch; more magic</li><li>(-) Not many pretrained models</li></ul><h2 id="Use-Cases"><a href="#Use-Cases" class="headerlink" title="Use Cases"></a>Use Cases</h2><ul><li>Extract AlexNet or VGG features? <strong>Use Caffe</strong></li><li>Fine-tune AlexNet for new classes? <strong>Use Caffe</strong></li><li>Image Captioning with finetuning?<ul><li>-&gt; Need pretrained models (Caffe, Torch, Lasagne)</li><li>-&gt; Need RNNs (Torch or Lasagne)</li><li>-&gt; <strong>Use Torch or Lasagna</strong></li></ul></li><li>Segmentation? (Classify every pixel)<ul><li>-&gt; Need pretrained model (Caffe, Torch, Lasagna)</li><li>-&gt; Need funny loss function</li><li>-&gt; If loss function exists in Caffe: <strong>Use Caffe</strong></li><li>-&gt; If you want to write your own loss: <strong>Use Torch</strong></li></ul></li><li>Object Detection?<ul><li>-&gt; Need pretrained model (Torch, Caffe, Lasagne)</li><li>-&gt; Need lots of custom imperative code (NOT Lasagne)</li><li>-&gt; Use <strong>Caffe + Python</strong> or <strong>Torch</strong></li></ul></li><li>Language modeling with new <strong>RNN</strong> structure?<ul><li>-&gt; Need easy recurrent nets (NOT Caffe, Torch)</li><li>-&gt; No need for pretrained models</li><li>-&gt; <strong>Use Theano or TensorFlow</strong></li></ul></li><li>Implement BatchNorm?<ul><li>-&gt; Don’t want to derive gradient? <strong>Theano</strong> or <strong>TensorFlow</strong></li><li>-&gt; Implement efficient backward pass? <strong>Use Torch</strong></li></ul></li></ul><p><strong>Recommendation</strong>:</p><ul><li>Feature extraction / finetuning existing models: Use Caffe</li><li>Complex uses of pretrained models: Use Lasagne or Torch</li><li>Write your own layers: Use Torch</li><li>Crazy RNNs: Use Theano or Tensorflow</li><li>Huge model, need model parallelism: Use TensorFlow</li></ul></div><div></div><div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/deep-learning/" rel="tag"># deep learning</a> <a href="/tags/machine-learning/" rel="tag"># machine learning</a> <a href="/tags/cs231n/" rel="tag"># cs231n</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/04/11/usr-bin-ld-cannot-find-lxxx-Solutions/" rel="next" title="usr/bin/ld: cannot find -lxxx Solutions"><i class="fa fa-chevron-left"></i> usr/bin/ld: cannot find -lxxx Solutions</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2017/04/16/cs231n-Assignments-2-3/" rel="prev" title="cs231n Assignments [2 & 3]">cs231n Assignments [2 & 3] <i class="fa fa-chevron-right"></i></a></div></div></footer></article><div class="post-spread"><div class="addthis_inline_share_toolbox"><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-58f731508143741d" async></script></div></div></div></div><div class="comments" id="comments"><div id="hypercomments_widget"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">Table of Contents</li><li class="sidebar-nav-overview" data-target="site-overview">Overview</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ewan Li"><p class="site-author-name" itemprop="name">Ewan Li</p><p class="site-description motion-element" itemprop="description">Ewan's IT Blog</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">115</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">58</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/ewanlee" target="_blank" title="Github"><i class="fa fa-fw fa-globe"></i> Github </a></span><span class="links-of-author-item"><a href="http://weibo.com/3946248928/profile?topnav=1&wvr=6" target="_blank" title="Weibo"><i class="fa fa-fw fa-weibo"></i> Weibo</a></span></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Software-Packages"><span class="nav-number">1.</span> <span class="nav-text">Software Packages</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Caffe"><span class="nav-number">1.1.</span> <span class="nav-text">Caffe</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Overview"><span class="nav-number">1.1.1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tip"><span class="nav-number">1.1.2.</span> <span class="nav-text">Tip</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Main-classes"><span class="nav-number">1.1.3.</span> <span class="nav-text">Main classes</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Protocol-Buffers"><span class="nav-number">1.1.4.</span> <span class="nav-text">Protocol Buffers</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Training-Finetuning"><span class="nav-number">1.1.5.</span> <span class="nav-text">Training / Finetuning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Step1-Convert-Data"><span class="nav-number">1.1.5.1.</span> <span class="nav-text">Step1: Convert Data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Step2-Define-Net"><span class="nav-number">1.1.5.2.</span> <span class="nav-text">Step2: Define Net</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Step2-Define-Net-finetuning"><span class="nav-number">1.1.5.3.</span> <span class="nav-text">Step2: Define Net (finetuning)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Step3-Define-Solver"><span class="nav-number">1.1.5.4.</span> <span class="nav-text">Step3: Define Solver</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Step-4-Train"><span class="nav-number">1.1.5.5.</span> <span class="nav-text">Step 4: Train</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-Zoo"><span class="nav-number">1.1.6.</span> <span class="nav-text">Model Zoo</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Python-Interface"><span class="nav-number">1.1.7.</span> <span class="nav-text">Python Interface</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pros-Cons"><span class="nav-number">1.1.8.</span> <span class="nav-text">Pros / Cons</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Torch"><span class="nav-number">1.2.</span> <span class="nav-text">Torch</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Overview-1"><span class="nav-number">1.2.1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lua"><span class="nav-number">1.2.2.</span> <span class="nav-text">Lua</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor"><span class="nav-number">1.2.3.</span> <span class="nav-text">Tensor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#nn"><span class="nav-number">1.2.4.</span> <span class="nav-text">nn</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cunn"><span class="nav-number">1.2.5.</span> <span class="nav-text">cunn</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#optim"><span class="nav-number">1.2.6.</span> <span class="nav-text">optim</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Modules"><span class="nav-number">1.2.7.</span> <span class="nav-text">Modules</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Container"><span class="nav-number">1.2.7.1.</span> <span class="nav-text">Container</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#nngraph"><span class="nav-number">1.2.8.</span> <span class="nav-text">nngraph</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pretrained-Models"><span class="nav-number">1.2.9.</span> <span class="nav-text">Pretrained Models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Package-Management"><span class="nav-number">1.2.10.</span> <span class="nav-text">Package Management</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Other-useful-packages"><span class="nav-number">1.2.11.</span> <span class="nav-text">Other useful packages</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Typical-Workflow"><span class="nav-number">1.2.12.</span> <span class="nav-text">Typical Workflow</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pros-Cons-1"><span class="nav-number">1.2.13.</span> <span class="nav-text">Pros / Cons</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Theano"><span class="nav-number">1.3.</span> <span class="nav-text">Theano</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Overview-2"><span class="nav-number">1.3.1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Other-Topics"><span class="nav-number">1.3.2.</span> <span class="nav-text">Other Topics</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multi-GPU"><span class="nav-number">1.3.3.</span> <span class="nav-text">Multi-GPU</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#High-level-wrapper"><span class="nav-number">1.3.4.</span> <span class="nav-text">High level wrapper</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pretrained-Models-1"><span class="nav-number">1.3.5.</span> <span class="nav-text">Pretrained Models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pros-Cons-2"><span class="nav-number">1.3.6.</span> <span class="nav-text">Pros / Cons</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TensorFlow"><span class="nav-number">1.4.</span> <span class="nav-text">TensorFlow</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Overview-3"><span class="nav-number">1.4.1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensorboard"><span class="nav-number">1.4.2.</span> <span class="nav-text">Tensorboard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multi-GPU-1"><span class="nav-number">1.4.3.</span> <span class="nav-text">Multi-GPU</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distributed"><span class="nav-number">1.4.4.</span> <span class="nav-text">Distributed</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pretrained-Models-2"><span class="nav-number">1.4.5.</span> <span class="nav-text">Pretrained Models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pros-Cons-3"><span class="nav-number">1.4.6.</span> <span class="nav-text">Pros / Cons</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Use-Cases"><span class="nav-number">1.5.</span> <span class="nav-text">Use Cases</span></a></li></ol></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Ewan Li</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user">本站访客数</i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人次</span> <span class="site-pv"><i class="fa fa-eye">本站总访问量</i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">_hcwp=window._hcwp||[],_hcwp.push({widget:"Bloggerstream",widget_id:89825,selector:".hc-comment-count",label:"{%COUNT%}"}),_hcwp.push({widget:"Stream",widget_id:89825,xid:"2017/04/13/cs231n-Software-Packages-notes/"}),function(){if(!("HC_LOAD_INIT"in window)){HC_LOAD_INIT=!0;var e=(navigator.language||navigator.systemLanguage||navigator.userLanguage||"en").substr(0,2).toLowerCase(),t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src=("https:"==document.location.protocol?"https":"http")+"://w.hypercomments.com/widget/hc/89825/"+e+"/widget.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(t,a.nextSibling)}}()</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("e27VKX5tTklQLCtF7iNMmhcA-gzGzoHsz","nnQn2znNgXXEdK7W2bVJ3bfK")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script></body></html>