<!doctype html><html class="theme-next mist use-motion" lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="machine learning,GAN,PyTorch,"><link rel="alternate" href="/atom.xml" title="Abracdabra" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="Source BlogPyTorch Install: http://pytorch.org/The models play two distinct (literally, adversarial) roles. Given some real data set R, G is the generator, trying to create fake data that looks just l"><meta property="og:type" content="article"><meta property="og:title" content="Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)"><meta property="og:url" content="http://yoursite.com/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/index.html"><meta property="og:site_name" content="Abracdabra"><meta property="og:description" content="Source BlogPyTorch Install: http://pytorch.org/The models play two distinct (literally, adversarial) roles. Given some real data set R, G is the generator, trying to create fake data that looks just l"><meta property="og:image" content="https://cdn-images-1.medium.com/max/800/1*-gFsbymY9oJUQJ-A3GTfeg.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/800/1*xsuE-nhsJOzk9lfI3rayuw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/800/1*wuhEVnK25V3zXQzuCwFDAg.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/800/1*NM6wfbhZLSiVnCX33f7eBw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/800/1*5x9hrP5oozp3e2pm-Mtqmw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*MESLBNZIWxJp553TWKUADQ.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*2Qm33RqWBKVF3g1Vg2HnVg.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/800/1*Ary_6gaLxIijk7j2trroBQ.png"><meta property="og:updated_time" content="2017-04-28T11:53:35.942Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)"><meta name="twitter:description" content="Source BlogPyTorch Install: http://pytorch.org/The models play two distinct (literally, adversarial) roles. Given some real data set R, G is the generator, trying to create fake data that looks just l"><meta name="twitter:image" content="https://cdn-images-1.medium.com/max/800/1*-gFsbymY9oJUQJ-A3GTfeg.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post"},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/"><title>Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch) | Abracdabra</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?dc405a79ad500922134d14cdf288f646";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container one-collumn sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Abracdabra</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Do it yourself</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracdabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracdabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-28T19:46:55+08:00">2017-04-28 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/" class="leancloud_visitors" data-flag-title="Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p><a href="https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f" target="_blank" rel="external">Source Blog</a></p><p>PyTorch Install: <a href="http://pytorch.org/" target="_blank" rel="external">http://pytorch.org/</a></p><p>The models play two distinct (literally, <em>adversarial</em>) roles. Given some real data set <strong>R</strong>, <strong>G</strong> is the <em>generator</em>, trying to create fake data that looks just like the genuine data, while <strong>D</strong> is the <em>discriminator</em>, getting data from either the real set or <strong>G </strong>and labeling the difference. Goodfellow’s metaphor (and a fine one it is) was that <strong>G</strong> was like a team of forgers trying to match real paintings with their output, while <strong>D</strong> was the team of detectives trying to tell the difference. (Except that in this case, the forgers <strong>G</strong> never get to see the original data — only the judgments of <strong>D</strong>. They’re like <em>blind</em> forgers.)</p><p><img src="https://cdn-images-1.medium.com/max/800/1*-gFsbymY9oJUQJ-A3GTfeg.png" alt="img"></p><p>In the ideal case, both <strong>D</strong> and <strong>G</strong> would get better over time until <strong>G</strong> had essentially become a “master forger” of the genuine article and <strong>D</strong> was at a loss, “unable to differentiate between the two distributions.”</p><p>In practice, what Goodfellow had shown was that <strong>G</strong> would be able to perform a form of <em>unsupervised learning</em> on the original dataset, finding some way of representing that data in a (possibly) much lower-dimensional manner. And as Yann LeCun famously stated, <a href="https://www.facebook.com/yann.lecun/posts/10153426023477143" target="_blank" rel="external">unsupervised learning is the “cake” of true AI</a>.</p><hr><p>This powerful technique seems like it must require a <strong>metric ton</strong> of code just to get started, right? Nope. Using <a href="http://pytorch.org/" target="_blank" rel="external">PyTorch</a>, we can actually create a very simple GAN in under 50 lines of code. There are really only 5 components to think about:</p><ul><li><strong>R</strong>: The original, genuine data set</li><li><strong>I</strong>: The random noise that goes into the generator as a source of entropy</li><li><strong>G</strong>: The generator which tries to copy/mimic the original data set</li><li><strong>D</strong>: The discriminator which tries to tell apart <strong>G</strong>’s output from <strong>R</strong></li><li>The actual ‘training’ loop where we teach <strong>G</strong> to trick <strong>D</strong> and <strong>D </strong>to <em>beware</em> <strong>G</strong>.</li></ul><p><strong>1.) R</strong>: In our case, we’ll start with the simplest possible <strong>R</strong> — a bell curve. This function takes a mean and a standard deviation and returns a function which provides the right shape of sample data from a Gaussian with those parameters. In our sample code, we’ll use a mean of 4.0 and a standard deviation of 1.25.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*xsuE-nhsJOzk9lfI3rayuw.png" alt="img"></p><p><strong>2.) I</strong>: The input into the generator is also random, but to make our job a little bit harder, let’s use a uniform distribution rather than a normal one. This means that our model <strong>G</strong> can’t simply shift/scale the input to copy <strong>R, </strong>but has to reshape the data in a non-linear way.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*wuhEVnK25V3zXQzuCwFDAg.png" alt="img"></p><p><strong>3.) G</strong>: The generator is a standard feedforward graph — two hidden layers, three linear maps. We’re using an <a href="http://pytorch.org/docs/nn.html#elu" target="_blank" rel="external">ELU (exponential linear unit)</a> because<a href="https://www.linkedin.com/pulse/exponential-linear-units-elu-deep-network-learning-martin-heusel" target="_blank" rel="external">they’re the new black, yo.</a> <strong>G</strong> is going to get the uniformly distributed data samples from <strong>I</strong> and somehow mimic the normally distributed samples from <strong>R</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*NM6wfbhZLSiVnCX33f7eBw.png" alt="img"></p><p><strong>4.) D</strong>: The discriminator code is very similar to <strong>G</strong>’s generator code; a feedforward graph with two hidden layers and three linear maps. It’s going to get samples from either <strong>R</strong> or <strong>G</strong> and will output a single scalar between 0 and 1, interpreted as ‘fake’ vs. ‘real’. This is about as milquetoast as a neural net can get.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*5x9hrP5oozp3e2pm-Mtqmw.png" alt="img"></p><p><strong>5.)</strong> Finally, the training loop alternates between two modes: first training <strong>D</strong> on real data vs. fake data, with <em>accurate</em> labels (think of this as <a href="https://en.wikipedia.org/wiki/Police_Academy_%28film%29" target="_blank" rel="external">Police Academy</a>); and then training <strong>G</strong> to fool <strong>D</strong>, with <em>inaccurate</em> labels (this is more like those preparation montages from <a href="https://en.wikipedia.org/wiki/Ocean%27s_Eleven" target="_blank" rel="external">Ocean’s Eleven</a>). It’s a fight between good and evil, people.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*MESLBNZIWxJp553TWKUADQ.png" alt="img"></p><p>Even if you haven’t seen PyTorch before, you can probably tell what’s going on. In the first (green) section, we push both types of data through <strong>D</strong> and apply a differentiable criterion to <strong>D</strong>’s guesses vs. the actual labels. That pushing is the ‘forward’ step; we then call ‘backward()’ explicitly in order to calculate gradients, which are then used to update <strong>D</strong>’s parameters in the d_optimizer step() call. <strong>G</strong> is used but isn’t trained here.</p><p>Then in the last (red) section, we do the same thing for <strong>G</strong> — note that we also run <strong>G</strong>’s output through <strong>D</strong> (we’re essentially giving the forger a detective to practice on) but we <em>do not optimize or change</em> <strong>D</strong> at this step. We don’t want the detective <strong>D</strong> to learn the wrong labels. Hence, we only call g_optimizer.step().</p><p>And…<em>that’s all</em>. There’s some other boilerplate code but the GAN-specific stuff is just those 5 components, nothing else.</p><hr><p>After a few thousand rounds of this forbidden dance between <strong>D</strong> and <strong>G</strong>, what do we get? The discriminator <strong>D</strong> gets good very quickly (while <strong>G</strong> slowly moves up), but once it gets to a certain level of power, <strong>G</strong> has a worthy adversary and begins to improve. <em>Really</em> improve.</p><p>Over 20,000 training rounds, the mean of <strong>G</strong>’s output overshoots 4.0 but then comes back in a fairly stable, correct range (left). Likewise, the standard deviation initially drops in the wrong direction but then rises up to the desired 1.25 range (right), matching <strong>R</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*2Qm33RqWBKVF3g1Vg2HnVg.png" alt="img"></p><p>Ok, so the basic stats match <strong>R</strong>, eventually. How about the higher moments? Does the shape of the distribution look right? After all, you could certainly have a uniform distribution with a mean of 4.0 and a standard deviation of 1.25, but that wouldn’t really match <strong>R</strong>. Let’s show the final distribution emitted by <strong>G</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*Ary_6gaLxIijk7j2trroBQ.png" alt="img"></p><p>Not bad. The left tail is a bit longer than the right, but the skew and kurtosis are, shall we say, <em>evocative</em> of the original Gaussian.</p><p><strong>G</strong> recovers the original distribution <strong>R</strong> nearly perfectly — and <strong>D</strong> is left cowering in the corner, mumbling to itself, unable to tell fact from fiction. This is <em>precisely</em> the behavior we want (see <a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank" rel="external">Figure 1 in Goodfellow</a>). <strong>From fewer than 50 lines of code</strong>.</p><p>Goodfellow would go on to publish many other papers on GANs, including a <a href="https://arxiv.org/pdf/1606.03498.pdf" target="_blank" rel="external">2016 gem describing some practical improvements</a>, including the minibatch discrimination method adapted here. And <a href="https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks" target="_blank" rel="external">here’s a 2-hour tutorial he presented at NIPS 2016</a>. For TensorFlow users, here’s a parallel <a href="http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/" target="_blank" rel="external">post from Aylien on GANs</a>.</p><p>Ok. Enough talk. <a href="https://github.com/devnag/pytorch-generative-adversarial-networks" target="_blank" rel="external"><strong>Go look at the code</strong></a>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="comment"># Generative Adversarial Networks (GAN) example in PyTorch.</span></div><div class="line"><span class="comment"># See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> torch</div><div class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div><div class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</div><div class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</div><div class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</div><div class="line"></div><div class="line"><span class="comment"># Data params</span></div><div class="line">data_mean = <span class="number">4</span></div><div class="line">data_stddev = <span class="number">1.25</span></div><div class="line"></div><div class="line"><span class="comment"># Model params</span></div><div class="line">g_input_size = <span class="number">1</span>     <span class="comment"># Random noise dimension coming into generator, per output vector</span></div><div class="line">g_hidden_size = <span class="number">50</span>   <span class="comment"># Generator complexity</span></div><div class="line">g_output_size = <span class="number">1</span>    <span class="comment"># size of generated output vector</span></div><div class="line">d_input_size = <span class="number">100</span>   <span class="comment"># Minibatch size - cardinality of distributions</span></div><div class="line">d_hidden_size = <span class="number">50</span>   <span class="comment"># Discriminator complexity</span></div><div class="line">d_output_size = <span class="number">1</span>    <span class="comment"># Single dimension for 'real' vs. 'fake'</span></div><div class="line">minibatch_size = d_input_size</div><div class="line"></div><div class="line">d_learning_rate = <span class="number">2e-4</span>  <span class="comment"># 2e-4</span></div><div class="line">g_learning_rate = <span class="number">2e-4</span></div><div class="line">optim_betas = (<span class="number">0.9</span>, <span class="number">0.999</span>)</div><div class="line">num_epochs = <span class="number">30000</span></div><div class="line">print_interval = <span class="number">200</span></div><div class="line">d_steps = <span class="number">1</span>  <span class="comment"># 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator</span></div><div class="line">g_steps = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># ### Uncomment only one of these</span></div><div class="line"><span class="comment">#(name, preprocess, d_input_func) = ("Raw data", lambda data: data, lambda x: x)</span></div><div class="line">(name, preprocess, d_input_func) = (<span class="string">"Data and variances"</span>, <span class="keyword">lambda</span> data: decorate_with_diffs(data, <span class="number">2.0</span>), <span class="keyword">lambda</span> x: x * <span class="number">2</span>)</div><div class="line"></div><div class="line">print(<span class="string">"Using data [%s]"</span> % (name))</div><div class="line"></div><div class="line"><span class="comment"># ##### DATA: Target data and generator input data</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_distribution_sampler</span><span class="params">(mu, sigma)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> n: torch.Tensor(np.random.normal(mu, sigma, (<span class="number">1</span>, n)))  <span class="comment"># Gaussian</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_generator_input_sampler</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> m, n: torch.rand(m, n)  <span class="comment"># Uniform-dist data into generator, _NOT_ Gaussian</span></div><div class="line"></div><div class="line"><span class="comment"># ##### MODELS: Generator model and discriminator model</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Generator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.sigmoid(self.map2(x))</div><div class="line">        <span class="keyword">return</span> self.map3(x)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Discriminator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.elu(self.map2(x))</div><div class="line">        <span class="keyword">return</span> F.sigmoid(self.map3(x))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract</span><span class="params">(v)</span>:</span></div><div class="line">    <span class="keyword">return</span> v.data.storage().tolist()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stats</span><span class="params">(d)</span>:</span></div><div class="line">    <span class="keyword">return</span> [np.mean(d), np.std(d)]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">decorate_with_diffs</span><span class="params">(data, exponent)</span>:</span></div><div class="line">    mean = torch.mean(data.data, <span class="number">1</span>)</div><div class="line">    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[<span class="number">0</span>][<span class="number">0</span>])</div><div class="line">    diffs = torch.pow(data - Variable(mean_broadcast), exponent)</div><div class="line">    <span class="keyword">return</span> torch.cat([data, diffs], <span class="number">1</span>)</div><div class="line"></div><div class="line">d_sampler = get_distribution_sampler(data_mean, data_stddev)</div><div class="line">gi_sampler = get_generator_input_sampler()</div><div class="line">G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)</div><div class="line">D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)</div><div class="line">criterion = nn.BCELoss()  <span class="comment"># Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss</span></div><div class="line">d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)</div><div class="line">g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)</div><div class="line"></div><div class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</div><div class="line">    <span class="keyword">for</span> d_index <span class="keyword">in</span> range(d_steps):</div><div class="line">        <span class="comment"># 1. Train D on real+fake</span></div><div class="line">        D.zero_grad()</div><div class="line"></div><div class="line">        <span class="comment">#  1A: Train D on real</span></div><div class="line">        d_real_data = Variable(d_sampler(d_input_size))</div><div class="line">        d_real_decision = D(preprocess(d_real_data))</div><div class="line">        d_real_error = criterion(d_real_decision, Variable(torch.ones(<span class="number">1</span>)))  <span class="comment"># ones = true</span></div><div class="line">        d_real_error.backward() <span class="comment"># compute/store gradients, but don't change params</span></div><div class="line"></div><div class="line">        <span class="comment">#  1B: Train D on fake</span></div><div class="line">        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        d_fake_data = G(d_gen_input).detach()  <span class="comment"># detach to avoid training G on these labels</span></div><div class="line">        d_fake_decision = D(preprocess(d_fake_data.t()))</div><div class="line">        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(<span class="number">1</span>)))  <span class="comment"># zeros = fake</span></div><div class="line">        d_fake_error.backward()</div><div class="line">        d_optimizer.step()     <span class="comment"># Only optimizes D's parameters; changes based on stored gradients from backward()</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> g_index <span class="keyword">in</span> range(g_steps):</div><div class="line">        <span class="comment"># 2. Train G on D's response (but DO NOT train D on these labels)</span></div><div class="line">        G.zero_grad()</div><div class="line"></div><div class="line">        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        g_fake_data = G(gen_input)</div><div class="line">        dg_fake_decision = D(preprocess(g_fake_data.t()))</div><div class="line">        g_error = criterion(dg_fake_decision, Variable(torch.ones(<span class="number">1</span>)))  <span class="comment"># we want to fool, so pretend it's all genuine</span></div><div class="line"></div><div class="line">        g_error.backward()</div><div class="line">        g_optimizer.step()  <span class="comment"># Only optimizes G's parameters</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> epoch % print_interval == <span class="number">0</span>:</div><div class="line">        print(<span class="string">"%s: D: %s/%s G: %s (Real: %s, Fake: %s) "</span> % (epoch,</div><div class="line">                                                            extract(d_real_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(d_fake_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(g_error)[<span class="number">0</span>],</div><div class="line">                                                            stats(extract(d_real_data)),</div><div class="line">                                                            stats(extract(d_fake_data))))</div></pre></td></tr></table></figure><p>Result：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div></pre></td><td class="code"><pre><div class="line">ewan<span class="meta">@ubuntu</span>:~<span class="regexp">/Documents/g</span>an/pytorch-generative-adversarial-networks$ python gan_pytorch.py </div><div class="line">Using data [Data and variances]</div><div class="line"><span class="number">0</span>: D: <span class="number">0.636019647121</span>/<span class="number">0.687892377377</span> G: <span class="number">0.692580163479</span> (Real: [<span class="number">4.0121619534492492</span>, <span class="number">1.3228379995364423</span>], Fake: [<span class="number">0.36497069358825684</span>, <span class="number">0.0040907625909989871</span>]) </div><div class="line"><span class="number">200</span>: D: <span class="number">2.92067015835e-05</span>/<span class="number">0.474851727486</span> G: <span class="number">1.00973010063</span> (Real: [<span class="number">4.0935744738578794</span>, <span class="number">1.3016500752040552</span>], Fake: [<span class="number">-0.5716635638475418</span>, <span class="number">0.019948046232028654</span>]) </div><div class="line"><span class="number">400</span>: D: <span class="number">0.0014917049557</span>/<span class="number">0.502498149872</span> G: <span class="number">0.943185687065</span> (Real: [<span class="number">4.198446000814438</span>, <span class="number">1.1262929992527102</span>], Fake: [<span class="number">-0.21786054879426955</span>, <span class="number">0.0067362612730766476</span>]) </div><div class="line"><span class="number">600</span>: D: <span class="number">6.4969262894e-06</span>/<span class="number">0.384293109179</span> G: <span class="number">1.15257537365</span> (Real: [<span class="number">3.8602226501703263</span>, <span class="number">1.3292726136430937</span>], Fake: [<span class="number">-0.29857088595628739</span>, <span class="number">0.03924369275813562</span>]) </div><div class="line"><span class="number">800</span>: D: <span class="number">1.84774467016e-06</span>/<span class="number">0.211148008704</span> G: <span class="number">1.67116880417</span> (Real: [<span class="number">4.0269100540876392</span>, <span class="number">1.2954351206409835</span>], Fake: [<span class="number">-0.32296697288751602</span>, <span class="number">0.14901211840131676</span>]) </div><div class="line"><span class="number">1000</span>: D: <span class="number">9.02455067262e-05</span>/<span class="number">0.0219078511</span> G: <span class="number">4.19585323334</span> (Real: [<span class="number">3.9491306754946707</span>, <span class="number">1.3613105655283608</span>], Fake: [<span class="number">0.13110455054789782</span>, <span class="number">0.5252103421913964</span>]) </div><div class="line"><span class="number">1200</span>: D: <span class="number">0.00441630883142</span>/<span class="number">0.137605398893</span> G: <span class="number">2.78980493546</span> (Real: [<span class="number">4.238747425079346</span>, <span class="number">1.1837142728845262</span>], Fake: [<span class="number">2.3851456820964811</span>, <span class="number">0.69947230698573948</span>]) </div><div class="line"><span class="number">1400</span>: D: <span class="number">0.291683584452</span>/<span class="number">0.824121117592</span> G: <span class="number">0.26126781106</span> (Real: [<span class="number">3.8486315739154815</span>, <span class="number">1.2074486225815622</span>], Fake: [<span class="number">3.4868409335613251</span>, <span class="number">1.2438192602257458</span>]) </div><div class="line"><span class="number">1600</span>: D: <span class="number">0.503275632858</span>/<span class="number">1.08712184429</span> G: <span class="number">0.628099560738</span> (Real: [<span class="number">3.7856648898124696</span>, <span class="number">1.1925325100947208</span>], Fake: [<span class="number">3.9149187129735945</span>, <span class="number">1.5374543372663099</span>]) </div><div class="line"><span class="number">1800</span>: D: <span class="number">0.992162883282</span>/<span class="number">0.955306172371</span> G: <span class="number">0.215137541294</span> (Real: [<span class="number">3.9097139459848402</span>, <span class="number">1.3729001379532129</span>], Fake: [<span class="number">4.9751595187187192</span>, <span class="number">1.2850838287273094</span>]) </div><div class="line"><span class="number">2000</span>: D: <span class="number">0.701098382473</span>/<span class="number">0.634775817394</span> G: <span class="number">0.389043629169</span> (Real: [<span class="number">3.9641699814796447</span>, <span class="number">1.1512756986625183</span>], Fake: [<span class="number">5.0374661159515384</span>, <span class="number">1.5190411587235346</span>]) </div><div class="line"><span class="number">2200</span>: D: <span class="number">0.510353624821</span>/<span class="number">0.350295126438</span> G: <span class="number">1.5988701582</span> (Real: [<span class="number">4.0406568145751951</span>, <span class="number">1.3612318676859239</span>], Fake: [<span class="number">5.4763065743446351</span>, <span class="number">1.2736378899688456</span>]) </div><div class="line"><span class="number">2400</span>: D: <span class="number">0.895085930824</span>/<span class="number">0.400622785091</span> G: <span class="number">0.922062814236</span> (Real: [<span class="number">3.8292097043991089</span>, <span class="number">1.1506111704583193</span>], Fake: [<span class="number">4.5642045128345492</span>, <span class="number">1.7082890861364539</span>]) </div><div class="line"><span class="number">2600</span>: D: <span class="number">0.802581310272</span>/<span class="number">0.717123866081</span> G: <span class="number">0.572393655777</span> (Real: [<span class="number">4.0654918360710148</span>, <span class="number">1.2552944260604222</span>], Fake: [<span class="number">5.1286249160766602</span>, <span class="number">1.0479449058428656</span>]) </div><div class="line"><span class="number">2800</span>: D: <span class="number">0.51098883152</span>/<span class="number">0.489002883434</span> G: <span class="number">0.842381119728</span> (Real: [<span class="number">4.0405197954177856</span>, <span class="number">1.136660175398452</span>], Fake: [<span class="number">3.9549839448928834</span>, <span class="number">1.1751749984899784</span>]) </div><div class="line"><span class="number">3000</span>: D: <span class="number">0.496278882027</span>/<span class="number">0.97537201643</span> G: <span class="number">0.753688693047</span> (Real: [<span class="number">4.0026307255029678</span>, <span class="number">1.2446167315972034</span>], Fake: [<span class="number">3.2340782660245897</span>, <span class="number">1.2949288892421307</span>]) </div><div class="line"><span class="number">3200</span>: D: <span class="number">0.696556508541</span>/<span class="number">0.829834342003</span> G: <span class="number">0.475445389748</span> (Real: [<span class="number">3.9983750417828561</span>, <span class="number">1.2828095340103229</span>], Fake: [<span class="number">3.5434492731094362</span>, <span class="number">0.98673911467128028</span>]) </div><div class="line"><span class="number">3400</span>: D: <span class="number">0.479906737804</span>/<span class="number">0.477254271507</span> G: <span class="number">1.2421528101</span> (Real: [<span class="number">4.1585888534784319</span>, <span class="number">1.2672863214247221</span>], Fake: [<span class="number">3.3173918831348419</span>, <span class="number">1.156708995162234</span>]) </div><div class="line"><span class="number">3600</span>: D: <span class="number">1.36562228203</span>/<span class="number">0.508370876312</span> G: <span class="number">0.550418972969</span> (Real: [<span class="number">4.0406067597866056</span>, <span class="number">1.1363201759386616</span>], Fake: [<span class="number">4.4300824308395388</span>, <span class="number">1.0639278538481793</span>]) </div><div class="line"><span class="number">3800</span>: D: <span class="number">0.538426816463</span>/<span class="number">0.622343420982</span> G: <span class="number">0.786149024963</span> (Real: [<span class="number">4.0097330248355867</span>, <span class="number">1.1609232820569348</span>], Fake: [<span class="number">4.5179304122924808</span>, <span class="number">1.2347411732817635</span>]) </div><div class="line"><span class="number">4000</span>: D: <span class="number">0.350504934788</span>/<span class="number">0.361344873905</span> G: <span class="number">0.728424191475</span> (Real: [<span class="number">3.7975878280401232</span>, <span class="number">1.2378775025626094</span>], Fake: [<span class="number">4.3484812033176423</span>, <span class="number">1.4327683271077338</span>]) </div><div class="line"><span class="number">4200</span>: D: <span class="number">0.912463009357</span>/<span class="number">0.779066801071</span> G: <span class="number">0.840294659138</span> (Real: [<span class="number">3.9861780107021332</span>, <span class="number">1.2293009498211762</span>], Fake: [<span class="number">4.0718169224262235</span>, <span class="number">1.2044778720046834</span>]) </div><div class="line"><span class="number">4400</span>: D: <span class="number">0.814347147942</span>/<span class="number">0.794115483761</span> G: <span class="number">0.889387726784</span> (Real: [<span class="number">3.9556436133384705</span>, <span class="number">1.1131208050960595</span>], Fake: [<span class="number">3.6148070895671847</span>, <span class="number">1.1790021094109027</span>]) </div><div class="line"><span class="number">4600</span>: D: <span class="number">0.637132883072</span>/<span class="number">0.639598190784</span> G: <span class="number">0.835896074772</span> (Real: [<span class="number">4.0807307386398319</span>, <span class="number">1.1590112689981971</span>], Fake: [<span class="number">3.6376679444313051</span>, <span class="number">1.2540016088688517</span>]) </div><div class="line"><span class="number">4800</span>: D: <span class="number">0.816388785839</span>/<span class="number">0.629823803902</span> G: <span class="number">0.6337043643</span> (Real: [<span class="number">4.1595975148677828</span>, <span class="number">1.2996693029809485</span>], Fake: [<span class="number">4.0303308999538423</span>, <span class="number">1.3050560562935769</span>]) </div><div class="line"><span class="number">5000</span>: D: <span class="number">1.38226401806</span>/<span class="number">0.714248239994</span> G: <span class="number">1.17240273952</span> (Real: [<span class="number">3.9217003214359285</span>, <span class="number">1.3408209709046912</span>], Fake: [<span class="number">4.4204820060729979</span>, <span class="number">1.0378887480226417</span>]) </div><div class="line"><span class="number">5200</span>: D: <span class="number">0.752707779408</span>/<span class="number">0.432243227959</span> G: <span class="number">0.735915839672</span> (Real: [<span class="number">4.033863249272108</span>, <span class="number">1.417255801501303</span>], Fake: [<span class="number">3.7434970003366472</span>, <span class="number">1.4305561672741818</span>]) </div><div class="line"><span class="number">5400</span>: D: <span class="number">0.672449588776</span>/<span class="number">0.694190680981</span> G: <span class="number">0.671269893646</span> (Real: [<span class="number">3.9849637061357499</span>, <span class="number">1.3054745436415693</span>], Fake: [<span class="number">3.7987613070011137</span>, <span class="number">1.1584021967574571</span>]) </div><div class="line"><span class="number">5600</span>: D: <span class="number">0.633513212204</span>/<span class="number">0.678804934025</span> G: <span class="number">0.736048042774</span> (Real: [<span class="number">3.8742538380622862</span>, <span class="number">1.1924929483627851</span>], Fake: [<span class="number">4.0905960440635685</span>, <span class="number">1.0496450658176097</span>]) </div><div class="line"><span class="number">5800</span>: D: <span class="number">0.954816102982</span>/<span class="number">0.619474828243</span> G: <span class="number">0.847522497177</span> (Real: [<span class="number">4.0848416697978971</span>, <span class="number">1.2377045321962332</span>], Fake: [<span class="number">4.5059887909889218</span>, <span class="number">1.0769809353783582</span>]) </div><div class="line"><span class="number">6000</span>: D: <span class="number">0.634225904942</span>/<span class="number">0.653471052647</span> G: <span class="number">0.402414888144</span> (Real: [<span class="number">3.9909452509880068</span>, <span class="number">1.2152347623325401</span>], Fake: [<span class="number">3.9412865948677065</span>, <span class="number">1.2808620107297906</span>]) </div><div class="line"><span class="number">6200</span>: D: <span class="number">0.733776032925</span>/<span class="number">0.414616316557</span> G: <span class="number">0.969770550728</span> (Real: [<span class="number">4.0096452310681343</span>, <span class="number">1.2858629342885464</span>], Fake: [<span class="number">3.4776910370588303</span>, <span class="number">1.4216167469252254</span>]) </div><div class="line"><span class="number">6400</span>: D: <span class="number">0.483776688576</span>/<span class="number">0.456314682961</span> G: <span class="number">0.42595911026</span> (Real: [<span class="number">4.16927042722702</span>, <span class="number">1.2557057135387499</span>], Fake: [<span class="number">3.905275868177414</span>, <span class="number">1.3509040440658031</span>]) </div><div class="line"><span class="number">6600</span>: D: <span class="number">1.06177055836</span>/<span class="number">0.443961560726</span> G: <span class="number">0.910483181477</span> (Real: [<span class="number">4.0327691116929056</span>, <span class="number">1.1752792712434861</span>], Fake: [<span class="number">4.1322225379943847</span>, <span class="number">1.3041032842304898</span>]) </div><div class="line"><span class="number">6800</span>: D: <span class="number">0.911615252495</span>/<span class="number">0.851063728333</span> G: <span class="number">0.822307884693</span> (Real: [<span class="number">4.0429812586307525</span>, <span class="number">1.0149434426406105</span>], Fake: [<span class="number">4.181604235172272</span>, <span class="number">1.1091966315801844</span>]) </div><div class="line"><span class="number">7000</span>: D: <span class="number">0.859644412994</span>/<span class="number">0.819373309612</span> G: <span class="number">0.683367550373</span> (Real: [<span class="number">4.0413902151584624</span>, <span class="number">1.2697299173474621</span>], Fake: [<span class="number">3.6461249232292174</span>, <span class="number">1.1392232969008105</span>]) </div><div class="line"><span class="number">7200</span>: D: <span class="number">0.697537004948</span>/<span class="number">1.29639554024</span> G: <span class="number">0.567749083042</span> (Real: [<span class="number">3.9289280462265013</span>, <span class="number">1.1476723124689931</span>], Fake: [<span class="number">4.3612218284606934</span>, <span class="number">1.1698644305174593</span>]) </div><div class="line"><span class="number">7400</span>: D: <span class="number">0.892510712147</span>/<span class="number">0.93148213625</span> G: <span class="number">1.18729686737</span> (Real: [<span class="number">3.9838603484630584</span>, <span class="number">1.10640478112829</span>], Fake: [<span class="number">4.1228645443916321</span>, <span class="number">1.2695625804586594</span>]) </div><div class="line"><span class="number">7600</span>: D: <span class="number">0.855136275291</span>/<span class="number">0.683420717716</span> G: <span class="number">0.87994658947</span> (Real: [<span class="number">4.1161885654926298</span>, <span class="number">1.1923004904972447</span>], Fake: [<span class="number">3.6958885985612868</span>, <span class="number">1.3379389180110717</span>]) </div><div class="line"><span class="number">7800</span>: D: <span class="number">0.549697399139</span>/<span class="number">1.37823116779</span> G: <span class="number">0.398991644382</span> (Real: [<span class="number">4.2173074555397037</span>, <span class="number">1.2371073094023581</span>], Fake: [<span class="number">3.8741448554396629</span>, <span class="number">1.3837623378110455</span>]) </div><div class="line"><span class="number">8000</span>: D: <span class="number">1.35398185253</span>/<span class="number">0.410179078579</span> G: <span class="number">0.527717351913</span> (Real: [<span class="number">3.9588229835033415</span>, <span class="number">1.3744496473744439</span>], Fake: [<span class="number">3.9429207968711855</span>, <span class="number">1.3684983506717674</span>]) </div><div class="line"><span class="number">8200</span>: D: <span class="number">0.700774013996</span>/<span class="number">0.295857429504</span> G: <span class="number">0.803082704544</span> (Real: [<span class="number">3.8515358114242555</span>, <span class="number">1.2566173136350174</span>], Fake: [<span class="number">3.7108538401126863</span>, <span class="number">1.3342916614304938</span>]) </div><div class="line"><span class="number">8400</span>: D: <span class="number">0.689352571964</span>/<span class="number">0.590398311615</span> G: <span class="number">0.698961615562</span> (Real: [<span class="number">3.965521250963211</span>, <span class="number">1.2231963456729893</span>], Fake: [<span class="number">4.6866454958915709</span>, <span class="number">1.1286615282559416</span>]) </div><div class="line"><span class="number">8600</span>: D: <span class="number">0.19632807374</span>/<span class="number">0.604559898376</span> G: <span class="number">0.812706291676</span> (Real: [<span class="number">3.8928249645233155</span>, <span class="number">1.3264703109197318</span>], Fake: [<span class="number">3.918080286383629</span>, <span class="number">1.2016505045193488</span>]) </div><div class="line"><span class="number">8800</span>: D: <span class="number">0.595732450485</span>/<span class="number">0.572122216225</span> G: <span class="number">0.738678693771</span> (Real: [<span class="number">3.7554583859443667</span>, <span class="number">1.2011572644775179</span>], Fake: [<span class="number">3.8252914756536485</span>, <span class="number">1.1905187885079342</span>]) </div><div class="line"><span class="number">9000</span>: D: <span class="number">0.232542961836</span>/<span class="number">1.26930451393</span> G: <span class="number">0.834500789642</span> (Real: [<span class="number">3.9203160056471824</span>, <span class="number">1.2725988502730134</span>], Fake: [<span class="number">4.1613124001026156</span>, <span class="number">1.2681795442466237</span>]) </div><div class="line"><span class="number">9200</span>: D: <span class="number">1.257376194</span>/<span class="number">0.5735257864</span> G: <span class="number">0.554405272007</span> (Real: [<span class="number">3.8860677522420883</span>, <span class="number">1.1041807259307903</span>], Fake: [<span class="number">3.9102136331796644</span>, <span class="number">1.3811967247690093</span>]) </div><div class="line"><span class="number">9400</span>: D: <span class="number">0.610212028027</span>/<span class="number">0.538761377335</span> G: <span class="number">0.558459818363</span> (Real: [<span class="number">4.0015355503559116</span>, <span class="number">0.99711450973270277</span>], Fake: [<span class="number">3.8555663478374482</span>, <span class="number">1.1037480705144518</span>]) </div><div class="line"><span class="number">9600</span>: D: <span class="number">0.702151358128</span>/<span class="number">0.81621837616</span> G: <span class="number">0.706716835499</span> (Real: [<span class="number">4.0513852632045744</span>, <span class="number">1.1984303669025829</span>], Fake: [<span class="number">4.2933621263504032</span>, <span class="number">1.1478353305254103</span>]) </div><div class="line"><span class="number">9800</span>: D: <span class="number">0.511451423168</span>/<span class="number">0.670217812061</span> G: <span class="number">0.873916983604</span> (Real: [<span class="number">3.935146123766899</span>, <span class="number">1.3218541944694313</span>], Fake: [<span class="number">4.2863738107681275</span>, <span class="number">1.1362357473661524</span>]) </div><div class="line"><span class="number">10000</span>: D: <span class="number">0.587130308151</span>/<span class="number">0.764386773109</span> G: <span class="number">0.714644312859</span> (Real: [<span class="number">4.0829932641983033</span>, <span class="number">1.1844677307174318</span>], Fake: [<span class="number">4.2149634605646131</span>, <span class="number">1.1542778585504672</span>]) </div><div class="line"><span class="number">10200</span>: D: <span class="number">0.454408079386</span>/<span class="number">0.390097141266</span> G: <span class="number">0.694087386131</span> (Real: [<span class="number">3.9480907583236693</span>, <span class="number">1.2586832917742197</span>], Fake: [<span class="number">3.9525690937042235</span>, <span class="number">1.3555640918653922</span>]) </div><div class="line"><span class="number">10400</span>: D: <span class="number">0.232991695404</span>/<span class="number">0.377689123154</span> G: <span class="number">0.839949011803</span> (Real: [<span class="number">3.9636431083083155</span>, <span class="number">1.2146210496905581</span>], Fake: [<span class="number">4.0022356742620468</span>, <span class="number">1.0348462356745984</span>]) </div><div class="line"><span class="number">10600</span>: D: <span class="number">0.887756228447</span>/<span class="number">0.452646583319</span> G: <span class="number">0.776298880577</span> (Real: [<span class="number">4.1107078218460087</span>, <span class="number">1.3061081296488184</span>], Fake: [<span class="number">4.3001403945684435</span>, <span class="number">1.3191353715419794</span>]) </div><div class="line"><span class="number">10800</span>: D: <span class="number">0.988030552864</span>/<span class="number">0.472889751196</span> G: <span class="number">2.00703763962</span> (Real: [<span class="number">4.1303015506267551</span>, <span class="number">1.2646447231333668</span>], Fake: [<span class="number">4.2425211107730867</span>, <span class="number">1.2706986066792705</span>]) </div><div class="line"><span class="number">11000</span>: D: <span class="number">0.962553679943</span>/<span class="number">1.00584948063</span> G: <span class="number">0.458068579435</span> (Real: [<span class="number">4.1017441129684444</span>, <span class="number">1.1564779436003478</span>], Fake: [<span class="number">3.861787896156311</span>, <span class="number">1.2478181443952361</span>]) </div><div class="line"><span class="number">11200</span>: D: <span class="number">0.404395908117</span>/<span class="number">0.560545325279</span> G: <span class="number">0.764987766743</span> (Real: [<span class="number">3.8819530367851258</span>, <span class="number">1.1290593525971337</span>], Fake: [<span class="number">4.0393019503355028</span>, <span class="number">1.1760851438968263</span>]) </div><div class="line"><span class="number">11400</span>: D: <span class="number">1.04482722282</span>/<span class="number">0.170368790627</span> G: <span class="number">0.979512214661</span> (Real: [<span class="number">4.0775347077846531</span>, <span class="number">1.1743573984958275</span>], Fake: [<span class="number">4.4076948529481887</span>, <span class="number">1.1430737801156545</span>]) </div><div class="line"><span class="number">11600</span>: D: <span class="number">0.767144262791</span>/<span class="number">0.419019073248</span> G: <span class="number">0.804197788239</span> (Real: [<span class="number">4.1507718646526337</span>, <span class="number">1.2935215526943189</span>], Fake: [<span class="number">4.2565110635757444</span>, <span class="number">1.1195747875890809</span>]) </div><div class="line"><span class="number">11800</span>: D: <span class="number">0.328228145838</span>/<span class="number">0.192100420594</span> G: <span class="number">0.694948136806</span> (Real: [<span class="number">4.2615561389923098</span>, <span class="number">1.3187283101366121</span>], Fake: [<span class="number">3.7841238260269163</span>, <span class="number">1.2796545407667934</span>]) </div><div class="line"><span class="number">12000</span>: D: <span class="number">0.939581632614</span>/<span class="number">0.512252509594</span> G: <span class="number">0.486280798912</span> (Real: [<span class="number">4.1770594882965089</span>, <span class="number">1.2492834466325793</span>], Fake: [<span class="number">4.0997331076860428</span>, <span class="number">1.0701209918243111</span>]) </div><div class="line"><span class="number">12200</span>: D: <span class="number">0.964525461197</span>/<span class="number">0.397465586662</span> G: <span class="number">1.45534229279</span> (Real: [<span class="number">3.9129967219382524</span>, <span class="number">1.3473476671217695</span>], Fake: [<span class="number">4.3561846733093263</span>, <span class="number">1.1667221650406194</span>]) </div><div class="line"><span class="number">12400</span>: D: <span class="number">0.516430974007</span>/<span class="number">0.255626231432</span> G: <span class="number">0.753806650639</span> (Real: [<span class="number">3.9942912605404852</span>, <span class="number">1.3623400447216258</span>], Fake: [<span class="number">4.2171517282724382</span>, <span class="number">1.2046534326031684</span>]) </div><div class="line"><span class="number">12600</span>: D: <span class="number">0.050210531801</span>/<span class="number">0.567070662975</span> G: <span class="number">0.887824892998</span> (Real: [<span class="number">3.9560802054405211</span>, <span class="number">1.3569670682588555</span>], Fake: [<span class="number">3.6434229278564452</span>, <span class="number">1.2798963544271591</span>]) </div><div class="line"><span class="number">12800</span>: D: <span class="number">0.566556215286</span>/<span class="number">1.45121753216</span> G: <span class="number">2.67591071129</span> (Real: [<span class="number">4.0868541407585148</span>, <span class="number">1.1440918337515926</span>], Fake: [<span class="number">3.7308121472597122</span>, <span class="number">1.2567484994327229</span>]) </div><div class="line"><span class="number">13000</span>: D: <span class="number">0.285438686609</span>/<span class="number">1.26493763924</span> G: <span class="number">0.714931368828</span> (Real: [<span class="number">4.0406689298152925</span>, <span class="number">1.2295255598171184</span>], Fake: [<span class="number">4.1976348906755447</span>, <span class="number">1.2778464434389283</span>]) </div><div class="line"><span class="number">13200</span>: D: <span class="number">0.420082330704</span>/<span class="number">0.20268279314</span> G: <span class="number">1.13221895695</span> (Real: [<span class="number">4.0006502330303189</span>, <span class="number">1.1790149224725006</span>], Fake: [<span class="number">4.2336275362968445</span>, <span class="number">1.2803975596845565</span>]) </div><div class="line"><span class="number">13400</span>: D: <span class="number">0.219869300723</span>/<span class="number">0.733704686165</span> G: <span class="number">1.4634616375</span> (Real: [<span class="number">3.8348834168910981</span>, <span class="number">1.240605849665303</span>], Fake: [<span class="number">3.8208065938949587</span>, <span class="number">1.3042463825727604</span>]) </div><div class="line"><span class="number">13600</span>: D: <span class="number">1.35286784172</span>/<span class="number">0.161317944527</span> G: <span class="number">2.29795908928</span> (Real: [<span class="number">4.0841373348236081</span>, <span class="number">1.2295542819596996</span>], Fake: [<span class="number">4.0513113558292391</span>, <span class="number">1.2789595441318489</span>]) </div><div class="line"><span class="number">13800</span>: D: <span class="number">0.188396275043</span>/<span class="number">0.38589566946</span> G: <span class="number">1.38826131821</span> (Real: [<span class="number">4.0228236329555509</span>, <span class="number">1.3524482715610078</span>], Fake: [<span class="number">4.2307587480545044</span>, <span class="number">1.2042737228043698</span>]) </div><div class="line"><span class="number">14000</span>: D: <span class="number">0.0101562952623</span>/<span class="number">0.363918542862</span> G: <span class="number">1.24292945862</span> (Real: [<span class="number">4.0695835274457934</span>, <span class="number">1.4484548400603423</span>], Fake: [<span class="number">4.3588982570171355</span>, <span class="number">1.2305509242343933</span>]) </div><div class="line"><span class="number">14200</span>: D: <span class="number">0.308517187834</span>/<span class="number">0.687216579914</span> G: <span class="number">0.831201374531</span> (Real: [<span class="number">4.1314239382743834</span>, <span class="number">1.2039768851618762</span>], Fake: [<span class="number">4.3469831347465515</span>, <span class="number">1.1622408025070994</span>]) </div><div class="line"><span class="number">14400</span>: D: <span class="number">1.05658388138</span>/<span class="number">0.777651846409</span> G: <span class="number">0.713593065739</span> (Real: [<span class="number">3.9307258637249469</span>, <span class="number">1.3932677098843045</span>], Fake: [<span class="number">3.8781710839271546</span>, <span class="number">1.3920662615905985</span>]) </div><div class="line"><span class="number">14600</span>: D: <span class="number">0.428974717855</span>/<span class="number">0.430344074965</span> G: <span class="number">0.865560889244</span> (Real: [<span class="number">4.2443156433105464</span>, <span class="number">1.4786604488020483</span>], Fake: [<span class="number">3.9386759352684022</span>, <span class="number">1.2173706417721266</span>]) </div><div class="line"><span class="number">14800</span>: D: <span class="number">0.358524769545</span>/<span class="number">0.631785154343</span> G: <span class="number">1.72760403156</span> (Real: [<span class="number">4.0897545439004901</span>, <span class="number">1.3611061267905207</span>], Fake: [<span class="number">4.0185626268386843</span>, <span class="number">1.2011546705663261</span>]) </div><div class="line"><span class="number">15000</span>: D: <span class="number">0.451200634241</span>/<span class="number">0.451773911715</span> G: <span class="number">1.10325527191</span> (Real: [<span class="number">3.9933083570003509</span>, <span class="number">1.0881706638388742</span>], Fake: [<span class="number">3.902902855873108</span>, <span class="number">1.1771562868487595</span>]) </div><div class="line"><span class="number">15200</span>: D: <span class="number">0.756480932236</span>/<span class="number">0.419855684042</span> G: <span class="number">0.942300021648</span> (Real: [<span class="number">4.1753564620018002</span>, <span class="number">1.3629881946025171</span>], Fake: [<span class="number">3.8721090507507325</span>, <span class="number">1.189488508024922</span>]) </div><div class="line"><span class="number">15400</span>: D: <span class="number">0.219109147787</span>/<span class="number">0.190036550164</span> G: <span class="number">2.20304942131</span> (Real: [<span class="number">3.9836783826351168</span>, <span class="number">1.4838718408508595</span>], Fake: [<span class="number">3.9491609585285188</span>, <span class="number">1.1700151592543104</span>]) </div><div class="line"><span class="number">15600</span>: D: <span class="number">1.01965582371</span>/<span class="number">0.519556045532</span> G: <span class="number">1.10594069958</span> (Real: [<span class="number">4.1213941669464109</span>, <span class="number">1.2398676800048194</span>], Fake: [<span class="number">4.1908504700660707</span>, <span class="number">1.1195751576139747</span>]) </div><div class="line"><span class="number">15800</span>: D: <span class="number">0.733263611794</span>/<span class="number">0.697221815586</span> G: <span class="number">0.84056687355</span> (Real: [<span class="number">4.0593542096018789</span>, <span class="number">1.1946663317303297</span>], Fake: [<span class="number">4.3031868946552274</span>, <span class="number">1.0306412415157991</span>]) </div><div class="line"><span class="number">16000</span>: D: <span class="number">0.400649875402</span>/<span class="number">0.377974271774</span> G: <span class="number">1.2899967432</span> (Real: [<span class="number">4.0140545344352718</span>, <span class="number">1.2630515897106358</span>], Fake: [<span class="number">4.1656066524982451</span>, <span class="number">1.1779954377184654</span>]) </div><div class="line"><span class="number">16200</span>: D: <span class="number">0.34089872241</span>/<span class="number">0.265896707773</span> G: <span class="number">1.11251270771</span> (Real: [<span class="number">4.0408088731765748</span>, <span class="number">1.3839176416694203</span>], Fake: [<span class="number">4.0593357777595518</span>, <span class="number">1.2213436233279213</span>]) </div><div class="line"><span class="number">16400</span>: D: <span class="number">0.00472234329209</span>/<span class="number">0.513436615467</span> G: <span class="number">1.63225841522</span> (Real: [<span class="number">4.1417997646331788</span>, <span class="number">1.2449733327544124</span>], Fake: [<span class="number">3.7269023895263671</span>, <span class="number">1.1296458384504016</span>]) </div><div class="line"><span class="number">16600</span>: D: <span class="number">0.756382524967</span>/<span class="number">0.66779255867</span> G: <span class="number">0.536718785763</span> (Real: [<span class="number">3.9379871004819869</span>, <span class="number">1.278594816781579</span>], Fake: [<span class="number">3.8750299978256226</span>, <span class="number">1.2829775944385431</span>]) </div><div class="line"><span class="number">16800</span>: D: <span class="number">0.879319548607</span>/<span class="number">0.169020995498</span> G: <span class="number">2.33787298203</span> (Real: [<span class="number">4.2075482982397077</span>, <span class="number">1.3725696551173026</span>], Fake: [<span class="number">3.6744112837314606</span>, <span class="number">1.3225226221432227</span>]) </div><div class="line"><span class="number">17000</span>: D: <span class="number">0.0482731573284</span>/<span class="number">1.43823099136</span> G: <span class="number">1.15067052841</span> (Real: [<span class="number">4.0404629743099214</span>, <span class="number">1.218948521692204</span>], Fake: [<span class="number">4.0387165582180025</span>, <span class="number">1.2794767516999943</span>]) </div><div class="line"><span class="number">17200</span>: D: <span class="number">2.88490628009e-05</span>/<span class="number">0.57872825861</span> G: <span class="number">0.495411038399</span> (Real: [<span class="number">3.9901529085636138</span>, <span class="number">1.4349120434336065</span>], Fake: [<span class="number">4.0573103535175328</span>, <span class="number">1.1918079188127153</span>]) </div><div class="line"><span class="number">17400</span>: D: <span class="number">0.231002807617</span>/<span class="number">1.2511702776</span> G: <span class="number">1.33606302738</span> (Real: [<span class="number">3.7472488379478452</span>, <span class="number">1.1658634335870959</span>], Fake: [<span class="number">3.9354779303073881</span>, <span class="number">1.2931455406139682</span>]) </div><div class="line"><span class="number">17600</span>: D: <span class="number">0.181431129575</span>/<span class="number">0.149175107479</span> G: <span class="number">2.51311731339</span> (Real: [<span class="number">4.1270963573455814</span>, <span class="number">1.312367798822683</span>], Fake: [<span class="number">4.3470913958549495</span>, <span class="number">1.1818067904116243</span>]) </div><div class="line"><span class="number">17800</span>: D: <span class="number">0.830040276051</span>/<span class="number">0.415931969881</span> G: <span class="number">1.57710897923</span> (Real: [<span class="number">3.99146986246109</span>, <span class="number">1.0836663745208763</span>], Fake: [<span class="number">4.3325731372833252</span>, <span class="number">1.266683405420135</span>]) </div><div class="line"><span class="number">18000</span>: D: <span class="number">0.20047518611</span>/<span class="number">0.460676729679</span> G: <span class="number">2.56421780586</span> (Real: [<span class="number">4.3388666504621503</span>, <span class="number">1.3881540592894346</span>], Fake: [<span class="number">3.9820314025878907</span>, <span class="number">1.0436684747098013</span>]) </div><div class="line"><span class="number">18200</span>: D: <span class="number">0.0659740716219</span>/<span class="number">0.428199917078</span> G: <span class="number">0.931035280228</span> (Real: [<span class="number">3.8892200005054476</span>, <span class="number">1.2217018988161374</span>], Fake: [<span class="number">3.8822696304321287</span>, <span class="number">1.304586899060783</span>]) </div><div class="line"><span class="number">18400</span>: D: <span class="number">0.791511416435</span>/<span class="number">0.56503880024</span> G: <span class="number">1.98549497128</span> (Real: [<span class="number">3.7894453473389147</span>, <span class="number">1.3567878969348022</span>], Fake: [<span class="number">4.0909739780426024</span>, <span class="number">1.2361544714927677</span>]) </div><div class="line"><span class="number">18600</span>: D: <span class="number">1.15297484398</span>/<span class="number">0.102882102132</span> G: <span class="number">1.85704553127</span> (Real: [<span class="number">4.2316720616817474</span>, <span class="number">1.2603607958456993</span>], Fake: [<span class="number">3.7415710711479186</span>, <span class="number">1.311454258421634</span>]) </div><div class="line"><span class="number">18800</span>: D: <span class="number">1.06078708172</span>/<span class="number">0.366641134024</span> G: <span class="number">0.914008259773</span> (Real: [<span class="number">3.9394708669185636</span>, <span class="number">1.2924449902046702</span>], Fake: [<span class="number">3.9466111737489702</span>, <span class="number">1.137776845711856</span>]) </div><div class="line"><span class="number">19000</span>: D: <span class="number">0.374139517546</span>/<span class="number">0.448283135891</span> G: <span class="number">0.701639294624</span> (Real: [<span class="number">3.9492650532722475</span>, <span class="number">1.2348435624999976</span>], Fake: [<span class="number">3.7365686148405075</span>, <span class="number">1.215777672310739</span>]) </div><div class="line"><span class="number">19200</span>: D: <span class="number">0.209440857172</span>/<span class="number">0.522395193577</span> G: <span class="number">0.707223057747</span> (Real: [<span class="number">3.8846979635953902</span>, <span class="number">1.2146658434075039</span>], Fake: [<span class="number">4.1696245861053463</span>, <span class="number">1.2979841463522084</span>]) </div><div class="line"><span class="number">19400</span>: D: <span class="number">0.15654887259</span>/<span class="number">0.133351936936</span> G: <span class="number">1.43907415867</span> (Real: [<span class="number">4.0292040088772776</span>, <span class="number">1.2291287794070285</span>], Fake: [<span class="number">3.8498308193683624</span>, <span class="number">1.1121767482065514</span>]) </div><div class="line"><span class="number">19600</span>: D: <span class="number">0.329566717148</span>/<span class="number">0.222448319197</span> G: <span class="number">0.429250627756</span> (Real: [<span class="number">3.7978928279876709</span>, <span class="number">1.1554982239517226</span>], Fake: [<span class="number">3.5122534275054931</span>, <span class="number">1.2462801759237472</span>]) </div><div class="line"><span class="number">19800</span>: D: <span class="number">0.0176634714007</span>/<span class="number">0.480926275253</span> G: <span class="number">0.39424943924</span> (Real: [<span class="number">4.0822606313228604</span>, <span class="number">1.2484518469881001</span>], Fake: [<span class="number">4.5482089626789097</span>, <span class="number">1.1266585202489452</span>]) </div><div class="line"><span class="number">20000</span>: D: <span class="number">0.45860773325</span>/<span class="number">0.517112135887</span> G: <span class="number">0.957448124886</span> (Real: [<span class="number">4.0875282829999922</span>, <span class="number">1.2310698313795749</span>], Fake: [<span class="number">4.2767848205566406</span>, <span class="number">1.1186856033319335</span>]) </div><div class="line"><span class="number">20200</span>: D: <span class="number">1.71172118187</span>/<span class="number">0.240745082498</span> G: <span class="number">0.314642876387</span> (Real: [<span class="number">3.8525538909435273</span>, <span class="number">1.2094100771830765</span>], Fake: [<span class="number">3.6543397814035417</span>, <span class="number">1.2917598911679764</span>]) </div><div class="line"><span class="number">20400</span>: D: <span class="number">0.583434104919</span>/<span class="number">0.703361749649</span> G: <span class="number">1.45571947098</span> (Real: [<span class="number">4.0388400733470915</span>, <span class="number">1.2267253073862441</span>], Fake: [<span class="number">3.9019298100471498</span>, <span class="number">1.0292402192122965</span>]) </div><div class="line"><span class="number">20600</span>: D: <span class="number">0.176266431808</span>/<span class="number">0.55411952734</span> G: <span class="number">0.962469100952</span> (Real: [<span class="number">4.0694609802961352</span>, <span class="number">1.2276659305759301</span>], Fake: [<span class="number">3.9728190612792971</span>, <span class="number">1.1212652107309595</span>]) </div><div class="line"><span class="number">20800</span>: D: <span class="number">1.17427504063</span>/<span class="number">0.212535098195</span> G: <span class="number">0.505771696568</span> (Real: [<span class="number">3.7983859290182589</span>, <span class="number">1.3565768879920506</span>], Fake: [<span class="number">4.0766829651594163</span>, <span class="number">1.1742807548541911</span>]) </div><div class="line"><span class="number">21000</span>: D: <span class="number">0.247546881437</span>/<span class="number">0.242251947522</span> G: <span class="number">2.533826828</span> (Real: [<span class="number">4.048124186992645</span>, <span class="number">1.2074367711533176</span>], Fake: [<span class="number">3.8443934541940687</span>, <span class="number">1.0964556009967605</span>]) </div><div class="line"><span class="number">21200</span>: D: <span class="number">0.000996549613774</span>/<span class="number">1.77280521393</span> G: <span class="number">0.741032421589</span> (Real: [<span class="number">3.8826335191726686</span>, <span class="number">1.3432952882949609</span>], Fake: [<span class="number">4.0052364200353621</span>, <span class="number">1.0658632049377181</span>]) </div><div class="line"><span class="number">21400</span>: D: <span class="number">0.0162861924618</span>/<span class="number">0.202122434974</span> G: <span class="number">0.640827775002</span> (Real: [<span class="number">3.949158318042755</span>, <span class="number">1.2312223613675215</span>], Fake: [<span class="number">3.9677765011787414</span>, <span class="number">1.1984950273079937</span>]) </div><div class="line"><span class="number">21600</span>: D: <span class="number">0.494586825371</span>/<span class="number">0.368914216757</span> G: <span class="number">1.73299539089</span> (Real: [<span class="number">4.2141097390651705</span>, <span class="number">1.3170628249721785</span>], Fake: [<span class="number">3.9259325069189073</span>, <span class="number">1.2402090610341174</span>]) </div><div class="line"><span class="number">21800</span>: D: <span class="number">1.72856020927</span>/<span class="number">0.280478566885</span> G: <span class="number">0.301942139864</span> (Real: [<span class="number">3.9425574642419816</span>, <span class="number">1.3421295277895979</span>], Fake: [<span class="number">4.1370714265108113</span>, <span class="number">1.3135434962232824</span>]) </div><div class="line"><span class="number">22000</span>: D: <span class="number">0.316263616085</span>/<span class="number">0.425417006016</span> G: <span class="number">4.6092467308</span> (Real: [<span class="number">3.9253722500801085</span>, <span class="number">1.1573266813219236</span>], Fake: [<span class="number">3.7590440094470976</span>, <span class="number">1.2176312271677099</span>]) </div><div class="line"><span class="number">22200</span>: D: <span class="number">1.70313096046</span>/<span class="number">0.166758075356</span> G: <span class="number">1.76803898811</span> (Real: [<span class="number">4.1788750314712528</span>, <span class="number">1.3796412025948377</span>], Fake: [<span class="number">4.4896411395072935</span>, <span class="number">0.88890948354147137</span>]) </div><div class="line"><span class="number">22400</span>: D: <span class="number">0.00245383195579</span>/<span class="number">0.618139982224</span> G: <span class="number">0.561835348606</span> (Real: [<span class="number">4.0531666296720505</span>, <span class="number">1.3030890495946361</span>], Fake: [<span class="number">3.9800510057806968</span>, <span class="number">1.2769573713555427</span>]) </div><div class="line"><span class="number">22600</span>: D: <span class="number">0.0456999950111</span>/<span class="number">0.270536243916</span> G: <span class="number">0.719259619713</span> (Real: [<span class="number">3.8036734467744826</span>, <span class="number">1.2489490089903446</span>], Fake: [<span class="number">4.2525720745325089</span>, <span class="number">1.3061806069103183</span>]) </div><div class="line"><span class="number">22800</span>: D: <span class="number">0.0318684391677</span>/<span class="number">0.34651991725</span> G: <span class="number">1.3301807642</span> (Real: [<span class="number">4.0768313544988635</span>, <span class="number">1.2930152979365797</span>], Fake: [<span class="number">4.4993063497543337</span>, <span class="number">1.2277717696258752</span>]) </div><div class="line"><span class="number">23000</span>: D: <span class="number">1.38112533092</span>/<span class="number">0.656377196312</span> G: <span class="number">0.700986683369</span> (Real: [<span class="number">4.0261077487468722</span>, <span class="number">1.1634786009859657</span>], Fake: [<span class="number">4.1274698692560197</span>, <span class="number">1.1909195549188023</span>]) </div><div class="line"><span class="number">23200</span>: D: <span class="number">0.7532761693</span>/<span class="number">0.30048418045</span> G: <span class="number">1.24321329594</span> (Real: [<span class="number">4.0255234652757643</span>, <span class="number">1.2277433432951119</span>], Fake: [<span class="number">4.0463824319839476</span>, <span class="number">1.2493841122917879</span>]) </div><div class="line"><span class="number">23400</span>: D: <span class="number">1.54497790337</span>/<span class="number">0.524266302586</span> G: <span class="number">1.88104653358</span> (Real: [<span class="number">4.1244187545776363</span>, <span class="number">1.2126284333800423</span>], Fake: [<span class="number">4.0199511092901226</span>, <span class="number">1.4125067136876193</span>]) </div><div class="line"><span class="number">23600</span>: D: <span class="number">0.838026106358</span>/<span class="number">1.1139113903</span> G: <span class="number">2.2735543251</span> (Real: [<span class="number">4.0352903008460999</span>, <span class="number">1.1687086536829701</span>], Fake: [<span class="number">4.5685070466995237</span>, <span class="number">1.4508884769834012</span>]) </div><div class="line"><span class="number">23800</span>: D: <span class="number">0.869914472103</span>/<span class="number">0.160864800215</span> G: <span class="number">1.42444908619</span> (Real: [<span class="number">4.1635012495517731</span>, <span class="number">1.1441051019240691</span>], Fake: [<span class="number">4.1520407730340958</span>, <span class="number">1.2022442680490875</span>]) </div><div class="line"><span class="number">24000</span>: D: <span class="number">0.0401677601039</span>/<span class="number">0.240127012134</span> G: <span class="number">1.21359109879</span> (Real: [<span class="number">4.0558859372138976</span>, <span class="number">1.1263029268841764</span>], Fake: [<span class="number">3.8535136532783509</span>, <span class="number">0.99055012605544335</span>]) </div><div class="line"><span class="number">24200</span>: D: <span class="number">0.444084912539</span>/<span class="number">0.761975646019</span> G: <span class="number">1.18176090717</span> (Real: [<span class="number">4.1462872040271757</span>, <span class="number">1.1670976588949802</span>], Fake: [<span class="number">4.0291124176979061</span>, <span class="number">1.4000525541431663</span>]) </div><div class="line"><span class="number">24400</span>: D: <span class="number">0.259448975325</span>/<span class="number">0.206390738487</span> G: <span class="number">0.850725114346</span> (Real: [<span class="number">4.2600694203376772</span>, <span class="number">1.3260391555100224</span>], Fake: [<span class="number">4.7161277580261229</span>, <span class="number">1.3763624799621637</span>]) </div><div class="line"><span class="number">24600</span>: D: <span class="number">0.821855664253</span>/<span class="number">0.381440609694</span> G: <span class="number">0.898442983627</span> (Real: [<span class="number">3.9929001557826997</span>, <span class="number">1.316718033939094</span>], Fake: [<span class="number">3.659836998283863</span>, <span class="number">1.033547623133473</span>]) </div><div class="line"><span class="number">24800</span>: D: <span class="number">0.869792580605</span>/<span class="number">0.143853545189</span> G: <span class="number">1.68244981766</span> (Real: [<span class="number">3.9503055346012115</span>, <span class="number">1.1980136516743376</span>], Fake: [<span class="number">4.3753550618886949</span>, <span class="number">1.4268488751378543</span>]) </div><div class="line"><span class="number">25000</span>: D: <span class="number">0.533834278584</span>/<span class="number">0.944993913174</span> G: <span class="number">1.35653877258</span> (Real: [<span class="number">3.8403973925113677</span>, <span class="number">1.1415226099240794</span>], Fake: [<span class="number">4.3022644245624546</span>, <span class="number">1.277824404897737</span>]) </div><div class="line"><span class="number">25200</span>: D: <span class="number">0.57686984539</span>/<span class="number">1.21011674404</span> G: <span class="number">0.49785476923</span> (Real: [<span class="number">4.1094828593730925</span>, <span class="number">1.0606124114518727</span>], Fake: [<span class="number">3.8350191235542299</span>, <span class="number">1.1822398134788241</span>]) </div><div class="line"><span class="number">25400</span>: D: <span class="number">1.30570268631</span>/<span class="number">0.127069279552</span> G: <span class="number">2.14658904076</span> (Real: [<span class="number">3.8440176880359651</span>, <span class="number">1.2759016439053388</span>], Fake: [<span class="number">4.2303895175457003</span>, <span class="number">1.2478330871411345</span>]) </div><div class="line"><span class="number">25600</span>: D: <span class="number">0.163877904415</span>/<span class="number">0.356351107359</span> G: <span class="number">1.50513041019</span> (Real: [<span class="number">3.9149920016527178</span>, <span class="number">1.3322359586431274</span>], Fake: [<span class="number">4.5107577931880947</span>, <span class="number">1.37733363996175</span>]) </div><div class="line"><span class="number">25800</span>: D: <span class="number">0.0257995054126</span>/<span class="number">0.501479804516</span> G: <span class="number">0.846267580986</span> (Real: [<span class="number">4.0328698861598973</span>, <span class="number">1.0891363228332751</span>], Fake: [<span class="number">4.2062628841400143</span>, <span class="number">1.2707193105443095</span>]) </div><div class="line"><span class="number">26000</span>: D: <span class="number">0.4208984375</span>/<span class="number">0.45090213418</span> G: <span class="number">1.24405300617</span> (Real: [<span class="number">4.0495267909765245</span>, <span class="number">1.3629959211491509</span>], Fake: [<span class="number">3.881335927248001</span>, <span class="number">1.1534035700479874</span>]) </div><div class="line"><span class="number">26200</span>: D: <span class="number">1.0977101326</span>/<span class="number">0.260044932365</span> G: <span class="number">0.274282753468</span> (Real: [<span class="number">4.0526520502567287</span>, <span class="number">1.1354404896569923</span>], Fake: [<span class="number">3.7989616423845289</span>, <span class="number">1.3036229409468019</span>]) </div><div class="line"><span class="number">26400</span>: D: <span class="number">0.836492598057</span>/<span class="number">0.194570705295</span> G: <span class="number">1.25769793987</span> (Real: [<span class="number">4.2580243301391603</span>, <span class="number">1.1229754918621602</span>], Fake: [<span class="number">4.9420129108428954</span>, <span class="number">1.4595622988211396</span>]) </div><div class="line"><span class="number">26600</span>: D: <span class="number">0.0381172671914</span>/<span class="number">0.229116663337</span> G: <span class="number">3.23367476463</span> (Real: [<span class="number">3.9871047949790954</span>, <span class="number">1.2891811878363044</span>], Fake: [<span class="number">5.5130027627944944</span>, <span class="number">1.3531596753079107</span>]) </div><div class="line"><span class="number">26800</span>: D: <span class="number">0.33750808239</span>/<span class="number">0.0588937625289</span> G: <span class="number">2.76632380486</span> (Real: [<span class="number">4.0901136839389798</span>, <span class="number">1.2240984948711151</span>], Fake: [<span class="number">5.9970619964599612</span>, <span class="number">1.3296608494175821</span>]) </div><div class="line"><span class="number">27000</span>: D: <span class="number">0.403919011354</span>/<span class="number">0.025144957006</span> G: <span class="number">5.00026988983</span> (Real: [<span class="number">3.9684947764873506</span>, <span class="number">1.1928812330565042</span>], Fake: [<span class="number">5.5821900677680967</span>, <span class="number">1.5869340992569609</span>]) </div><div class="line"><span class="number">27200</span>: D: <span class="number">1.26118826866</span>/<span class="number">1.14945113659</span> G: <span class="number">0.233536079526</span> (Real: [<span class="number">4.0953157800436024</span>, <span class="number">1.2000917970554563</span>], Fake: [<span class="number">3.457775202393532</span>, <span class="number">1.2362199991432059</span>]) </div><div class="line"><span class="number">27400</span>: D: <span class="number">0.842516124249</span>/<span class="number">0.577941656113</span> G: <span class="number">0.518706798553</span> (Real: [<span class="number">3.8673747038841246</span>, <span class="number">1.1826108239366226</span>], Fake: [<span class="number">3.6999527400732042</span>, <span class="number">1.2050256827670227</span>]) </div><div class="line"><span class="number">27600</span>: D: <span class="number">0.459548681974</span>/<span class="number">0.516558885574</span> G: <span class="number">1.69328427315</span> (Real: [<span class="number">4.0379843235015871</span>, <span class="number">1.267741160236167</span>], Fake: [<span class="number">4.3069088852405546</span>, <span class="number">1.2883256614455194</span>]) </div><div class="line"><span class="number">27800</span>: D: <span class="number">0.757292568684</span>/<span class="number">0.295852422714</span> G: <span class="number">0.82683211565</span> (Real: [<span class="number">3.6750951480865477</span>, <span class="number">1.1881818498282759</span>], Fake: [<span class="number">4.3079475378990173</span>, <span class="number">1.3863961893145142</span>]) </div><div class="line"><span class="number">28000</span>: D: <span class="number">1.0311729908</span>/<span class="number">0.836829304695</span> G: <span class="number">0.54562240839</span> (Real: [<span class="number">3.8109287106990815</span>, <span class="number">1.2699445078581264</span>], Fake: [<span class="number">4.0800623488426204</span>, <span class="number">1.2420579399013889</span>]) </div><div class="line"><span class="number">28200</span>: D: <span class="number">0.662180066109</span>/<span class="number">0.698618113995</span> G: <span class="number">0.430238395929</span> (Real: [<span class="number">3.8820258617401122</span>, <span class="number">1.3192879801078357</span>], Fake: [<span class="number">3.8678512275218964</span>, <span class="number">1.2100339116659864</span>]) </div><div class="line"><span class="number">28400</span>: D: <span class="number">0.857332766056</span>/<span class="number">0.637849986553</span> G: <span class="number">0.443328052759</span> (Real: [<span class="number">4.0044168281555175</span>, <span class="number">1.2977773729964786</span>], Fake: [<span class="number">3.77621297955513</span>, <span class="number">1.10884790779666</span>]) </div><div class="line"><span class="number">28600</span>: D: <span class="number">0.518617451191</span>/<span class="number">0.676390469074</span> G: <span class="number">0.824631929398</span> (Real: [<span class="number">3.9321113193035124</span>, <span class="number">1.189980080467403</span>], Fake: [<span class="number">4.1412628889083862</span>, <span class="number">1.4110153520360829</span>]) </div><div class="line"><span class="number">28800</span>: D: <span class="number">0.924657285213</span>/<span class="number">0.57682287693</span> G: <span class="number">0.867313206196</span> (Real: [<span class="number">3.8806186806410552</span>, <span class="number">1.2663798129949515</span>], Fake: [<span class="number">3.7928846073150635</span>, <span class="number">0.96599856269415929</span>]) </div><div class="line"><span class="number">29000</span>: D: <span class="number">0.681347727776</span>/<span class="number">0.833830595016</span> G: <span class="number">0.880895376205</span> (Real: [<span class="number">4.0122552135586735</span>, <span class="number">1.3382642859979685</span>], Fake: [<span class="number">3.8699622356891634</span>, <span class="number">1.5246898233773196</span>]) </div><div class="line"><span class="number">29200</span>: D: <span class="number">0.690975308418</span>/<span class="number">0.571468651295</span> G: <span class="number">0.539677977562</span> (Real: [<span class="number">3.9422134029865266</span>, <span class="number">1.2798402813873653</span>], Fake: [<span class="number">3.4796924066543578</span>, <span class="number">1.0078584415562459</span>]) </div><div class="line"><span class="number">29400</span>: D: <span class="number">0.600927650928</span>/<span class="number">0.692537486553</span> G: <span class="number">0.785535871983</span> (Real: [<span class="number">4.0494313037395475</span>, <span class="number">1.2729051468200046</span>], Fake: [<span class="number">4.0457676327228542</span>, <span class="number">1.2121629628604733</span>]) </div><div class="line"><span class="number">29600</span>: D: <span class="number">0.662378668785</span>/<span class="number">0.552553355694</span> G: <span class="number">0.665563106537</span> (Real: [<span class="number">3.8692034566402436</span>, <span class="number">1.1988600586203602</span>], Fake: [<span class="number">4.3626180648803707</span>, <span class="number">1.3098951956607312</span>]) </div><div class="line"><span class="number">29800</span>: D: <span class="number">0.844242811203</span>/<span class="number">0.719559967518</span> G: <span class="number">0.89226102829</span> (Real: [<span class="number">3.8751950478553772</span>, <span class="number">1.1053984789259368</span>], Fake: [<span class="number">3.9671442759037019</span>, <span class="number">1.1584875699071935</span>])</div></pre></td></tr></table></figure></div><div></div><div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/machine-learning/" rel="tag"># machine learning</a> <a href="/tags/GAN/" rel="tag"># GAN</a> <a href="/tags/PyTorch/" rel="tag"># PyTorch</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/04/26/LSTM-by-Example-using-Tensorflow-Text-Generate/" rel="next" title="LSTM by Example using Tensorflow (Text Generate)"><i class="fa fa-chevron-left"></i> LSTM by Example using Tensorflow (Text Generate)</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></article><div class="post-spread"><div class="addthis_inline_share_toolbox"><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-58f731508143741d" async></script></div></div></div></div><div class="comments" id="comments"><div id="hypercomments_widget"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ewan Li"><p class="site-author-name" itemprop="name">Ewan Li</p><p class="site-description motion-element" itemprop="description">Ewan's IT Blog</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">52</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">35</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/ewanlee" target="_blank" title="Github"><i class="fa fa-fw fa-globe"></i> Github </a></span><span class="links-of-author-item"><a href="http://weibo.com/3946248928/profile?topnav=1&wvr=6" target="_blank" title="Weibo"><i class="fa fa-fw fa-weibo"></i> Weibo</a></span></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2017</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Ewan Li</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user">本站访客数</i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人次</span> <span class="site-pv"><i class="fa fa-eye">本站总访问量</i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">_hcwp=window._hcwp||[],_hcwp.push({widget:"Bloggerstream",widget_id:89825,selector:".hc-comment-count",label:"{%COUNT%}"}),_hcwp.push({widget:"Stream",widget_id:89825,xid:"2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/"}),function(){if(!("HC_LOAD_INIT"in window)){HC_LOAD_INIT=!0;var e=(navigator.language||navigator.systemLanguage||navigator.userLanguage||"en").substr(0,2).toLowerCase(),t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src=("https:"==document.location.protocol?"https":"http")+"://w.hypercomments.com/widget/hc/89825/"+e+"/widget.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(t,a.nextSibling)}}()</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("e27VKX5tTklQLCtF7iNMmhcA-gzGzoHsz","nnQn2znNgXXEdK7W2bVJ3bfK")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script></body></html>