<!doctype html><html class="theme-next mist use-motion" lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="deep learning,machine learning,GAN,"><link rel="alternate" href="/atom.xml" title="Abracadabra" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210"><meta property="og:type" content="article"><meta property="og:title" content="WGAN implemented by PyTorch"><meta property="og:url" content="http://yoursite.com/2017/04/29/WGAN-implemented-by-PyTorch/index.html"><meta property="og:site_name" content="Abracadabra"><meta property="og:description" content="12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210"><meta property="og:updated_time" content="2017-04-29T15:42:29.191Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="WGAN implemented by PyTorch"><meta name="twitter:description" content="12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post"},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/2017/04/29/WGAN-implemented-by-PyTorch/"><title>WGAN implemented by PyTorch | Abracadabra</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?dc405a79ad500922134d14cdf288f646";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container one-collumn sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Abracadabra</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Do it yourself</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-categories"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/29/WGAN-implemented-by-PyTorch/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline">WGAN implemented by PyTorch</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-29T23:21:33+08:00">2017-04-29 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/29/WGAN-implemented-by-PyTorch/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/29/WGAN-implemented-by-PyTorch/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/29/WGAN-implemented-by-PyTorch/" class="leancloud_visitors" data-flag-title="WGAN implemented by PyTorch"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="comment"># Wasserstein Generative Adversarial Networks (WGAN) example in PyTorch.</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> torch</div><div class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div><div class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</div><div class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</div><div class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</div><div class="line"></div><div class="line"><span class="comment"># Data params</span></div><div class="line">data_mean = <span class="number">4</span></div><div class="line">data_stddev = <span class="number">1.25</span></div><div class="line"></div><div class="line"><span class="comment"># Model params</span></div><div class="line">g_input_size = <span class="number">1</span>     <span class="comment"># Random noise dimension coming into generator, per output vector</span></div><div class="line">g_hidden_size = <span class="number">50</span>   <span class="comment"># Generator complexity</span></div><div class="line">g_output_size = <span class="number">1</span>    <span class="comment"># size of generated output vector</span></div><div class="line">d_input_size = <span class="number">100</span>   <span class="comment"># Minibatch size - cardinality of distributions</span></div><div class="line">d_hidden_size = <span class="number">50</span>   <span class="comment"># Discriminator complexity</span></div><div class="line">d_output_size = <span class="number">1</span>    <span class="comment"># Single dimension for 'real' vs. 'fake'</span></div><div class="line">minibatch_size = d_input_size</div><div class="line"></div><div class="line">d_learning_rate = <span class="number">2e-4</span>  <span class="comment"># 2e-4</span></div><div class="line">g_learning_rate = <span class="number">2e-4</span></div><div class="line"><span class="comment"># optim_betas = (0.9, 0.999)</span></div><div class="line">num_epochs = <span class="number">30000</span></div><div class="line">print_interval = <span class="number">200</span></div><div class="line"><span class="comment"># d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator</span></div><div class="line">d_steps = <span class="number">5</span></div><div class="line">g_steps = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># ### Uncomment only one of these</span></div><div class="line"><span class="comment">#(name, preprocess, d_input_func) = ("Raw data", lambda data: data, lambda x: x)</span></div><div class="line">(name, preprocess, d_input_func) = (<span class="string">"Data and variances"</span>, <span class="keyword">lambda</span> data: decorate_with_diffs(data, <span class="number">2.0</span>), <span class="keyword">lambda</span> x: x * <span class="number">2</span>)</div><div class="line"></div><div class="line">print(<span class="string">"Using data [%s]"</span> % (name))</div><div class="line"></div><div class="line"><span class="comment"># ##### DATA: Target data and generator input data</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_distribution_sampler</span><span class="params">(mu, sigma)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> n: torch.Tensor(np.random.normal(mu, sigma, (<span class="number">1</span>, n)))  <span class="comment"># Gaussian</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_generator_input_sampler</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> m, n: torch.rand(m, n)  <span class="comment"># Uniform-dist data into generator, _NOT_ Gaussian</span></div><div class="line"></div><div class="line"><span class="comment"># ##### MODELS: Generator model and discriminator model</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Generator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.sigmoid(self.map2(x))</div><div class="line">        <span class="keyword">return</span> self.map3(x)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Discriminator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.elu(self.map2(x))</div><div class="line">        <span class="comment"># return F.sigmoid(self.map3(x))</span></div><div class="line">        <span class="keyword">return</span> self.map3(x)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract</span><span class="params">(v)</span>:</span></div><div class="line">    <span class="keyword">return</span> v.data.storage().tolist()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stats</span><span class="params">(d)</span>:</span></div><div class="line">    <span class="keyword">return</span> [np.mean(d), np.std(d)]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">decorate_with_diffs</span><span class="params">(data, exponent)</span>:</span></div><div class="line">    mean = torch.mean(data.data, <span class="number">1</span>)</div><div class="line">    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[<span class="number">0</span>][<span class="number">0</span>])</div><div class="line">    diffs = torch.pow(data - Variable(mean_broadcast), exponent)</div><div class="line">    <span class="keyword">return</span> torch.cat([data, diffs], <span class="number">1</span>)</div><div class="line"></div><div class="line">d_sampler = get_distribution_sampler(data_mean, data_stddev)</div><div class="line">gi_sampler = get_generator_input_sampler()</div><div class="line">G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)</div><div class="line">D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)</div><div class="line"><span class="comment"># criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss</span></div><div class="line"><span class="comment"># d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)</span></div><div class="line"><span class="comment"># g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)</span></div><div class="line">d_optimizer = optim.RMSprop(D.parameters(), lr=d_learning_rate)</div><div class="line">g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate)</div><div class="line"></div><div class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</div><div class="line">    <span class="keyword">for</span> d_index <span class="keyword">in</span> range(d_steps):</div><div class="line">        <span class="comment"># 1. Train D on real+fake</span></div><div class="line">        D.zero_grad()</div><div class="line"></div><div class="line">        <span class="comment">#  1A: Train D on real</span></div><div class="line">        d_real_data = Variable(d_sampler(d_input_size))</div><div class="line">        d_real_decision = D(preprocess(d_real_data))</div><div class="line">        <span class="comment"># d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true</span></div><div class="line">        d_real_error = -torch.mean(d_real_decision)</div><div class="line">        d_real_error.backward() <span class="comment"># compute/store gradients, but don't change params</span></div><div class="line"></div><div class="line">        <span class="comment">#  1B: Train D on fake</span></div><div class="line">        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        d_fake_data = G(d_gen_input).detach()  <span class="comment"># detach to avoid training G on these labels</span></div><div class="line">        d_fake_decision = D(preprocess(d_fake_data.t()))</div><div class="line">        <span class="comment"># d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake</span></div><div class="line">        d_fake_error = torch.mean(d_fake_decision)</div><div class="line">        d_fake_error.backward()</div><div class="line">        d_optimizer.step()     <span class="comment"># Only optimizes D's parameters; changes based on stored gradients from backward()</span></div><div class="line">        <span class="comment"># Weight Clipping</span></div><div class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> D.parameters():</div><div class="line">        	p.data.clamp_(<span class="number">-0.01</span>, <span class="number">0.01</span>)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> g_index <span class="keyword">in</span> range(g_steps):</div><div class="line">        <span class="comment"># 2. Train G on D's response (but DO NOT train D on these labels)</span></div><div class="line">        G.zero_grad()</div><div class="line"></div><div class="line">        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        g_fake_data = G(gen_input)</div><div class="line">        dg_fake_decision = D(preprocess(g_fake_data.t()))</div><div class="line">        <span class="comment"># g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine</span></div><div class="line">        g_error = -torch.mean(dg_fake_decision)</div><div class="line"></div><div class="line">        g_error.backward()</div><div class="line">        g_optimizer.step()  <span class="comment"># Only optimizes G's parameters</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> epoch % print_interval == <span class="number">0</span>:</div><div class="line">        print(<span class="string">"%s: D: %s/%s G: %s (Real: %s, Fake: %s) "</span> % (epoch,</div><div class="line">                                                            extract(d_real_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(d_fake_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(g_error)[<span class="number">0</span>],</div><div class="line">                                                            stats(extract(d_real_data)),</div><div class="line">                                                            stats(extract(d_fake_data))))</div></pre></td></tr></table></figure><p>与<a href="https://ewanlee.github.io/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/" target="_blank" rel="external">之前的文章</a>所做的修改仅仅只有以下几点（理论支持参考我之前转发的一篇<a href="https://ewanlee.github.io/2017/04/29/The-awesome-Wasserstein-GAN/" target="_blank" rel="external">博文</a>）:</p><ul><li><p>判别模型最后一层直接用线型激活函数，而不是用Sigmoid函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Discriminator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.elu(self.map2(x))</div><div class="line">        <span class="comment"># return F.sigmoid(self.map3(x))</span></div><div class="line">        <span class="keyword">return</span> self.map3(x)</div></pre></td></tr></table></figure></li><li><p>生成模型与判别模型的loss函数进行修改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 生成模型</span></div><div class="line"><span class="comment"># d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true</span></div><div class="line">d_real_error = -torch.mean(d_real_decision)</div><div class="line"><span class="comment"># d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake</span></div><div class="line">d_fake_error = torch.mean(d_fake_decision)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 判别模型</span></div><div class="line"><span class="comment"># g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine</span></div><div class="line">g_error = -torch.mean(dg_fake_decision)</div></pre></td></tr></table></figure></li><li><p>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c (这里取的是0.01)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Weight Clipping</span></div><div class="line"><span class="keyword">for</span> p <span class="keyword">in</span> D.parameters():</div><div class="line">    p.data.clamp_(<span class="number">-0.01</span>, <span class="number">0.01</span>)</div></pre></td></tr></table></figure></li><li><p>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)</span></div><div class="line"><span class="comment"># g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)</span></div><div class="line">d_optimizer = optim.RMSprop(D.parameters(), lr=d_learning_rate)</div><div class="line">g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate)</div></pre></td></tr></table></figure><p>​</p></li></ul><p>实验结果如下：</p><a id="more"></a><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div></pre></td><td class="code"><pre><div class="line">ewan<span class="meta">@ubuntu</span>:~<span class="regexp">/Documents/g</span>an/pytorch-generative-adversarial-networks$ python wgan_pytorch.py </div><div class="line">Using data [Data and variances]</div><div class="line"><span class="number">0</span>: D: <span class="number">-0.00291868206114</span>/<span class="number">-0.0098686888814</span> G: <span class="number">0.0101090818644</span> (Real: [<span class="number">3.9948547959327696</span>, <span class="number">1.1746644935894675</span>], Fake: [<span class="number">-0.49681734740734101</span>, <span class="number">0.012067284766516822</span>]) </div><div class="line"><span class="number">200</span>: D: <span class="number">-0.607654631138</span>/<span class="number">0.150195807219</span> G: <span class="number">-0.148662015796</span> (Real: [<span class="number">3.8201908415555952</span>, <span class="number">1.2529761319208725</span>], Fake: [<span class="number">1.3578049659729003</span>, <span class="number">0.068574913818859801</span>]) </div><div class="line"><span class="number">400</span>: D: <span class="number">-0.463035583496</span>/<span class="number">0.187745466828</span> G: <span class="number">-0.199109002948</span> (Real: [<span class="number">3.9679448902606964</span>, <span class="number">1.0966020511088672</span>], Fake: [<span class="number">2.7924281167984009</span>, <span class="number">0.10128610818888226</span>]) </div><div class="line"><span class="number">600</span>: D: <span class="number">-0.195529654622</span>/<span class="number">-0.0762325078249</span> G: <span class="number">0.0709114596248</span> (Real: [<span class="number">4.0289887523651124</span>, <span class="number">1.130490874393266</span>], Fake: [<span class="number">3.2025665378570558</span>, <span class="number">0.11113662831727719</span>]) </div><div class="line"><span class="number">800</span>: D: <span class="number">-0.267909675837</span>/<span class="number">-0.0125531600788</span> G: <span class="number">0.0149036226794</span> (Real: [<span class="number">3.8386318933963777</span>, <span class="number">1.1596351907184081</span>], Fake: [<span class="number">2.9168305301666262</span>, <span class="number">0.18930262941797507</span>]) </div><div class="line"><span class="number">1000</span>: D: <span class="number">-0.305421292782</span>/<span class="number">0.0375043526292</span> G: <span class="number">-0.0430304855108</span> (Real: [<span class="number">4.036220012307167</span>, <span class="number">1.2074152140825467</span>], Fake: [<span class="number">2.980299861431122</span>, <span class="number">0.34328656032877736</span>]) </div><div class="line"><span class="number">1200</span>: D: <span class="number">-0.52364641428</span>/<span class="number">0.34957420826</span> G: <span class="number">-0.336933553219</span> (Real: [<span class="number">4.2644650164060298</span>, <span class="number">1.3088487291781874</span>], Fake: [<span class="number">3.5564545428752901</span>, <span class="number">0.93418534418781807</span>]) </div><div class="line"><span class="number">1400</span>: D: <span class="number">0.0167735591531</span>/<span class="number">-0.0165516249835</span> G: <span class="number">0.0153960846364</span> (Real: [<span class="number">4.005841153860092</span>, <span class="number">1.2205788960289556</span>], Fake: [<span class="number">3.6258796131610871</span>, <span class="number">1.3573166859479273</span>]) </div><div class="line"><span class="number">1600</span>: D: <span class="number">0.00350501108915</span>/<span class="number">-0.0680181980133</span> G: <span class="number">0.0898797661066</span> (Real: [<span class="number">4.0096039956808092</span>, <span class="number">1.3040836884406217</span>], Fake: [<span class="number">4.2868031549453738</span>, <span class="number">1.1195239069375269</span>]) </div><div class="line"><span class="number">1800</span>: D: <span class="number">-0.017161777243</span>/<span class="number">-0.0345846936107</span> G: <span class="number">0.00348377227783</span> (Real: [<span class="number">3.8140131759643556</span>, <span class="number">1.2696980193364791</span>], Fake: [<span class="number">3.6976867783069611</span>, <span class="number">1.3915195404268279</span>]) </div><div class="line"><span class="number">2000</span>: D: <span class="number">0.0342473760247</span>/<span class="number">-0.0408688522875</span> G: <span class="number">0.042895399034</span> (Real: [<span class="number">3.8277990472316743</span>, <span class="number">1.2935257967493754</span>], Fake: [<span class="number">4.0553032100200657</span>, <span class="number">1.0920039067237071</span>]) </div><div class="line"><span class="number">2200</span>: D: <span class="number">-0.0247789677233</span>/<span class="number">-0.0973515734076</span> G: <span class="number">0.0561916455626</span> (Real: [<span class="number">4.0955437314510341</span>, <span class="number">1.3877739508665123</span>], Fake: [<span class="number">4.2196925377845762</span>, <span class="number">1.1830430815754616</span>]) </div><div class="line"><span class="number">2400</span>: D: <span class="number">0.0279140714556</span>/<span class="number">-0.0485894307494</span> G: <span class="number">0.051317743957</span> (Real: [<span class="number">4.1299532175064089</span>, <span class="number">1.2504224526907901</span>], Fake: [<span class="number">3.6290897476673125</span>, <span class="number">1.4143234578612853</span>]) </div><div class="line"><span class="number">2600</span>: D: <span class="number">-0.0277859847993</span>/<span class="number">0.0174758173525</span> G: <span class="number">-0.0226532723755</span> (Real: [<span class="number">4.1205433750152585</span>, <span class="number">1.1041964193630893</span>], Fake: [<span class="number">4.1067905998229977</span>, <span class="number">1.1112897398730086</span>]) </div><div class="line"><span class="number">2800</span>: D: <span class="number">0.0298485141248</span>/<span class="number">-0.0404594913125</span> G: <span class="number">0.0436173528433</span> (Real: [<span class="number">3.8474615824222567</span>, <span class="number">1.376119005659207</span>], Fake: [<span class="number">4.1015409564971925</span>, <span class="number">1.1240560154112995</span>]) </div><div class="line"><span class="number">3000</span>: D: <span class="number">-0.00891616754234</span>/<span class="number">-0.0320432707667</span> G: <span class="number">-0.00200085714459</span> (Real: [<span class="number">4.2869654643535613</span>, <span class="number">1.2452766642692439</span>], Fake: [<span class="number">4.0315418589115142</span>, <span class="number">1.1215360762164166</span>]) </div><div class="line"><span class="number">3200</span>: D: <span class="number">0.125043600798</span>/<span class="number">-0.141845062375</span> G: <span class="number">0.180229827762</span> (Real: [<span class="number">4.1041129958629607</span>, <span class="number">1.2669502216408666</span>], Fake: [<span class="number">3.9350157177448271</span>, <span class="number">1.2041076720740758</span>]) </div><div class="line"><span class="number">3400</span>: D: <span class="number">0.00801010616124</span>/<span class="number">-0.0085571501404</span> G: <span class="number">0.00837498996407</span> (Real: [<span class="number">4.1750692510604859</span>, <span class="number">1.1555020360853467</span>], Fake: [<span class="number">3.7647246885299683</span>, <span class="number">1.3171958013324914</span>]) </div><div class="line"><span class="number">3600</span>: D: <span class="number">-0.0108975172043</span>/<span class="number">0.00422720238566</span> G: <span class="number">0.0679717883468</span> (Real: [<span class="number">4.2474800306558613</span>, <span class="number">1.1525478772018374</span>], Fake: [<span class="number">3.9568253087997438</span>, <span class="number">1.2016376545965635</span>]) </div><div class="line"><span class="number">3800</span>: D: <span class="number">0.174184441566</span>/<span class="number">-0.0896890684962</span> G: <span class="number">0.132265836</span> (Real: [<span class="number">3.6444931725133212</span>, <span class="number">1.4372372290167961</span>], Fake: [<span class="number">4.1011261808872224</span>, <span class="number">1.2724649929743026</span>]) </div><div class="line"><span class="number">4000</span>: D: <span class="number">0.0152352238074</span>/<span class="number">-0.0211527496576</span> G: <span class="number">0.0241769701242</span> (Real: [<span class="number">4.298748409748077</span>, <span class="number">1.2334686924805018</span>], Fake: [<span class="number">3.8711180412769317</span>, <span class="number">1.2375391560481097</span>]) </div><div class="line"><span class="number">4200</span>: D: <span class="number">0.00989393051714</span>/<span class="number">-0.00974932964891</span> G: <span class="number">0.00978021323681</span> (Real: [<span class="number">3.8817882406711579</span>, <span class="number">1.2274675510251392</span>], Fake: [<span class="number">4.4020989084243771</span>, <span class="number">1.1135816847780859</span>]) </div><div class="line"><span class="number">4400</span>: D: <span class="number">0.110887765884</span>/<span class="number">-0.195888444781</span> G: <span class="number">0.185447320342</span> (Real: [<span class="number">4.0501037514209743</span>, <span class="number">1.3391687317184524</span>], Fake: [<span class="number">3.9222843647003174</span>, <span class="number">1.0870922014501809</span>]) </div><div class="line"><span class="number">4600</span>: D: <span class="number">0.0116609586403</span>/<span class="number">0.0201185699552</span> G: <span class="number">-0.0251631941646</span> (Real: [<span class="number">4.097090389728546</span>, <span class="number">1.190104784646782</span>], Fake: [<span class="number">4.0819661796092985</span>, <span class="number">1.3105115963188185</span>]) </div><div class="line"><span class="number">4800</span>: D: <span class="number">0.00524073652923</span>/<span class="number">-0.00464708916843</span> G: <span class="number">0.0057549579069</span> (Real: [<span class="number">3.8242294645309447</span>, <span class="number">1.2650652243397946</span>], Fake: [<span class="number">4.1804288566112522</span>, <span class="number">1.2938617118884317</span>]) </div><div class="line"><span class="number">5000</span>: D: <span class="number">-0.142288714647</span>/<span class="number">0.0809833407402</span> G: <span class="number">-0.128578931093</span> (Real: [<span class="number">3.7870366251468659</span>, <span class="number">1.1074026548781364</span>], Fake: [<span class="number">3.9050006806850432</span>, <span class="number">1.298625653396472</span>]) </div><div class="line"><span class="number">5200</span>: D: <span class="number">0.00282126059756</span>/<span class="number">-0.000789406709373</span> G: <span class="number">0.00220172246918</span> (Real: [<span class="number">3.8225140625238421</span>, <span class="number">1.2743034472730719</span>], Fake: [<span class="number">4.1409763026237485</span>, <span class="number">1.1529764181372026</span>]) </div><div class="line"><span class="number">5400</span>: D: <span class="number">0.0688827335835</span>/<span class="number">-0.143126890063</span> G: <span class="number">0.177940413356</span> (Real: [<span class="number">3.9872682169079781</span>, <span class="number">1.3030584347635661</span>], Fake: [<span class="number">4.1435868382453922</span>, <span class="number">1.1051301998899086</span>]) </div><div class="line"><span class="number">5600</span>: D: <span class="number">-0.0711650624871</span>/<span class="number">0.0871955379844</span> G: <span class="number">-0.134067937732</span> (Real: [<span class="number">3.9407234787940979</span>, <span class="number">1.1742557675838305</span>], Fake: [<span class="number">4.2017855679988863</span>, <span class="number">1.2602829191705458</span>]) </div><div class="line"><span class="number">5800</span>: D: <span class="number">0.000587910413742</span>/<span class="number">0.000934307463467</span> G: <span class="number">0.00103192776442</span> (Real: [<span class="number">4.0573597419261933</span>, <span class="number">1.2623953329979454</span>], Fake: [<span class="number">3.8340791404247283</span>, <span class="number">1.339685454959999</span>]) </div><div class="line"><span class="number">6000</span>: D: <span class="number">0.00821333751082</span>/<span class="number">-0.12042221427</span> G: <span class="number">0.0573511943221</span> (Real: [<span class="number">4.1211176145076749</span>, <span class="number">1.2369626300361085</span>], Fake: [<span class="number">3.6600258636474607</span>, <span class="number">1.3520569881721223</span>]) </div><div class="line"><span class="number">6200</span>: D: <span class="number">0.00682129478082</span>/<span class="number">0.001195830293</span> G: <span class="number">0.00338123179972</span> (Real: [<span class="number">4.0544225633144375</span>, <span class="number">1.2749644040623289</span>], Fake: [<span class="number">4.1039247584342959</span>, <span class="number">1.2693975476155579</span>]) </div><div class="line"><span class="number">6400</span>: D: <span class="number">-0.00134055688977</span>/<span class="number">0.00293467193842</span> G: <span class="number">-0.00249383598566</span> (Real: [<span class="number">4.0987548109889032</span>, <span class="number">1.4076174670922545</span>], Fake: [<span class="number">3.8387181401252746</span>, <span class="number">1.0786043697026602</span>]) </div><div class="line"><span class="number">6600</span>: D: <span class="number">-0.0879130512476</span>/<span class="number">0.00771049968898</span> G: <span class="number">0.0105132861063</span> (Real: [<span class="number">4.0482780200242994</span>, <span class="number">1.3183274437573238</span>], Fake: [<span class="number">4.1890638065338131</span>, <span class="number">1.0659647273618436</span>]) </div><div class="line"><span class="number">6800</span>: D: <span class="number">-0.0613053664565</span>/<span class="number">0.00630968250334</span> G: <span class="number">0.00345144513994</span> (Real: [<span class="number">3.9884191691875457</span>, <span class="number">1.2496578805847449</span>], Fake: [<span class="number">4.0083020174503323</span>, <span class="number">1.1951200826269044</span>]) </div><div class="line"><span class="number">7000</span>: D: <span class="number">-0.00451065413654</span>/<span class="number">0.0126703362912</span> G: <span class="number">-0.0153036154807</span> (Real: [<span class="number">4.1685840785503387</span>, <span class="number">1.0996732796623405</span>], Fake: [<span class="number">3.8199899888038633</span>, <span class="number">1.3533216043161698</span>]) </div><div class="line"><span class="number">7200</span>: D: <span class="number">-0.00164794549346</span>/<span class="number">-0.026672417298</span> G: <span class="number">0.00926311034709</span> (Real: [<span class="number">3.9697488701343535</span>, <span class="number">1.1614389493998623</span>], Fake: [<span class="number">4.0069102811813355</span>, <span class="number">1.332521020789126</span>]) </div><div class="line"><span class="number">7400</span>: D: <span class="number">0.0479753166437</span>/<span class="number">-0.00875021051615</span> G: <span class="number">0.0273390654474</span> (Real: [<span class="number">3.9136831092834474</span>, <span class="number">1.3941734665017038</span>], Fake: [<span class="number">3.9792356503009798</span>, <span class="number">1.2934269648663987</span>]) </div><div class="line"><span class="number">7600</span>: D: <span class="number">0.0299390181899</span>/<span class="number">-0.0244860406965</span> G: <span class="number">0.0235633179545</span> (Real: [<span class="number">3.9529241484403612</span>, <span class="number">1.3003400363613378</span>], Fake: [<span class="number">4.1008431494235991</span>, <span class="number">1.1966721541073959</span>]) </div><div class="line"><span class="number">7800</span>: D: <span class="number">-0.106096304953</span>/<span class="number">-0.00319136725739</span> G: <span class="number">0.0128062078729</span> (Real: [<span class="number">3.8472019118070602</span>, <span class="number">1.3776392180901436</span>], Fake: [<span class="number">3.9847766911983489</span>, <span class="number">1.1441746730859625</span>]) </div><div class="line"><span class="number">8000</span>: D: <span class="number">-0.0541454330087</span>/<span class="number">0.0360651388764</span> G: <span class="number">-0.0368629023433</span> (Real: [<span class="number">4.001156520843506</span>, <span class="number">1.2686070678293795</span>], Fake: [<span class="number">3.7170648825168611</span>, <span class="number">1.2630303399418346</span>]) </div><div class="line"><span class="number">8200</span>: D: <span class="number">0.0385981723666</span>/<span class="number">-0.0308057032526</span> G: <span class="number">0.0258536860347</span> (Real: [<span class="number">4.0773776215314861</span>, <span class="number">1.1340129155680212</span>], Fake: [<span class="number">4.025383379459381</span>, <span class="number">1.327217397616157</span>]) </div><div class="line"><span class="number">8400</span>: D: <span class="number">0.0323679596186</span>/<span class="number">-0.0363558754325</span> G: <span class="number">0.0379030331969</span> (Real: [<span class="number">4.068932784795761</span>, <span class="number">1.1369141540559231</span>], Fake: [<span class="number">3.9889052593708039</span>, <span class="number">1.292853623065962</span>]) </div><div class="line"><span class="number">8600</span>: D: <span class="number">-0.00726405344903</span>/<span class="number">-0.0198955982924</span> G: <span class="number">-0.0463897511363</span> (Real: [<span class="number">4.1387977415323256</span>, <span class="number">1.2983278993502099</span>], Fake: [<span class="number">3.9634271264076233</span>, <span class="number">1.2541944672524785</span>]) </div><div class="line"><span class="number">8800</span>: D: <span class="number">0.0214307252318</span>/<span class="number">-0.0323143824935</span> G: <span class="number">0.0147992642596</span> (Real: [<span class="number">3.8878944924473764</span>, <span class="number">1.2858782523769321</span>], Fake: [<span class="number">3.9738967609405518</span>, <span class="number">1.2617951400969825</span>]) </div><div class="line"><span class="number">9000</span>: D: <span class="number">0.0408670082688</span>/<span class="number">-0.0408971831203</span> G: <span class="number">0.0338222235441</span> (Real: [<span class="number">3.8935359448194502</span>, <span class="number">1.2102182389881371</span>], Fake: [<span class="number">4.1026345968246458</span>, <span class="number">1.1619291320679421</span>]) </div><div class="line"><span class="number">9200</span>: D: <span class="number">0.0334619283676</span>/<span class="number">-0.0487795248628</span> G: <span class="number">0.043896459043</span> (Real: [<span class="number">4.0024692767858507</span>, <span class="number">1.3035652548917089</span>], Fake: [<span class="number">4.2494437253475192</span>, <span class="number">1.1284849306040097</span>]) </div><div class="line"><span class="number">9400</span>: D: <span class="number">-0.0662252604961</span>/<span class="number">0.0567465648055</span> G: <span class="number">-0.0975001305342</span> (Real: [<span class="number">3.9983484780788423</span>, <span class="number">1.2727864024938771</span>], Fake: [<span class="number">4.1652837800979619</span>, <span class="number">1.2757452301144367</span>]) </div><div class="line"><span class="number">9600</span>: D: <span class="number">-0.0437398403883</span>/<span class="number">0.0547546446323</span> G: <span class="number">-0.0755473896861</span> (Real: [<span class="number">3.9568819630146028</span>, <span class="number">1.2089398910557572</span>], Fake: [<span class="number">4.0577589499950406</span>, <span class="number">1.254854081501209</span>]) </div><div class="line"><span class="number">9800</span>: D: <span class="number">0.00763822672889</span>/<span class="number">-0.00536214653403</span> G: <span class="number">0.00614025257528</span> (Real: [<span class="number">4.0391950635612011</span>, <span class="number">1.3067671354062065</span>], Fake: [<span class="number">3.8441065263748171</span>, <span class="number">1.3304282270617658</span>]) </div><div class="line"><span class="number">10000</span>: D: <span class="number">0.0420219749212</span>/<span class="number">-0.000623900443316</span> G: <span class="number">0.0955700650811</span> (Real: [<span class="number">4.0145307508111001</span>, <span class="number">1.2332284552616837</span>], Fake: [<span class="number">4.1720886218547824</span>, <span class="number">1.3184165599194013</span>]) </div><div class="line"><span class="number">10200</span>: D: <span class="number">-0.0580518990755</span>/<span class="number">-0.0247586201876</span> G: <span class="number">0.0602744668722</span> (Real: [<span class="number">3.9131186211109164</span>, <span class="number">1.1547087942243295</span>], Fake: [<span class="number">3.8442363095283509</span>, <span class="number">1.3100046689992075</span>]) </div><div class="line"><span class="number">10400</span>: D: <span class="number">0.0350324884057</span>/<span class="number">-0.0446610674262</span> G: <span class="number">0.0443669557571</span> (Real: [<span class="number">3.9732863992452621</span>, <span class="number">1.0900301299537192</span>], Fake: [<span class="number">4.1616083049774169</span>, <span class="number">1.1977412391369193</span>]) </div><div class="line"><span class="number">10600</span>: D: <span class="number">0.0309124011546</span>/<span class="number">-0.0327286012471</span> G: <span class="number">0.0324002951384</span> (Real: [<span class="number">4.1375643616914752</span>, <span class="number">1.3491791182650394</span>], Fake: [<span class="number">4.1360740911960603</span>, <span class="number">1.2026694938475944</span>]) </div><div class="line"><span class="number">10800</span>: D: <span class="number">0.0251356009394</span>/<span class="number">-0.0600365921855</span> G: <span class="number">0.0182816889137</span> (Real: [<span class="number">3.9463955080509185</span>, <span class="number">1.209152327657528</span>], Fake: [<span class="number">4.0492063975334167</span>, <span class="number">1.1931266255697688</span>]) </div><div class="line"><span class="number">11000</span>: D: <span class="number">-0.0226037632674</span>/<span class="number">0.0645630285144</span> G: <span class="number">-0.00730620510876</span> (Real: [<span class="number">4.0881260240077975</span>, <span class="number">1.1610880829221104</span>], Fake: [<span class="number">4.1015665113925932</span>, <span class="number">1.2508656591000114</span>]) </div><div class="line"><span class="number">11200</span>: D: <span class="number">-0.203874662519</span>/<span class="number">0.129180550575</span> G: <span class="number">-0.137796327472</span> (Real: [<span class="number">3.9598375034332274</span>, <span class="number">1.3812077142172803</span>], Fake: [<span class="number">4.0204527139663693</span>, <span class="number">1.2581185304639424</span>]) </div><div class="line"><span class="number">11400</span>: D: <span class="number">-0.0908113643527</span>/<span class="number">0.0762611478567</span> G: <span class="number">-0.0800914615393</span> (Real: [<span class="number">4.0449822235107424</span>, <span class="number">1.3556268019161497</span>], Fake: [<span class="number">3.6170706963539123</span>, <span class="number">1.2538775159913775</span>]) </div><div class="line"><span class="number">11600</span>: D: <span class="number">0.0127945197746</span>/<span class="number">-0.0136474575847</span> G: <span class="number">0.0115108992904</span> (Real: [<span class="number">3.8434849847108126</span>, <span class="number">1.4191038384690144</span>], Fake: [<span class="number">3.6834572017192841</span>, <span class="number">1.3749317238019667</span>]) </div><div class="line"><span class="number">11800</span>: D: <span class="number">-0.0162955205888</span>/<span class="number">0.00703074596822</span> G: <span class="number">0.0635928660631</span> (Real: [<span class="number">4.0656388866901398</span>, <span class="number">1.1733235519103811</span>], Fake: [<span class="number">4.2119219648838042</span>, <span class="number">1.2884029757138897</span>]) </div><div class="line"><span class="number">12000</span>: D: <span class="number">0.00804834254086</span>/<span class="number">0.0114726442844</span> G: <span class="number">-0.0416676998138</span> (Real: [<span class="number">4.0812106788158413</span>, <span class="number">1.2768383065648503</span>], Fake: [<span class="number">3.8802548873424532</span>, <span class="number">1.1682818121544778</span>]) </div><div class="line"><span class="number">12200</span>: D: <span class="number">0.00880087539554</span>/<span class="number">-0.00853784382343</span> G: <span class="number">0.00878115184605</span> (Real: [<span class="number">3.9501210238039492</span>, <span class="number">1.2609298922930623</span>], Fake: [<span class="number">4.016851776838303</span>, <span class="number">1.1958214043365074</span>]) </div><div class="line"><span class="number">12400</span>: D: <span class="number">-0.0908231809735</span>/<span class="number">0.0565089061856</span> G: <span class="number">-0.0594271346927</span> (Real: [<span class="number">4.2189184671640394</span>, <span class="number">1.2027120432908258</span>], Fake: [<span class="number">4.0232754671573643</span>, <span class="number">1.0601718488768348</span>]) </div><div class="line"><span class="number">12600</span>: D: <span class="number">0.0851941630244</span>/<span class="number">-0.0584048479795</span> G: <span class="number">0.0588090792298</span> (Real: [<span class="number">3.7772543743252753</span>, <span class="number">1.130624908263915</span>], Fake: [<span class="number">3.9319257283210756</span>, <span class="number">1.2051865367836399</span>]) </div><div class="line"><span class="number">12800</span>: D: <span class="number">-0.0560997053981</span>/<span class="number">-0.0248175561428</span> G: <span class="number">-0.0423211455345</span> (Real: [<span class="number">4.1257915179431439</span>, <span class="number">1.3557555020469465</span>], Fake: [<span class="number">3.9178791642189026</span>, <span class="number">1.1446278900771538</span>]) </div><div class="line"><span class="number">13000</span>: D: <span class="number">-0.021879715845</span>/<span class="number">-0.0102085536346</span> G: <span class="number">0.049164660275</span> (Real: [<span class="number">3.8891402572393416</span>, <span class="number">1.340302981622111</span>], Fake: [<span class="number">4.1098264539241791</span>, <span class="number">1.1973190716986095</span>]) </div><div class="line"><span class="number">13200</span>: D: <span class="number">0.00609071925282</span>/<span class="number">0.000411780551076</span> G: <span class="number">0.000873317010701</span> (Real: [<span class="number">4.0079734873771669</span>, <span class="number">1.0734378076269375</span>], Fake: [<span class="number">4.16044829249382</span>, <span class="number">1.24589904041035</span>]) </div><div class="line"><span class="number">13400</span>: D: <span class="number">0.0619652941823</span>/<span class="number">-0.0918542221189</span> G: <span class="number">0.0685269758105</span> (Real: [<span class="number">4.0059312301874161</span>, <span class="number">1.2294789910478197</span>], Fake: [<span class="number">3.935395474433899</span>, <span class="number">1.2204450041984987</span>]) </div><div class="line"><span class="number">13600</span>: D: <span class="number">-0.0172225553542</span>/<span class="number">0.0116953141987</span> G: <span class="number">-0.0139160379767</span> (Real: [<span class="number">3.9669277960062028</span>, <span class="number">1.2823045137798716</span>], Fake: [<span class="number">3.9422059106826781</span>, <span class="number">1.1863138013678882</span>]) </div><div class="line"><span class="number">13800</span>: D: <span class="number">-0.0343380719423</span>/<span class="number">-0.0341883003712</span> G: <span class="number">0.0315745696425</span> (Real: [<span class="number">3.9349321211874484</span>, <span class="number">1.3515663905606217</span>], Fake: [<span class="number">4.0361522984504701</span>, <span class="number">1.1889982801815446</span>]) </div><div class="line"><span class="number">14000</span>: D: <span class="number">-0.0781251713634</span>/<span class="number">0.0379043146968</span> G: <span class="number">-0.0811991766095</span> (Real: [<span class="number">3.9622140777111055</span>, <span class="number">1.3270647840200485</span>], Fake: [<span class="number">3.958692445755005</span>, <span class="number">1.1882249562538854</span>]) </div><div class="line"><span class="number">14200</span>: D: <span class="number">-0.00332566350698</span>/<span class="number">0.00831608474255</span> G: <span class="number">-0.00968919880688</span> (Real: [<span class="number">4.0868309581279751</span>, <span class="number">1.2649052154720533</span>], Fake: [<span class="number">3.9996533656120299</span>, <span class="number">1.2424544463340046</span>]) </div><div class="line"><span class="number">14400</span>: D: <span class="number">0.00310544949025</span>/<span class="number">-0.00344840623438</span> G: <span class="number">0.002937767189</span> (Real: [<span class="number">3.9016156983375549</span>, <span class="number">1.3394072373207904</span>], Fake: [<span class="number">3.8578492951393129</span>, <span class="number">1.2802578210924642</span>]) </div><div class="line"><span class="number">14600</span>: D: <span class="number">0.00954662263393</span>/<span class="number">-0.00955961830914</span> G: <span class="number">0.00952168926597</span> (Real: [<span class="number">3.951248247921467</span>, <span class="number">1.3720542385537113</span>], Fake: [<span class="number">3.9343765902519228</span>, <span class="number">1.3196731296807518</span>]) </div><div class="line"><span class="number">14800</span>: D: <span class="number">-0.118950776756</span>/<span class="number">-0.0234697107226</span> G: <span class="number">-0.0475859940052</span> (Real: [<span class="number">4.224924056529999</span>, <span class="number">1.2198087928062376</span>], Fake: [<span class="number">3.8152624690532684</span>, <span class="number">1.407979253312801</span>]) </div><div class="line"><span class="number">15000</span>: D: <span class="number">-0.0943605676293</span>/<span class="number">0.0735622048378</span> G: <span class="number">-0.104274556041</span> (Real: [<span class="number">3.8776874673366546</span>, <span class="number">1.2303474890793162</span>], Fake: [<span class="number">3.8042025637626646</span>, <span class="number">1.2641632638711853</span>]) </div><div class="line"><span class="number">15200</span>: D: <span class="number">-0.000172574073076</span>/<span class="number">-0.0136091653258</span> G: <span class="number">-0.0342488661408</span> (Real: [<span class="number">3.9725669431686401</span>, <span class="number">1.3636566655582356</span>], Fake: [<span class="number">3.7739255595207215</span>, <span class="number">1.286560381931142</span>]) </div><div class="line"><span class="number">15400</span>: D: <span class="number">0.0314685925841</span>/<span class="number">-0.0321847423911</span> G: <span class="number">0.0224884226918</span> (Real: [<span class="number">3.9619563330709933</span>, <span class="number">1.191049295263032</span>], Fake: [<span class="number">3.7949125266075132</span>, <span class="number">1.144446158701051</span>]) </div><div class="line"><span class="number">15600</span>: D: <span class="number">0.00764724984765</span>/<span class="number">-0.00575984269381</span> G: <span class="number">0.0064948592335</span> (Real: [<span class="number">3.7679578655958177</span>, <span class="number">1.3149928065248815</span>], Fake: [<span class="number">4.2461013138294224</span>, <span class="number">1.0951171764483221</span>]) </div><div class="line"><span class="number">15800</span>: D: <span class="number">-0.0777092948556</span>/<span class="number">0.0849689692259</span> G: <span class="number">-0.0924058929086</span> (Real: [<span class="number">3.932852659225464</span>, <span class="number">1.2573061632959293</span>], Fake: [<span class="number">4.1913282787799835</span>, <span class="number">1.2836186853339466</span>]) </div><div class="line"><span class="number">16000</span>: D: <span class="number">-0.050300322473</span>/<span class="number">-0.0388206243515</span> G: <span class="number">0.0357397347689</span> (Real: [<span class="number">4.0962446802854542</span>, <span class="number">1.4029011906591213</span>], Fake: [<span class="number">4.070586755275726</span>, <span class="number">1.1271350494375147</span>]) </div><div class="line"><span class="number">16200</span>: D: <span class="number">0.0753296241164</span>/<span class="number">-0.0198806431144</span> G: <span class="number">0.0808434784412</span> (Real: [<span class="number">3.8760965394973756</span>, <span class="number">1.1409524988246751</span>], Fake: [<span class="number">3.8057461333274842</span>, <span class="number">1.2098168757605468</span>]) </div><div class="line"><span class="number">16400</span>: D: <span class="number">-0.0372299104929</span>/<span class="number">0.0351875349879</span> G: <span class="number">-0.0454745069146</span> (Real: [<span class="number">4.0939353704452515</span>, <span class="number">1.2848196043395506</span>], Fake: [<span class="number">3.9558720147609709</span>, <span class="number">1.2728235384902225</span>]) </div><div class="line"><span class="number">16600</span>: D: <span class="number">-0.0101340338588</span>/<span class="number">0.0110626723617</span> G: <span class="number">-0.0111222248524</span> (Real: [<span class="number">3.986977145075798</span>, <span class="number">1.3259823635587689</span>], Fake: [<span class="number">3.9554380464553831</span>, <span class="number">1.2907862191410846</span>]) </div><div class="line"><span class="number">16800</span>: D: <span class="number">-0.0494117587805</span>/<span class="number">0.0523075163364</span> G: <span class="number">-0.0535500720143</span> (Real: [<span class="number">3.8448826253414152</span>, <span class="number">1.3117905469567066</span>], Fake: [<span class="number">3.7438095784187317</span>, <span class="number">1.2535150365672076</span>]) </div><div class="line"><span class="number">17000</span>: D: <span class="number">0.0156182665378</span>/<span class="number">-0.0128254238516</span> G: <span class="number">0.0146374739707</span> (Real: [<span class="number">3.9421124708652497</span>, <span class="number">1.1052540236280552</span>], Fake: [<span class="number">3.8871842885017394</span>, <span class="number">1.2453511923222738</span>]) </div><div class="line"><span class="number">17200</span>: D: <span class="number">0.0429224148393</span>/<span class="number">-0.0480623096228</span> G: <span class="number">0.0399292707443</span> (Real: [<span class="number">3.9799196243286135</span>, <span class="number">1.2941615666073001</span>], Fake: [<span class="number">4.1375756561756134</span>, <span class="number">1.2109081564509361</span>]) </div><div class="line"><span class="number">17400</span>: D: <span class="number">0.00968278944492</span>/<span class="number">-0.00968171562999</span> G: <span class="number">0.00966327264905</span> (Real: [<span class="number">3.935849468111992</span>, <span class="number">1.2695645007229639</span>], Fake: [<span class="number">3.8996728241443632</span>, <span class="number">1.3144268300578967</span>]) </div><div class="line"><span class="number">17600</span>: D: <span class="number">-0.00301436148584</span>/<span class="number">-0.000785265117884</span> G: <span class="number">0.00103102996945</span> (Real: [<span class="number">3.9284519279003143</span>, <span class="number">1.2341036313393001</span>], Fake: [<span class="number">3.6972431838512421</span>, <span class="number">1.3855687155856462</span>]) </div><div class="line"><span class="number">17800</span>: D: <span class="number">0.116903491318</span>/<span class="number">-0.0937560945749</span> G: <span class="number">0.172590240836</span> (Real: [<span class="number">4.2645069471001626</span>, <span class="number">1.3080363040531007</span>], Fake: [<span class="number">3.9567726898193358</span>, <span class="number">1.2967345311449683</span>]) </div><div class="line"><span class="number">18000</span>: D: <span class="number">-0.0608675032854</span>/<span class="number">0.0476493611932</span> G: <span class="number">-0.00500288326293</span> (Real: [<span class="number">4.0269851100444791</span>, <span class="number">1.2116770270672328</span>], Fake: [<span class="number">4.1152600276470181</span>, <span class="number">1.281199668474674</span>]) </div><div class="line"><span class="number">18200</span>: D: <span class="number">-0.0734401643276</span>/<span class="number">0.0987718477845</span> G: <span class="number">-0.0819599106908</span> (Real: [<span class="number">3.8394976514577865</span>, <span class="number">1.2749873300796422</span>], Fake: [<span class="number">4.0419886147975923</span>, <span class="number">1.327963817546014</span>]) </div><div class="line"><span class="number">18400</span>: D: <span class="number">0.0497582927346</span>/<span class="number">-0.155175164342</span> G: <span class="number">0.13303783536</span> (Real: [<span class="number">3.7719902545213699</span>, <span class="number">1.0897407967420649</span>], Fake: [<span class="number">3.7615046393871308</span>, <span class="number">1.3089916470515932</span>]) </div><div class="line"><span class="number">18600</span>: D: <span class="number">0.0239700898528</span>/<span class="number">-0.0381186343729</span> G: <span class="number">0.0276864990592</span> (Real: [<span class="number">4.188409751355648</span>, <span class="number">1.285584105229516</span>], Fake: [<span class="number">4.0233318042755126</span>, <span class="number">1.2681527004757882</span>]) </div><div class="line"><span class="number">18800</span>: D: <span class="number">0.00111512281001</span>/<span class="number">-0.0264507420361</span> G: <span class="number">0.0286112166941</span> (Real: [<span class="number">3.9199141567945479</span>, <span class="number">1.2738313063627613</span>], Fake: [<span class="number">4.1139781177043915</span>, <span class="number">1.330488711219485</span>]) </div><div class="line"><span class="number">19000</span>: D: <span class="number">-0.0473541393876</span>/<span class="number">0.111352369189</span> G: <span class="number">-0.0523310601711</span> (Real: [<span class="number">3.7932651308923959</span>, <span class="number">1.3147127405682739</span>], Fake: [<span class="number">3.7947627007961273</span>, <span class="number">1.0531299503292175</span>]) </div><div class="line"><span class="number">19200</span>: D: <span class="number">-0.0304779503495</span>/<span class="number">0.045797213912</span> G: <span class="number">-0.0440187454224</span> (Real: [<span class="number">4.0896886540949344</span>, <span class="number">1.3392233824907658</span>], Fake: [<span class="number">3.8646358847618103</span>, <span class="number">1.304593284039177</span>]) </div><div class="line"><span class="number">19400</span>: D: <span class="number">0.194737583399</span>/<span class="number">-0.192367076874</span> G: <span class="number">0.230072781444</span> (Real: [<span class="number">3.9661449289321897</span>, <span class="number">1.2822216197459986</span>], Fake: [<span class="number">4.0850893747806545</span>, <span class="number">1.3070266600721223</span>]) </div><div class="line"><span class="number">19600</span>: D: <span class="number">-0.195656016469</span>/<span class="number">0.194369539618</span> G: <span class="number">-0.204969212413</span> (Real: [<span class="number">3.9445683220028878</span>, <span class="number">1.2908669424594961</span>], Fake: [<span class="number">4.0273511683940884</span>, <span class="number">1.3484937484757897</span>]) </div><div class="line"><span class="number">19800</span>: D: <span class="number">0.276149004698</span>/<span class="number">-0.262592494488</span> G: <span class="number">0.261271834373</span> (Real: [<span class="number">3.9244625726342202</span>, <span class="number">1.2138755313418907</span>], Fake: [<span class="number">3.896045311689377</span>, <span class="number">1.3239168205792633</span>]) </div><div class="line"><span class="number">20000</span>: D: <span class="number">-0.037402831018</span>/<span class="number">0.0541176348925</span> G: <span class="number">-0.0254273694009</span> (Real: [<span class="number">3.7887831997871397</span>, <span class="number">1.0838328443531984</span>], Fake: [<span class="number">4.1803205323219297</span>, <span class="number">1.2069399210575202</span>]) </div><div class="line"><span class="number">20200</span>: D: <span class="number">-0.14391182363</span>/<span class="number">0.154710128903</span> G: <span class="number">-0.127932995558</span> (Real: [<span class="number">3.9718186306953429</span>, <span class="number">1.1938920103826984</span>], Fake: [<span class="number">3.8623993241786958</span>, <span class="number">1.1992380687067719</span>]) </div><div class="line"><span class="number">20400</span>: D: <span class="number">0.277315825224</span>/<span class="number">-0.276595175266</span> G: <span class="number">0.280247867107</span> (Real: [<span class="number">3.9932824140787124</span>, <span class="number">1.2951435399231526</span>], Fake: [<span class="number">3.9807376277446749</span>, <span class="number">1.1784780448683547</span>]) </div><div class="line"><span class="number">20600</span>: D: <span class="number">-0.213297829032</span>/<span class="number">0.245908752084</span> G: <span class="number">-0.243222758174</span> (Real: [<span class="number">3.8720276713371278</span>, <span class="number">1.2542419688526467</span>], Fake: [<span class="number">3.8206098222732545</span>, <span class="number">1.1661960388796837</span>]) </div><div class="line"><span class="number">20800</span>: D: <span class="number">0.114619217813</span>/<span class="number">-0.100926779211</span> G: <span class="number">0.0922625884414</span> (Real: [<span class="number">3.9682870441675187</span>, <span class="number">1.3188621677189192</span>], Fake: [<span class="number">3.5771069145202636</span>, <span class="number">1.1369803011602813</span>]) </div><div class="line"><span class="number">21000</span>: D: <span class="number">-0.303231596947</span>/<span class="number">0.294602781534</span> G: <span class="number">-0.288874447346</span> (Real: [<span class="number">3.991482014656067</span>, <span class="number">1.0697520343686426</span>], Fake: [<span class="number">3.674229063987732</span>, <span class="number">1.162594834704991</span>]) </div><div class="line"><span class="number">21200</span>: D: <span class="number">-0.074034973979</span>/<span class="number">0.0798109993339</span> G: <span class="number">-0.0742214098573</span> (Real: [<span class="number">3.5809044003486634</span>, <span class="number">1.1568557007313405</span>], Fake: [<span class="number">4.0297869884967801</span>, <span class="number">1.262183063172349</span>]) </div><div class="line"><span class="number">21400</span>: D: <span class="number">0.262162327766</span>/<span class="number">-0.297971874475</span> G: <span class="number">0.296678453684</span> (Real: [<span class="number">4.0233621561527251</span>, <span class="number">1.1153293685921177</span>], Fake: [<span class="number">4.3256152606010438</span>, <span class="number">1.293378983535336</span>]) </div><div class="line"><span class="number">21600</span>: D: <span class="number">0.253285288811</span>/<span class="number">-0.265974611044</span> G: <span class="number">0.271079391241</span> (Real: [<span class="number">3.8655495065450669</span>, <span class="number">1.3046362904478612</span>], Fake: [<span class="number">4.0383575105667111</span>, <span class="number">1.1593536714254398</span>]) </div><div class="line"><span class="number">21800</span>: D: <span class="number">-0.668483495712</span>/<span class="number">0.693548798561</span> G: <span class="number">-0.597621560097</span> (Real: [<span class="number">4.0561192989349362</span>, <span class="number">1.3785832256993071</span>], Fake: [<span class="number">4.0196917986869813</span>, <span class="number">1.1727416034901368</span>]) </div><div class="line"><span class="number">22000</span>: D: <span class="number">-0.247271433473</span>/<span class="number">0.260498434305</span> G: <span class="number">-0.254284113646</span> (Real: [<span class="number">4.0449540507793422</span>, <span class="number">1.1182831642815363</span>], Fake: [<span class="number">3.9410277414321899</span>, <span class="number">1.35662918383663</span>]) </div><div class="line"><span class="number">22200</span>: D: <span class="number">0.0106530245394</span>/<span class="number">-0.0105826444924</span> G: <span class="number">0.010412142612</span> (Real: [<span class="number">3.9709725368022917</span>, <span class="number">1.1935909496194108</span>], Fake: [<span class="number">3.6618342864513398</span>, <span class="number">1.1302755516153604</span>]) </div><div class="line"><span class="number">22400</span>: D: <span class="number">-0.0474079549313</span>/<span class="number">0.0512998178601</span> G: <span class="number">-0.0483585894108</span> (Real: [<span class="number">4.0366528975963591</span>, <span class="number">1.255590190060166</span>], Fake: [<span class="number">4.4536384451389317</span>, <span class="number">1.1817009846117434</span>]) </div><div class="line"><span class="number">22600</span>: D: <span class="number">-0.322408914566</span>/<span class="number">0.294503211975</span> G: <span class="number">-0.294557034969</span> (Real: [<span class="number">4.1648625326156612</span>, <span class="number">1.2910376071493044</span>], Fake: [<span class="number">3.9514351594448089</span>, <span class="number">1.2428792207747439</span>]) </div><div class="line"><span class="number">22800</span>: D: <span class="number">-0.0832418426871</span>/<span class="number">0.0778618454933</span> G: <span class="number">-0.0830294713378</span> (Real: [<span class="number">4.1286677682399748</span>, <span class="number">1.2808552112825371</span>], Fake: [<span class="number">4.0503418278694152</span>, <span class="number">1.2931609764101457</span>]) </div><div class="line"><span class="number">23000</span>: D: <span class="number">-0.369321852922</span>/<span class="number">0.350715816021</span> G: <span class="number">-0.379378199577</span> (Real: [<span class="number">4.0539671546220779</span>, <span class="number">1.2841527209665038</span>], Fake: [<span class="number">3.7385779893398285</span>, <span class="number">1.226034767157562</span>]) </div><div class="line"><span class="number">23200</span>: D: <span class="number">-0.20978730917</span>/<span class="number">0.198253154755</span> G: <span class="number">-0.20125605166</span> (Real: [<span class="number">3.8997612628340721</span>, <span class="number">1.2476609639285596</span>], Fake: [<span class="number">3.9131766259670258</span>, <span class="number">1.1745094337139723</span>]) </div><div class="line"><span class="number">23400</span>: D: <span class="number">-0.0713088735938</span>/<span class="number">0.070287771523</span> G: <span class="number">-0.0685144215822</span> (Real: [<span class="number">3.8823761761188509</span>, <span class="number">1.2554855061572396</span>], Fake: [<span class="number">3.916521146297455</span>, <span class="number">1.1589148704590277</span>]) </div><div class="line"><span class="number">23600</span>: D: <span class="number">0.0427192002535</span>/<span class="number">-0.0458992123604</span> G: <span class="number">0.0468493178487</span> (Real: [<span class="number">4.2497683775424955</span>, <span class="number">1.3534774394799314</span>], Fake: [<span class="number">3.7455072367191313</span>, <span class="number">1.2035723328660535</span>]) </div><div class="line"><span class="number">23800</span>: D: <span class="number">0.0886824280024</span>/<span class="number">-0.089180290699</span> G: <span class="number">0.0824339240789</span> (Real: [<span class="number">4.1368276840448379</span>, <span class="number">1.3053732424006685</span>], Fake: [<span class="number">3.7440953600406646</span>, <span class="number">1.3403098424499473</span>]) </div><div class="line"><span class="number">24000</span>: D: <span class="number">0.0765529945493</span>/<span class="number">-0.0702198073268</span> G: <span class="number">0.067143753171</span> (Real: [<span class="number">4.1424573111534118</span>, <span class="number">1.1894154051554844</span>], Fake: [<span class="number">3.9408028304576872</span>, <span class="number">1.311870950939225</span>]) </div><div class="line"><span class="number">24200</span>: D: <span class="number">-0.0332999974489</span>/<span class="number">0.0289861243218</span> G: <span class="number">-0.0238233078271</span> (Real: [<span class="number">4.0625021523237228</span>, <span class="number">1.3193496247910601</span>], Fake: [<span class="number">4.0214765596389768</span>, <span class="number">1.3626613178115112</span>]) </div><div class="line"><span class="number">24400</span>: D: <span class="number">0.0116833550856</span>/<span class="number">-0.0433083474636</span> G: <span class="number">0.0294151268899</span> (Real: [<span class="number">4.155729653835297</span>, <span class="number">1.2443573708805233</span>], Fake: [<span class="number">4.0276014816761014</span>, <span class="number">1.2064370896635035</span>]) </div><div class="line"><span class="number">24600</span>: D: <span class="number">-0.143586605787</span>/<span class="number">0.176585748792</span> G: <span class="number">-0.18224260211</span> (Real: [<span class="number">4.1486411762237552</span>, <span class="number">1.1859516848633762</span>], Fake: [<span class="number">4.1132693731784817</span>, <span class="number">1.1922180729014844</span>]) </div><div class="line"><span class="number">24800</span>: D: <span class="number">-0.0138712525368</span>/<span class="number">0.0168411824852</span> G: <span class="number">-0.0119427125901</span> (Real: [<span class="number">4.1591709744930263</span>, <span class="number">1.2359258557380455</span>], Fake: [<span class="number">4.1677398359775539</span>, <span class="number">1.3845231707709731</span>]) </div><div class="line"><span class="number">25000</span>: D: <span class="number">0.255919009447</span>/<span class="number">-0.294253230095</span> G: <span class="number">0.279962956905</span> (Real: [<span class="number">3.9463270044326784</span>, <span class="number">1.1874795319708413</span>], Fake: [<span class="number">4.2903580510616299</span>, <span class="number">1.3555421660554561</span>]) </div><div class="line"><span class="number">25200</span>: D: <span class="number">-0.0276325326413</span>/<span class="number">0.0174208488315</span> G: <span class="number">-0.0236964281648</span> (Real: [<span class="number">3.9243721216917038</span>, <span class="number">1.0837602743237815</span>], Fake: [<span class="number">3.6880193889141082</span>, <span class="number">1.3551960082382857</span>]) </div><div class="line"><span class="number">25400</span>: D: <span class="number">0.0133695462719</span>/<span class="number">-0.0217840373516</span> G: <span class="number">0.0382910817862</span> (Real: [<span class="number">3.9248281943798067</span>, <span class="number">1.3498579423514441</span>], Fake: [<span class="number">3.9377611076831815</span>, <span class="number">1.3147392264391</span>]) </div><div class="line"><span class="number">25600</span>: D: <span class="number">0.0533282607794</span>/<span class="number">-0.0582511797547</span> G: <span class="number">0.0426382124424</span> (Real: [<span class="number">3.9252138528227807</span>, <span class="number">1.2343049898537437</span>], Fake: [<span class="number">4.1364144349098204</span>, <span class="number">1.2410536065514364</span>]) </div><div class="line"><span class="number">25800</span>: D: <span class="number">-0.00288704037666</span>/<span class="number">0.00770187750459</span> G: <span class="number">-0.0114914979786</span> (Real: [<span class="number">3.9242496091127395</span>, <span class="number">1.2788150012319115</span>], Fake: [<span class="number">4.0345127677917478</span>, <span class="number">1.1882337663095883</span>]) </div><div class="line"><span class="number">26000</span>: D: <span class="number">-0.0608727261424</span>/<span class="number">0.0541118755937</span> G: <span class="number">-0.0474198237062</span> (Real: [<span class="number">4.0897465288639072</span>, <span class="number">1.3095601996023096</span>], Fake: [<span class="number">4.1400825273990627</span>, <span class="number">1.2148829163174772</span>]) </div><div class="line"><span class="number">26200</span>: D: <span class="number">-0.130559697747</span>/<span class="number">0.0733794793487</span> G: <span class="number">-0.104144588113</span> (Real: [<span class="number">4.2607862049341199</span>, <span class="number">1.2942193499055861</span>], Fake: [<span class="number">3.8867506885528567</span>, <span class="number">1.1942672801186012</span>]) </div><div class="line"><span class="number">26400</span>: D: <span class="number">-0.0439343079925</span>/<span class="number">0.0573879256845</span> G: <span class="number">-0.0878697857261</span> (Real: [<span class="number">3.7808335113525389</span>, <span class="number">1.0880880845236942</span>], Fake: [<span class="number">3.9782328522205352</span>, <span class="number">1.1620106342824015</span>]) </div><div class="line"><span class="number">26600</span>: D: <span class="number">0.0152015341446</span>/<span class="number">0.00366508681327</span> G: <span class="number">0.041159953922</span> (Real: [<span class="number">3.8900859886407853</span>, <span class="number">1.1779470629112894</span>], Fake: [<span class="number">3.7596992158889773</span>, <span class="number">1.2139592079531667</span>]) </div><div class="line"><span class="number">26800</span>: D: <span class="number">0.0352714285254</span>/<span class="number">-0.1031877473</span> G: <span class="number">0.067874789238</span> (Real: [<span class="number">4.0695308989286421</span>, <span class="number">1.1837713697563146</span>], Fake: [<span class="number">4.0929770147800442</span>, <span class="number">1.0965869589580517</span>]) </div><div class="line"><span class="number">27000</span>: D: <span class="number">-0.0881021544337</span>/<span class="number">0.0813493356109</span> G: <span class="number">-0.0242269244045</span> (Real: [<span class="number">3.9890777540206908</span>, <span class="number">1.2553969722414431</span>], Fake: [<span class="number">3.7988330614566803</span>, <span class="number">1.2567013288504758</span>]) </div><div class="line"><span class="number">27200</span>: D: <span class="number">0.0763045027852</span>/<span class="number">-0.0917293503881</span> G: <span class="number">0.114218316972</span> (Real: [<span class="number">4.0028738850355152</span>, <span class="number">1.3423566094628674</span>], Fake: [<span class="number">3.9770897746086122</span>, <span class="number">1.3219552807466088</span>]) </div><div class="line"><span class="number">27400</span>: D: <span class="number">0.0594872310758</span>/<span class="number">-0.0451167076826</span> G: <span class="number">0.0368666872382</span> (Real: [<span class="number">4.0800592017173765</span>, <span class="number">1.2152901513624952</span>], Fake: [<span class="number">3.9476736617088317</span>, <span class="number">1.2989705597833583</span>]) </div><div class="line"><span class="number">27600</span>: D: <span class="number">0.0153470486403</span>/<span class="number">-0.0201481245458</span> G: <span class="number">-0.000402322039008</span> (Real: [<span class="number">4.1604018148779867</span>, <span class="number">1.3359014716469342</span>], Fake: [<span class="number">3.9977971708774565</span>, <span class="number">1.2944576179632961</span>]) </div><div class="line"><span class="number">27800</span>: D: <span class="number">-0.00789823569357</span>/<span class="number">0.00908922962844</span> G: <span class="number">-0.0111076626927</span> (Real: [<span class="number">4.0212037134170533</span>, <span class="number">1.1874018724012747</span>], Fake: [<span class="number">4.1083386635780332</span>, <span class="number">1.2509297017041943</span>]) </div><div class="line"><span class="number">28000</span>: D: <span class="number">0.00757996272296</span>/<span class="number">-0.00654019229114</span> G: <span class="number">0.00611820165068</span> (Real: [<span class="number">3.7911120998859404</span>, <span class="number">1.1977103659955959</span>], Fake: [<span class="number">4.0841165268421173</span>, <span class="number">1.1898253993115502</span>]) </div><div class="line"><span class="number">28200</span>: D: <span class="number">0.0131957577541</span>/<span class="number">0.00322831980884</span> G: <span class="number">-0.00111622922122</span> (Real: [<span class="number">4.1888789300620557</span>, <span class="number">1.3496568725947327</span>], Fake: [<span class="number">4.0611115002632143</span>, <span class="number">1.3183184144220856</span>]) </div><div class="line"><span class="number">28400</span>: D: <span class="number">-0.0306499581784</span>/<span class="number">0.0331647247076</span> G: <span class="number">-0.0338053703308</span> (Real: [<span class="number">4.1849153059720994</span>, <span class="number">1.3391440077022734</span>], Fake: [<span class="number">3.8500063753128053</span>, <span class="number">1.3092803392722017</span>]) </div><div class="line"><span class="number">28600</span>: D: <span class="number">-0.0750854164362</span>/<span class="number">0.0745137408376</span> G: <span class="number">-0.0692436397076</span> (Real: [<span class="number">4.2219353467226028</span>, <span class="number">1.3228632865628431</span>], Fake: [<span class="number">3.9156518685817718</span>, <span class="number">1.322625042830196</span>]) </div><div class="line"><span class="number">28800</span>: D: <span class="number">0.0400990955532</span>/<span class="number">-0.0271217841655</span> G: <span class="number">0.0072197439149</span> (Real: [<span class="number">4.1668396210670471</span>, <span class="number">1.1685380084057959</span>], Fake: [<span class="number">3.8380984902381896</span>, <span class="number">1.362370341203504</span>]) </div><div class="line"><span class="number">29000</span>: D: <span class="number">-0.0643707811832</span>/<span class="number">0.0576644167304</span> G: <span class="number">-0.100686855614</span> (Real: [<span class="number">3.8912058281898498</span>, <span class="number">1.1764897014192157</span>], Fake: [<span class="number">4.1498241519927976</span>, <span class="number">1.2432322677870791</span>]) </div><div class="line"><span class="number">29200</span>: D: <span class="number">0.0442187860608</span>/<span class="number">-0.0331076569855</span> G: <span class="number">0.0377507209778</span> (Real: [<span class="number">3.995900819301605</span>, <span class="number">1.1999502583881319</span>], Fake: [<span class="number">3.9349853229522704</span>, <span class="number">1.3676764998638458</span>]) </div><div class="line"><span class="number">29400</span>: D: <span class="number">-0.0614512637258</span>/<span class="number">0.0583380833268</span> G: <span class="number">-0.059112302959</span> (Real: [<span class="number">4.1833238875865932</span>, <span class="number">1.4038158613161691</span>], Fake: [<span class="number">4.1426575899124147</span>, <span class="number">1.2694314780433735</span>]) </div><div class="line"><span class="number">29600</span>: D: <span class="number">-0.0337703973055</span>/<span class="number">0.0392336845398</span> G: <span class="number">-0.0504648312926</span> (Real: [<span class="number">4.1217511665821078</span>, <span class="number">1.2264251023812502</span>], Fake: [<span class="number">3.838116307258606</span>, <span class="number">1.2309841481033876</span>]) </div><div class="line"><span class="number">29800</span>: D: <span class="number">0.129453405738</span>/<span class="number">-0.13672092557</span> G: <span class="number">0.143395990133</span> (Real: [<span class="number">3.8660407388210296</span>, <span class="number">1.2221890139039508</span>], Fake: [<span class="number">4.0156518769264222</span>, <span class="number">1.3044469158238432</span>])</div></pre></td></tr></table></figure></div><div></div><div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/deep-learning/" rel="tag"># deep learning</a> <a href="/tags/machine-learning/" rel="tag"># machine learning</a> <a href="/tags/GAN/" rel="tag"># GAN</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/04/29/The-awesome-Wasserstein-GAN/" rel="next" title="The awesome Wasserstein GAN"><i class="fa fa-chevron-left"></i> The awesome Wasserstein GAN</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2017/04/30/The-basic-of-Hidden-Markov-Model/" rel="prev" title="The Basic of Hidden Markov Model">The Basic of Hidden Markov Model <i class="fa fa-chevron-right"></i></a></div></div></footer></article><div class="post-spread"><div class="addthis_inline_share_toolbox"><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-58f731508143741d" async></script></div></div></div></div><div class="comments" id="comments"><div id="hypercomments_widget"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ewan Li"><p class="site-author-name" itemprop="name">Ewan Li</p><p class="site-description motion-element" itemprop="description">Ewan's IT Blog</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">130</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">64</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/ewanlee" target="_blank" title="Github"><i class="fa fa-fw fa-globe"></i> Github </a></span><span class="links-of-author-item"><a href="https://twitter.com/tomaxent" target="_blank" title="Twitter"><i class="fa fa-fw fa-twitter"></i> Twitter</a></span></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Ewan Li</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user">本站访客数</i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人次</span> <span class="site-pv"><i class="fa fa-eye">本站总访问量</i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">_hcwp=window._hcwp||[],_hcwp.push({widget:"Bloggerstream",widget_id:89825,selector:".hc-comment-count",label:"{%COUNT%}"}),_hcwp.push({widget:"Stream",widget_id:89825,xid:"2017/04/29/WGAN-implemented-by-PyTorch/"}),function(){if(!("HC_LOAD_INIT"in window)){HC_LOAD_INIT=!0;var e=(navigator.language||navigator.systemLanguage||navigator.userLanguage||"en").substr(0,2).toLowerCase(),t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src=("https:"==document.location.protocol?"https":"http")+"://w.hypercomments.com/widget/hc/89825/"+e+"/widget.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(t,n.nextSibling)}}()</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("e27VKX5tTklQLCtF7iNMmhcA-gzGzoHsz","nnQn2znNgXXEdK7W2bVJ3bfK")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script></body></html>