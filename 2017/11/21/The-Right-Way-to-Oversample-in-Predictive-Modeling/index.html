<!doctype html><html class="theme-next mist use-motion" lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="machine learning,"><link rel="alternate" href="/atom.xml" title="Abracadabra" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="The Source Blog: https://beckernick.github.io/oversampling-modeling/Imbalanced datasets spring up everywhere. Amazon wants to classify fake reviews, banks want to predict fraudulent credit card charge"><meta property="og:type" content="article"><meta property="og:title" content="The Right Way to Oversample in Predictive Modeling"><meta property="og:url" content="http://yoursite.com/2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/index.html"><meta property="og:site_name" content="Abracadabra"><meta property="og:description" content="The Source Blog: https://beckernick.github.io/oversampling-modeling/Imbalanced datasets spring up everywhere. Amazon wants to classify fake reviews, banks want to predict fraudulent credit card charge"><meta property="og:updated_time" content="2017-11-21T08:57:45.929Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="The Right Way to Oversample in Predictive Modeling"><meta name="twitter:description" content="The Source Blog: https://beckernick.github.io/oversampling-modeling/Imbalanced datasets spring up everywhere. Amazon wants to classify fake reviews, banks want to predict fraudulent credit card charge"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post"},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/"><title>The Right Way to Oversample in Predictive Modeling | Abracadabra</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?dc405a79ad500922134d14cdf288f646";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container one-collumn sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Abracadabra</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Do it yourself</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline">The Right Way to Oversample in Predictive Modeling</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-21T09:10:22+08:00">2017-11-21 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/" itemprop="commentsCount"></span> </a></span><span id="/2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/" class="leancloud_visitors" data-flag-title="The Right Way to Oversample in Predictive Modeling"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>The Source Blog: <a href="https://beckernick.github.io/oversampling-modeling/" target="_blank" rel="external">https://beckernick.github.io/oversampling-modeling/</a></p><p>Imbalanced datasets spring up everywhere. Amazon wants to classify fake reviews, banks want to predict fraudulent credit card charges, and, as of this November, Facebook researchers are probably wondering if they can predict which news articles are fake.</p><p>In each of these cases, only a small fraction of observations are actually positives. I’d guess that only 1 in 10,000 credit card charges are fraudulent, at most. Recently, oversampling the minority class observations has become a common approach to improve the quality of predictive modeling. By oversampling, models are sometimes better able to learn patterns that differentiate classes.</p><p>However, this post isn’t about how this can improve modeling. Instead, it’s about how the <strong>*timing*</strong> of oversampling can affect the generalization ability of a model. Since one of the primary goals of model validation is to estimate how it will perform on unseen data, oversampling correctly is critical.</p><h1 id="Preparing-the-Data"><a href="#Preparing-the-Data" class="headerlink" title="Preparing the Data"></a>Preparing the Data</h1><p>I’m going to try to predict whether someone will default on or a creditor will have to charge off a loan, using data from Lending Club. I’ll start by importing some modules and loading the data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</div><div class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">loans = pd.read_csv(<span class="string">'../lending-club-data.csv.zip'</span>)</div><div class="line">loans.iloc[<span class="number">0</span>]</div></pre></td></tr></table></figure><p>There’s a lot of cool person and loan-specific information in this dataset. The target variable is <code>bad_loans</code>, which is 1 if the loan was charged off or the lessee defaulted, and 0 otherwise. I know this dataset should be imbalanced (most loans are paid off), but how imbalanced is it?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loans.bad_loans.value_counts()</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="number">0</span>    <span class="number">99457</span></div><div class="line"><span class="number">1</span>    <span class="number">23150</span></div><div class="line">Name: bad_loans, dtype: int64</div></pre></td></tr></table></figure><p>Charge offs occurred or people defaulted on about 19% of loans, so there’s some imbalance in the data but it’s not terrible. I’ll remove a few observations with missing values for a payment-to-income ratio and then pick a handful of features to use in a random forest model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loans = loans[~loans.payment_inc_ratio.isnull()]</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">model_variables = [<span class="string">'grade'</span>, <span class="string">'home_ownership'</span>,<span class="string">'emp_length_num'</span>, <span class="string">'sub_grade'</span>,<span class="string">'short_emp'</span>, <span class="string">'dti'</span>, <span class="string">'term'</span>, <span class="string">'purpose'</span>, <span class="string">'int_rate'</span>, <span class="string">'last_delinq_none'</span>, <span class="string">'last_major_derog_none'</span>, <span class="string">'revol_util'</span>, <span class="string">'total_rec_late_fee'</span>, <span class="string">'payment_inc_ratio'</span>, <span class="string">'bad_loans'</span>]</div><div class="line"></div><div class="line">loans_data_relevent = loans[model_variables]</div></pre></td></tr></table></figure><p>Next, I need to one-hot encode the categorical features as binary variables to use them in sklearn’s random forest classifier.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loans_relevant_enconded = pd.get_dummies(loans_data_relevent)</div></pre></td></tr></table></figure><h1 id="Creating-the-Training-and-Test-Sets"><a href="#Creating-the-Training-and-Test-Sets" class="headerlink" title="Creating the Training and Test Sets"></a>Creating the Training and Test Sets</h1><p>With the data prepared, I can create a training dataset and a test dataset. I’ll use the training dataset to build and validate the model, and treat the test dataset as the unseen new data I’d see if the model were in production.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">training_features, test_features, \</div><div class="line">training_target, test_target, = train_test_split(loans_relevant_enconded.drop([<span class="string">'bad_loans'</span>], axis=<span class="number">1</span>),                        loans_relevant_enconded[<span class="string">'bad_loans'</span>],</div><div class="line">			    test_size = <span class="number">.1</span>,</div><div class="line">			    random_state=<span class="number">12</span>)</div></pre></td></tr></table></figure><h1 id="The-Wrong-Way-to-Oversample"><a href="#The-Wrong-Way-to-Oversample" class="headerlink" title="The Wrong Way to Oversample"></a>The Wrong Way to Oversample</h1><p>With my training data created, I’ll upsample the bad loans using the <a href="https://www.jair.org/media/953/live-953-2037-jair.pdf" target="_blank" rel="external">SMOTE algorithm</a> (Synthetic Minority Oversampling Technique). At a high level, SMOTE creates synthetic observations of the minority class (bad loans) by:</p><ol><li>Finding the k-nearest-neighbors for minority class observations (finding similar observations)</li><li>Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observation.</li></ol><p>After upsampling to a class ratio of 1.0, I should have a balanced dataset. There’s no need (and often it’s not smart) to balance the classes, but it magnifies the issue caused by incorrectly timed oversampling.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sm = SMOTE(random_state=<span class="number">12</span>, ratio = <span class="number">1.0</span>)</div><div class="line">x_res, y_res = sm.fit_sample(training_features, training_target)</div><div class="line"><span class="keyword">print</span> training_target.value_counts(), np.bincount(y_res)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="number">0</span>    <span class="number">89493</span></div><div class="line"><span class="number">1</span>    <span class="number">20849</span></div><div class="line">Name: bad_loans, dtype: int64 [<span class="number">89493</span> <span class="number">89493</span>]</div></pre></td></tr></table></figure><p>After upsampling, I’ll split the data into separate training and validation sets and build a random forest model to classify the bad loans.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">x_train_res, x_val_res, y_train_res, y_val_res = train_test_split(x_res,</div><div class="line">                                                    y_res,</div><div class="line">                                                    test_size = <span class="number">.1</span>,</div><div class="line">                                                    random_state=<span class="number">12</span>)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">clf_rf = RandomForestClassifier(n_estimators=<span class="number">25</span>, random_state=<span class="number">12</span>)</div><div class="line">clf_rf.fit(x_train_res, y_train_res)</div><div class="line">clf_rf.score(x_val_res, y_val_res)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="number">0.88468629532376108</span></div></pre></td></tr></table></figure><p>88% accuracy looks good, but I’m not just interested in accuracy. I also want to know how well I can specifically classify bad loans, since they’re more important. In statistics, this is called <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" target="_blank" rel="external">recall</a>, and it’s the number of correctly predicted “positives” divided by the total number of “positives”.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">recall_score(y_val_res, clf_rf.predict(x_val_res))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="number">0.81192097332291546</span></div></pre></td></tr></table></figure><p>81% recall. That means the model correctly identified 81% of the total bad loans. That’s pretty great. But is this actually representative of how the model will perform? To find out, I’ll calculate the accuracy and recall for the model on the test dataset I created initially.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> clf_rf.score(test_features, test_target)</div><div class="line"><span class="keyword">print</span> recall_score(test_target, clf_rf.predict(test_features))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="number">0.801973737868</span></div><div class="line"><span class="number">0.129943502825</span></div></pre></td></tr></table></figure><p>Only 80% accuracy and 13% recall on the test data. That’s a <strong>huge</strong> difference!</p><h1 id="What-Happened"><a href="#What-Happened" class="headerlink" title="What Happened?"></a>What Happened?</h1><p>By oversampling before splitting into training and validation datasets, I “bleed” information from the validation set into the training of the model.</p><p>To see how this works, think about the case of simple oversampling (where I just duplicate observations). If I upsample a dataset before splitting it into a train and validation set, I could end up with the same observation in both datasets. As a result, a complex enough model will be able to perfectly predict the value for those observations when predicting on the validation set, inflating the accuracy and recall.</p><p>When upsampling using SMOTE, I don’t create duplicate observations. However, because the SMOTE algorithm uses the nearest neighbors of observations to create synthetic data, it still bleeds information. If the nearest neighbors of minority class observations in the training set end up in the validation set, their information is partially captured by the synthetic data in the training set. Since I’m splitting the data randomly, we’d expect to have this happen. As a result, the model will be better able to predict validation set values than completely new data.</p><h1 id="The-Right-Way-to-Oversample"><a href="#The-Right-Way-to-Oversample" class="headerlink" title="The Right Way to Oversample"></a>The Right Way to Oversample</h1><p>Okay, so I’ve gone through the wrong way to oversample. Now I’ll go through the right way: oversampling on only the training data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">x_train, x_val, y_train, y_val = \</div><div class="line">			train_test_split(training_features, 											    training_target,</div><div class="line">						    test_size = <span class="number">.1</span>,</div><div class="line">                              random_state=<span class="number">12</span>)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sm = SMOTE(random_state=<span class="number">12</span>, ratio = <span class="number">1.0</span>)</div><div class="line">x_train_res, y_train_res = sm.fit_sample(x_train, y_train)</div></pre></td></tr></table></figure><p>By oversampling only on the training data, none of the information in the validation data is being used to create synthetic observations. So these results should be generalizable. Let’s see if that’s true.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">clf_rf = RandomForestClassifier(n_estimators=<span class="number">25</span>, random_state=<span class="number">12</span>)</div><div class="line">clf_rf.fit(x_train_res, y_train_res)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'Validation Results'</span></div><div class="line"><span class="keyword">print</span> clf_rf.score(x_val, y_val)</div><div class="line"><span class="keyword">print</span> recall_score(y_val, clf_rf.predict(x_val))</div><div class="line"><span class="keyword">print</span> <span class="string">'\nTest Results'</span></div><div class="line"><span class="keyword">print</span> clf_rf.score(test_features, test_target)</div><div class="line"><span class="keyword">print</span> recall_score(test_target, clf_rf.predict(test_features))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Validation Results</div><div class="line"><span class="number">0.800362483009</span></div><div class="line"><span class="number">0.138195777351</span></div><div class="line"></div><div class="line">Test Results</div><div class="line"><span class="number">0.803278688525</span></div><div class="line"><span class="number">0.142546718818</span></div></pre></td></tr></table></figure><p>The validation results closely match the unseen test data results, which is exactly what I would want to see after putting a model into production.</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>Oversampling is a well-known way to potentially improve models trained on imbalanced data. But it’s important to remember that oversampling incorrectly can lead to thinking a model will generalize better than it actually does. Random forests are great because the model architecture reduces overfitting (see <a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf" target="_blank" rel="external">Brieman 2001</a> for a proof), but poor sampling practices can still lead to false conclusions about the quality of a model.</p><p>When the model is in production, it’s predicting on unseen data. The main point of model validation is to estimate how the model will generalize to new data. If the decision to put a model into production is based on how it performs on a validation set, it’s critical that oversampling is done correctly.</p></div><div></div><div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/machine-learning/" rel="tag"># machine learning</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/11/20/Note-of-the-DenseNet-contains-TensorFlow-and-PyTorch-Implementation/" rel="next" title="Note of the DenseNet (contains TensorFlow and PyTorch Implementation)"><i class="fa fa-chevron-left"></i> Note of the DenseNet (contains TensorFlow and PyTorch Implementation)</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2017/11/21/A-Simple-Multi-Class-Classification-Task-Keras-and-Scikit-Learn/" rel="prev" title="A Simple Multi-Class Classification Task: Keras and Scikit-Learn">A Simple Multi-Class Classification Task: Keras and Scikit-Learn <i class="fa fa-chevron-right"></i></a></div></div></footer></article><div class="post-spread"><div class="addthis_inline_share_toolbox"><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-58f731508143741d" async></script></div></div></div></div><div class="comments" id="comments"><div id="hypercomments_widget"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">Table of Contents</li><li class="sidebar-nav-overview" data-target="site-overview">Overview</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ewan Li"><p class="site-author-name" itemprop="name">Ewan Li</p><p class="site-description motion-element" itemprop="description">Ewan's IT Blog</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">97</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">53</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/ewanlee" target="_blank" title="Github"><i class="fa fa-fw fa-globe"></i> Github </a></span><span class="links-of-author-item"><a href="http://weibo.com/3946248928/profile?topnav=1&wvr=6" target="_blank" title="Weibo"><i class="fa fa-fw fa-weibo"></i> Weibo</a></span></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Preparing-the-Data"><span class="nav-number">1.</span> <span class="nav-text">Preparing the Data</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Creating-the-Training-and-Test-Sets"><span class="nav-number">2.</span> <span class="nav-text">Creating the Training and Test Sets</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-Wrong-Way-to-Oversample"><span class="nav-number">3.</span> <span class="nav-text">The Wrong Way to Oversample</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#What-Happened"><span class="nav-number">4.</span> <span class="nav-text">What Happened?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-Right-Way-to-Oversample"><span class="nav-number">5.</span> <span class="nav-text">The Right Way to Oversample</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Conclusion"><span class="nav-number">6.</span> <span class="nav-text">Conclusion</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Ewan Li</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user">本站访客数</i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人次</span> <span class="site-pv"><i class="fa fa-eye">本站总访问量</i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">_hcwp=window._hcwp||[],_hcwp.push({widget:"Bloggerstream",widget_id:89825,selector:".hc-comment-count",label:"{%COUNT%}"}),_hcwp.push({widget:"Stream",widget_id:89825,xid:"2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/"}),function(){if(!("HC_LOAD_INIT"in window)){HC_LOAD_INIT=!0;var e=(navigator.language||navigator.systemLanguage||navigator.userLanguage||"en").substr(0,2).toLowerCase(),t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src=("https:"==document.location.protocol?"https":"http")+"://w.hypercomments.com/widget/hc/89825/"+e+"/widget.js";var i=document.getElementsByTagName("script")[0];i.parentNode.insertBefore(t,i.nextSibling)}}()</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("e27VKX5tTklQLCtF7iNMmhcA-gzGzoHsz","nnQn2znNgXXEdK7W2bVJ3bfK")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script></body></html>