<!doctype html><html class="theme-next mist use-motion" lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="Deep learning,machine learning,CNN,"><link rel="alternate" href="/atom.xml" title="Abracadabra" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="Ever since Alex Krizhevsky, Geoff Hinton, and Ilya Sutskever won ImageNet in 2012, Convolutional Neural Networks(CNNs) have become the gold standard for image classification. In fact, since then, CNNs"><meta property="og:type" content="article"><meta property="og:title" content="A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN"><meta property="og:url" content="http://yoursite.com/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/index.html"><meta property="og:site_name" content="Abracadabra"><meta property="og:description" content="Ever since Alex Krizhevsky, Geoff Hinton, and Ilya Sutskever won ImageNet in 2012, Convolutional Neural Networks(CNNs) have become the gold standard for image classification. In fact, since then, CNNs"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*bGTawFxQwzc5yV1_szDrwQ.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*8GVucX9yhnL21KCtcyFDRQ.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*eJjj2TVUVZDiVSTcnzh7fA.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*NdwfHMrW3rpj5SW_VQtWVw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*r9ELExnk1B1zHnRReDW9Ow.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*ZQ03Ib84bYioFKoho5HnKg.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/0*Sdj6sKDRQyZpO6oH."><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*3xnXHBEAz6FGzb-EehXtkA.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*4K_Bq1AhAsTe9vlT0wsdXQ.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*E_P1vAEbGT4HNYjqMtIz4g.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*xY9rmw06KZWQlNIPk6ItqA.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/0*_nNI03ESXm2P6YXO."><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/0*n6pZEyvW47nlcdQz."><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*pJ3OTVXjtp9vWfBOPsnWIw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*E_5qBTrotLzclyaxsekBmQ.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*cYW3EdKx75Stl1EreATdfw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*BiRpf-ogjxARQf5LxI17Jw.png"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/0*KtaZfpUErYqwH4RX."><meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*VDGql5VDbLWU3jOhRmzwFQ.jpeg"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1250/1*6CClgIKH8zhZjmcftfNoEQ.png"><meta property="og:updated_time" content="2018-04-10T12:05:59.651Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN"><meta name="twitter:description" content="Ever since Alex Krizhevsky, Geoff Hinton, and Ilya Sutskever won ImageNet in 2012, Convolutional Neural Networks(CNNs) have become the gold standard for image classification. In fact, since then, CNNs"><meta name="twitter:image" content="https://cdn-images-1.medium.com/max/1000/1*bGTawFxQwzc5yV1_szDrwQ.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post"},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/"><title>A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN | Abracadabra</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?dc405a79ad500922134d14cdf288f646";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container one-collumn sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Abracadabra</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Do it yourself</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline">A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-10T16:34:47+08:00">2018-04-10 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/" itemprop="commentsCount"></span> </a></span><span id="/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/" class="leancloud_visitors" data-flag-title="A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>Ever since <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="external">Alex Krizhevsky, Geoff Hinton, and Ilya Sutskever won ImageNet in 2012</a>, Convolutional Neural Networks(CNNs) have become the gold standard for image classification. In fact, since then, CNNs have improved to the point where they now outperform humans on the ImageNet challenge!</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*bGTawFxQwzc5yV1_szDrwQ.png" alt="img"></p><p>CNNs now outperform humans on the ImageNet challenge. The y-axis in the above graph is the error rate on ImageNet.</p><p>While these results are impressive, image classification is far simpler than the complexity and diversity of true human visual understanding.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*8GVucX9yhnL21KCtcyFDRQ.png" alt="img"></p><p>An example of an image used in the classification challenge. Note how the image is well framed and has just one object.</p><p>In classification, there’s generally an image with a single object as the focus and the task is to say what that image is (see above). But when we look at the world around us, we carry out far more complex tasks.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*eJjj2TVUVZDiVSTcnzh7fA.png" alt="img"></p><p>Sights in real life are often composed of a multitude of different, overlapping objects, backgrounds, and actions.</p><p>We see complicated sights with multiple overlapping objects, and different backgrounds and we not only classify these different objects but also identify their boundaries, differences, and relations to one another!</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*NdwfHMrW3rpj5SW_VQtWVw.png" alt="img"></p><p>In image segmentation, our goal is to classify the different objects in the image, and identify their boundaries. Source: Mask R-CNN paper.</p><p>Can CNNs help us with such complex tasks? Namely, given a more complicated image, can we use CNNs to identify the different objects in the image, and their boundaries? As has been shown by Ross Girshick and his peers over the last few years, the answer is conclusively yes.</p><h4 id="Goals-of-this-Post"><a href="#Goals-of-this-Post" class="headerlink" title="Goals of this Post"></a>Goals of this Post</h4><p>Through this post, we’ll cover the intuition behind some of the main techniques used in object detection and segmentation and see how they’ve evolved from one implementation to the next. In particular, we’ll cover R-CNN (Regional CNN), the original application of CNNs to this problem, along with its descendants Fast R-CNN, and Faster R-CNN. Finally, we’ll cover Mask R-CNN, a paper released recently by Facebook Research that extends such object detection techniques to provide pixel level segmentation. Here are the papers referenced in this post:</p><ol><li>R-CNN: <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="external">https://arxiv.org/abs/1311.2524</a></li><li>Fast R-CNN: <a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="external">https://arxiv.org/abs/1504.08083</a></li><li>Faster R-CNN: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a></li><li>Mask R-CNN: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a></li></ol><hr><h4 id="2014-R-CNN-An-Early-Application-of-CNNs-to-Object-Detection"><a href="#2014-R-CNN-An-Early-Application-of-CNNs-to-Object-Detection" class="headerlink" title="2014: R-CNN - An Early Application of CNNs to Object Detection"></a>2014: R-CNN - An Early Application of CNNs to Object Detection</h4><p><img src="https://cdn-images-1.medium.com/max/1000/1*r9ELExnk1B1zHnRReDW9Ow.png" alt="img"></p><p>Object detection algorithms such as R-CNN take in an image and identify the locations and classifications of the main objects in the image. Source: <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="external">https://arxiv.org/abs/1311.2524</a>.</p><p>Inspired by the research of Hinton’s lab at the University of Toronto, a small team at UC Berkeley, led by Professor Jitendra Malik, asked themselves what today seems like an inevitable question:</p><blockquote><p>To what extent do [Krizhevsky et. al’s results] generalize to object detection?</p></blockquote><p>Object detection is the task of finding the different objects in an image and classifying them (as seen in the image above). The team, comprised of Ross Girshick (a name we’ll see again), Jeff Donahue, and Trevor Darrel found that this problem can be solved with Krizhevsky’s results by testing on the PASCAL VOC Challenge, a popular object detection challenge akin to ImageNet. They write,</p><blockquote><p>This paper is the first to show that a CNN can lead to dramatically higher object detection performance on PASCAL VOC as compared to systems based on simpler HOG-like features.</p></blockquote><p>Let’s now take a moment to understand how their architecture, Regions With CNNs (R-CNN) works.</p><p><strong>Understanding R-CNN</strong></p><p>The goal of R-CNN is to take in an image, and correctly identify where the main objects (via a bounding box) in the image.</p><ul><li><strong>Inputs</strong>: Image</li><li><strong>Outputs</strong>: Bounding boxes + labels for each object in the image.</li></ul><p>But how do we find out where these bounding boxes are? R-CNN does what we might intuitively do as well - <strong>propose</strong> <strong>a bunch of boxes in the image and see if any of them actually correspond to an object</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*ZQ03Ib84bYioFKoho5HnKg.png" alt="img"></p><p>Selective Search looks through windows of multiple scales and looks for adjacent pixels that share textures, colors, or intensities. Image source: <a href="https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf" target="_blank" rel="external">https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf</a></p><p>R-CNN creates these bounding boxes, or region proposals, using a process called Selective Search which you can read about <a href="http://www.cs.cornell.edu/courses/cs7670/2014sp/slides/VisionSeminar14.pdf" target="_blank" rel="external">here</a>. At a high level, Selective Search (shown in the image above) looks at the image through windows of different sizes, and for each size tries to group together adjacent pixels by texture, color, or intensity to identify objects.</p><p><img src="https://cdn-images-1.medium.com/max/1000/0*Sdj6sKDRQyZpO6oH." alt="img"></p><p>After creating a set of region proposals, R-CNN passes the image through a modified version of AlexNet to determine whether or not it is a valid region. Source: <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="external">https://arxiv.org/abs/1311.2524</a>.</p><p>Once the proposals are created, R-CNN warps the region to a standard square size and passes it through to a modified version of AlexNet (the winning submission to ImageNet 2012 that inspired R-CNN), as shown above.</p><p>On the final layer of the CNN, R-CNN adds a Support Vector Machine (SVM) that simply classifies whether this is an object, and if so what object. This is step 4 in the image above.</p><p><strong>Improving the Bounding Boxes</strong></p><p>Now, having found the object in the box, can we tighten the box to fit the true dimensions of the object? We can, and this is the final step of R-CNN. R-CNN runs a simple linear regression on the region proposal to generate tighter bounding box coordinates to get our final result. Here are the inputs and outputs of this regression model:</p><ul><li><strong>Inputs</strong>: sub-regions of the image corresponding to objects.</li><li><strong>Outputs</strong>: New bounding box coordinates for the object in the sub-region.</li></ul><p>So, to summarize, R-CNN is just the following steps:</p><ol><li>Generate a set of proposals for bounding boxes.</li><li>Run the images in the bounding boxes through a pre-trained AlexNet and finally an SVM to see what object the image in the box is.</li><li>Run the box through a linear regression model to output tighter coordinates for the box once the object has been classified.</li></ol><hr><h4 id="2015-Fast-R-CNN-Speeding-up-and-Simplifying-R-CNN"><a href="#2015-Fast-R-CNN-Speeding-up-and-Simplifying-R-CNN" class="headerlink" title="2015: Fast R-CNN - Speeding up and Simplifying R-CNN"></a>2015: Fast R-CNN - Speeding up and Simplifying R-CNN</h4><p><img src="https://cdn-images-1.medium.com/max/1000/1*3xnXHBEAz6FGzb-EehXtkA.png" alt="img"></p><p>Ross Girshick wrote both R-CNN and Fast R-CNN. He continues to push the boundaries of Computer Vision at Facebook Research.</p><p>R-CNN works really well, but is really quite slow for a few simple reasons:</p><ol><li>It requires a forward pass of the CNN (AlexNet) for every single region proposal for every single image (that’s around 2000 forward passes per image!).</li><li>It has to train three different models separately - the CNN to generate image features, the classifier that predicts the class, and the regression model to tighten the bounding boxes. This makes the pipeline extremely hard to train.</li></ol><p>In 2015, Ross Girshick, the first author of R-CNN, solved both these problems, leading to the second algorithm in our short history - Fast R-CNN. Let’s now go over its main insights.</p><p><strong>Fast R-CNN Insight 1: RoI (Region of Interest) Pooling</strong></p><p>For the forward pass of the CNN, Girshick realized that for each image, a lot of proposed regions for the image invariably overlapped causing us to run the same CNN computation again and again (~2000 times!). His insight was simple — <strong>Why not run the CNN just once per image and then find a way to share that computation across the ~2000 proposals?</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/1*4K_Bq1AhAsTe9vlT0wsdXQ.png" alt="img"></p><p>In RoIPool, a full forward pass of the image is created and the conv features for each region of interest are extracted from the resulting forward pass. Source: Stanford’s CS231N slides by Fei Fei Li, Andrei Karpathy, and Justin Johnson.</p><p>This is exactly what Fast R-CNN does using a technique known as RoIPool (Region of Interest Pooling). At its core, RoIPool shares the forward pass of a CNN for an image across its subregions. In the image above, notice how the CNN features for each region are obtained by selecting a corresponding region from the CNN’s feature map. Then, the features in each region are pooled (usually using max pooling). So all it takes us is one pass of the original image as opposed to ~2000!</p><p><strong>Fast R-CNN Insight 2: Combine All Models into One Network</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/1*E_P1vAEbGT4HNYjqMtIz4g.png" alt="img"></p><p>Fast R-CNN combined the CNN, classifier, and bounding box regressor into one, single network. Source: <a href="https://www.slideshare.net/simplyinsimple/detection-52781995" target="_blank" rel="external">https://www.slideshare.net/simplyinsimple/detection-52781995</a>.</p><p>The second insight of Fast R-CNN is to jointly train the CNN, classifier, and bounding box regressor in a single model. Where earlier we had different models to extract image features (CNN), classify (SVM), and tighten bounding boxes (regressor), <strong>Fast R-CNN instead used a single network to compute all three.</strong></p><p>You can see how this was done in the image above. Fast R-CNN replaced the SVM classifier with a softmax layer on top of the CNN to output a classification. It also added a linear regression layer parallel to the softmax layer to output bounding box coordinates. In this way, all the outputs needed came from one single network! Here are the inputs and outputs to this overall model:</p><ul><li><strong>Inputs</strong>: Images with region proposals.</li><li><strong>Outputs</strong>: Object classifications of each region along with tighter bounding boxes.</li></ul><hr><h4 id="2016-Faster-R-CNN-Speeding-Up-Region-Proposal"><a href="#2016-Faster-R-CNN-Speeding-Up-Region-Proposal" class="headerlink" title="2016: Faster R-CNN - Speeding Up Region Proposal"></a>2016: Faster R-CNN - Speeding Up Region Proposal</h4><p>Even with all these advancements, there was still one remaining bottleneck in the Fast R-CNN process — the region proposer. As we saw, the very first step to detecting the locations of objects is generating a bunch of potential bounding boxes or regions of interest to test. In Fast R-CNN, these proposals were created using <strong>Selective Search</strong>, a fairly slow process that was found to be the bottleneck of the overall process.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*xY9rmw06KZWQlNIPk6ItqA.png" alt="img"></p><p>Jian Sun, a principal researcher at Microsoft Research, led the team behind Faster R-CNN. Source: <a href="https://blogs.microsoft.com/next/2015/12/10/microsoft-researchers-win-imagenet-computer-vision-challenge/#sm.00017fqnl1bz6fqf11amuo0d9ttdp" target="_blank" rel="external">https://blogs.microsoft.com/next/2015/12/10/microsoft-researchers-win-imagenet-computer-vision-challenge/#sm.00017fqnl1bz6fqf11amuo0d9ttdp</a></p><p>In the middle 2015, a team at Microsoft Research composed of Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun, found a way to make the region proposal step almost cost free through an architecture they (creatively) named Faster R-CNN.</p><p>The insight of Faster R-CNN was that region proposals depended on features of the image that were already calculated with the forward pass of the CNN (first step of classification). <strong>So why not reuse those same CNN results for region proposals instead of running a separate selective search algorithm?</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/0*_nNI03ESXm2P6YXO." alt="img"></p><p>In Faster R-CNN, a single CNN is used for region proposals, and classifications. Source: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a>.</p><p>Indeed, this is just what the Faster R-CNN team achieved. In the image above, you can see how a single CNN is used to both carry out region proposals and classification. This way, <strong>only one CNN needs to be trained</strong> and we get region proposals almost for free! The authors write:</p><blockquote><p>Our observation is that the convolutional feature maps used by region-based detectors, like Fast R- CNN, can also be used for generating region proposals [thus enabling nearly cost-free region proposals].</p></blockquote><p>Here are the inputs and outputs of their model:</p><ul><li><strong>Inputs</strong>: Images (Notice how region proposals are not needed).</li><li><strong>Outputs</strong>: Classifications and bounding box coordinates of objects in the images.</li></ul><p><strong>How the Regions are Generated</strong></p><p>Let’s take a moment to see how Faster R-CNN generates these region proposals from CNN features. Faster R-CNN adds a Fully Convolutional Network on top of the features of the CNN creating what’s known as the <strong>Region Proposal Network</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/0*n6pZEyvW47nlcdQz." alt="img"></p><p>The Region Proposal Network slides a window over the features of the CNN. At each window location, the network outputs a score and a bounding box per anchor (hence 4k box coordinates where k is the number of anchors). Source: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a>.</p><p>The Region Proposal Network works by passing a sliding window over the CNN feature map and at each window, outputting <strong>k </strong>potential bounding boxes and scores for how good each of those boxes is expected to be. What do these <strong>k </strong>boxes represent?</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*pJ3OTVXjtp9vWfBOPsnWIw.png" alt="img"></p><p>We know that the bounding boxes for people tend to be rectangular and vertical. We can use this intuition to guide our Region Proposal networks through creating an anchor of such dimensions. Image Source: <a href="http://vlm1.uta.edu/~athitsos/courses/cse6367_spring2011/assignments/assignment1/bbox0062.jpg" target="_blank" rel="external">http://vlm1.uta.edu/~athitsos/courses/cse6367_spring2011/assignments/assignment1/bbox0062.jpg</a>.</p><p>Intuitively, we know that objects in an image should fit certain common aspect ratios and sizes. For instance, we know that we want some rectangular boxes that resemble the shapes of humans. Likewise, we know we won’t see many boxes that are very very thin. In such a way, we create <strong>k</strong> such common aspect ratios we call <strong>anchor boxes</strong>. For each such anchor box, we output one bounding box and score per position in the image.</p><p>With these anchor boxes in mind, let’s take a look at the inputs and outputs to this Region Proposal Network:</p><ul><li><strong>Inputs</strong>: CNN Feature Map.</li><li><strong>Outputs</strong>: A bounding box per anchor. A score representing how likely the image in that bounding box will be an object.</li></ul><p>We then pass each such bounding box that is likely to be an object into Fast R-CNN to generate a classification and tightened bounding boxes.</p><hr><h4 id="2017-Mask-R-CNN-Extending-Faster-R-CNN-for-Pixel-Level-Segmentation"><a href="#2017-Mask-R-CNN-Extending-Faster-R-CNN-for-Pixel-Level-Segmentation" class="headerlink" title="2017: Mask R-CNN - Extending Faster R-CNN for Pixel Level Segmentation"></a>2017: Mask R-CNN - Extending Faster R-CNN for Pixel Level Segmentation</h4><p><img src="https://cdn-images-1.medium.com/max/1000/1*E_5qBTrotLzclyaxsekBmQ.png" alt="img"></p><p>The goal of image instance segmentation is to identify, at a pixel level, what the different objets in a scene are. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><p>So far, we’ve seen how we’ve been able to use CNN features in many interesting ways to effectively locate different objects in an image with bounding boxes.</p><p>Can we extend such techniques to go one step further and locate exact pixels of each object instead of just bounding boxes? This problem, known as image segmentation, is what Kaiming He and a team of researchers, including Girshick, explored at Facebook AI using an architecture known as <strong>Mask R-CNN</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*cYW3EdKx75Stl1EreATdfw.png" alt="img"></p><p>Kaiming He, a researcher at Facebook AI, is lead author of Mask R-CNN and also a coauthor of Faster R-CNN.</p><p>Much like Fast R-CNN, and Faster R-CNN, Mask R-CNN’s underlying intuition is straight forward. Given that Faster R-CNN works so well for object detection, could we extend it to also carry out pixel level segmentation?</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*BiRpf-ogjxARQf5LxI17Jw.png" alt="img"></p><p>In Mask R-CNN, a Fully Convolutional Network (FCN) is added on top of the CNN features of Faster R-CNN to generate a mask (segmentation output). Notice how this is in parallel to the classification and bounding box regression network of Faster R-CNN. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><p>Mask R-CNN does this by adding a branch to Faster R-CNN that outputs a binary mask that says whether or not a given pixel is part of an object. The branch (in white in the above image), as before, is just a Fully Convolutional Network on top of a CNN based feature map. Here are its inputs and outputs:</p><ul><li><strong>Inputs</strong>: CNN Feature Map.</li><li><strong>Outputs</strong>: Matrix with 1s on all locations where the pixel belongs to the object and 0s elsewhere (this is known as a <a href="https://en.wikipedia.org/wiki/Mask_%28computing%29" target="_blank" rel="external">binary mask</a>).</li></ul><p>But the Mask R-CNN authors had to make one small adjustment to make this pipeline work as expected.</p><p><strong>RoiAlign - Realigning RoIPool to be More Accurate</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/0*KtaZfpUErYqwH4RX." alt="img"></p><p>Instead of RoIPool, the image gets passed through RoIAlign so that the regions of the feature map selected by RoIPool correspond more precisely to the regions of the original image. This is needed because pixel level segmentation requires more fine-grained alignment than bounding boxes. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><p>When run without modifications on the original Faster R-CNN architecture, the Mask R-CNN authors realized that the regions of the feature map selected by RoIPool were slightly misaligned from the regions of the original image. Since image segmentation requires pixel level specificity, unlike bounding boxes, this naturally led to inaccuracies.</p><p>The authors were able to solve this problem by cleverly adjusting RoIPool to be more precisely aligned using a method known as RoIAlign.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*VDGql5VDbLWU3jOhRmzwFQ.jpeg" alt="img"></p><p>How do we accurately map a region of interest from the original image onto the feature map?</p><p>Imagine we have an image of size <strong>128x128</strong> and a feature map of size <strong>25x25</strong>. Let’s imagine we want features the region corresponding to the top-left <strong>15x15</strong>pixels in the original image (see above). How might we select these pixels from the feature map?</p><p>We know each pixel in the original image corresponds to ~ 25/128 pixels in the feature map. To select 15 pixels from the original image, we just select 15 <em>25/128 ~= <em>*2.93</em></em> pixels.</p><p>In RoIPool, we would round this down and select 2 pixels causing a slight misalignment. However, in RoIAlign, <strong>we avoid such rounding.</strong> Instead, we use <a href="https://en.wikipedia.org/wiki/Bilinear_interpolation" target="_blank" rel="external">bilinear interpolation</a> to get a precise idea of what would be at pixel 2.93. This, at a high level, is what allows us to avoid the misalignments caused by RoIPool.</p><p>Once these masks are generated, Mask R-CNN combines them with the classifications and bounding boxes from Faster R-CNN to generate such wonderfully precise segmentations:</p><p><img src="https://cdn-images-1.medium.com/max/1250/1*6CClgIKH8zhZjmcftfNoEQ.png" alt="img"></p><p>Mask R-CNN is able to segment as well as classify the objects in an image. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><hr><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>If you’re interested in trying out these algorithms yourselves, here are relevant repositories:</p><p><strong>Faster R-CNN</strong></p><ul><li>Caffe: <a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="external">https://github.com/rbgirshick/py-faster-rcnn</a></li><li>PyTorch: <a href="https://github.com/longcw/faster_rcnn_pytorch" target="_blank" rel="external">https://github.com/longcw/faster_rcnn_pytorch</a></li><li>MatLab: <a href="https://github.com/ShaoqingRen/faster_rcnn" target="_blank" rel="external">https://github.com/ShaoqingRen/faster_rcnn</a></li></ul><p><strong>Mask R-CNN</strong></p><ul><li>PyTorch: <a href="https://github.com/felixgwu/mask_rcnn_pytorch" target="_blank" rel="external">https://github.com/felixgwu/mask_rcnn_pytorch</a></li><li>TensorFlow: <a href="https://github.com/CharlesShang/FastMaskRCNN" target="_blank" rel="external">https://github.com/CharlesShang/FastMaskRCNN</a></li></ul><p>Reblog from <a href="https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4" target="_blank" rel="external">here</a>.</p></div><div></div><div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Deep-learning/" rel="tag"># Deep learning</a> <a href="/tags/machine-learning/" rel="tag"># machine learning</a> <a href="/tags/CNN/" rel="tag"># CNN</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/03/27/Understanding-nested-list-comprehension-syntax-in-Python/" rel="next" title="Understanding nested list comprehension syntax in Python"><i class="fa fa-chevron-left"></i> Understanding nested list comprehension syntax in Python</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018/04/10/Some-Paper-Summaries-of-Semantic-Segmentation-with-Deep-Learning/" rel="prev" title="Some Paper Summaries of Semantic Segmentation with Deep Learning">Some Paper Summaries of Semantic Segmentation with Deep Learning <i class="fa fa-chevron-right"></i></a></div></div></footer></article><div class="post-spread"><div class="addthis_inline_share_toolbox"><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-58f731508143741d" async></script></div></div></div></div><div class="comments" id="comments"><div id="hypercomments_widget"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">Table of Contents</li><li class="sidebar-nav-overview" data-target="site-overview">Overview</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ewan Li"><p class="site-author-name" itemprop="name">Ewan Li</p><p class="site-description motion-element" itemprop="description">Ewan's IT Blog</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">109</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">57</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/ewanlee" target="_blank" title="Github"><i class="fa fa-fw fa-globe"></i> Github </a></span><span class="links-of-author-item"><a href="http://weibo.com/3946248928/profile?topnav=1&wvr=6" target="_blank" title="Weibo"><i class="fa fa-fw fa-weibo"></i> Weibo</a></span></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#Goals-of-this-Post"><span class="nav-number">1.</span> <span class="nav-text">Goals of this Post</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2014-R-CNN-An-Early-Application-of-CNNs-to-Object-Detection"><span class="nav-number">2.</span> <span class="nav-text">2014: R-CNN - An Early Application of CNNs to Object Detection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2015-Fast-R-CNN-Speeding-up-and-Simplifying-R-CNN"><span class="nav-number">3.</span> <span class="nav-text">2015: Fast R-CNN - Speeding up and Simplifying R-CNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2016-Faster-R-CNN-Speeding-Up-Region-Proposal"><span class="nav-number">4.</span> <span class="nav-text">2016: Faster R-CNN - Speeding Up Region Proposal</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2017-Mask-R-CNN-Extending-Faster-R-CNN-for-Pixel-Level-Segmentation"><span class="nav-number">5.</span> <span class="nav-text">2017: Mask R-CNN - Extending Faster R-CNN for Pixel Level Segmentation</span></a></li></ol><li class="nav-item nav-level-3"><a class="nav-link" href="#Code"><span class="nav-number"></span> <span class="nav-text">Code</span></a></li></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Ewan Li</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user">本站访客数</i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人次</span> <span class="site-pv"><i class="fa fa-eye">本站总访问量</i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">_hcwp=window._hcwp||[],_hcwp.push({widget:"Bloggerstream",widget_id:89825,selector:".hc-comment-count",label:"{%COUNT%}"}),_hcwp.push({widget:"Stream",widget_id:89825,xid:"2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/"}),function(){if(!("HC_LOAD_INIT"in window)){HC_LOAD_INIT=!0;var t=(navigator.language||navigator.systemLanguage||navigator.userLanguage||"en").substr(0,2).toLowerCase(),e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src=("https:"==document.location.protocol?"https":"http")+"://w.hypercomments.com/widget/hc/89825/"+t+"/widget.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(e,a.nextSibling)}}()</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("e27VKX5tTklQLCtF7iNMmhcA-gzGzoHsz","nnQn2znNgXXEdK7W2bVJ3bfK")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script></body></html>