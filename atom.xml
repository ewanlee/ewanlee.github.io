<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Abracadabra</title>
  <subtitle>Do it yourself</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-10-17T09:15:07.256Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Ewan Li</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Curiosity-Driven Learning made easy Part I (Repost)</title>
    <link href="http://yoursite.com/2018/10/17/Curiosity-Driven-Learning-made-easy-Part-I-Repost/"/>
    <id>http://yoursite.com/2018/10/17/Curiosity-Driven-Learning-made-easy-Part-I-Repost/</id>
    <published>2018-10-17T09:13:19.000Z</published>
    <updated>2018-10-17T09:15:07.256Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Curiosity-Driven-Learning-made-easy-Part-I"><a href="#Curiosity-Driven-Learning-made-easy-Part-I" class="headerlink" title="Curiosity-Driven Learning made easy Part I"></a>Curiosity-Driven Learning made easy Part I</h1><blockquote><p>This article is part of Deep Reinforcement Learning Course with Tensorflow üïπÔ∏è. Check the syllabus <a href="https://simoninithomas.github.io/Deep_reinforcement_learning_Course/" target="_blank" rel="external">here</a>.</p></blockquote><p><img src="https://cdn-images-1.medium.com/max/2000/0*qvMOs9XAWBAGfCgU.jpg" alt="img"></p><p>OpenAI Five contest</p><p>In the recent years, we‚Äôve seen a lot of innovations in Deep Reinforcement Learning. From <a href="https://deepmind.com/research/dqn/" target="_blank" rel="external">DeepMind and the Deep Q learning architecture</a> in 2014 to <a href="https://blog.openai.com/openai-five/" target="_blank" rel="external">OpenAI playing Dota2 with OpenAI five in 2018</a>, we live in an exciting and promising moment.</p><p>And today we‚Äôll learn about Curiosity-Driven Learning, <strong>one of the most exciting and promising strategy in Deep Reinforcement Learning.</strong></p><p>Reinforcement Learning is based on the <a href="https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419" target="_blank" rel="external">reward hypothesis</a>, which is the idea that each goal can be described as the maximization of the rewards. However, the current problem of extrinsic rewards (aka rewards given by the environment) is that <strong>this function is hard coded by a human, which is not scalable.</strong></p><p>The idea of Curiosity-Driven learning, is to build a reward function that is <strong>intrinsic to the agent</strong> (generated by the agent itself). It means that the agent will be a self-learner since he will be the student but also the feedback master.</p><a id="more"></a><p><img src="https://cdn-images-1.medium.com/max/1600/1*SI8itmr1PZPkXCBtgIh2Sw.png" alt="img"></p><p>Sounds crazy? Yes but that‚Äôs a genius idea that was introduced in the 2017 paper <a href="https://pathak22.github.io/noreward-rl/" target="_blank" rel="external">Curiosity-driven Exploration by Self-supervised Prediction</a>. The results were then improved with the second paper <a href="https://pathak22.github.io/large-scale-curiosity/" target="_blank" rel="external">Large-Scale Study of Curiosity-Driven Learning.</a></p><p>They discovered that curiosity driven learning agents perform as good as if they had extrinsic rewards, <strong>and were able to generalize better with unexplored environments.</strong></p><p>In this first article we‚Äôll talk about the theory and explain how works Curiosity Driven Learning in theory.</p><p>Then, in a second article, we‚Äôll implement a Curiosity driven PPO agent playing Super Mario Bros.</p><p>Sounds fun? Let‚Äôs dive on in !</p><h3 id="Two-main-problems-in-Reinforcement-Learning"><a href="#Two-main-problems-in-Reinforcement-Learning" class="headerlink" title="Two main problems in Reinforcement Learning"></a>Two main problems in Reinforcement Learning</h3><p>First, the problem of <em>sparse rewards</em>, which is the time difference between an action and its feedback (its reward). An agent learns fast if each of its action has a reward, so that he gets a rapid feedback.</p><p>For instance, if you play Space Invaders, you shoot and kill an enemy, you get a reward. Consequently you‚Äôll understand that this action at that state was good.</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*jhrhZm8G1rQfpxEF8l5XoQ.png" alt="img"></p><p>Thanks the reward our agent knows that this action at that state was good</p><p>However, in complex games such as real time strategy games, you will not have a direct reward for each of your actions. Therefore, a bad decision will not have a feedback until hours later.</p><p>For example, if we take Age Of Empires II, we can see on the first image that agent decided to build one barrack and focus on collecting resources. Thus in the second picture (some hours after) the enemies destroyed our barrack consequently we have ton of resources but we can‚Äôt create an army so we‚Äôre dead.</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*c6DjPzsDc9Qd-Iv-_Y8fxg.png" alt="img"></p><p>Enemies destroyed our barrack</p><p>The second big problem is that <em>extrinsic rewards are not scalable</em>. Since in each environment, a human implemented a reward function. But how we can scale that in big and complex environments?</p><p>The solution is to develop a reward function that is intrinsic to the agent (generated by the agent itself). <strong>This reward function will be called curiosity.</strong></p><h3 id="A-new-reward-function-curiosity"><a href="#A-new-reward-function-curiosity" class="headerlink" title="A new reward function: curiosity"></a>A new reward function: curiosity</h3><p>Curiosity is an intrinsic reward that is equal to the <strong>error of our agent to predict the consequence of its own actions given its current state (aka to predict the next state given current state and action taken).</strong></p><p>Why? Because the idea of curiosity is <strong>to encourage our agent to perform actions that reduce the uncertainty in the agent‚Äôs ability to predict the consequence of its own action</strong> (uncertainty will be higher <strong>in areas where the agent has spent less time,</strong> or in areas with complex dynamics).</p><p>Consequently measuring error requires <strong>building a model of environmental dynamics that predicts the next state given the current state and the action a.</strong></p><blockquote><p>The question that we can ask here is how we can calculate this error?</p></blockquote><p>To calculate curiosity, we will use a module introduced in the first paper called Intrinsic Curiosity module.</p><h3 id="Introducing-the-Intrinsic-Curiosity-Module"><a href="#Introducing-the-Intrinsic-Curiosity-Module" class="headerlink" title="Introducing the Intrinsic Curiosity Module"></a>Introducing the Intrinsic Curiosity Module</h3><h4 id="The-need-of-a-good-feature-space"><a href="#The-need-of-a-good-feature-space" class="headerlink" title="The need of a good feature space"></a>The need of a good feature space</h4><p>Before diving into the description of the module, we must ask ourselves <strong>how our agent can predict the next state given our current state and our action?</strong></p><p>We know that we can define the curiosity as the error between the predicted new state (st+1) given our state st and action at and the real new state.</p><p>But, remember that most of the time, our state is a stack of 4 frames (pixels). It means that we need to find a way to predict the next stack of frames which is really hard for two reasons:</p><p>First of all, it‚Äôs hard to predict the pixels directly, imagine you‚Äôre in Doom you move left, you need to predict 248*248 = 61504 pixels!</p><p>Second, the researchers think that‚Äôs not the right thing to do and take a good example to prove it.</p><p>Imagine you need to study the movement of the tree leaves in a breeze. First of all, it‚Äôs already hard to model breeze, consequently it is much harder to predict the pixel location of each leaves at each time step.</p><p>The problem, is that because you‚Äôll always have a big pixel prediction error, the agent will always be curious even if the movement of the leaves is not the consequence of the agent actions <strong>therefore its continued curiosity is undesirable.</strong></p><p>Trying to predict the movement of each pixel at each timeframe is really hard</p><p>So instead of making prediction in the raw sensory space (pixels), we <strong>need to transform the raw sensory input (array of pixels) into a feature space with only relevant information.</strong></p><p>We need to define what rules must respect a good feature space, there are 3:</p><ul><li>Needs to model things that can be <strong>controlled by the agent.</strong></li><li>Needs also to model things that can‚Äôt be controlled by the agent but that <strong>can affect an agent.</strong></li><li>Needs to not model (and consequently be unaffected) by things that are not in agent‚Äôs control and have no effect on him.</li></ul><p>Let‚Äôs take this example, your agent is a car, if we want to create a good feature representation we need to model:</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*r5i0ZxqEWNE5nvY5thMdYg.png" alt="img"></p><p>The yellow boxes are the important elements</p><p>Our car (controlled by our agent), the other cars (we can‚Äôt control it but that can affect the agent) but we don‚Äôt need to model the leaves (not affect the agent and we can‚Äôt control it). This way we will have a feature representation with less noise.</p><p>The desired embedding space should:</p><ul><li>Be compact in terms of dimensional (remove irrelevant parts of the observation space).</li><li>Preserve sufficient information about the observation.</li><li>Stable: <strong>because non-stationary rewards make it difficult for reinforcement agents to learn.</strong></li></ul><h4 id="Intrinsic-Curiosity-Module-ICM"><a href="#Intrinsic-Curiosity-Module-ICM" class="headerlink" title="Intrinsic Curiosity Module (ICM)"></a>Intrinsic Curiosity Module (ICM)</h4><p><img src="https://cdn-images-1.medium.com/max/1600/1*JHhacgi6jzpzKtReLgNE2w.png" alt="img"></p><p>ICM Taken from the<a href="https://pathak22.github.io/noreward-rl/resources/icml17.pdf" target="_blank" rel="external"> Paper</a></p><p>The Intrinsic Curiosity Module is the system <strong>that helps us to generate curiosity.</strong> It is composed of two neural networks.</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*pLDg3MIz5Q6TRsGesVmRwA.png" alt="img"></p><p>Remember, we want to only predict changes in the environment <strong>that could possibly be due to the actions of our agent or affect the agent and ignore the rest.</strong> It means, we need instead of making predictions from a raw sensory space (pixels), transform the sensory input <strong>into a feature vector where only the information relevant to the action performed by the agent is represented.</strong></p><p>To learn this feature space: we <strong>use self-supervision</strong>, training a neural network on a proxy inverse dynamics task of predicting the agent action (√¢t) given its current and next states (st and st+1).</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*xJehwVNbkI6SdrShiSyCbQ.png" alt="img"></p><p>Inverse Model Part</p><p>Since the neural network is only required to predict the action, <strong>it has no incentive to represent within its feature embedding space, the factors of variation in the environment that does not affect the agent itself.</strong></p><p><img src="https://cdn-images-1.medium.com/max/1600/1*k8gMwh8_ZVgE2bVCKZo_gA.png" alt="img"></p><p>Forward Model Part</p><p>Then we use this feature space to train a forward dynamics model that predicts the future representation of the next state phi(st+1), <strong>given the feature representation of the current state phi(st) and the action at.</strong></p><p>And we provide the prediction error of the forward dynamics model to the agent <strong>as an intrinsic reward to encourage its curiosity.</strong></p><p>Curiosity = predicted_phi(st+1)‚Ää‚Äî‚Ääphi(st+1)</p><p>So, we have two models in ICM:</p><ul><li><em>Inverse Model</em> (Blue): Encode the states st and st+1 into the feature vectors phi(st) and phi(st+1) that are trained to predict action √¢t.</li></ul><p><img src="https://cdn-images-1.medium.com/max/1600/1*G7O492AyEu-jlOHHQvTRug.png" alt="img"></p><p><img src="https://cdn-images-1.medium.com/max/1600/1*hw9WW9_DqI2DLiK5GjOSig.png" alt="img"></p><p>Inverse Loss function that measures the difference between the real action and our predicted action</p><ul><li><em>Forward Model</em> (Red): Takes as input phi(st) and at and predict the feature representation phi(st+1) of st+1.</li></ul><p><img src="https://cdn-images-1.medium.com/max/1600/1*EsMzj_wLYR_kx1UZ2fC1dQ.png" alt="img"></p><p><img src="https://cdn-images-1.medium.com/max/1600/1*cmKEatcnl83GRZ8kJriBiQ.png" alt="img"></p><p>Forward Model Loss function</p><p>Then mathematically speaking, curiosity will be the difference between our predicted feature vector of the next state and the real feature vector of the next state.</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*-hRqX-e4OEcJlc6jp8rgRw.png" alt="img"></p><p>Finally the overall optimization problem of this module is a composition of Inverse Loss, Forward Loss.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*4BiRJ-_jGRF8N1HRFInBtQ.png" alt="img"></p><p>That‚Äôs was a lot of information and mathematics!</p><p>To recap:</p><ul><li>Because of extrinsic rewards implementation and sparse rewards problems, <strong>we want to create a reward that is intrinsic to the agent.</strong></li><li>To do that we created curiosity, <strong>which is the agent‚Äôs error in predicting the consequence of its action given its current state.</strong></li><li>Using curiosity will push our agent to <strong>favor transitions with high prediction error</strong> (which will be higher <strong>in areas where the agent has spent less time,</strong> or in areas with complex dynamics) and consequently better explore our environment.</li><li>But because we can‚Äôt predict the next state by predicting the next frame (too much complicated), we use a <strong>better feature representation that will keep only elements that can be controlled by our agent or affect our agent.</strong></li><li>To generate curiosity, we use Intrinsic Curiosity module that is composed of two models: <strong>Inverse Model</strong> that is used to learn the feature representation of state and next state and <strong>Forward Dynamics</strong> model used to generate the predicted feature representation of the next state.</li><li>Curiosity will be equal <strong>to the difference between predicted_phi(st+1) (Forward Dynamics model) and phi(st+1) (Inverse Dynamics model)</strong></li></ul><p>That‚Äôs all for today! Now that you understood the theory, you should read the two papers experiments results <a href="https://pathak22.github.io/noreward-rl/" target="_blank" rel="external">Curiosity-driven Exploration by Self-supervised Prediction</a> <a href="https://pathak22.github.io/large-scale-curiosity/" target="_blank" rel="external">and Large-Scale Study of Curiosity-Driven Learning.</a></p><p>Next time, we‚Äôll implement a PPO agent using curiosity as intrinsic reward to play Super Mario Bros.</p><hr><p>Source address is <a href="https://towardsdatascience.com/curiosity-driven-learning-made-easy-part-i-d3e5a2263359" target="_blank" rel="external">here</a>,</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Curiosity-Driven-Learning-made-easy-Part-I&quot;&gt;&lt;a href=&quot;#Curiosity-Driven-Learning-made-easy-Part-I&quot; class=&quot;headerlink&quot; title=&quot;Curiosity-Driven Learning made easy Part I&quot;&gt;&lt;/a&gt;Curiosity-Driven Learning made easy Part I&lt;/h1&gt;&lt;blockquote&gt;&lt;p&gt;This article is part of Deep Reinforcement Learning Course with Tensorflow üïπÔ∏è. Check the syllabus &lt;a href=&quot;https://simoninithomas.github.io/Deep_reinforcement_learning_Course/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/2000/0*qvMOs9XAWBAGfCgU.jpg&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;&lt;p&gt;OpenAI Five contest&lt;/p&gt;&lt;p&gt;In the recent years, we‚Äôve seen a lot of innovations in Deep Reinforcement Learning. From &lt;a href=&quot;https://deepmind.com/research/dqn/&quot;&gt;DeepMind and the Deep Q learning architecture&lt;/a&gt; in 2014 to &lt;a href=&quot;https://blog.openai.com/openai-five/&quot;&gt;OpenAI playing Dota2 with OpenAI five in 2018&lt;/a&gt;, we live in an exciting and promising moment.&lt;/p&gt;&lt;p&gt;And today we‚Äôll learn about Curiosity-Driven Learning, &lt;strong&gt;one of the most exciting and promising strategy in Deep Reinforcement Learning.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Reinforcement Learning is based on the &lt;a href=&quot;https://medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419&quot;&gt;reward hypothesis&lt;/a&gt;, which is the idea that each goal can be described as the maximization of the rewards. However, the current problem of extrinsic rewards (aka rewards given by the environment) is that &lt;strong&gt;this function is hard coded by a human, which is not scalable.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The idea of Curiosity-Driven learning, is to build a reward function that is &lt;strong&gt;intrinsic to the agent&lt;/strong&gt; (generated by the agent itself). It means that the agent will be a self-learner since he will be the student but also the feedback master.&lt;/p&gt;
    
    </summary>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
  </entry>
  
  <entry>
    <title>Validation Checklist in Kaggle Competition</title>
    <link href="http://yoursite.com/2018/10/16/Validation-Checklist-in-Kaggle-Competition/"/>
    <id>http://yoursite.com/2018/10/16/Validation-Checklist-in-Kaggle-Competition/</id>
    <published>2018-10-16T13:47:42.000Z</published>
    <updated>2018-10-16T13:52:22.383Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Data Splitting Strategies</strong></p><ul><li>Random</li><li>Timewise</li><li>By id (maybe hidden)</li><li>Combined</li></ul><p><strong>Notices</strong></p><ul><li><strong>Make sure the strategy used by train/val splitting is same as train/test splitting.</strong></li><li><strong>Different models trained from different data splitting strategies have much performance gap.</strong></li><li><strong>Logic of feature generation depends on the data splitting strategy.</strong></li></ul><p><strong>Validation problems</strong></p><ul><li>Validation stage<ul><li>Causes of different scores and optimal parameters<ul><li>Too little data</li><li>Too diverse and inconsistent data</li></ul></li><li>Solutions<ul><li>Average scores from different K-Fold splits</li><li>Tune model on one split and evaluate score on the other</li></ul></li></ul></li><li>Submission stage<ul><li>We can observe that<ul><li>LB score is consistently higher/lower than validation score</li><li>LB score is not correlated with validation score at all</li></ul></li><li>Causes<ul><li>We may already have quite different scores in K-Fold<ul><li>make sure split train/validation correct</li></ul></li><li>too litter data in public LB<ul><li>Just trust your validation scores</li></ul></li><li>train and test data are from different distributions<ul><li>classes show in the test set not show in the train set<ul><li>make a shift to your prediction (mean of train minus mean of test) ‚Äì LB probing</li></ul></li><li>classes ratio is not same<ul><li>make the validation classes ratio is same as test classes ratio</li></ul></li></ul></li></ul></li></ul></li></ul><p><strong>Expect LB shuffle because of</strong></p><ul><li>Randomness</li><li>Litter amount of data</li><li>Different public/private distributions</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Data Splitting Strategies&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Random&lt;/li&gt;&lt;li&gt;Timewise&lt;/li&gt;&lt;li&gt;By id (maybe hidden)&lt;/li&gt;&lt;li&gt;Combined&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="kaggle" scheme="http://yoursite.com/tags/kaggle/"/>
    
  </entry>
  
  <entry>
    <title>Coursera-dl plugin issues on Windows 10</title>
    <link href="http://yoursite.com/2018/10/16/Coursera-dl-plugin-issues-on-Windows-10/"/>
    <id>http://yoursite.com/2018/10/16/Coursera-dl-plugin-issues-on-Windows-10/</id>
    <published>2018-10-16T12:28:11.000Z</published>
    <updated>2018-10-16T12:29:41.525Z</updated>
    
    <content type="html"><![CDATA[<h1 id="I-can-x27-t-download-the-video"><a href="#I-can-x27-t-download-the-video" class="headerlink" title="I can&#x27;t download the video ~ "></a><a href="https://github.com/coursera-dl/coursera-dl/issues/606" target="_blank" rel="external">I can&#x27;t download the video ~</a></h1><blockquote><p>state: <strong>closed</strong> opened by: <strong>jenkey2011</strong> on: <strong>2017-05-04</strong></p></blockquote><h1 id="I-can-x27-t-download-the-video-1"><a href="#I-can-x27-t-download-the-video-1" class="headerlink" title="I can&#x27;t download the video ~"></a>I can&#x27;t download the video ~</h1><h3 id="Your-environment"><a href="#Your-environment" class="headerlink" title="Your environment"></a>Your environment</h3><ul><li>win10</li><li>Python version : 3.6</li><li>coursera-dl version:0.8</li><li>PSÔºöI&#x27;m from China‚Ä¶‚Ä¶<h3 id="Steps-to-reproduce"><a href="#Steps-to-reproduce" class="headerlink" title="Steps to reproduce"></a>Steps to reproduce</h3>&gt; coursera-dl -u xxx -p xxxx -b html-css-javascript</li></ul><p>Then it works , but only the subtitles were downloaded ; And the cmd shows &quot;The following URLs (64) could not be downloaded:&quot; , they&#x27;re all video links;</p><h3 id="Comments"><a href="#Comments" class="headerlink" title="Comments"></a>Comments</h3><hr><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-301991709" target="_blank" rel="external"><strong>wanghoppe</strong></a> on: <strong>2017-05-17</strong></p></blockquote><h2 id="Me-too-have-the-issue‚Ä¶-Could-someone-help"><a href="#Me-too-have-the-issue‚Ä¶-Could-someone-help" class="headerlink" title="Me too have the issue‚Ä¶. Could someone help??"></a>Me too have the issue‚Ä¶. Could someone help??</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-302359248" target="_blank" rel="external"><strong>lvhuiyang</strong></a> on: <strong>2017-05-18</strong></p></blockquote><p>I met the same problem yesterday.</p><p>I use the command &#x60;coursera-dl -u xx@xxx.com -p xxx course_name ‚Äìwget&#x60; to solve it.</p><h2 id="env-Mac-OS-wget-python3-6"><a href="#env-Mac-OS-wget-python3-6" class="headerlink" title=" (env: Mac OS, wget, python3.6)"></a> (env: Mac OS, wget, python3.6)</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-302361973" target="_blank" rel="external"><strong>balta2ar</strong></a> on: <strong>2017-05-18</strong></p></blockquote><h2 id="Are-you-guys-all-from-China-Did-you-try-downloading-over-a-VPN-or-Tor-If-it-x27-s-your-government-x27-s-firewall-we-can-x27-t-do-anything-about-it-use-proxies-VPNs-and-Tor"><a href="#Are-you-guys-all-from-China-Did-you-try-downloading-over-a-VPN-or-Tor-If-it-x27-s-your-government-x27-s-firewall-we-can-x27-t-do-anything-about-it-use-proxies-VPNs-and-Tor" class="headerlink" title="Are you guys all from China? Did you try downloading over a VPN or Tor? If it&#x27;s your government&#x27;s firewall, we can&#x27;t do anything about it, use proxies, VPNs and Tor."></a>Are you guys all from China? Did you try downloading over a VPN or Tor? If it&#x27;s your government&#x27;s firewall, we can&#x27;t do anything about it, use proxies, VPNs and Tor.</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-302579356" target="_blank" rel="external"><strong>jenkey2011</strong></a> on: <strong>2017-05-19</strong></p></blockquote><h2 id="I-guess-so‚Ä¶‚Ä¶-What-a-pity"><a href="#I-guess-so‚Ä¶‚Ä¶-What-a-pity" class="headerlink" title="I guess so‚Ä¶‚Ä¶ What a pity."></a>I guess so‚Ä¶‚Ä¶ What a pity.</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-305698809" target="_blank" rel="external"><strong>FBryce</strong></a> on: <strong>2017-06-02</strong></p></blockquote><h2 id="Hi-If-you-are-from-China-adding-quot-52-84-246-72-d3c33hcgiwev3-cloudfront-net-quot-in-the-host-file-and-fresh-dns-with-quot-ipconfig-flushdns-quot-may-work"><a href="#Hi-If-you-are-from-China-adding-quot-52-84-246-72-d3c33hcgiwev3-cloudfront-net-quot-in-the-host-file-and-fresh-dns-with-quot-ipconfig-flushdns-quot-may-work" class="headerlink" title="Hi, If you are from China, adding  &quot;52.84.246.72  d3c33hcgiwev3.cloudfront.net&quot; in the host file and fresh dns with &quot; ipconfig/flushdns&quot;  may work "></a>Hi, If you are from China, adding &quot;52.84.246.72 d3c33hcgiwev3.cloudfront.net&quot; in the host file and fresh dns with &quot; ipconfig/flushdns&quot; may work</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-305716556" target="_blank" rel="external"><strong>wanghoppe</strong></a> on: <strong>2017-06-02</strong></p></blockquote><a id="more"></a><h2 id="FBryce-It-worked-Thank-you-so-much"><a href="#FBryce-It-worked-Thank-you-so-much" class="headerlink" title="@FBryce It worked! Thank you so much."></a>@FBryce It worked! Thank you so much.</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-318615319" target="_blank" rel="external"><strong>XiangBicheng</strong></a> on: <strong>2017-07-28</strong></p></blockquote><h2 id="FBryce-Nice-Thank-you-for-useful-information"><a href="#FBryce-Nice-Thank-you-for-useful-information" class="headerlink" title="@FBryce Nice! Thank you for useful information."></a>@FBryce Nice! Thank you for useful information.</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-324089509" target="_blank" rel="external"><strong>techlarry</strong></a> on: <strong>2017-08-23</strong></p></blockquote><h2 id="Good-job-FBryce-I-downloaded-several-courses-manually-because-of-the-issue-It-wasted-me-at-least-half-day-to-download-files‚Ä¶"><a href="#Good-job-FBryce-I-downloaded-several-courses-manually-because-of-the-issue-It-wasted-me-at-least-half-day-to-download-files‚Ä¶" class="headerlink" title="Good job @FBryce, I downloaded several courses manually because of the issue. It wasted me at least half day to download files‚Ä¶."></a>Good job @FBryce, I downloaded several courses manually because of the issue. It wasted me at least half day to download files‚Ä¶.</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-325155491" target="_blank" rel="external"><strong>balta2ar</strong></a> on: <strong>2017-08-27</strong></p></blockquote><p>&gt; Hi, If you are from China, adding &quot;52.84.246.72 d3c33hcgiwev3.cloudfront.net&quot; in the host file and fresh dns with &quot; ipconfig/flushdns&quot; may work</p><h2 id="I-x27-ve-added-your-comment-to-the-readme-Thanks-Closing"><a href="#I-x27-ve-added-your-comment-to-the-readme-Thanks-Closing" class="headerlink" title="I&#x27;ve added your comment to the readme. Thanks! Closing."></a>I&#x27;ve added your comment to the readme. Thanks! Closing.</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-353938932" target="_blank" rel="external"><strong>wenxingxing</strong></a> on: <strong>2017-12-26</strong></p></blockquote><h2 id="It-works-thanks"><a href="#It-works-thanks" class="headerlink" title="It works, thanks~~"></a>It works, thanks~~</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-423740448" target="_blank" rel="external"><strong>1c7</strong></a> on: <strong>2018-09-22</strong></p></blockquote><p><img src="https://user-images.githubusercontent.com/1804755/45917239-53d2b800-bea5-11e8-91b0-4c421b5b9cb8.png" alt="image"></p><h2 id="Still-work-in-2018-Thanks"><a href="#Still-work-in-2018-Thanks" class="headerlink" title="Still work in 2018, Thanks!"></a>Still work in 2018, Thanks!</h2><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-427588031" target="_blank" rel="external"><strong>shuoooo</strong></a> on: <strong>2018-10-07</strong></p></blockquote><p>&gt; Hi, If you are from China, adding &quot;52.84.246.72 d3c33hcgiwev3.cloudfront.net&quot; in the host file and fresh dns with &quot; ipconfig/flushdns&quot; may work</p><p>Works beautifully, thanks a lot</p><h1 id="Could-not-authenticate-Cannot-login-on-coursera-org-400-Client-Error-Bad-Request-for-url-https-api-coursera-org-api-login-v3"><a href="#Could-not-authenticate-Cannot-login-on-coursera-org-400-Client-Error-Bad-Request-for-url-https-api-coursera-org-api-login-v3" class="headerlink" title="Could not authenticate: Cannot login on coursera.org: 400 Client Error: Bad Request for url: https://api.coursera.org/api/login/v3"></a><a href="https://github.com/coursera-dl/coursera-dl/issues/670" target="_blank" rel="external">Could not authenticate: Cannot login on coursera.org: 400 Client Error: Bad Request for url: https://api.coursera.org/api/login/v3</a></h1><blockquote><p>state: <strong>closed</strong> opened by: <strong>jeet-parekh</strong> on: <strong>2018-06-15</strong></p></blockquote><h3 id="Subject-of-the-issue"><a href="#Subject-of-the-issue" class="headerlink" title="Subject of the issue"></a>Subject of the issue</h3><p>Running coursera-dl gives an error 400.</p><h3 id="Your-environment-1"><a href="#Your-environment-1" class="headerlink" title="Your environment"></a>Your environment</h3><ul><li>Operating System (name/version): Windows 8.1</li><li>Python version: 3.6.5</li><li>coursera-dl version: 0.11.2</li></ul><h3 id="Steps-to-reproduce-1"><a href="#Steps-to-reproduce-1" class="headerlink" title="Steps to reproduce"></a>Steps to reproduce</h3><p>I ran the command &#x60;coursera-dl -u myusername -p mypassword machine-learning&#x60;.</p><ul><li>Is the problem happening with the latest version of the script?<br>Yes.</li><li>Do you have all the recommended versions of the modules? See them in the<br>file &#x60;requirements.txt&#x60;.<br>Yes. I did a &#x60;pip install&#x60;.</li><li>What is the course that you are trying to access?<br>machine-learning</li><li>What is the precise command line that you are using (don&#x27;t forget to obfuscate<br>your username and password, but leave all other information untouched).<br>&#x60;coursera-dl -u myusername -p mypassword machine-learning&#x60;</li><li>What are the precise messages that you get? Please, use the &#x60;‚Äìdebug&#x60;<br>option before posting the messages as a bug report. Please, copy and paste<br>them. Don&#x27;t reword/paraphrase the messages.</li></ul><p>&#x60;&#x60;&#x60;<br>root[main] coursera_dl version 0.11.2<br>root[main] Downloading class: machine-learning (1 / 1)<br>root[download_class] Downloading new style (on demand) class machine-learning<br>root[login] Initiating login.<br>root[login] There were no .coursera.org cookies to be cleared.<br>root[prepape_auth_headers] Forging cookie header: csrftoken&#x3D;rgrpC7s9fPPIdLTaWeGA; csrf2_token_doUFgKoj&#x3D;G39Y5Rvw4XFBwlb8W8cN5SEM.<br>urllib3.connectionpool[_new_conn] Starting new HTTPS connection (1): api.coursera.org<br>urllib3.connectionpool[_make_request] <a href="https://api.coursera.org:443" target="_blank" rel="external">https://api.coursera.org:443</a> &quot;POST /api/login/v3 HTTP/1.1&quot; 400 None<br>root[main] Could not authenticate: Cannot login on coursera.org: 400 Client Error: Bad Request for url: <a href="https://api.coursera.org/api/login/v3" target="_blank" rel="external">https://api.coursera.org/api/login/v3</a><br>&#x60;&#x60;&#x60;</p><h3 id="Expected-behaviour"><a href="#Expected-behaviour" class="headerlink" title="Expected behaviour"></a>Expected behaviour</h3><p>There would be no errors and the course would download.</p><h3 id="Actual-behaviour"><a href="#Actual-behaviour" class="headerlink" title="Actual behaviour"></a>Actual behaviour</h3><p>The output given above.</p><h3 id="Comments-1"><a href="#Comments-1" class="headerlink" title="Comments"></a>Comments</h3><hr><blockquote><p>from: <a href="https://github.com/coursera-dl/coursera-dl/issues/670#issuecomment-397850484" target="_blank" rel="external"><strong>jeet-parekh</strong></a> on: <strong>2018-06-17</strong></p></blockquote><p>It worked when I used my email id as the user name.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;I-can-x27-t-download-the-video&quot;&gt;&lt;a href=&quot;#I-can-x27-t-download-the-video&quot; class=&quot;headerlink&quot; title=&quot;I can&amp;#x27;t download the video ~ &quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/coursera-dl/coursera-dl/issues/606&quot;&gt;I can&amp;#x27;t download the video ~&lt;/a&gt;&lt;/h1&gt;&lt;blockquote&gt;&lt;p&gt;state: &lt;strong&gt;closed&lt;/strong&gt; opened by: &lt;strong&gt;jenkey2011&lt;/strong&gt; on: &lt;strong&gt;2017-05-04&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h1 id=&quot;I-can-x27-t-download-the-video-1&quot;&gt;&lt;a href=&quot;#I-can-x27-t-download-the-video-1&quot; class=&quot;headerlink&quot; title=&quot;I can&amp;#x27;t download the video ~&quot;&gt;&lt;/a&gt;I can&amp;#x27;t download the video ~&lt;/h1&gt;&lt;h3 id=&quot;Your-environment&quot;&gt;&lt;a href=&quot;#Your-environment&quot; class=&quot;headerlink&quot; title=&quot;Your environment&quot;&gt;&lt;/a&gt;Your environment&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;win10&lt;/li&gt;&lt;li&gt;Python version : 3.6&lt;/li&gt;&lt;li&gt;coursera-dl version:0.8&lt;/li&gt;&lt;li&gt;PSÔºöI&amp;#x27;m from China‚Ä¶‚Ä¶&lt;h3 id=&quot;Steps-to-reproduce&quot;&gt;&lt;a href=&quot;#Steps-to-reproduce&quot; class=&quot;headerlink&quot; title=&quot;Steps to reproduce&quot;&gt;&lt;/a&gt;Steps to reproduce&lt;/h3&gt;&amp;gt; coursera-dl -u xxx -p xxxx -b html-css-javascript&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Then it works , but only the subtitles were downloaded ; And the cmd shows &amp;quot;The following URLs (64) could not be downloaded:&amp;quot; , they&amp;#x27;re all video links;&lt;/p&gt;&lt;h3 id=&quot;Comments&quot;&gt;&lt;a href=&quot;#Comments&quot; class=&quot;headerlink&quot; title=&quot;Comments&quot;&gt;&lt;/a&gt;Comments&lt;/h3&gt;&lt;hr&gt;&lt;blockquote&gt;&lt;p&gt;from: &lt;a href=&quot;https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-301991709&quot;&gt;&lt;strong&gt;wanghoppe&lt;/strong&gt;&lt;/a&gt; on: &lt;strong&gt;2017-05-17&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 id=&quot;Me-too-have-the-issue‚Ä¶-Could-someone-help&quot;&gt;&lt;a href=&quot;#Me-too-have-the-issue‚Ä¶-Could-someone-help&quot; class=&quot;headerlink&quot; title=&quot;Me too have the issue‚Ä¶. Could someone help??&quot;&gt;&lt;/a&gt;Me too have the issue‚Ä¶. Could someone help??&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;from: &lt;a href=&quot;https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-302359248&quot;&gt;&lt;strong&gt;lvhuiyang&lt;/strong&gt;&lt;/a&gt; on: &lt;strong&gt;2017-05-18&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;I met the same problem yesterday.&lt;/p&gt;&lt;p&gt;I use the command &amp;#x60;coursera-dl -u xx@xxx.com -p xxx course_name ‚Äìwget&amp;#x60; to solve it.&lt;/p&gt;&lt;h2 id=&quot;env-Mac-OS-wget-python3-6&quot;&gt;&lt;a href=&quot;#env-Mac-OS-wget-python3-6&quot; class=&quot;headerlink&quot; title=&quot; (env: Mac OS, wget, python3.6)&quot;&gt;&lt;/a&gt; (env: Mac OS, wget, python3.6)&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;from: &lt;a href=&quot;https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-302361973&quot;&gt;&lt;strong&gt;balta2ar&lt;/strong&gt;&lt;/a&gt; on: &lt;strong&gt;2017-05-18&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 id=&quot;Are-you-guys-all-from-China-Did-you-try-downloading-over-a-VPN-or-Tor-If-it-x27-s-your-government-x27-s-firewall-we-can-x27-t-do-anything-about-it-use-proxies-VPNs-and-Tor&quot;&gt;&lt;a href=&quot;#Are-you-guys-all-from-China-Did-you-try-downloading-over-a-VPN-or-Tor-If-it-x27-s-your-government-x27-s-firewall-we-can-x27-t-do-anything-about-it-use-proxies-VPNs-and-Tor&quot; class=&quot;headerlink&quot; title=&quot;Are you guys all from China? Did you try downloading over a VPN or Tor? If it&amp;#x27;s your government&amp;#x27;s firewall, we can&amp;#x27;t do anything about it, use proxies, VPNs and Tor.&quot;&gt;&lt;/a&gt;Are you guys all from China? Did you try downloading over a VPN or Tor? If it&amp;#x27;s your government&amp;#x27;s firewall, we can&amp;#x27;t do anything about it, use proxies, VPNs and Tor.&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;from: &lt;a href=&quot;https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-302579356&quot;&gt;&lt;strong&gt;jenkey2011&lt;/strong&gt;&lt;/a&gt; on: &lt;strong&gt;2017-05-19&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 id=&quot;I-guess-so‚Ä¶‚Ä¶-What-a-pity&quot;&gt;&lt;a href=&quot;#I-guess-so‚Ä¶‚Ä¶-What-a-pity&quot; class=&quot;headerlink&quot; title=&quot;I guess so‚Ä¶‚Ä¶ What a pity.&quot;&gt;&lt;/a&gt;I guess so‚Ä¶‚Ä¶ What a pity.&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;from: &lt;a href=&quot;https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-305698809&quot;&gt;&lt;strong&gt;FBryce&lt;/strong&gt;&lt;/a&gt; on: &lt;strong&gt;2017-06-02&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h2 id=&quot;Hi-If-you-are-from-China-adding-quot-52-84-246-72-d3c33hcgiwev3-cloudfront-net-quot-in-the-host-file-and-fresh-dns-with-quot-ipconfig-flushdns-quot-may-work&quot;&gt;&lt;a href=&quot;#Hi-If-you-are-from-China-adding-quot-52-84-246-72-d3c33hcgiwev3-cloudfront-net-quot-in-the-host-file-and-fresh-dns-with-quot-ipconfig-flushdns-quot-may-work&quot; class=&quot;headerlink&quot; title=&quot;Hi, If you are from China, adding  &amp;quot;52.84.246.72  d3c33hcgiwev3.cloudfront.net&amp;quot; in the host file and fresh dns with &amp;quot; ipconfig/flushdns&amp;quot;  may work &quot;&gt;&lt;/a&gt;Hi, If you are from China, adding &amp;quot;52.84.246.72 d3c33hcgiwev3.cloudfront.net&amp;quot; in the host file and fresh dns with &amp;quot; ipconfig/flushdns&amp;quot; may work&lt;/h2&gt;&lt;blockquote&gt;&lt;p&gt;from: &lt;a href=&quot;https://github.com/coursera-dl/coursera-dl/issues/606#issuecomment-305716556&quot;&gt;&lt;strong&gt;wanghoppe&lt;/strong&gt;&lt;/a&gt; on: &lt;strong&gt;2017-06-02&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>EDA Example I (Springleaf competition)</title>
    <link href="http://yoursite.com/2018/10/16/EDA-Example-I-Springleaf-competition/"/>
    <id>http://yoursite.com/2018/10/16/EDA-Example-I-Springleaf-competition/</id>
    <published>2018-10-16T10:19:20.000Z</published>
    <updated>2018-10-16T10:28:20.153Z</updated>
    
    <content type="html"><![CDATA[<p>This is a notebook, used in the screencast video. Note, that the data files are not present here in Jupyter hub and you will not be able to run it. But you can always download the notebook to your local machine as well as the competition data and make it interactive.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </div><div class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm_notebook</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">%matplotlib inline</div><div class="line"></div><div class="line"><span class="keyword">import</span> warnings</div><div class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</div><div class="line"></div><div class="line"><span class="keyword">import</span> seaborn</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">autolabel</span><span class="params">(arrayA)</span>:</span></div><div class="line">    <span class="string">''' label each colored square with the corresponding data value. </span></div><div class="line">    If value &gt; 20, the text is in black, else in white.</div><div class="line">    '''</div><div class="line">    arrayA = np.array(arrayA)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(arrayA.shape[<span class="number">0</span>]):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(arrayA.shape[<span class="number">1</span>]):</div><div class="line">                plt.text(j,i, <span class="string">"%.2f"</span>%arrayA[i,j], ha=<span class="string">'center'</span>, va=<span class="string">'bottom'</span>,color=<span class="string">'w'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">hist_it</span><span class="params">(feat)</span>:</span></div><div class="line">    plt.figure(figsize=(<span class="number">16</span>,<span class="number">4</span>))</div><div class="line">    feat[Y==<span class="number">0</span>].hist(bins=range(int(feat.min()),int(feat.max()+<span class="number">2</span>)),normed=<span class="keyword">True</span>,alpha=<span class="number">0.8</span>)</div><div class="line">    feat[Y==<span class="number">1</span>].hist(bins=range(int(feat.min()),int(feat.max()+<span class="number">2</span>)),normed=<span class="keyword">True</span>,alpha=<span class="number">0.5</span>)</div><div class="line">    plt.ylim((<span class="number">0</span>,<span class="number">1</span>))</div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gt_matrix</span><span class="params">(feats,sz=<span class="number">16</span>)</span>:</span></div><div class="line">    a = []</div><div class="line">    <span class="keyword">for</span> i,c1 <span class="keyword">in</span> enumerate(feats):</div><div class="line">        b = [] </div><div class="line">        <span class="keyword">for</span> j,c2 <span class="keyword">in</span> enumerate(feats):</div><div class="line">            mask = (~train[c1].isnull()) &amp; (~train[c2].isnull())</div><div class="line">            <span class="keyword">if</span> i&gt;=j:</div><div class="line">                b.append((train.loc[mask,c1].values&gt;=train.loc[mask,c2].values).mean())</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                b.append((train.loc[mask,c1].values&gt;train.loc[mask,c2].values).mean())</div><div class="line"></div><div class="line">        a.append(b)</div><div class="line"></div><div class="line">    plt.figure(figsize = (sz,sz))</div><div class="line">    plt.imshow(a, interpolation = <span class="string">'None'</span>)</div><div class="line">    _ = plt.xticks(range(len(feats)),feats,rotation = <span class="number">90</span>)</div><div class="line">    _ = plt.yticks(range(len(feats)),feats,rotation = <span class="number">0</span>)</div><div class="line">    autolabel(a)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">hist_it1</span><span class="params">(feat)</span>:</span></div><div class="line">    plt.figure(figsize=(<span class="number">16</span>,<span class="number">4</span>))</div><div class="line">    feat[Y==<span class="number">0</span>].hist(bins=<span class="number">100</span>,range=(feat.min(),feat.max()),normed=<span class="keyword">True</span>,alpha=<span class="number">0.5</span>)</div><div class="line">    feat[Y==<span class="number">1</span>].hist(bins=<span class="number">100</span>,range=(feat.min(),feat.max()),normed=<span class="keyword">True</span>,alpha=<span class="number">0.5</span>)</div><div class="line">    plt.ylim((<span class="number">0</span>,<span class="number">1</span>))</div></pre></td></tr></table></figure><h1 id="Read-the-data"><a href="#Read-the-data" class="headerlink" title="Read the data"></a>Read the data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">'train.csv.zip'</span>)</div><div class="line">Y = train.target</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">test = pd.read_csv(<span class="string">'test.csv.zip'</span>)</div><div class="line">test_ID = test.ID</div></pre></td></tr></table></figure><a id="more"></a><h1 id="Data-overview"><a href="#Data-overview" class="headerlink" title="Data overview"></a>Data overview</h1><p>Probably the first thing you check is the shapes of the train and test matrices and look inside them.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'Train shape'</span>, train.shape</div><div class="line"><span class="keyword">print</span> <span class="string">'Test shape'</span>,  test.shape</div></pre></td></tr></table></figure><pre><code>Train shape (145231, 1934)
Test shape (145232, 1933)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.head()</div></pre></td></tr></table></figure><div><br><style><br>.dataframe thead tr:only-child th{<br>        text-align:right}<br><br>.dataframe thead th{<br>        text-align:left}<br><br>.dataframe tbody tr th{<br>        vertical-align:top}<br></style><br><table border="1" class="dataframe"><br><thead><br><tr style="text-align:right"><br><th></th><br><th>ID</th><br><th>VAR_0001</th><br><th>VAR_0002</th><br><th>VAR_0003</th><br><th>VAR_0004</th><br><th>VAR_0005</th><br><th>VAR_0006</th><br><th>VAR_0007</th><br><th>VAR_0008</th><br><th>VAR_0009</th><br><th>‚Ä¶</th><br><th>VAR_1926</th><br><th>VAR_1927</th><br><th>VAR_1928</th><br><th>VAR_1929</th><br><th>VAR_1930</th><br><th>VAR_1931</th><br><th>VAR_1932</th><br><th>VAR_1933</th><br><th>VAR_1934</th><br><th>target</th><br></tr><br></thead><br><tbody><br><tr><br><th>0</th><br><td>2</td><br><td>H</td><br><td>224</td><br><td>0</td><br><td>4300</td><br><td>C</td><br><td>0.0</td><br><td>0.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>IAPS</td><br><td>0</td><br></tr><br><tr><br><th>1</th><br><td>4</td><br><td>H</td><br><td>7</td><br><td>53</td><br><td>4448</td><br><td>B</td><br><td>1.0</td><br><td>0.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>IAPS</td><br><td>0</td><br></tr><br><tr><br><th>2</th><br><td>5</td><br><td>H</td><br><td>116</td><br><td>3</td><br><td>3464</td><br><td>C</td><br><td>0.0</td><br><td>0.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>IAPS</td><br><td>0</td><br></tr><br><tr><br><th>3</th><br><td>7</td><br><td>H</td><br><td>240</td><br><td>300</td><br><td>3200</td><br><td>C</td><br><td>0.0</td><br><td>0.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>RCC</td><br><td>0</td><br></tr><br><tr><br><th>4</th><br><td>8</td><br><td>R</td><br><td>72</td><br><td>261</td><br><td>2000</td><br><td>N</td><br><td>0.0</td><br><td>0.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>BRANCH</td><br><td>1</td><br></tr><br></tbody><br></table><br><p>5 rows √ó 1934 columns</p><br></div><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">test.head()</div></pre></td></tr></table></figure><div><br><style><br>.dataframe thead tr:only-child th{<br>        text-align:right}<br><br>.dataframe thead th{<br>        text-align:left}<br><br>.dataframe tbody tr th{<br>        vertical-align:top}<br></style><br><table border="1" class="dataframe"><br><thead><br><tr style="text-align:right"><br><th></th><br><th>ID</th><br><th>VAR_0001</th><br><th>VAR_0002</th><br><th>VAR_0003</th><br><th>VAR_0004</th><br><th>VAR_0005</th><br><th>VAR_0006</th><br><th>VAR_0007</th><br><th>VAR_0008</th><br><th>VAR_0009</th><br><th>‚Ä¶</th><br><th>VAR_1925</th><br><th>VAR_1926</th><br><th>VAR_1927</th><br><th>VAR_1928</th><br><th>VAR_1929</th><br><th>VAR_1930</th><br><th>VAR_1931</th><br><th>VAR_1932</th><br><th>VAR_1933</th><br><th>VAR_1934</th><br></tr><br></thead><br><tbody><br><tr><br><th>0</th><br><td>1</td><br><td>R</td><br><td>360</td><br><td>25</td><br><td>2251</td><br><td>B</td><br><td>2.0</td><br><td>2.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>0</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>IAPS</td><br></tr><br><tr><br><th>1</th><br><td>3</td><br><td>R</td><br><td>74</td><br><td>192</td><br><td>3274</td><br><td>C</td><br><td>2.0</td><br><td>3.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>0</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>IAPS</td><br></tr><br><tr><br><th>2</th><br><td>6</td><br><td>R</td><br><td>21</td><br><td>36</td><br><td>3500</td><br><td>C</td><br><td>1.0</td><br><td>1.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>0</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>IAPS</td><br></tr><br><tr><br><th>3</th><br><td>9</td><br><td>R</td><br><td>8</td><br><td>2</td><br><td>1500</td><br><td>B</td><br><td>0.0</td><br><td>0.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>0</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>IAPS</td><br></tr><br><tr><br><th>4</th><br><td>10</td><br><td>H</td><br><td>91</td><br><td>39</td><br><td>84500</td><br><td>C</td><br><td>8.0</td><br><td>3.0</td><br><td>False</td><br><td>False</td><br><td>‚Ä¶</td><br><td>0</td><br><td>98</td><br><td>98</td><br><td>998</td><br><td>999999998</td><br><td>998</td><br><td>998</td><br><td>9998</td><br><td>9998</td><br><td>IAPS</td><br></tr><br></tbody><br></table><br><p>5 rows √ó 1933 columns</p><br></div><p>There are almost 2000 anonymized variables! It‚Äôs clear, some of them are categorical, some look like numeric. Some numeric feateures are integer typed, so probably they are event conters or dates. And others are of float type, but from the first few rows they look like integer-typed too, since fractional part is zero, but pandas treats them as <code>float</code> since there are NaN values in that features.</p><p>From the first glance we see train has one more column <code>target</code> which we should not forget to drop before fitting a classifier. We also see <code>ID</code> column is shared between train and test, which sometimes can be succesfully used to improve the score.</p><p>It is also useful to know if there are any NaNs in the data. You should pay attention to columns with NaNs and the number of NaNs for each row can serve as a nice feature later.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Number of NaNs for each object</span></div><div class="line">train.isnull().sum(axis=<span class="number">1</span>).head(<span class="number">15</span>)</div></pre></td></tr></table></figure><pre><code>0     25
1     19
2     24
3     24
4     24
5     24
6     24
7     24
8     16
9     24
10    22
11    24
12    17
13    24
14    24
dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Number of NaNs for each column</span></div><div class="line">train.isnull().sum(axis=<span class="number">0</span>).head(<span class="number">15</span>)</div></pre></td></tr></table></figure><pre><code>ID           0
VAR_0001     0
VAR_0002     0
VAR_0003     0
VAR_0004     0
VAR_0005     0
VAR_0006    56
VAR_0007    56
VAR_0008    56
VAR_0009    56
VAR_0010    56
VAR_0011    56
VAR_0012    56
VAR_0013    56
VAR_0014    56
dtype: int64
</code></pre><p>Just by reviewing the head of the lists we immediately see the patterns, exactly 56 NaNs for a set of variables, and 24 NaNs for objects.</p><h1 id="Dataset-cleaning"><a href="#Dataset-cleaning" class="headerlink" title="Dataset cleaning"></a>Dataset cleaning</h1><h3 id="Remove-constant-features"><a href="#Remove-constant-features" class="headerlink" title="Remove constant features"></a>Remove constant features</h3><p>All 1932 columns are anonimized which makes us to deduce the meaning of the features ourselves. We will now try to clean the dataset.</p><p>It is usually convenient to concatenate train and test into one dataframe and do all feature engineering using it.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">traintest = pd.concat([train, test], axis = <span class="number">0</span>)</div></pre></td></tr></table></figure><p>First we schould look for a constant features, such features do not provide any information and only make our dataset larger.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># `dropna = False` makes nunique treat NaNs as a distinct value</span></div><div class="line">feats_counts = train.nunique(dropna = <span class="keyword">False</span>)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">feats_counts.sort_values()[:<span class="number">10</span>]</div></pre></td></tr></table></figure><pre><code>VAR_0213    1
VAR_0207    1
VAR_0840    1
VAR_0847    1
VAR_1428    1
VAR_1165    2
VAR_0438    2
VAR_1164    2
VAR_1163    2
VAR_1162    2
dtype: int64
</code></pre><p>We found 5 constant features. Let‚Äôs remove them.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">constant_features = feats_counts.loc[feats_counts==<span class="number">1</span>].index.tolist()</div><div class="line"><span class="keyword">print</span> (constant_features)</div><div class="line"></div><div class="line"></div><div class="line">traintest.drop(constant_features,axis = <span class="number">1</span>,inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><pre><code>[&apos;VAR_0207&apos;, &apos;VAR_0213&apos;, &apos;VAR_0840&apos;, &apos;VAR_0847&apos;, &apos;VAR_1428&apos;]
</code></pre><h3 id="Remove-duplicated-features"><a href="#Remove-duplicated-features" class="headerlink" title="Remove duplicated features"></a>Remove duplicated features</h3><p>Fill NaNs with something we can find later if needed.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">traintest.fillna(<span class="string">'NaN'</span>, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><p>Now let‚Äôs encode each feature, as we discussed.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">train_enc =  pd.DataFrame(index = train.index)</div><div class="line"></div><div class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm_notebook(traintest.columns):</div><div class="line">    train_enc[col] = train[col].factorize()[<span class="number">0</span>]</div></pre></td></tr></table></figure><p>‚Äã</p><p>We could also do something like this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># train_enc[col] = train[col].map(train[col].value_counts())</span></div></pre></td></tr></table></figure><p>The resulting data frame is very very large, so we cannot just transpose it and use .duplicated. That is why we will use a simple loop.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">dup_cols = &#123;&#125;</div><div class="line"></div><div class="line"><span class="keyword">for</span> i, c1 <span class="keyword">in</span> enumerate(tqdm_notebook(train_enc.columns)):</div><div class="line">    <span class="keyword">for</span> c2 <span class="keyword">in</span> train_enc.columns[i + <span class="number">1</span>:]:</div><div class="line">        <span class="keyword">if</span> c2 <span class="keyword">not</span> <span class="keyword">in</span> dup_cols <span class="keyword">and</span> np.all(train_enc[c1] == train_enc[c2]):</div><div class="line">            dup_cols[c2] = c1</div></pre></td></tr></table></figure><p>‚Äã</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dup_cols</div></pre></td></tr></table></figure><pre><code>{&apos;VAR_0009&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0010&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0011&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0012&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0013&apos;: &apos;VAR_0006&apos;,
 &apos;VAR_0018&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0019&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0020&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0021&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0022&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0023&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0024&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0025&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0026&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0027&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0028&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0029&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0030&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0031&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0032&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0038&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0039&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0040&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0041&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0042&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0043&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0044&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0181&apos;: &apos;VAR_0180&apos;,
 &apos;VAR_0182&apos;: &apos;VAR_0180&apos;,
 &apos;VAR_0189&apos;: &apos;VAR_0188&apos;,
 &apos;VAR_0190&apos;: &apos;VAR_0188&apos;,
 &apos;VAR_0196&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0197&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0199&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0201&apos;: &apos;VAR_0051&apos;,
 &apos;VAR_0202&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0203&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0210&apos;: &apos;VAR_0208&apos;,
 &apos;VAR_0211&apos;: &apos;VAR_0208&apos;,
 &apos;VAR_0215&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0216&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0221&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0222&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0223&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0228&apos;: &apos;VAR_0227&apos;,
 &apos;VAR_0229&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0238&apos;: &apos;VAR_0089&apos;,
 &apos;VAR_0239&apos;: &apos;VAR_0008&apos;,
 &apos;VAR_0357&apos;: &apos;VAR_0260&apos;,
 &apos;VAR_0394&apos;: &apos;VAR_0246&apos;,
 &apos;VAR_0438&apos;: &apos;VAR_0246&apos;,
 &apos;VAR_0446&apos;: &apos;VAR_0246&apos;,
 &apos;VAR_0512&apos;: &apos;VAR_0506&apos;,
 &apos;VAR_0527&apos;: &apos;VAR_0246&apos;,
 &apos;VAR_0528&apos;: &apos;VAR_0246&apos;,
 &apos;VAR_0529&apos;: &apos;VAR_0526&apos;,
 &apos;VAR_0530&apos;: &apos;VAR_0246&apos;,
 &apos;VAR_0672&apos;: &apos;VAR_0670&apos;,
 &apos;VAR_1036&apos;: &apos;VAR_0916&apos;}
</code></pre><p>Don‚Äôt forget to save them, as it takes long time to find these.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> cPickle <span class="keyword">as</span> pickle</div><div class="line">pickle.dump(dup_cols, open(<span class="string">'dup_cols.p'</span>, <span class="string">'w'</span>), protocol=pickle.HIGHEST_PROTOCOL)</div></pre></td></tr></table></figure><p>Drop from traintest.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">traintest.drop(dup_cols.keys(), axis = <span class="number">1</span>,inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><h1 id="Determine-types"><a href="#Determine-types" class="headerlink" title="Determine types"></a>Determine types</h1><p>Let‚Äôs examine the number of unique values.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">nunique = train.nunique(dropna=<span class="keyword">False</span>)</div><div class="line">nunique</div></pre></td></tr></table></figure><pre><code>ID                145231
VAR_0001               3
VAR_0002             820
VAR_0003             588
VAR_0004            7935
VAR_0005               4
VAR_0006              38
VAR_0007              36
VAR_0008               2
VAR_0009               2
VAR_0010               2
VAR_0011               2
VAR_0012               2
VAR_0013              38
VAR_0014              38
VAR_0015              27
VAR_0016              30
VAR_0017              26
VAR_0018               2
VAR_0019               2
VAR_0020               2
VAR_0021               2
VAR_0022               2
VAR_0023               2
VAR_0024               2
VAR_0025               2
VAR_0026               2
VAR_0027               2
VAR_0028               2
VAR_0029               2
                   ...  
VAR_1907              41
VAR_1908              37
VAR_1909              41
VAR_1910              37
VAR_1911             107
VAR_1912           16370
VAR_1913           25426
VAR_1914           14226
VAR_1915            1148
VAR_1916               8
VAR_1917              10
VAR_1918              86
VAR_1919             383
VAR_1920              22
VAR_1921              18
VAR_1922            6798
VAR_1923            2445
VAR_1924             573
VAR_1925              11
VAR_1926               6
VAR_1927              10
VAR_1928              30
VAR_1929             591
VAR_1930               8
VAR_1931              10
VAR_1932              74
VAR_1933             363
VAR_1934               5
target                 2
VAR_0004_mod50        50
Length: 1935, dtype: int64
</code></pre><p>and build a histogram of those values</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</div><div class="line">_ = plt.hist(nunique.astype(float)/train.shape[<span class="number">0</span>], bins=<span class="number">100</span>)</div></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/ewanlee/blog-image-hosting/master/output_44_0.png" alt="png"></p><p>Let‚Äôs take a looks at the features with a huge number of unique values:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mask = (nunique.astype(float)/train.shape[<span class="number">0</span>] &gt; <span class="number">0.8</span>)</div><div class="line">train.loc[:, mask]</div></pre></td></tr></table></figure><div><br><style><br>.dataframe thead tr:only-child th{<br>        text-align:right}<br><br>.dataframe thead th{<br>        text-align:left}<br><br>.dataframe tbody tr th{<br>        vertical-align:top}<br></style><br><table border="1" class="dataframe"><br><thead><br><tr style="text-align:right"><br><th></th><br><th>ID</th><br><th>VAR_0212</th><br><th>VAR_0227</th><br></tr><br></thead><br><tbody><br><tr><br><th>0</th><br><td>2</td><br><td>NaN</td><br><td>311951</td><br></tr><br><tr><br><th>1</th><br><td>4</td><br><td>9.20713e+10</td><br><td>2.76949e+06</td><br></tr><br><tr><br><th>2</th><br><td>5</td><br><td>2.65477e+10</td><br><td>654127</td><br></tr><br><tr><br><th>3</th><br><td>7</td><br><td>7.75753e+10</td><br><td>3.01509e+06</td><br></tr><br><tr><br><th>4</th><br><td>8</td><br><td>6.04238e+10</td><br><td>118678</td><br></tr><br><tr><br><th>5</th><br><td>14</td><br><td>7.73796e+10</td><br><td>1.76557e+06</td><br></tr><br><tr><br><th>6</th><br><td>16</td><br><td>9.70303e+10</td><br><td>80151</td><br></tr><br><tr><br><th>7</th><br><td>20</td><br><td>3.10981e+10</td><br><td>853641</td><br></tr><br><tr><br><th>8</th><br><td>21</td><br><td>7.82124e+10</td><br><td>1.40254e+06</td><br></tr><br><tr><br><th>9</th><br><td>22</td><br><td>1.94014e+10</td><br><td>2.2187e+06</td><br></tr><br><tr><br><th>10</th><br><td>23</td><br><td>3.71295e+10</td><br><td>2.77679e+06</td><br></tr><br><tr><br><th>11</th><br><td>24</td><br><td>3.01203e+10</td><br><td>434300</td><br></tr><br><tr><br><th>12</th><br><td>25</td><br><td>1.80185e+10</td><br><td>1.48914e+06</td><br></tr><br><tr><br><th>13</th><br><td>26</td><br><td>9.83358e+10</td><br><td>686666</td><br></tr><br><tr><br><th>14</th><br><td>28</td><br><td>9.33087e+10</td><br><td>1.4847e+06</td><br></tr><br><tr><br><th>15</th><br><td>30</td><br><td>2.01715e+10</td><br><td>883714</td><br></tr><br><tr><br><th>16</th><br><td>31</td><br><td>4.15638e+10</td><br><td>2.6707e+06</td><br></tr><br><tr><br><th>17</th><br><td>32</td><br><td>9.17617e+10</td><br><td>2.65485e+06</td><br></tr><br><tr><br><th>18</th><br><td>35</td><br><td>3.81344e+10</td><br><td>487721</td><br></tr><br><tr><br><th>19</th><br><td>36</td><br><td>NaN</td><br><td>2.54705e+06</td><br></tr><br><tr><br><th>20</th><br><td>37</td><br><td>3.27144e+10</td><br><td>1.74684e+06</td><br></tr><br><tr><br><th>21</th><br><td>38</td><br><td>1.82142e+10</td><br><td>2.5813e+06</td><br></tr><br><tr><br><th>22</th><br><td>40</td><br><td>7.70153e+10</td><br><td>2.59396e+06</td><br></tr><br><tr><br><th>23</th><br><td>42</td><br><td>4.69701e+10</td><br><td>1.02977e+06</td><br></tr><br><tr><br><th>24</th><br><td>43</td><br><td>9.84442e+10</td><br><td>1.45101e+06</td><br></tr><br><tr><br><th>25</th><br><td>46</td><br><td>NaN</td><br><td>2.37136e+06</td><br></tr><br><tr><br><th>26</th><br><td>50</td><br><td>9.25094e+10</td><br><td>665930</td><br></tr><br><tr><br><th>27</th><br><td>51</td><br><td>3.09094e+10</td><br><td>497686</td><br></tr><br><tr><br><th>28</th><br><td>52</td><br><td>6.06105e+10</td><br><td>1.95816e+06</td><br></tr><br><tr><br><th>29</th><br><td>54</td><br><td>3.78768e+10</td><br><td>1.62591e+06</td><br></tr><br><tr><br><th>‚Ä¶</th><br><td>‚Ä¶</td><br><td>‚Ä¶</td><br><td>‚Ä¶</td><br></tr><br><tr><br><th>145201</th><br><td>290409</td><br><td>8.80126e+10</td><br><td>1.83053e+06</td><br></tr><br><tr><br><th>145202</th><br><td>290412</td><br><td>4.6152e+10</td><br><td>1.02024e+06</td><br></tr><br><tr><br><th>145203</th><br><td>290414</td><br><td>9.33055e+10</td><br><td>1.88151e+06</td><br></tr><br><tr><br><th>145204</th><br><td>290415</td><br><td>4.63509e+10</td><br><td>669351</td><br></tr><br><tr><br><th>145205</th><br><td>290417</td><br><td>2.36028e+10</td><br><td>655797</td><br></tr><br><tr><br><th>145206</th><br><td>290424</td><br><td>3.73293e+10</td><br><td>1.45626e+06</td><br></tr><br><tr><br><th>145207</th><br><td>290426</td><br><td>2.38892e+10</td><br><td>1.9503e+06</td><br></tr><br><tr><br><th>145208</th><br><td>290427</td><br><td>6.38632e+10</td><br><td>596365</td><br></tr><br><tr><br><th>145209</th><br><td>290429</td><br><td>3.00602e+10</td><br><td>572119</td><br></tr><br><tr><br><th>145210</th><br><td>290431</td><br><td>4.33429e+10</td><br><td>16120</td><br></tr><br><tr><br><th>145211</th><br><td>290432</td><br><td>3.86543e+10</td><br><td>2.08375e+06</td><br></tr><br><tr><br><th>145212</th><br><td>290434</td><br><td>9.21391e+10</td><br><td>1.89779e+06</td><br></tr><br><tr><br><th>145213</th><br><td>290436</td><br><td>3.07472e+10</td><br><td>2.94532e+06</td><br></tr><br><tr><br><th>145214</th><br><td>290439</td><br><td>7.83326e+10</td><br><td>2.54726e+06</td><br></tr><br><tr><br><th>145215</th><br><td>290440</td><br><td>NaN</td><br><td>600318</td><br></tr><br><tr><br><th>145216</th><br><td>290441</td><br><td>2.78561e+10</td><br><td>602505</td><br></tr><br><tr><br><th>145217</th><br><td>290443</td><br><td>1.90952e+10</td><br><td>2.44184e+06</td><br></tr><br><tr><br><th>145218</th><br><td>290445</td><br><td>4.62035e+10</td><br><td>2.87349e+06</td><br></tr><br><tr><br><th>145219</th><br><td>290447</td><br><td>NaN</td><br><td>1.53493e+06</td><br></tr><br><tr><br><th>145220</th><br><td>290448</td><br><td>7.54282e+10</td><br><td>1.60102e+06</td><br></tr><br><tr><br><th>145221</th><br><td>290449</td><br><td>4.30768e+10</td><br><td>2.08415e+06</td><br></tr><br><tr><br><th>145222</th><br><td>290450</td><br><td>7.81325e+10</td><br><td>2.85367e+06</td><br></tr><br><tr><br><th>145223</th><br><td>290452</td><br><td>4.51061e+10</td><br><td>1.56506e+06</td><br></tr><br><tr><br><th>145224</th><br><td>290453</td><br><td>4.62223e+10</td><br><td>1.46815e+06</td><br></tr><br><tr><br><th>145225</th><br><td>290454</td><br><td>7.74507e+10</td><br><td>2.92811e+06</td><br></tr><br><tr><br><th>145226</th><br><td>290457</td><br><td>7.05088e+10</td><br><td>2.03657e+06</td><br></tr><br><tr><br><th>145227</th><br><td>290458</td><br><td>9.02492e+10</td><br><td>1.68013e+06</td><br></tr><br><tr><br><th>145228</th><br><td>290459</td><br><td>9.17224e+10</td><br><td>2.41922e+06</td><br></tr><br><tr><br><th>145229</th><br><td>290461</td><br><td>4.51033e+10</td><br><td>1.53960e+06</td><br></tr><br><tr><br><th>145230</th><br><td>290463</td><br><td>9.14114e+10</td><br><td>2.6609e+06</td><br></tr><br></tbody><br></table><br><p>145231 rows √ó 3 columns</p><br></div><p>The values are not float, they are integer, so these features are likely to be even counts. Let‚Äôs look at another pack of features.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mask = (nunique.astype(float)/train.shape[<span class="number">0</span>] &lt; <span class="number">0.8</span>) &amp; (nunique.astype(float)/train.shape[<span class="number">0</span>] &gt; <span class="number">0.4</span>)</div><div class="line">train.loc[:<span class="number">25</span>, mask]</div></pre></td></tr></table></figure><div><br><style><br>.dataframe thead tr:only-child th{<br>        text-align:right}<br><br>.dataframe thead th{<br>        text-align:left}<br><br>.dataframe tbody tr th{<br>        vertical-align:top}<br></style><br><table border="1" class="dataframe"><br><thead><br><tr style="text-align:right"><br><th></th><br><th>VAR_0541</th><br><th>VAR_0543</th><br><th>VAR_0899</th><br><th>VAR_1081</th><br><th>VAR_1082</th><br><th>VAR_1087</th><br><th>VAR_1179</th><br><th>VAR_1180</th><br><th>VAR_1181</th><br></tr><br></thead><br><tbody><br><tr><br><th>0</th><br><td>49463</td><br><td>116783</td><br><td>112871</td><br><td>76857</td><br><td>76857</td><br><td>116783</td><br><td>76857</td><br><td>76857</td><br><td>76857</td><br></tr><br><tr><br><th>1</th><br><td>303472</td><br><td>346196</td><br><td>346375</td><br><td>341365</td><br><td>341365</td><br><td>346196</td><br><td>341365</td><br><td>341365</td><br><td>176604</td><br></tr><br><tr><br><th>2</th><br><td>94990</td><br><td>122601</td><br><td>121501</td><br><td>107267</td><br><td>107267</td><br><td>121501</td><br><td>107267</td><br><td>107267</td><br><td>58714</td><br></tr><br><tr><br><th>3</th><br><td>20593</td><br><td>59490</td><br><td>61890</td><br><td>45794</td><br><td>47568</td><br><td>59490</td><br><td>45794</td><br><td>47568</td><br><td>47568</td><br></tr><br><tr><br><th>4</th><br><td>10071</td><br><td>35708</td><br><td>34787</td><br><td>20475</td><br><td>23647</td><br><td>34708</td><br><td>20475</td><br><td>23647</td><br><td>23647</td><br></tr><br><tr><br><th>5</th><br><td>18877</td><br><td>28055</td><br><td>28455</td><br><td>21139</td><br><td>21139</td><br><td>28055</td><br><td>21139</td><br><td>21139</td><br><td>20627</td><br></tr><br><tr><br><th>6</th><br><td>321783</td><br><td>333565</td><br><td>886886</td><br><td>327744</td><br><td>327744</td><br><td>333565</td><br><td>327744</td><br><td>327744</td><br><td>163944</td><br></tr><br><tr><br><th>7</th><br><td>2961</td><br><td>5181</td><br><td>11084</td><br><td>4326</td><br><td>4326</td><br><td>5181</td><br><td>4326</td><br><td>4326</td><br><td>4326</td><br></tr><br><tr><br><th>8</th><br><td>20359</td><br><td>30114</td><br><td>33434</td><br><td>24969</td><br><td>27128</td><br><td>30114</td><br><td>24969</td><br><td>27128</td><br><td>27128</td><br></tr><br><tr><br><th>9</th><br><td>815</td><br><td>1300</td><br><td>7677</td><br><td>1197</td><br><td>1197</td><br><td>1300</td><br><td>1197</td><br><td>1197</td><br><td>1197</td><br></tr><br><tr><br><th>10</th><br><td>6088</td><br><td>15233</td><br><td>15483</td><br><td>7077</td><br><td>7077</td><br><td>15233</td><br><td>7077</td><br><td>7077</td><br><td>4033</td><br></tr><br><tr><br><th>11</th><br><td>432</td><br><td>1457</td><br><td>2000</td><br><td>621</td><br><td>621</td><br><td>757</td><br><td>621</td><br><td>621</td><br><td>621</td><br></tr><br><tr><br><th>12</th><br><td>383</td><br><td>539</td><br><td>860</td><br><td>752</td><br><td>1158</td><br><td>539</td><br><td>752</td><br><td>1158</td><br><td>1158</td><br></tr><br><tr><br><th>13</th><br><td>14359</td><br><td>47562</td><br><td>47562</td><br><td>17706</td><br><td>17706</td><br><td>47562</td><br><td>17706</td><br><td>17706</td><br><td>17706</td><br></tr><br><tr><br><th>14</th><br><td>145391</td><br><td>218067</td><br><td>214836</td><br><td>176627</td><br><td>176627</td><br><td>216307</td><br><td>175273</td><br><td>175273</td><br><td>91019</td><br></tr><br><tr><br><th>15</th><br><td>10040</td><br><td>12119</td><br><td>17263</td><br><td>10399</td><br><td>10399</td><br><td>12119</td><br><td>10399</td><br><td>10399</td><br><td>5379</td><br></tr><br><tr><br><th>16</th><br><td>4880</td><br><td>9607</td><br><td>9607</td><br><td>9165</td><br><td>9165</td><br><td>9607</td><br><td>9165</td><br><td>9165</td><br><td>9165</td><br></tr><br><tr><br><th>17</th><br><td>12900</td><br><td>35590</td><br><td>35781</td><br><td>26096</td><br><td>26096</td><br><td>35590</td><br><td>26096</td><br><td>26096</td><br><td>19646</td><br></tr><br><tr><br><th>18</th><br><td>104442</td><br><td>139605</td><br><td>150505</td><br><td>136419</td><br><td>142218</td><br><td>139605</td><br><td>136419</td><br><td>142218</td><br><td>142218</td><br></tr><br><tr><br><th>19</th><br><td>13898</td><br><td>25566</td><br><td>26685</td><br><td>20122</td><br><td>20122</td><br><td>25566</td><br><td>20122</td><br><td>20122</td><br><td>20122</td><br></tr><br><tr><br><th>20</th><br><td>3524</td><br><td>10033</td><br><td>10133</td><br><td>5838</td><br><td>5838</td><br><td>10033</td><br><td>5838</td><br><td>5838</td><br><td>5838</td><br></tr><br><tr><br><th>21</th><br><td>129873</td><br><td>204072</td><br><td>206946</td><br><td>183049</td><br><td>183049</td><br><td>204072</td><br><td>183049</td><br><td>183049</td><br><td>96736</td><br></tr><br><tr><br><th>22</th><br><td>3591</td><br><td>11400</td><br><td>17680</td><br><td>5565</td><br><td>5565</td><br><td>11400</td><br><td>5565</td><br><td>5565</td><br><td>5565</td><br></tr><br><tr><br><th>23</th><br><td>999999999</td><br><td>999999999</td><br><td>-99999</td><br><td>999999999</td><br><td>999999999</td><br><td>999999999</td><br><td>999999999</td><br><td>999999999</td><br><td>999999999</td><br></tr><br><tr><br><th>24</th><br><td>1270</td><br><td>4955</td><br><td>12201</td><br><td>2490</td><br><td>2490</td><br><td>4955</td><br><td>2490</td><br><td>2490</td><br><td>2490</td><br></tr><br><tr><br><th>25</th><br><td>2015</td><br><td>2458</td><br><td>2458</td><br><td>2015</td><br><td>2015</td><br><td>2458</td><br><td>2015</td><br><td>2015</td><br><td>1008</td><br></tr><br></tbody><br></table><br></div><p>These look like counts too. First thing to notice is the 23th line: 99999.., -99999 values look like NaNs so we should probably built a related feature. Second: the columns are sometimes placed next to each other, so the columns are probably grouped together and we can disentangle that.</p><p>Our conclusion: there are no floating point variables, there are some counts variables, which we will treat as numeric.</p><p>And finally, let‚Äôs pick one variable (in this case ‚ÄòVAR_0015‚Äô) from the third group of features.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train[<span class="string">'VAR_0015'</span>].value_counts()</div></pre></td></tr></table></figure><pre><code> 0.0      102382
 1.0       28045
 2.0        8981
 3.0        3199
 4.0        1274
 5.0         588
 6.0         275
 7.0         166
 8.0          97
-999.0        56
 9.0          51
 10.0         39
 11.0         18
 12.0         16
 13.0          9
 14.0          8
 15.0          8
 16.0          6
 22.0          3
 21.0          3
 19.0          1
 35.0          1
 17.0          1
 29.0          1
 18.0          1
 32.0          1
 23.0          1
Name: VAR_0015, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cat_cols = list(train.select_dtypes(include=[<span class="string">'object'</span>]).columns)</div><div class="line">num_cols = list(train.select_dtypes(exclude=[<span class="string">'object'</span>]).columns)</div></pre></td></tr></table></figure><h1 id="Go-through"><a href="#Go-through" class="headerlink" title="Go through"></a>Go through</h1><p>Let‚Äôs replace NaNs with something first.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.replace(<span class="string">'NaN'</span>, <span class="number">-999</span>, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><p>Let‚Äôs calculate how many times one feature is greater than the other and create cross tabel out of it.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># select first 42 numeric features</span></div><div class="line">feats = num_cols[:<span class="number">42</span>]</div><div class="line"></div><div class="line"><span class="comment"># build 'mean(feat1 &gt; feat2)' plot</span></div><div class="line">gt_matrix(feats,<span class="number">16</span>)</div></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/ewanlee/blog-image-hosting/master/output_57_0.png" alt="png"></p><p>Indeed, we see interesting patterns here. There are blocks of geatures where one is strictly greater than the other. So we can hypothesize, that each column correspondes to cumulative counts, e.g. feature number one is counts in first month, second ‚Äì total count number in first two month and so on. So we immediately understand what features we should generate to make tree-based models more efficient: the differences between consecutive values.</p><h2 id="VAR-0002-VAR-0003"><a href="#VAR-0002-VAR-0003" class="headerlink" title="VAR_0002, VAR_0003"></a>VAR_0002, VAR_0003</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">hist_it(train[<span class="string">'VAR_0002'</span>])</div><div class="line">plt.ylim((<span class="number">0</span>,<span class="number">0.05</span>))</div><div class="line">plt.xlim((<span class="number">-10</span>,<span class="number">1010</span>))</div><div class="line"></div><div class="line">hist_it(train[<span class="string">'VAR_0003'</span>])</div><div class="line">plt.ylim((<span class="number">0</span>,<span class="number">0.03</span>))</div><div class="line">plt.xlim((<span class="number">-10</span>,<span class="number">1010</span>))</div></pre></td></tr></table></figure><pre><code>(-10, 1010)
</code></pre><p><img src="https://raw.githubusercontent.com/ewanlee/blog-image-hosting/master/output_60_1.png" alt="png"></p><p><img src="https://raw.githubusercontent.com/ewanlee/blog-image-hosting/master/output_60_2.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train[<span class="string">'VAR_0002'</span>].value_counts()</div></pre></td></tr></table></figure><pre><code>12     5264
24     4763
36     3499
60     2899
6      2657
13     2478
72     2243
48     2222
3      2171
4      1917
2      1835
84     1801
120    1786
1      1724
7      1671
26     1637
5      1624
14     1572
18     1555
8      1513
999    1510
25     1504
96     1445
30     1438
9      1306
144    1283
15     1221
27     1186
38     1146
37     1078
       ... 
877       1
785       1
750       1
653       1
784       1
764       1
751       1
797       1
926       1
691       1
808       1
774       1
902       1
755       1
656       1
814       1
813       1
685       1
739       1
935       1
906       1
807       1
550       1
933       1
804       1
675       1
674       1
745       1
778       1
851       1
Name: VAR_0002, Length: 820, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train[<span class="string">'VAR_0003'</span>].value_counts()</div></pre></td></tr></table></figure><pre><code>0      17436
24      3469
12      3271
60      3054
36      2498
72      2081
48      2048
6       1993
1       1797
3       1679
84      1553
2       1459
999     1428
4       1419
120     1411
7       1356
13      1297
18      1296
96      1253
14      1228
8       1216
5       1189
9       1182
30      1100
25      1100
144     1090
15      1047
61      1008
26       929
42       921
       ...  
560        1
552        1
550        1
804        1
543        1
668        1
794        1
537        1
531        1
664        1
632        1
709        1
597        1
965        1
852        1
648        1
596        1
466        1
592        1
521        1
533        1
636        1
975        1
973        1
587        1
523        1
584        1
759        1
583        1
570        1
Name: VAR_0003, Length: 588, dtype: int64
</code></pre><p>We see there is something special about 12, 24 and so on, sowe can create another feature x mod 12.</p><h2 id="VAR-0004"><a href="#VAR-0004" class="headerlink" title="VAR_0004"></a>VAR_0004</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">train[<span class="string">'VAR_0004_mod50'</span>] = train[<span class="string">'VAR_0004'</span>] % <span class="number">50</span></div><div class="line">hist_it(train[<span class="string">'VAR_0004_mod50'</span>])</div><div class="line">plt.ylim((<span class="number">0</span>,<span class="number">0.6</span>))</div></pre></td></tr></table></figure><pre><code>(0, 0.6)
</code></pre><p><img src="https://raw.githubusercontent.com/ewanlee/blog-image-hosting/master/output_65_1.png" alt="png"></p><h1 id="Categorical-features"><a href="#Categorical-features" class="headerlink" title="Categorical features"></a>Categorical features</h1><p>Let‚Äôs take a look at categorical features we have.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.loc[:,cat_cols].head().T</div></pre></td></tr></table></figure><div><br><style><br>.dataframe thead tr:only-child th{<br>        text-align:right}<br><br>.dataframe thead th{<br>        text-align:left}<br><br>.dataframe tbody tr th{<br>        vertical-align:top}<br></style><br><table border="1" class="dataframe"><br><thead><br><tr style="text-align:right"><br><th></th><br><th>0</th><br><th>1</th><br><th>2</th><br><th>3</th><br><th>4</th><br></tr><br></thead><br><tbody><br><tr><br><th>VAR_0001</th><br><td>H</td><br><td>H</td><br><td>H</td><br><td>H</td><br><td>R</td><br></tr><br><tr><br><th>VAR_0005</th><br><td>C</td><br><td>B</td><br><td>C</td><br><td>C</td><br><td>N</td><br></tr><br><tr><br><th>VAR_0008</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0009</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0010</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0011</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0012</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0043</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0044</th><br><td>[]</td><br><td>[]</td><br><td>[]</td><br><td>[]</td><br><td>[]</td><br></tr><br><tr><br><th>VAR_0073</th><br><td>NaT</td><br><td>2012-09-04 00:00:00</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0075</th><br><td>2011-11-08 00:00:00</td><br><td>2011-11-10 00:00:00</td><br><td>2011-12-13 00:00:00</td><br><td>2010-09-23 00:00:00</td><br><td>2011-10-15 00:00:00</td><br></tr><br><tr><br><th>VAR_0156</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0157</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0158</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0159</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0166</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0167</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0168</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0169</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0176</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0177</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0178</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0179</th><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br><td>NaT</td><br></tr><br><tr><br><th>VAR_0196</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0200</th><br><td>FT LAUDERDALE</td><br><td>SANTEE</td><br><td>REEDSVILLE</td><br><td>LIBERTY</td><br><td>FRANKFORT</td><br></tr><br><tr><br><th>VAR_0202</th><br><td>BatchInquiry</td><br><td>BatchInquiry</td><br><td>BatchInquiry</td><br><td>BatchInquiry</td><br><td>BatchInquiry</td><br></tr><br><tr><br><th>VAR_0204</th><br><td>2014-01-29 21:16:00</td><br><td>2014-02-01 00:11:00</td><br><td>2014-01-30 15:11:00</td><br><td>2014-02-01 00:07:00</td><br><td>2014-01-29 19:31:00</td><br></tr><br><tr><br><th>VAR_0214</th><br><td>NaN</td><br><td>NaN</td><br><td>NaN</td><br><td>NaN</td><br><td>NaN</td><br></tr><br><tr><br><th>VAR_0216</th><br><td>DS</td><br><td>DS</td><br><td>DS</td><br><td>DS</td><br><td>DS</td><br></tr><br><tr><br><th>VAR_0217</th><br><td>2011-11-08 02:00:00</td><br><td>2012-10-02 02:00:00</td><br><td>2011-12-13 02:00:00</td><br><td>2012-11-01 02:00:00</td><br><td>2011-10-15 02:00:00</td><br></tr><br><tr><br><th>VAR_0222</th><br><td>C6</td><br><td>C6</td><br><td>C6</td><br><td>C6</td><br><td>C6</td><br></tr><br><tr><br><th>VAR_0226</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0229</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0230</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0232</th><br><td>True</td><br><td>False</td><br><td>True</td><br><td>False</td><br><td>True</td><br></tr><br><tr><br><th>VAR_0236</th><br><td>True</td><br><td>True</td><br><td>True</td><br><td>True</td><br><td>True</td><br></tr><br><tr><br><th>VAR_0237</th><br><td>FL</td><br><td>CA</td><br><td>WV</td><br><td>TX</td><br><td>IL</td><br></tr><br><tr><br><th>VAR_0239</th><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br><td>False</td><br></tr><br><tr><br><th>VAR_0274</th><br><td>FL</td><br><td>MI</td><br><td>WV</td><br><td>TX</td><br><td>IL</td><br></tr><br><tr><br><th>VAR_0283</th><br><td>S</td><br><td>S</td><br><td>S</td><br><td>S</td><br><td>S</td><br></tr><br><tr><br><th>VAR_0305</th><br><td>S</td><br><td>S</td><br><td>P</td><br><td>P</td><br><td>P</td><br></tr><br><tr><br><th>VAR_0325</th><br><td>-1</td><br><td>H</td><br><td>R</td><br><td>H</td><br><td>S</td><br></tr><br><tr><br><th>VAR_0342</th><br><td>CF</td><br><td>EC</td><br><td>UU</td><br><td>-1</td><br><td>-1</td><br></tr><br><tr><br><th>VAR_0352</th><br><td>O</td><br><td>O</td><br><td>R</td><br><td>R</td><br><td>R</td><br></tr><br><tr><br><th>VAR_0353</th><br><td>U</td><br><td>R</td><br><td>R</td><br><td>R</td><br><td>U</td><br></tr><br><tr><br><th>VAR_0354</th><br><td>O</td><br><td>R</td><br><td>-1</td><br><td>-1</td><br><td>O</td><br></tr><br><tr><br><th>VAR_0404</th><br><td>CHIEF EXECUTIVE OFFICER</td><br><td>-1</td><br><td>-1</td><br><td>-1</td><br><td>-1</td><br></tr><br><tr><br><th>VAR_0466</th><br><td>-1</td><br><td>I</td><br><td>-1</td><br><td>-1</td><br><td>-1</td><br></tr><br><tr><br><th>VAR_0467</th><br><td>-1</td><br><td>Discharged</td><br><td>-1</td><br><td>-1</td><br><td>-1</td><br></tr><br><tr><br><th>VAR_0493</th><br><td>COMMUNITY ASSOCIATION MANAGER</td><br><td>-1</td><br><td>-1</td><br><td>-1</td><br><td>-1</td><br></tr><br><tr><br><th>VAR_1934</th><br><td>IAPS</td><br><td>IAPS</td><br><td>IAPS</td><br><td>RCC</td><br><td>BRANCH</td><br></tr><br></tbody><br></table><br></div><p><code>VAR_0200</code>, <code>VAR_0237</code>, <code>VAR_0274</code> look like some georgraphical data thus one could generate geography related features, we will talk later in the course.</p><p>There are some features, that are hard to identify, but look, there a date columns <code>VAR_0073</code> ‚Äì <code>VAR_0179</code>, <code>VAR_0204</code>, <code>VAR_0217</code>. It is useful to plot one date against another to find relationships.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">date_cols = [<span class="string">u'VAR_0073'</span>,<span class="string">'VAR_0075'</span>,</div><div class="line">             <span class="string">u'VAR_0156'</span>,<span class="string">u'VAR_0157'</span>,<span class="string">u'VAR_0158'</span>,<span class="string">'VAR_0159'</span>,</div><div class="line">             <span class="string">u'VAR_0166'</span>, <span class="string">u'VAR_0167'</span>,<span class="string">u'VAR_0168'</span>,<span class="string">u'VAR_0169'</span>,</div><div class="line">             <span class="string">u'VAR_0176'</span>,<span class="string">u'VAR_0177'</span>,<span class="string">u'VAR_0178'</span>,<span class="string">u'VAR_0179'</span>,</div><div class="line">             <span class="string">u'VAR_0204'</span>,</div><div class="line">             <span class="string">u'VAR_0217'</span>]</div><div class="line"></div><div class="line"><span class="keyword">for</span> c <span class="keyword">in</span> date_cols:</div><div class="line">    train[c] = pd.to_datetime(train[c],format = <span class="string">'%d%b%y:%H:%M:%S'</span>)</div><div class="line">    test[c] = pd.to_datetime(test[c],  format = <span class="string">'%d%b%y:%H:%M:%S'</span>)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">c1 = <span class="string">'VAR_0217'</span></div><div class="line">c2 = <span class="string">'VAR_0073'</span></div><div class="line"></div><div class="line"><span class="comment"># mask = (~test[c1].isnull()) &amp; (~test[c2].isnull())</span></div><div class="line"><span class="comment"># sc2(test.ix[mask,c1].values,test.ix[mask,c2].values,alpha=0.7,c = 'black')</span></div><div class="line"></div><div class="line">mask = (~train[c1].isnull()) &amp; (~train[c2].isnull())</div><div class="line">sc2(train.loc[mask,c1].values,train.loc[mask,c2].values,c=train.loc[mask,<span class="string">'target'</span>].values)</div></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/ewanlee/blog-image-hosting/master/output_71_0.png" alt="png"></p><p>We see that one date is strictly greater than the other, so the difference between them can be a good feature. Also look at horizontal line there ‚Äì it also looks like NaN, so I would rather create a new binary feature which will serve as an idicator that our time feature is NaN.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is a notebook, used in the screencast video. Note, that the data files are not present here in Jupyter hub and you will not be able to run it. But you can always download the notebook to your local machine as well as the competition data and make it interactive.&lt;/p&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; os&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; tqdm &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; tqdm_notebook&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; plt&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;%matplotlib inline&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; warnings&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;warnings.filterwarnings(&lt;span class=&quot;string&quot;&gt;&#39;ignore&#39;&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; seaborn&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;autolabel&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(arrayA)&lt;/span&gt;:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&#39;&#39;&#39; label each colored square with the corresponding data value. &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    If value &amp;gt; 20, the text is in black, else in white.&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &#39;&#39;&#39;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    arrayA = np.array(arrayA)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; range(arrayA.shape[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;]):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; j &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; range(arrayA.shape[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                plt.text(j,i, &lt;span class=&quot;string&quot;&gt;&quot;%.2f&quot;&lt;/span&gt;%arrayA[i,j], ha=&lt;span class=&quot;string&quot;&gt;&#39;center&#39;&lt;/span&gt;, va=&lt;span class=&quot;string&quot;&gt;&#39;bottom&#39;&lt;/span&gt;,color=&lt;span class=&quot;string&quot;&gt;&#39;w&#39;&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;hist_it&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(feat)&lt;/span&gt;:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    plt.figure(figsize=(&lt;span class=&quot;number&quot;&gt;16&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    feat[Y==&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;].hist(bins=range(int(feat.min()),int(feat.max()+&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)),normed=&lt;span class=&quot;keyword&quot;&gt;True&lt;/span&gt;,alpha=&lt;span class=&quot;number&quot;&gt;0.8&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    feat[Y==&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;].hist(bins=range(int(feat.min()),int(feat.max()+&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)),normed=&lt;span class=&quot;keyword&quot;&gt;True&lt;/span&gt;,alpha=&lt;span class=&quot;number&quot;&gt;0.5&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    plt.ylim((&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;gt_matrix&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(feats,sz=&lt;span class=&quot;number&quot;&gt;16&lt;/span&gt;)&lt;/span&gt;:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    a = []&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i,c1 &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; enumerate(feats):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        b = [] &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; j,c2 &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; enumerate(feats):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            mask = (~train[c1].isnull()) &amp;amp; (~train[c2].isnull())&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; i&amp;gt;=j:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                b.append((train.loc[mask,c1].values&amp;gt;=train.loc[mask,c2].values).mean())&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;:&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;                b.append((train.loc[mask,c1].values&amp;gt;train.loc[mask,c2].values).mean())&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        a.append(b)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    plt.figure(figsize = (sz,sz))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    plt.imshow(a, interpolation = &lt;span class=&quot;string&quot;&gt;&#39;None&#39;&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    _ = plt.xticks(range(len(feats)),feats,rotation = &lt;span class=&quot;number&quot;&gt;90&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    _ = plt.yticks(range(len(feats)),feats,rotation = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    autolabel(a)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;hist_it1&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(feat)&lt;/span&gt;:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    plt.figure(figsize=(&lt;span class=&quot;number&quot;&gt;16&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;))&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    feat[Y==&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;].hist(bins=&lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;,range=(feat.min(),feat.max()),normed=&lt;span class=&quot;keyword&quot;&gt;True&lt;/span&gt;,alpha=&lt;span class=&quot;number&quot;&gt;0.5&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    feat[Y==&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;].hist(bins=&lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;,range=(feat.min(),feat.max()),normed=&lt;span class=&quot;keyword&quot;&gt;True&lt;/span&gt;,alpha=&lt;span class=&quot;number&quot;&gt;0.5&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    plt.ylim((&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;))&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h1 id=&quot;Read-the-data&quot;&gt;&lt;a href=&quot;#Read-the-data&quot; class=&quot;headerlink&quot; title=&quot;Read the data&quot;&gt;&lt;/a&gt;Read the data&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;train = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&#39;train.csv.zip&#39;&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Y = train.target&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;test = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&#39;test.csv.zip&#39;&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;test_ID = test.ID&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>EDA check list</title>
    <link href="http://yoursite.com/2018/10/16/EDA-check-list/"/>
    <id>http://yoursite.com/2018/10/16/EDA-check-list/</id>
    <published>2018-10-16T08:05:28.000Z</published>
    <updated>2018-10-16T08:06:51.636Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Get domain knowledge</li><li>Check if the data is intuitive (abnormal detection)<ul><li>add a feature <code>is_incorrect</code></li></ul></li><li><a href="https://tomaxent.com/2018/10/16/Exploratory-Data-Analysis/" target="_blank" rel="external">Understand how the data was generated</a><ul><li>It is crucial to understand the generation process to set up a proper validation scheme</li></ul></li><li>Two things to do with anonymized features<ul><li>Try to decode the features<ul><li><a href="https://tomaxent.com/2018/10/16/Processing-anonymized-features/" target="_blank" rel="external">Guess the true meaning of the feature</a></li></ul></li><li>Guess the feature types<ul><li>Each type need its own preprocessing</li></ul></li></ul></li><li>Visualization<ul><li>Tools for individual features exploration<ul><li>Histograms <code>plt.hist(x)</code></li><li>Plot (index versus value) <code>plt.plot(x, something)</code></li><li>Statistics <code>df.describe() or x.mean() or x.var()</code></li><li>Other tools <code>x.value_counts() or x.isnull()</code></li></ul></li><li>Tools for feature relationships<ul><li>Pairs<ul><li><code>plt.scatter(x1, x2)</code></li><li><code>pd.scatter_matrix(df)</code></li><li><code>df.corr() or plt.matshow()</code></li></ul></li><li>Groups:<ul><li>Clustering</li><li>Plot (index vs feature statistics) <code>df.mean().sort_values().plot()</code></li></ul></li></ul></li></ul></li><li>Data Clean<ul><li>remove duplicated and constant features<ul><li><code>traintest.nunique(axis=1) == 1</code></li><li><code>traintest.T.drop_duplicates()</code></li><li><code>for f in categorical_feats: traintest[f] = traintest[f].factorize then traintest.T.drop_duplicates()</code></li></ul></li><li>check if same rows have same label</li><li>check if dataset is shuffled</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;&lt;li&gt;Get domain knowledge&lt;/li&gt;&lt;li&gt;Check if the data is intuitive (abnormal detection)&lt;ul&gt;&lt;li&gt;add a feature &lt;code&gt;is_incorrect&lt;/code&gt;&lt;/li&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Processing Anonymized Features</title>
    <link href="http://yoursite.com/2018/10/16/Processing-anonymized-features/"/>
    <id>http://yoursite.com/2018/10/16/Processing-anonymized-features/</id>
    <published>2018-10-16T07:22:45.000Z</published>
    <updated>2018-10-16T07:23:19.410Z</updated>
    
    <content type="html"><![CDATA[<p><strong>IMPORTANT:</strong> You will not be able to run this notebook at coursera platform, as the dataset is not there. The notebook is in read-only mode.</p><p>But you can run the notebook locally and download the dataset using <a href="https://habrastorage.org/storage/stuff/special/beeline/00.beeline_bigdata.zip" target="_blank" rel="external">this link</a> to explore the data interactively.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pd.set_option(<span class="string">'max_columns'</span>, <span class="number">100</span>)</div></pre></td></tr></table></figure><h1 id="Load-the-data"><a href="#Load-the-data" class="headerlink" title="Load the data"></a>Load the data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">train = pd.read_csv(<span class="string">'./train.csv'</span>)</div><div class="line">train.head()</div></pre></td></tr></table></figure><a id="more"></a><div><br><style><br>.dataframe thead tr:only-child th{<br>        text-align:right}<br><br>.dataframe thead th{<br>        text-align:left}<br><br>.dataframe tbody tr th{<br>        vertical-align:top}<br></style><br><table border="1" class="dataframe"><br><thead><br><tr style="text-align:right"><br><th></th><br><th>x0</th><br><th>x1</th><br><th>x2</th><br><th>x3</th><br><th>x4</th><br><th>x5</th><br><th>x6</th><br><th>x7</th><br><th>x8</th><br><th>x9</th><br><th>x10</th><br><th>x11</th><br><th>x12</th><br><th>x13</th><br><th>x14</th><br><th>x15</th><br><th>x16</th><br><th>x17</th><br><th>x18</th><br><th>x19</th><br><th>x20</th><br><th>x21</th><br><th>x22</th><br><th>x23</th><br><th>x24</th><br><th>x25</th><br><th>x26</th><br><th>x27</th><br><th>x28</th><br><th>x29</th><br><th>x30</th><br><th>x31</th><br><th>x32</th><br><th>x33</th><br><th>x34</th><br><th>x35</th><br><th>x36</th><br><th>x37</th><br><th>x38</th><br><th>x39</th><br><th>x40</th><br><th>x41</th><br><th>x42</th><br><th>x43</th><br><th>x44</th><br><th>x45</th><br><th>x46</th><br><th>x47</th><br><th>x48</th><br><th>x49</th><br><th>x50</th><br><th>x51</th><br><th>x52</th><br><th>x53</th><br><th>x54</th><br><th>x55</th><br><th>x56</th><br><th>x57</th><br><th>x58</th><br><th>x59</th><br><th>x60</th><br><th>x61</th><br><th>y</th><br></tr><br></thead><br><tbody><br><tr><br><th>0</th><br><td>b4d8a653ea</td><br><td>16a14a2d17</td><br><td>06330986ed</td><br><td>ca63304de0</td><br><td>a62168d626</td><br><td>1746600cb0</td><br><td>1</td><br><td>1</td><br><td>-0.688706</td><br><td>7e5c97705a</td><br><td>e5df3eff9b</td><br><td>91bb549494</td><br><td>e33c63cf35</td><br><td>3694.0</td><br><td>6e40247e69</td><br><td>617a4ad3f9</td><br><td>718c61545b</td><br><td>c26d08129a</td><br><td>634e3cf3ac</td><br><td>dd9c9e0da2</td><br><td>17c99905b6</td><br><td>513a3e3f36</td><br><td>9aba4d7f51</td><br><td>40.579612</td><br><td>-0.112693</td><br><td>-0.172191</td><br><td>1.166667</td><br><td>1.674538</td><br><td>0.630889</td><br><td>37.000000</td><br><td>1.294922</td><br><td>55.0</td><br><td>0.166667</td><br><td>10.0</td><br><td>0.0</td><br><td>0.000000</td><br><td>1.0</td><br><td>9.0</td><br><td>0.0</td><br><td>1.0</td><br><td>23.0</td><br><td>3.67</td><br><td>0.12</td><br><td>1.935</td><br><td>2.2</td><br><td>0.625</td><br><td>0.250</td><br><td>0.125</td><br><td>0.000</td><br><td>0.813</td><br><td>0.074</td><br><td>0.634</td><br><td>0.548</td><br><td>0.235333</td><br><td>0.264952</td><br><td>0.000000</td><br><td>0.333333</td><br><td>0.333333</td><br><td>0.333333</td><br><td>0.000000</td><br><td>0.000000</td><br><td>9.0</td><br><td>2</td><br></tr><br><tr><br><th>1</th><br><td>467f9617a3</td><br><td>16a14a2d17</td><br><td>06330986ed</td><br><td>ca63304de0</td><br><td>b7584c2d52</td><br><td>1746600cb0</td><br><td>1</td><br><td>1</td><br><td>0.870871</td><br><td>5624b8f759</td><br><td>fa0b797a92</td><br><td>669ea3d319</td><br><td>f178803074</td><br><td>18156.0</td><br><td>01ede04b4b</td><br><td>617a4ad3f9</td><br><td>718c61545b</td><br><td>d342e2765f</td><br><td>bb20e1ca06</td><br><td>8a6c8cef83</td><br><td>1b02793146</td><br><td>992153ed65</td><br><td>9aba4d7f51</td><br><td>28.765503</td><br><td>2.612285</td><br><td>2.159091</td><br><td>4.000000</td><br><td>1.710714</td><br><td>1.713538</td><br><td>0.166667</td><br><td>0.027669</td><br><td>109.0</td><br><td>0.000000</td><br><td>31.0</td><br><td>0.0</td><br><td>0.000000</td><br><td>1.0</td><br><td>244.0</td><br><td>1.0</td><br><td>1.0</td><br><td>68.0</td><br><td>17.25</td><br><td>0.57</td><br><td>3.452</td><br><td>4.0</td><br><td>0.409</td><br><td>0.619</td><br><td>0.579</td><br><td>0.248</td><br><td>0.346</td><br><td>0.541</td><br><td>0.522</td><br><td>0.000</td><br><td>1.782346</td><br><td>1.322409</td><br><td>0.011647</td><br><td>0.397671</td><br><td>0.239601</td><br><td>0.249584</td><br><td>0.068220</td><br><td>0.033278</td><br><td>601.0</td><br><td>4</td><br></tr><br><tr><br><th>2</th><br><td>190436e528</td><br><td>16a14a2d17</td><br><td>06330986ed</td><br><td>ca63304de0</td><br><td>b7584c2d52</td><br><td>1746600cb0</td><br><td>1</td><br><td>1</td><br><td>0.437655</td><br><td>5624b8f759</td><br><td>152af2cb2f</td><br><td>91bb549494</td><br><td>e33c63cf35</td><br><td>1178.0</td><br><td>cc69cbe29a</td><br><td>617a4ad3f9</td><br><td>e8a040423a</td><br><td>c82c3dbd33</td><br><td>ee3501282b</td><br><td>199ce7c484</td><br><td>5f17dedd5c</td><br><td>5c5025bd0a</td><br><td>9aba4d7f51</td><br><td>24.943933</td><br><td>-0.814660</td><br><td>-0.708308</td><br><td>1.500000</td><br><td>-0.512422</td><br><td>-0.733967</td><br><td>0.333333</td><br><td>14.837728</td><br><td>11.0</td><br><td>0.000000</td><br><td>24.0</td><br><td>0.0</td><br><td>0.000000</td><br><td>1.0</td><br><td>29.0</td><br><td>0.0</td><br><td>3.0</td><br><td>11.0</td><br><td>4.42</td><br><td>0.15</td><br><td>0.161</td><br><td>0.2</td><br><td>1.000</td><br><td>1.000</td><br><td>1.000</td><br><td>1.000</td><br><td>1.000</td><br><td>0.520</td><br><td>0.533</td><br><td>0.835</td><br><td>-0.586540</td><br><td>0.672436</td><br><td>0.000000</td><br><td>0.606061</td><br><td>0.121212</td><br><td>0.212121</td><br><td>0.060606</td><br><td>0.000000</td><br><td>33.0</td><br><td>3</td><br></tr><br><tr><br><th>3</th><br><td>43859085bc</td><br><td>16a14a2d17</td><br><td>06330986ed</td><br><td>ca63304de0</td><br><td>a62168d626</td><br><td>1746600cb0</td><br><td>1</td><br><td>1</td><br><td>0.004439</td><br><td>f67f142e40</td><br><td>c4dd2197c3</td><br><td>91bb549494</td><br><td>e33c63cf35</td><br><td>14559.0</td><br><td>6e40247e69</td><br><td>617a4ad3f9</td><br><td>718c61545b</td><br><td>c26d08129a</td><br><td>9e166b965d</td><br><td>466f8951b0</td><br><td>fde72a6d5c</td><br><td>acfadc5c01</td><br><td>9aba4d7f51</td><br><td>41.576860</td><br><td>-0.907833</td><br><td>-0.761736</td><br><td>0.500000</td><br><td>-0.627525</td><br><td>-0.805801</td><br><td>1.166667</td><br><td>0.004395</td><br><td>0.0</td><br><td>0.500000</td><br><td>0.0</td><br><td>0.0</td><br><td>0.000000</td><br><td>7.0</td><br><td>7.0</td><br><td>0.0</td><br><td>3.0</td><br><td>15.0</td><br><td>8.92</td><br><td>0.29</td><br><td>0.226</td><br><td>0.8</td><br><td>0.000</td><br><td>0.000</td><br><td>0.000</td><br><td>0.000</td><br><td>0.000</td><br><td>1.000</td><br><td>0.000</td><br><td>0.000</td><br><td>-1.600326</td><br><td>-1.838680</td><br><td>0.000000</td><br><td>1.000000</td><br><td>0.000000</td><br><td>0.000000</td><br><td>0.000000</td><br><td>0.000000</td><br><td>1.0</td><br><td>4</td><br></tr><br><tr><br><th>4</th><br><td>a4c3095b75</td><br><td>16a14a2d17</td><br><td>06330986ed</td><br><td>ca63304de0</td><br><td>b7584c2d52</td><br><td>1746600cb0</td><br><td>1</td><br><td>1</td><br><td>0.480977</td><br><td>7e5c97705a</td><br><td>e071d01df5</td><br><td>91bb549494</td><br><td>e33c63cf35</td><br><td>5777.0</td><br><td>6e40247e69</td><br><td>617a4ad3f9</td><br><td>4b9480aa42</td><br><td>e84655292c</td><br><td>527b6ca8cc</td><br><td>dd9c9e0da2</td><br><td>17c99905b6</td><br><td>0fc56ea1f0</td><br><td>9aba4d7f51</td><br><td>31.080282</td><br><td>-0.371787</td><br><td>-0.367616</td><br><td>1.666667</td><br><td>0.271307</td><br><td>0.013112</td><br><td>17.333333</td><br><td>1713.439128</td><br><td>33.0</td><br><td>0.000000</td><br><td>6.0</td><br><td>1.0</td><br><td>0.666667</td><br><td>8.0</td><br><td>108.0</td><br><td>1.0</td><br><td>4.0</td><br><td>86.0</td><br><td>1.58</td><br><td>0.05</td><br><td>2.032</td><br><td>2.4</td><br><td>0.348</td><br><td>0.762</td><br><td>0.550</td><br><td>0.392</td><br><td>0.489</td><br><td>0.517</td><br><td>1.000</td><br><td>0.642</td><br><td>0.960991</td><br><td>0.790990</td><br><td>0.020161</td><br><td>0.645161</td><br><td>0.258065</td><br><td>0.036290</td><br><td>0.040323</td><br><td>0.000000</td><br><td>248.0</td><br><td>3</td><br></tr><br></tbody><br></table><br></div><h1 id="Build-a-quick-baseline"><a href="#Build-a-quick-baseline" class="headerlink" title="Build a quick baseline"></a>Build a quick baseline</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</div><div class="line"></div><div class="line"><span class="comment"># Create a copy to work with</span></div><div class="line">X = train.copy()</div><div class="line"></div><div class="line"><span class="comment"># Save and drop labels</span></div><div class="line">y = train.y</div><div class="line">X = X.drop(<span class="string">'y'</span>, axis=<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment"># fill NANs </span></div><div class="line">X = X.fillna(<span class="number">-999</span>)</div><div class="line"></div><div class="line"><span class="comment"># Label encoder</span></div><div class="line"><span class="keyword">for</span> c <span class="keyword">in</span> train.columns[train.dtypes == <span class="string">'object'</span>]:</div><div class="line">    X[c] = X[c].factorize()[<span class="number">0</span>]</div><div class="line">    </div><div class="line">rf = RandomForestClassifier()</div><div class="line">rf.fit(X,y)</div></pre></td></tr></table></figure><pre><code>RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&apos;gini&apos;,
            max_depth=None, max_features=&apos;auto&apos;, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
            verbose=0, warm_start=False)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">plt.plot(rf.feature_importances_)</div><div class="line">plt.xticks(np.arange(X.shape[<span class="number">1</span>]), X.columns.tolist(), rotation=<span class="number">90</span>);</div></pre></td></tr></table></figure><pre><code>/home/dulyanov/miniconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:1297: UserWarning: findfont: Font family [u&apos;serif&apos;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))
</code></pre><p><img src="https://github.com/ewanlee/blog-image-hosting/blob/master/output_6_1.png?raw=true" alt="png"></p><p>There is something interesting about <code>x8</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># we see it was standard scaled, most likely, if we concat train and test, we will get exact mean=1, and std 1 </span></div><div class="line"><span class="keyword">print</span> <span class="string">'Mean:'</span>, train.x8.mean()</div><div class="line"><span class="keyword">print</span> <span class="string">'std:'</span>, train.x8.std()</div></pre></td></tr></table></figure><pre><code>Mean: -0.000252352028622
std: 1.02328163601
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># And we see that it has a lot of repeated values</span></div><div class="line">train.x8.value_counts().head(<span class="number">15</span>)</div></pre></td></tr></table></figure><pre><code>-2.984750    2770
 0.480977    2569
 0.610941    1828
 0.654263    1759
 0.567620    1746
 0.697585    1691
 0.524298    1639
 0.740906    1628
 0.394333    1610
 0.437655    1513
 0.351012    1450
 0.264369    1429
 0.307690    1401
 0.221047    1372
 0.784228    1293
Name: x8, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># It's very hard to work with scaled feature, so let's try to scale them back</span></div><div class="line"><span class="comment"># Let's first take a look at difference between neighbouring values in x8</span></div><div class="line"></div><div class="line">x8_unique = train.x8.unique()</div><div class="line">x8_unique_sorted = np.sort(x8_unique)</div><div class="line">                           </div><div class="line">np.diff(x8_unique_sorted)</div></pre></td></tr></table></figure><pre><code>array([ 43.27826527,  38.98942817,   0.21660793,   0.04332159,
         0.17328635,   0.21660793,   0.08664317,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.12996476,   0.04332159,
         0.04332159,   0.04332159,   0.04332159,   0.04332159,
         0.04332159,   0.04332159,   0.21660793,   1.16968285,
         0.04332159,   0.38989428,          nan])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># The most of the diffs are 0.04332159! </span></div><div class="line"><span class="comment"># The data is scaled, so we don't know what was the diff value for the original feature</span></div><div class="line"><span class="comment"># But let's assume it was 1.0</span></div><div class="line"><span class="comment"># Let's devide all the numbers by 0.04332159 to get the right scaling</span></div><div class="line"><span class="comment"># note, that feature will still have zero mean</span></div><div class="line"></div><div class="line">np.diff(x8_unique_sorted/<span class="number">0.04332159</span>)</div></pre></td></tr></table></figure><pre><code>array([ 998.99992752,  899.9999347 ,    4.99999964,    0.99999993,
          3.99999971,    4.99999964,    1.99999985,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    2.99999978,    0.99999993,
          0.99999993,    0.99999993,    0.99999993,    0.99999993,
          0.99999993,    0.99999993,    4.99999964,   26.99999804,
          0.99999993,    8.99999935,           nan])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(train.x8/<span class="number">0.04332159</span>).head(<span class="number">10</span>)</div></pre></td></tr></table></figure><pre><code>0   -15.897530
1    20.102468
2    10.102468
3     0.102469
4    11.102468
5   -68.897526
6    10.102468
7    15.102468
8     9.102468
9   -68.897526
Name: x8, dtype: float64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Ok, now we see .102468 in every value</span></div><div class="line"><span class="comment"># this looks like a part of a mean that was subtracted during standard scaling</span></div><div class="line"><span class="comment"># If we subtract it, the values become almost integers</span></div><div class="line">(train.x8/<span class="number">0.04332159</span> - <span class="number">.102468</span>).head(<span class="number">10</span>)</div></pre></td></tr></table></figure><pre><code>0   -15.999998
1    20.000000
2    10.000000
3     0.000001
4    11.000000
5   -68.999994
6    10.000000
7    15.000000
8     9.000000
9   -68.999994
Name: x8, dtype: float64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># let's round them </span></div><div class="line">x8_int = (train.x8/<span class="number">0.04332159</span> - <span class="number">.102468</span>).round()</div><div class="line">x8_int.head(<span class="number">10</span>)</div></pre></td></tr></table></figure><pre><code>0   -16.0
1    20.0
2    10.0
3     0.0
4    11.0
5   -69.0
6    10.0
7    15.0
8     9.0
9   -69.0
Name: x8, dtype: float64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Ok, what's next? In fact it is not obvious how to find shift parameter, </span></div><div class="line"><span class="comment"># and how to understand what the data this feature actually store</span></div><div class="line"><span class="comment"># But ...</span></div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x8_int.value_counts()</div></pre></td></tr></table></figure><pre><code>-69.0      2770
 11.0      2569
 14.0      1828
 15.0      1759
 13.0      1746
 16.0      1691
 12.0      1639
 17.0      1628
 9.0       1610
 10.0      1513
 8.0       1450
 6.0       1429
 7.0       1401
 5.0       1372
 18.0      1293
 1.0       1290
 4.0       1276
 2.0       1250
 3.0       1213
-1.0       1085
 0.0       1080
-2.0       1006
-4.0        995
-3.0        976
-5.0        954
-8.0        923
-9.0        921
-6.0        906
 19.0       893
-7.0        881
           ... 
 26.0         3
-40.0         3
-41.0         3
 25.0         2
-59.0         2
 31.0         2
 34.0         2
-46.0         2
-49.0         2
 33.0         2
-42.0         2
 32.0         2
 37.0         2
 30.0         2
-45.0         2
-54.0         1
 36.0         1
-51.0         1
 27.0         1
 79.0         1
-47.0         1
 69.0         1
 70.0         1
-50.0         1
-1968.0       1
 42.0         1
-63.0         1
-48.0         1
-64.0         1
 35.0         1
Name: x8, Length: 99, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># do you see this -1968? Doesn't it look like a year? ... So my hypothesis is that this feature is a year of birth! </span></div><div class="line"><span class="comment"># Maybe it was a textbox where users enter their year of birth, and someone entered 0000 instead</span></div><div class="line"><span class="comment"># The hypothesis looks plausible, isn't it?</span></div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(x8_int + <span class="number">1968.0</span>).value_counts().sort_index()</div></pre></td></tr></table></figure><pre><code>0.0          1
999.0        4
1899.0    2770
1904.0       1
1905.0       1
1909.0       2
1914.0       1
1916.0       3
1917.0       1
1918.0       1
1919.0       2
1920.0       1
1921.0       1
1922.0       2
1923.0       2
1924.0       4
1925.0       4
1926.0       2
1927.0       3
1928.0       3
1929.0       4
1930.0       4
1931.0      12
1932.0      10
1933.0       7
1934.0      13
1935.0      28
1936.0      35
1937.0      35
1938.0      45
          ... 
1978.0    1513
1979.0    2569
1980.0    1639
1981.0    1746
1982.0    1828
1983.0    1759
1984.0    1691
1985.0    1628
1986.0    1293
1987.0     893
1988.0     624
1989.0     434
1990.0     233
1991.0     110
1992.0      31
1993.0       2
1994.0       3
1995.0       1
1998.0       2
1999.0       2
2000.0       2
2001.0       2
2002.0       2
2003.0       1
2004.0       1
2005.0       2
2010.0       1
2037.0       1
2038.0       1
2047.0       1
Name: x8, Length: 99, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># After the competition ended the organisers told it was really a year of birth</span></div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;IMPORTANT:&lt;/strong&gt; You will not be able to run this notebook at coursera platform, as the dataset is not there. The notebook is in read-only mode.&lt;/p&gt;&lt;p&gt;But you can run the notebook locally and download the dataset using &lt;a href=&quot;https://habrastorage.org/storage/stuff/special/beeline/00.beeline_bigdata.zip&quot;&gt;this link&lt;/a&gt; to explore the data interactively.&lt;/p&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;pd.set_option(&lt;span class=&quot;string&quot;&gt;&#39;max_columns&#39;&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h1 id=&quot;Load-the-data&quot;&gt;&lt;a href=&quot;#Load-the-data&quot; class=&quot;headerlink&quot; title=&quot;Load the data&quot;&gt;&lt;/a&gt;Load the data&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;train = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&#39;./train.csv&#39;&lt;/span&gt;)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;train.head()&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Exploratory Data Analysis</title>
    <link href="http://yoursite.com/2018/10/16/Exploratory-Data-Analysis/"/>
    <id>http://yoursite.com/2018/10/16/Exploratory-Data-Analysis/</id>
    <published>2018-10-16T06:39:40.000Z</published>
    <updated>2018-10-16T07:15:25.325Z</updated>
    
    <content type="html"><![CDATA[<p>This is a detailed EDA of the data, shown in the second video of ‚ÄúExploratory data analysis‚Äù lecture (week 2).</p><p><strong>PLEASE NOTE</strong>: the dataset cannot be published, so this notebook is read-only.</p><h2 id="Load-data"><a href="#Load-data" class="headerlink" title="Load data"></a>Load data</h2><p>In this competition hosted by <em>solutions.se</em>, the task was to predict the advertisement cost for a particular ad.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">%matplotlib inline</div><div class="line"></div><div class="line">data_path = <span class="string">'./data'</span></div><div class="line">train = pd.read_csv(<span class="string">'%s/train.csv.gz'</span> % data_path, parse_dates=[<span class="string">'Date'</span>])</div><div class="line">test  = pd.read_csv(<span class="string">'%s/test.csv.gz'</span> % data_path,  parse_dates=[<span class="string">'Date'</span>])</div></pre></td></tr></table></figure><p>Let‚Äôs look at the data (notice that the table is transposed, so we can see all feature names).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.head().T</div></pre></td></tr></table></figure><a id="more"></a><table border="1" class="dataframe"><br><br><br><thead><br><tr style="text-align:right"><br><th></th><br><th>0</th><br><th>1</th><br><th>2</th><br><th>3</th><br><th>4</th><br></tr><br></thead><br><tbody><br><tr><br><th>AdGroupId</th><br><td>78db034136</td><br><td>68a0110c69</td><br><td>21af1035af</td><br><td>f63fda0c33</td><br><td>cd868ebdcc</td><br></tr><br><tr><br><th>AdGroupName</th><br><td>6d91d 25866 9c594</td><br><td>2657d cb2d0 6d91d</td><br><td>6d91d e33a0 9a99b</td><br><td>59991 9c594</td><br><td>6d91d 25866 9a99b</td><br></tr><br><tr><br><th>AdNetworkType2</th><br><td>s</td><br><td>s</td><br><td>s</td><br><td>s</td><br><td>s</td><br></tr><br><tr><br><th>AveragePosition</th><br><td>1.2</td><br><td>2</td><br><td>1</td><br><td>1</td><br><td>1.1</td><br></tr><br><tr><br><th>CampaignId</th><br><td>273823cb71</td><br><td>273823cb71</td><br><td>273823cb71</td><br><td>273823cb71</td><br><td>273823cb71</td><br></tr><br><tr><br><th>CampaignName</th><br><td>2657d 16cb2 74532 b4842 0136e 35aca f140d</td><br><td>2657d 16cb2 74532 b4842 0136e 35aca f140d</td><br><td>2657d 16cb2 74532 b4842 0136e 35aca f140d</td><br><td>2657d 16cb2 74532 b4842 0136e 35aca f140d</td><br><td>2657d 16cb2 74532 b4842 0136e 35aca f140d</td><br></tr><br><tr><br><th>Clicks</th><br><td>0</td><br><td>0</td><br><td>0</td><br><td>0</td><br><td>3</td><br></tr><br><tr><br><th>Conversions</th><br><td>0</td><br><td>0</td><br><td>0</td><br><td>0</td><br><td>0</td><br></tr><br><tr><br><th>ConversionsManyPerClick</th><br><td>0</td><br><td>0</td><br><td>0</td><br><td>0</td><br><td>0</td><br></tr><br><tr><br><th>Cost</th><br><td>0</td><br><td>0</td><br><td>0</td><br><td>0</td><br><td>0.94</td><br></tr><br><tr><br><th>Date</th><br><td>2014-01-01 00:00:00</td><br><td>2014-01-01 00:00:00</td><br><td>2014-01-01 00:00:00</td><br><td>2014-01-01 00:00:00</td><br><td>2014-01-01 00:00:00</td><br></tr><br><tr><br><th>DestinationUrl</th><br><td>98035d60fc</td><br><td>c25f23cd08</td><br><td>01f87f7639</td><br><td>5c0e89f532</td><br><td>8888b55dde</td><br></tr><br><tr><br><th>Device</th><br><td>t</td><br><td>t</td><br><td>t</td><br><td>d</td><br><td>d</td><br></tr><br><tr><br><th>FirstPageCpc</th><br><td>1.06</td><br><td>2.94</td><br><td>0.42</td><br><td>1.75</td><br><td>0.17</td><br></tr><br><tr><br><th>Impressions</th><br><td>32</td><br><td>1</td><br><td>4</td><br><td>1</td><br><td>22</td><br></tr><br><tr><br><th>KeywordMatchType</th><br><td>b</td><br><td>b</td><br><td>b</td><br><td>b</td><br><td>b</td><br></tr><br><tr><br><th>KeywordText</th><br><td>jze 10 +uxsgk</td><br><td>+jze +dznvgyhjclr</td><br><td>jze 100 +gzpxyk</td><br><td>jze 10 +uxsgk 1950k</td><br><td>jze 10 mykj +gzpxyk</td><br></tr><br><tr><br><th>MaxCpc</th><br><td>0.28</td><br><td>1</td><br><td>0.22</td><br><td>0.54</td><br><td>0.12</td><br></tr><br><tr><br><th>QualityScore</th><br><td>1</td><br><td>1</td><br><td>1</td><br><td>1</td><br><td>1</td><br></tr><br><tr><br><th>Slot</th><br><td>s_2</td><br><td>s_2</td><br><td>s_1</td><br><td>s_2</td><br><td>s_1</td><br></tr><br><tr><br><th>TopOfPageCpc</th><br><td>1.07</td><br><td>5.02</td><br><td>0.42</td><br><td>4</td><br><td>0.25</td><br></tr><br><tr><br><th>KeywordId</th><br><td>7d20d63df9</td><br><td>a617d4f037</td><br><td>6e0b7024d2</td><br><td>9c2ea0cdf8</td><br><td>4c8ba7affd</td><br></tr><br></tbody><br></table><p>We see a lot of features with not obvious names. If you search for the <em>CampaignId</em>, <em>AdGroupName</em>, <em>AdNetworkType2</em> using any web search engine, you will find this dataset was exported from Google AdWords. So what is the required domain knowledge here? The knowledge of how web advertisement and Google AdWords work! After you have learned it, the features will make sense to you and you can proceed.</p><p>For the sake of the story I will briefly describe Google AdWords system now. Basically every time a user queries a search engine, Google AdWords decides what ad will be shown along with the actual search results. On the other side of AdWords, the advertisers manage the ads ‚Äì they can set a multiple keywords, that a user should query in order to their ad to be shown. If the keywords are set properly and are relevant to the ad, then the ad will be shown to relevant users and the ad will get clicked. Advertisers pay to Google for some type of events, happened with their ad: for example for a click event, i.e. the user saw this ad and clicked it. AdWords uses complex algorithms to decide which ad to show to a particular user with a particular search query. The advertisers can only indirectly influence AdWords decesion process by changing keywords and several other parameters. So at a high level, the task is to predict what will be the costs for the advertiser (how much he will pay to Google, column <em>Cost</em>) when the parameters (e.g. keywords) are changed.</p><p>The ads are grouped in groups, there are features <em>AdGroupId</em> <em>AdGroupName</em> describing them. A campaign corresponds to some specific parameters that an advertiser sets. Similarly, there are ID and name features <em>CampaignId</em>, <em>CampaignName</em>. And finally there is some information about keywords: <em>KeywordId</em> and <em>KeywordText</em>. Slot is $1$ when ad is shown on top of the page, and $2$ when on the side. Device is a categorical variable and can be either ‚Äútablet‚Äù, ‚Äúmobile‚Äù or ‚Äúpc‚Äù. And finally the <em>Date</em> is just the date, for which clicks were aggregated.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">test.head().T</div></pre></td></tr></table></figure><table border="1" class="dataframe"><br><thead><br><tr style="text-align:right"><br><th></th><br><th>0</th><br><th>1</th><br><th>2</th><br><th>3</th><br><th>4</th><br></tr><br></thead><br><tbody><br><tr><br><th>Id</th><br><td>0</td><br><td>1</td><br><td>2</td><br><td>3</td><br><td>4</td><br></tr><br><tr><br><th>AdGroupId</th><br><td>00096e7611</td><br><td>00096e7611</td><br><td>00096e7611</td><br><td>00096e7611</td><br><td>00096e7611</td><br></tr><br><tr><br><th>AdGroupName</th><br><td>c8037 75b01 9a99b 3b678 52ba4 2657d</td><br><td>c8037 75b01 9a99b 3b678 52ba4 2657d</td><br><td>c8037 75b01 9a99b 3b678 52ba4 2657d</td><br><td>c8037 75b01 9a99b 3b678 52ba4 2657d</td><br><td>c8037 75b01 9a99b 3b678 52ba4 2657d</td><br></tr><br><tr><br><th>AdNetworkType2</th><br><td>s</td><br><td>s</td><br><td>s</td><br><td>s</td><br><td>s</td><br></tr><br><tr><br><th>AveragePosition</th><br><td>1</td><br><td>1</td><br><td>1</td><br><td>1</td><br><td>1</td><br></tr><br><tr><br><th>CampaignId</th><br><td>e62b4bc4c3</td><br><td>e62b4bc4c3</td><br><td>e62b4bc4c3</td><br><td>e62b4bc4c3</td><br><td>e62b4bc4c3</td><br></tr><br><tr><br><th>CampaignName</th><br><td>2657d 16cb2 74532 06feb 0136e 3a15d</td><br><td>2657d 16cb2 74532 06feb 0136e 3a15d</td><br><td>2657d 16cb2 74532 06feb 0136e 3a15d</td><br><td>2657d 16cb2 74532 06feb 0136e 3a15d</td><br><td>2657d 16cb2 74532 06feb 0136e 3a15d</td><br></tr><br><tr><br><th>Date</th><br><td>2014-06-01 00:00:00</td><br><td>2014-06-01 00:00:00</td><br><td>2014-06-01 00:00:00</td><br><td>2014-06-01 00:00:00</td><br><td>2014-06-01 00:00:00</td><br></tr><br><tr><br><th>DestinationUrl</th><br><td>f5aad09031</td><br><td>f5aad09031</td><br><td>f5aad09031</td><br><td>f5aad09031</td><br><td>f5aad09031</td><br></tr><br><tr><br><th>Device</th><br><td>t</td><br><td>d</td><br><td>m</td><br><td>t</td><br><td>d</td><br></tr><br><tr><br><th>KeywordId</th><br><td>539778bb80</td><br><td>539778bb80</td><br><td>539778bb80</td><br><td>539778bb80</td><br><td>539778bb80</td><br></tr><br><tr><br><th>KeywordMatchType</th><br><td>e</td><br><td>e</td><br><td>e</td><br><td>e</td><br><td>e</td><br></tr><br><tr><br><th>KeywordText</th><br><td>tcjnw gzpxyk nyss ewzhy</td><br><td>tcjnw gzpxyk nyss ewzhy</td><br><td>tcjnw gzpxyk nyss ewzhy</td><br><td>tcjnw gzpxyk nyss ewzhy</td><br><td>tcjnw gzpxyk nyss ewzhy</td><br></tr><br><tr><br><th>Slot</th><br><td>s_1</td><br><td>s_1</td><br><td>s_1</td><br><td>s_2</td><br><td>s_2</td><br></tr><br></tbody><br></table><p>Notice there is diffrent number of columns in test and train ‚Äì our target is <em>Cost</em> column, but it is closly related to several other features, e.g. <em>Clicks</em>, <em>Conversions</em>. All of the related columns were deleted from the test set to avoid data leakages.</p><h1 id="Let‚Äôs-analyze"><a href="#Let‚Äôs-analyze" class="headerlink" title="Let‚Äôs analyze"></a>Let‚Äôs analyze</h1><p>Are we ready to modeling? Not yet. Take a look at this statistic:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'Train min/max date: %s / %s'</span> % (train.Date.min().date(), train.Date.max().date())</div><div class="line"><span class="keyword">print</span> <span class="string">'Test  min/max date: %s / %s'</span> % ( test.Date.min().date(),  test.Date.max().date())</div><div class="line"><span class="keyword">print</span> <span class="string">''</span></div><div class="line"><span class="keyword">print</span> <span class="string">'Number of days in train: %d'</span> % ((train.Date.max() - train.Date.min()).days + <span class="number">1</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">'Number of days in test:  %d'</span> % (( test.Date.max() -  test.Date.min()).days + <span class="number">1</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">''</span></div><div class="line"><span class="keyword">print</span> <span class="string">'Train shape: %d rows'</span> % train.shape[<span class="number">0</span>]</div><div class="line"><span class="keyword">print</span> <span class="string">'Test shape: %d rows'</span>  % test.shape[<span class="number">0</span>]</div></pre></td></tr></table></figure><pre><code>Train min/max date: 2014-01-01 / 2014-05-31
Test  min/max date: 2014-06-01 / 2014-06-14

Number of days in train: 151
Number of days in test:  14

Train shape: 3493820 rows
Test shape: 8951040 rows
</code></pre><p>Train period is more than 10 times larger than the test period, but train set has fewer rows, how could that happen?</p><p>At this point I suggest you to stop and think yourself, what could be a reason, why this did happen. Unfortunately we cannot share the data for this competition, but the information from above should be enough to get a right idea.</p><p>Alternatively, you can go along for the explanation, if you want.</p><h1 id="Investigation"><a href="#Investigation" class="headerlink" title="Investigation"></a>Investigation</h1><p>Let‚Äôs take a look how many rows with each date we have in train and test.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">test.Date.value_counts()</div></pre></td></tr></table></figure><pre><code>2014-06-02    639360
2014-06-12    639360
2014-06-09    639360
2014-06-14    639360
2014-06-01    639360
2014-06-11    639360
2014-06-08    639360
2014-06-05    639360
2014-06-10    639360
2014-06-07    639360
2014-06-04    639360
2014-06-06    639360
2014-06-03    639360
2014-06-13    639360
Name: Date, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># print only first 10</span></div><div class="line">train.Date.value_counts().head(<span class="number">10</span>)</div></pre></td></tr></table></figure><pre><code>2014-01-01    36869
2014-01-04    36427
2014-01-05    36137
2014-01-02    34755
2014-01-03    34693
2014-01-06    31349
2014-04-07    30950
2014-02-09    30101
2014-01-26    29830
2014-02-08    29187
Name: Date, dtype: int64
</code></pre><p>Interesting, for the test set we have the same number of rows for every date, while in train set the number of rows is different for each day. It looks like that for each day in the test set a loop through some kind of IDs had been run. But what about train set? So far we don‚Äôt know, but let‚Äôs find the test IDs first.</p><h3 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h3><p>So now we know, that there is $639360$ different IDs. It should be easy to find the columns, that form ID, because if the ID is [‚Äòcol1‚Äô, ‚Äòcol2‚Äô], then to compute the number of combinations we should just multiply the number of unique elements in each.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">test_nunique = test.nunique()</div><div class="line">test_nunique</div></pre></td></tr></table></figure><pre><code>Id                  8951040
AdGroupId             13548
AdGroupName            2281
AdNetworkType2            2
AveragePosition         131
CampaignId              252
CampaignName            252
Date                     14
DestinationUrl        52675
Device                    3
KeywordId             12285
KeywordMatchType          3
KeywordText           11349
Slot                      4
dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> itertools</div><div class="line"></div><div class="line"><span class="comment"># This function looks for a combination of elements </span></div><div class="line"><span class="comment"># with product of 639360 </span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_prod</span><span class="params">(data)</span>:</span></div><div class="line">    <span class="comment"># combinations of not more than 5 features</span></div><div class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">5</span>):</div><div class="line">        <span class="comment"># iterate through all combinations</span></div><div class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> itertools.combinations(range(len(data)), n):</div><div class="line">            <span class="keyword">if</span> data[list(c)].prod() == <span class="number">639360</span>:</div><div class="line">                <span class="keyword">print</span> test_nunique.index[c]</div><div class="line">                <span class="keyword">return</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Nothing found'</span></div><div class="line"></div><div class="line">    </div><div class="line">find_prod(test_nunique.values)</div></pre></td></tr></table></figure><pre><code>Nothing found
</code></pre><p>Hmm, nothing found! The problem is that some features are tied, and the number of their combinations does not equal to product of individual unique number of elements. For example it does not make sense to create all possible combinations of <em>DestinationUrl</em> and <em>AdGroupId</em> as <em>DestinationUrl</em> belong to exactly one <em>AdGroupId</em>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">test.groupby(<span class="string">'DestinationUrl'</span>).AdGroupId.nunique()</div></pre></td></tr></table></figure><pre><code>DestinationUrl
00010d62df    1
000249f717    1
00054cf3f8    1
000684bf0b    1
00072a9fa7    1
00077a6729    1
0007cc191f    1
0009388900    1
001144cae4    1
00115f6477    1
00141a299f    1
00169dc49b    1
0018b27e06    1
001b0b3d06    1
001ef8368e    1
00205e056a    1
002082ab8b    1
0020c585ea    1
0021419f7e    1
00225519cc    1
002498dc88    1
0026171436    1
00265dc4bb    1
0026833e5c    1
0027ffbad9    1
002b1deb25    1
002c55ccef    1
002e44290f    1
0030ca870e    1
0032b64beb    1
             ..
ffda377018    1
ffda3c412a    1
ffda5b53d6    1
ffda8c0d8c    1
ffdbf5d179    1
ffdc872fcf    1
ffde114af5    1
ffde41a800    1
ffe2fb7007    1
ffe4a040d4    1
ffe685e937    1
ffe8c3da53    1
ffe8f82e08    1
ffeb9fda9d    1
ffebd1d253    1
ffebea724f    1
ffecf398b1    1
ffecf3e7d4    1
ffed185438    1
fff02d7269    1
fff10adcb0    1
fff12e5f19    1
fff132d5bd    1
fff19836a0    1
fff3539204    1
fff4c5d255    1
fff55db78a    1
fff8c11ad9    1
fff90ea351    1
fffb248bf0    1
Name: AdGroupId, Length: 52675, dtype: int64
</code></pre><p>So, now let‚Äôs try to find ID differently. Let‚Äôs try to find a list of columns, such that threre is exazctly $639360$ unique combinations of their values <strong>in the test set</strong> (not overall). So, we want to find <code>columns</code>, such that:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">test[columns].drop_duplicates().shape[<span class="number">0</span>]  == <span class="number">639360</span></div></pre></td></tr></table></figure><p>We could do it with a similar loop.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> itertools</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_ncombinations</span><span class="params">(data)</span>:</span></div><div class="line">    <span class="comment"># combinations of not more than 5 features</span></div><div class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">5</span>):</div><div class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> itertools.combinations(range(data.shape[<span class="number">1</span>]), n):</div><div class="line">            <span class="keyword">print</span> c</div><div class="line">            columns = test.columns[list(c)]</div><div class="line">            <span class="keyword">if</span> test[columns].drop_duplicates().shape[<span class="number">0</span>] == <span class="number">639360</span>:</div><div class="line">                <span class="keyword">print</span> columns</div><div class="line">                <span class="keyword">return</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Nothing found'</span></div><div class="line"></div><div class="line">    </div><div class="line">find_ncombinations(test)</div></pre></td></tr></table></figure><p>But it will take forever to compute. So it is easier to find the combination manually.</p><p>So after some time of trials and errors I figured out, that the four features <em>KeywordId, AdGroupId, Device, Slot</em> form the index. The number of unique rows is exactly <em>639360</em> as we wanted to find.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">columns = [<span class="string">'KeywordId'</span>, <span class="string">'AdGroupId'</span>, <span class="string">'Device'</span>, <span class="string">'Slot'</span>]</div><div class="line">test[columns].drop_duplicates().shape</div></pre></td></tr></table></figure><pre><code>(639360, 4)
</code></pre><p>Looks reasonable. For each <em>AdGroupId</em> there is a <strong>distinct set</strong> of possible <em>KeywordId‚Äôs</em>, but <em>Device</em> and <em>Slot</em> variants are the same for each ad. And the target is to predict what will be the daily cost for using different <em>KeywordId‚Äôs</em>, <em>Device</em> type, <em>Slot</em> type to advertise ads from <em>AdGroups</em>.</p><h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><p>To this end, we found how test set was constructed, but what about the train set? Let us plot something, probably we will find it out.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</div><div class="line">sns.set(palette=<span class="string">'pastel'</span>)</div><div class="line">sns.set(font_scale=<span class="number">2</span>)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># from absolute dates to relative</span></div><div class="line">train[<span class="string">'date_diff'</span>] =  (train.Date - train.Date.min()).dt.days</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># group by the index, that we've found</span></div><div class="line">g= train.groupby([<span class="string">'KeywordId'</span>, <span class="string">'AdGroupId'</span>, <span class="string">'Device'</span>, <span class="string">'Slot'</span>])</div><div class="line"></div><div class="line"><span class="comment"># and for each index show average relative date versus </span></div><div class="line"><span class="comment"># the number of rows with that index</span></div><div class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">12</span>))</div><div class="line">plt.scatter(g.date_diff.mean(),g.size(),edgecolor = <span class="string">'none'</span>,alpha = <span class="number">0.2</span>, s=<span class="number">20</span>, c=<span class="string">'b'</span>)</div><div class="line">plt.xlabel(<span class="string">'Group mean relative date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Group size'</span>)</div><div class="line">plt.title(<span class="string">'Train'</span>);</div></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/ewanlee/blog-image-hosting/master/output_36_0.png" alt="png"></p><p>Looks interesting, isn‚Äôt it? That is something we need to explain! How the same plot looks for the test set?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># from absolute dates to relative</span></div><div class="line">test[<span class="string">'date_diff'</span>] =  (test.Date - test.Date.min()).dt.days</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># group by the index, that we've found</span></div><div class="line">g= test.groupby([<span class="string">'KeywordId'</span>, <span class="string">'AdGroupId'</span>, <span class="string">'Device'</span>, <span class="string">'Slot'</span>])</div><div class="line"></div><div class="line"><span class="comment"># and for each index show average relative date versus </span></div><div class="line"><span class="comment"># the number of rows with that index</span></div><div class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">12</span>))</div><div class="line">plt.scatter(g.date_diff.mean(),g.size(),edgecolor = <span class="string">'none'</span>,alpha = <span class="number">0.2</span>, s=<span class="number">20</span>, c=<span class="string">'b'</span>)</div><div class="line">plt.xlabel(<span class="string">'Group mean relative date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Group size'</span>)</div><div class="line">plt.ylim(<span class="number">-2</span>, <span class="number">30</span>)</div><div class="line">plt.title(<span class="string">'Test'</span>);</div></pre></td></tr></table></figure><p><img src="https://github.com/ewanlee/blog-image-hosting/blob/master/output_39_0.png?raw=true" alt="png"></p><p>Just a dot!</p><p>Now let‚Äôs think, what we actually plotted? We grouped the data by the ID that we‚Äôve found previously and we plotted average <em>Date</em> in the group versus the size of each group. We found that ID is an aggregation index ‚Äì so for each date the <em>Cost</em> is aggreagated for each possible index. So group size shows for how many days we have <em>Const</em> information for each ID and mean relative date shows some information about these days.</p><p>For test set it is expectable that both average date and the size of the groups are the same for each group: the size of each group is $14$ (as we have $14$ test days) and mean date is $6.5$, because for each group (index) we have $14$ different days, and $\frac{0 + 1 + \dots + 13}{14} = 6.5$.</p><p>And now we can explain everything for the train set. Look at the top of the triangle: for those points (groups) we have <em>Cost</em> information for all the days in the train period, while on the sides we see groups, for which we have very few rows.</p><p>But why for some groups we have smaller number of rows, than number of days? Let‚Äôs look at the <em>Impressions</em> column.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train.Impressions.value_counts()</div></pre></td></tr></table></figure><pre><code>1         1602929
2          565896
3          287128
4          175197
5          119092
6           86651
7           66443
8           53007
9           42984
10          35731
11          30248
12          25950
13          22629
14          20126
15          17503
16          15682
17          14100
18          12848
19          11597
20          10724
21           9864
22           8931
23           8316
24           7953
25           7168
26           6684
27           6196
28           5863
29           5556
30           5223
           ...   
4978            1
15210           1
9076            1
13174           1
116535          1
4979            1
17273           1
90974           1
4976            1
5906            1
7023            1
60282           1
7955            1
13881           1
2921            1
4970            1
7019            1
17249           1
23394           1
28210           1
11116           1
15929           1
7017            1
95761           1
2923            1
15213           1
9070            1
5692            1
13162           1
13922           1
Name: Impressions, Length: 8135, dtype: int64
</code></pre><p>We never have $0$ value in <em>Imressions</em> column. But in reality, of course, some ads with some combination of keyword, slot, device were never shown. So this looks like a nice explanation for the data: in the train set we <strong>only</strong> have information about ads (IDs, groups) which were shown at least once. And for the test set, we, of course, want to predict <em>Cost</em> <strong>for every</strong> possible ID.</p><p>What it means for competitors, is that if one would just fit a model on the train set as is, the predictions for the test set will be biased by a lot. The predictions will be much higher than they should be, as we are only given a specific subset of rows as <code>train.csv</code> file.</p><p>So, before modeling we should first extend the trainset and inject rows with <code>0</code> impressions. Such change will make train set very similar to the test set and the models will generalize nicely.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is a detailed EDA of the data, shown in the second video of ‚ÄúExploratory data analysis‚Äù lecture (week 2).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;PLEASE NOTE&lt;/strong&gt;: the dataset cannot be published, so this notebook is read-only.&lt;/p&gt;&lt;h2 id=&quot;Load-data&quot;&gt;&lt;a href=&quot;#Load-data&quot; class=&quot;headerlink&quot; title=&quot;Load data&quot;&gt;&lt;/a&gt;Load data&lt;/h2&gt;&lt;p&gt;In this competition hosted by &lt;em&gt;solutions.se&lt;/em&gt;, the task was to predict the advertisement cost for a particular ad.&lt;/p&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; plt&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;%matplotlib inline&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;data_path = &lt;span class=&quot;string&quot;&gt;&#39;./data&#39;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;train = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&#39;%s/train.csv.gz&#39;&lt;/span&gt; % data_path, parse_dates=[&lt;span class=&quot;string&quot;&gt;&#39;Date&#39;&lt;/span&gt;])&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;test  = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&#39;%s/test.csv.gz&#39;&lt;/span&gt; % data_path,  parse_dates=[&lt;span class=&quot;string&quot;&gt;&#39;Date&#39;&lt;/span&gt;])&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;Let‚Äôs look at the data (notice that the table is transposed, so we can see all feature names).&lt;/p&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;train.head().T&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÁõ∏ÂÖ≥ÊäÄÊúØ</title>
    <link href="http://yoursite.com/2018/10/15/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/"/>
    <id>http://yoursite.com/2018/10/15/Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÁõ∏ÂÖ≥ÊäÄÊúØ/</id>
    <published>2018-10-15T14:07:35.000Z</published>
    <updated>2018-10-15T14:35:02.055Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Êï∞ÂÄºÂûãÊï∞ÊçÆ-non-tree-based-model"><a href="#Êï∞ÂÄºÂûãÊï∞ÊçÆ-non-tree-based-model" class="headerlink" title="Êï∞ÂÄºÂûãÊï∞ÊçÆ (non-tree based model)"></a>Êï∞ÂÄºÂûãÊï∞ÊçÆ (non-tree based model)</h1><ul><li>ÁâπÂæÅÈ¢ÑÂ§ÑÁêÜ<ul><li>MinMaxScalar ‰∏ç‰ºöÊîπÂèòÊï∞ÊçÆÂàÜÂ∏É</li><li>StandardScalar</li><li>scipy.stats.rankdata</li><li>log transform <code>np.log(1+x)</code></li><li>raising to the power &lt; 1 <code>np.sqrt(x + 2/3)</code></li><li><strong>drop outlierÔºàwinsorizationÔºåspecify upper and lower boundÔºâ</strong></li></ul></li></ul><p>ËûçÂêà‰∏çÂêåÈ¢ÑÂ§ÑÁêÜÊñπÊ≥ïÂæóÂà∞ÁöÑÁâπÂæÅËÆ≠ÁªÉ‰∏Ä‰∏™Ê®°ÂûãÊàñËÄÖÊØè‰∏ÄÁßçÁâπÂæÅËÆ≠ÁªÉÂá∫‰∏Ä‰∏™Ê®°ÂûãÊúÄÂêéÂÅöÊ®°ÂûãËûçÂêà</p><ul><li>ÁâπÂæÅÁîüÊàê<ul><li><strong>‰∏ªË¶Å‰æùÊçÆÂÖàÈ™åÁªèÈ™å‰ª•ÂèäÂØπÊï∞ÊçÆÁöÑÊ∑±ÂàªÁêÜËß£</strong></li><li>‰æãÂ¶ÇÔºåÊµÆÁÇπÊï∞ÁöÑÂ∞èÊï∞ÈÉ®ÂàÜÂçïÁã¨ÊèêÂèñÂá∫Êù•‰Ωú‰∏∫ÁâπÂæÅ</li></ul></li></ul><h1 id="Á±ªÂà´Êï∞ÊçÆ‰ª•ÂèäÊúâÂ∫èÁ±ªÂà´Êï∞ÊçÆ"><a href="#Á±ªÂà´Êï∞ÊçÆ‰ª•ÂèäÊúâÂ∫èÁ±ªÂà´Êï∞ÊçÆ" class="headerlink" title="Á±ªÂà´Êï∞ÊçÆ‰ª•ÂèäÊúâÂ∫èÁ±ªÂà´Êï∞ÊçÆ"></a>Á±ªÂà´Êï∞ÊçÆ‰ª•ÂèäÊúâÂ∫èÁ±ªÂà´Êï∞ÊçÆ</h1><ul><li>ÁâπÂæÅÈ¢ÑÂ§ÑÁêÜ<ul><li>Label encoding (tree(or non-tree)-based model)<ul><li>alphabetical sorted <code>sklearn.preprocessing.LabelEncoder</code></li><li>order of appearance <code>Pandas.factorize</code></li><li><strong>frequency encoding</strong> ÔºàÈùûÂ∏∏ÈÄÇÁî®‰∫éÊµãËØïÊï∞ÊçÆ‰∏≠ÂåÖÂê´ËÆ≠ÁªÉÊï∞ÊçÆÊú™ÂåÖÂê´ÁöÑÁ±ªÂà´Ôºâ</li></ul></li><li>Label encoding (non-tree(or tree)-based model)<ul><li>one-hot encoding (sparse matrix)</li></ul></li></ul></li><li>ÁâπÂæÅÁîüÊàê<ul><li>Êûö‰∏æ‰∏çÂêåÁöÑÁ±ªÂà´ÁâπÂæÅÁöÑÁªÑÂêàÂΩ¢ÊàêÊñ∞ÁöÑÁ±ªÂà´ÁâπÂæÅ (linear models and KNN)</li></ul></li></ul><h1 id="Êó•ÊúüÊï∞ÊçÆ‰ª•ÂèäÂùêÊ†áÊï∞ÊçÆ"><a href="#Êó•ÊúüÊï∞ÊçÆ‰ª•ÂèäÂùêÊ†áÊï∞ÊçÆ" class="headerlink" title="Êó•ÊúüÊï∞ÊçÆ‰ª•ÂèäÂùêÊ†áÊï∞ÊçÆ"></a>Êó•ÊúüÊï∞ÊçÆ‰ª•ÂèäÂùêÊ†áÊï∞ÊçÆ</h1><h2 id="Êó•ÊúüÊï∞ÊçÆ"><a href="#Êó•ÊúüÊï∞ÊçÆ" class="headerlink" title="Êó•ÊúüÊï∞ÊçÆ"></a>Êó•ÊúüÊï∞ÊçÆ</h2><ul><li>ÁâπÂæÅÁîüÊàê<ul><li>Âë®ÊúüÊÄßÊï∞ÊçÆ<ul><li>Day number in week, month, season, year</li><li>second, minute, second</li></ul></li><li>Ëá™‰ªÄ‰πàÊó∂ÂÄô‰ª•Êù•<ul><li>ÈóÆÈ¢òÊó†ÂÖ≥Ôºå ÊØîÂ¶ÇËá™1970Âπ¥1Êúà1Êó•‰ª•Êù•</li><li>ÈóÆÈ¢òÁõ∏ÂÖ≥ÔºåÊØîÂ¶ÇË∑ùÁ¶ª‰∏ã‰∏Ä‰∏™ËäÇÂÅáÊó•ËøòÊúâÂ§öÂ∞ëÂ§©Á≠âÁ≠â</li></ul></li><li>‰∏§‰∏™Êó•ÊúüÁâπÂæÅ‰πãÈó¥ÁöÑÂ∑ÆÂÄº</li></ul></li></ul><h2 id="ÂùêÊ†áÊï∞ÊçÆ"><a href="#ÂùêÊ†áÊï∞ÊçÆ" class="headerlink" title="ÂùêÊ†áÊï∞ÊçÆ"></a>ÂùêÊ†áÊï∞ÊçÆ</h2><ul><li><p>ÁâπÂæÅÁîüÊàê</p><ul><li>Ë∑ùÁ¶ªÊüê‰∫õÂÖ≥ÈîÆÂùêÊ†áÁöÑË∑ùÁ¶ªÁ≠âÁ≠âÔºàÈúÄË¶ÅÂ§ñÈÉ®Êï∞ÊçÆÊîØÊåÅÔºâ</li><li>ÂØπÂùêÊ†áËøõË°åÁΩëÊ†ºÂåñÊàñËÄÖËÅöÁ±ªÔºåÁÑ∂ÂêéËÆ°ÁÆóÊØè‰∏™ÁΩëÊ†º‰∏≠ÁöÑÁÇπË∑ùÁ¶ªÈÄâÂÆöÁÇπÁöÑË∑ùÁ¶ªÊàñËÄÖÊØè‰∏™Á∞á‰∏≠ÁöÑÁÇπË∑ùÁ¶ªËÅöÁ±ª‰∏≠ÂøÉÁöÑË∑ùÁ¶ª</li><li>ÁÇπÁöÑÂØÜÂ∫¶ÔºàÊüê‰∏ÄÈôêÂÆöËåÉÂõ¥‰πãÂÜÖÔºâ</li><li>Âå∫Âüü‰ª∑ÂÄºÔºå‰æãÂ¶ÇÁâ©‰ª∑Êàø‰ª∑Á≠âÔºàÊüê‰∏ÄÈôêÂÆöËåÉÂõ¥‰πãÂÜÖÔºâ</li></ul></li><li><p>ÁâπÂæÅÈ¢ÑÂ§ÑÁêÜ</p><ul><li>ÂùêÊ†áÊóãËΩ¨Ôºà‰æãÂ¶Ç45¬∞Ôºâ</li></ul></li></ul><h1 id="Áº∫Â§±ÂÄºÂ§ÑÁêÜ"><a href="#Áº∫Â§±ÂÄºÂ§ÑÁêÜ" class="headerlink" title="Áº∫Â§±ÂÄºÂ§ÑÁêÜ"></a>Áº∫Â§±ÂÄºÂ§ÑÁêÜ</h1><ul><li>ÊâæÂá∫ÈöêÂê´ÁöÑNaNÔºåÈÄöËøáÂèØËßÜÂåñÊï∞ÊçÆÂàÜÂ∏É</li><li>Â°´ÂÖÖÊñπÊ≥ï<ul><li><code>-999, -1</code>Á≠â</li><li>‰∏≠ÂÄºÔºåÂùáÂÄºÁ≠â</li><li>Â∞ùËØïÊÅ¢Â§çÁº∫Â§±Êï∞ÊçÆÔºàÁ∫øÊÄßÂõûÂΩíÔºâ</li></ul></li><li>ÁâπÂæÅÁîüÊàê<ul><li>Â¢ûÂä†‰∏Ä‰∏™ÁâπÂæÅÔºåÊòØÂê¶ÊúâÁº∫Â§±ÂÄº</li><li><strong>ÈááÁî®Â°´ÂÖÖÁöÑÁº∫Â§±ÂÄºËøõË°åÁâπÂæÅÁîüÊàêË¶ÅÁâπÂà´Â∞èÂøÉÔºå‰∏ÄËà¨Êù•ËØ¥Ëã•Ë¶ÅËøõË°åÁâπÂæÅÁîüÊàêÔºåÂàôÊúÄÂ•Ω‰∏çË¶ÅÂú®‰πãÂâçËøõË°åÁº∫Â§±ÂÄºÂ°´ÂÖÖ</strong></li></ul></li><li>xgboostÂØπ‰∫éÁº∫Â§±ÂÄº‰∏çÊïèÊÑü</li></ul><h1 id="ÊñáÊú¨Êï∞ÊçÆ"><a href="#ÊñáÊú¨Êï∞ÊçÆ" class="headerlink" title="ÊñáÊú¨Êï∞ÊçÆ"></a>ÊñáÊú¨Êï∞ÊçÆ</h1><ul><li>ÁâπÂæÅÁîüÊàê<ul><li>ËØçË¢ã <code>skearn.feature_extraction.text.CountVectorizer</code></li><li>TF-IDF <code>skearn.feature_extraction.text.TfidfVectorizer</code></li><li>N-grams <code>ngram</code></li></ul></li><li>ÁâπÂæÅÈ¢ÑÂ§ÑÁêÜ<ul><li>lowercase</li><li>lemmatization (ÂçïËØçÊúÄÂéüÂßãÁöÑÂΩ¢Âºè)</li><li>stemming</li><li>stopwords <code>nltk</code></li></ul></li><li><strong>Word2Vec, Doc2vec, Glove, FastText, etc</strong></li><li>Pipeline<ol><li>È¢ÑÂ§ÑÁêÜ</li><li>Ngrams then TF-IDF</li><li>or Word2Vec, etc</li></ol></li></ul><h1 id="ÂõæÂÉèÊï∞ÊçÆ"><a href="#ÂõæÂÉèÊï∞ÊçÆ" class="headerlink" title="ÂõæÂÉèÊï∞ÊçÆ"></a>ÂõæÂÉèÊï∞ÊçÆ</h1><ul><li>ÂèØ‰ª•ÁªìÂêà‰∏çÂêåÂ±ÇÁöÑÁâπÂæÅÂõæ</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Êï∞ÂÄºÂûãÊï∞ÊçÆ-non-tree-based-model&quot;&gt;&lt;a href=&quot;#Êï∞ÂÄºÂûãÊï∞ÊçÆ-non-tree-based-model&quot; class=&quot;headerlink&quot; title=&quot;Êï∞ÂÄºÂûãÊï∞ÊçÆ (non-tree based model)&quot;&gt;&lt;/a&gt;Êï∞ÂÄºÂûãÊï∞ÊçÆ 
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>About Feature Scaling and Normalization</title>
    <link href="http://yoursite.com/2018/10/15/About-Feature-Scaling-and-Normalization/"/>
    <id>http://yoursite.com/2018/10/15/About-Feature-Scaling-and-Normalization/</id>
    <published>2018-10-15T13:48:20.000Z</published>
    <updated>2018-10-15T14:05:31.310Z</updated>
    
    <content type="html"><![CDATA[<h2 id="About-standardization"><a href="#About-standardization" class="headerlink" title="About standardization"></a>About standardization</h2><p>The result of <strong>standardization</strong> (or <strong>Z-score normalization</strong>) is that the features will be rescaled so that they‚Äôll have the properties of a standard normal distribution with $\mu=0$ and $\sigma=1$</p><p>where $\mu$ is the mean (average) and $\sigma$ is the standard deviation from the mean; standard scores (also called <strong>z</strong> scores) of the samples are calculated as follows:<br>$$<br>z = \frac{x - \mu}{\sigma}<br>$$<br>Standardizing the features so that they are centered around 0 with a standard deviation of 1 is not only important if we are comparing measurements that have different units, but it is also a general requirement for many machine learning algorithms. Intuitively, we can think of gradient descent as a prominent example (an optimization algorithm often used in logistic regression, SVMs, perceptrons, neural networks etc.); with features being on different scales, certain weights may update faster than others since the feature values $x_j$ play a role in the weight updates<br>$$<br>\Delta w_j = - \eta \frac{\partial J}{\partial w_j} = \eta \sum_i (t^{(i)} - o^{(i)}) x_j^{(i)},<br>$$<br>so that</p><p>$w_j := w_j + \Delta w_j$, where $\eta$ is the learning rate, $t$ the target class label, and $o$ the actual output. Other intuitive examples include K-Nearest Neighbor algorithms and clustering algorithms that use, for example, Euclidean distance measures ‚Äì in fact, tree-based classifier are probably the only classifiers where feature scaling doesn‚Äôt make a difference.</p><p>In fact, the only family of algorithms that I could think of being scale-invariant are tree-based methods. Let‚Äôs take the general CART decision tree algorithm. Without going into much depth regarding information gain and impurity measures, we can think of the decision as ‚Äúis feature x_i &gt;= some_val?‚Äù Intuitively, we can see that it really doesn‚Äôt matter on which scale this feature is (centimeters, Fahrenheit, a standardized scale ‚Äì it really doesn‚Äôt matter).</p><p>Some examples of algorithms where feature scaling matters are:</p><ul><li>k-nearest neighbors with an Euclidean distance measure if want all features to contribute equally</li><li>k-means (see k-nearest neighbors)</li><li>logistic regression, SVMs, perceptrons, neural networks etc. if you are using gradient descent/ascent-based optimization, otherwise some weights will update much faster than others</li><li>linear discriminant analysis, principal component analysis, kernel principal component analysis since you want to find directions of maximizing the variance (under the constraints that those directions/eigenvectors/principal components are orthogonal); you want to have features on the same scale since you‚Äôd emphasize variables on ‚Äúlarger measurement scales‚Äù more. There are many more cases than I can possibly list here ‚Ä¶ I always recommend you to think about the algorithm and what it‚Äôs doing, and then it typically becomes obvious whether we want to scale your features or not.</li></ul><p>In addition, we‚Äôd also want to think about whether we want to ‚Äústandardize‚Äù or ‚Äúnormalize‚Äù (here: scaling to [0, 1] range) our data. Some algorithms assume that our data is centered at 0. For example, if we initialize the weights of a small multi-layer perceptron with tanh activation units to 0 or small random values centered around zero, we want to update the model weights ‚Äúequally.‚Äù As a rule of thumb I‚Äôd say: When in doubt, just standardize the data, it shouldn‚Äôt hurt.</p><h2 id="About-Min-Max-scaling"><a href="#About-Min-Max-scaling" class="headerlink" title="About Min-Max scaling"></a>About Min-Max scaling</h2><p>An alternative approach to Z-score normalization (or standardization) is the so-called <strong>Min-Max scaling</strong>(often also simply called ‚Äúnormalization‚Äù - a common cause for ambiguities).<br>In this approach, the data is scaled to a fixed range - usually 0 to 1.<br>The cost of having this bounded range - in contrast to standardization - is that we will end up with smaller standard deviations, which can suppress the effect of outliers.</p><p>A Min-Max scaling is typically done via the following equation:<br>$$<br>X_{norm} = \frac{X - X_{min}}{X_{max} - X_{min}}<br>$$</p><h2 id="Z-score-standardization-or-Min-Max-scaling"><a href="#Z-score-standardization-or-Min-Max-scaling" class="headerlink" title="Z-score standardization or Min-Max scaling?"></a>Z-score standardization or Min-Max scaling?</h2><p><em>‚ÄúStandardization or Min-Max scaling?‚Äù</em> - There is no obvious answer to this question: it really depends on the application.</p><p>For example, in clustering analyses, standardization may be especially crucial in order to compare similarities between features based on certain distance measures. Another prominent example is the Principal Component Analysis, where we usually prefer standardization over Min-Max scaling, since we are interested in the components that maximize the variance (depending on the question and if the PCA computes the components via the correlation matrix instead of the covariance matrix; <a href="http://sebastianraschka.com/Articles/2014_pca_step_by_step.html" target="_blank" rel="external">but more about PCA in my previous article</a>).</p><p>However, this doesn‚Äôt mean that Min-Max scaling is not useful at all! A popular application is image processing, where pixel intensities have to be normalized to fit within a certain range (i.e., 0 to 255 for the RGB color range). Also, typical neural network algorithm require data that on a 0-1 scale.</p><h2 id="Standardizing-and-normalizing-how-it-can-be-done-using-scikit-learn"><a href="#Standardizing-and-normalizing-how-it-can-be-done-using-scikit-learn" class="headerlink" title="Standardizing and normalizing - how it can be done using scikit-learn"></a>Standardizing and normalizing - how it can be done using scikit-learn</h2><p>Of course, we could make use of NumPy‚Äôs vectorization capabilities to calculate the z-scores for standardization and to normalize the data using the equations that were mentioned in the previous sections. However, there is an even more convenient approach using the preprocessing module from one of Python‚Äôs open-source machine learning library <a href="http://scikit-learn.org/" target="_blank" rel="external">scikit-learn</a>.</p><p>For the following examples and discussion, we will have a look at the free ‚ÄúWine‚Äù Dataset that is deposited on the UCI machine learning repository<br>(<a href="http://archive.ics.uci.edu/ml/datasets/Wine" target="_blank" rel="external">http://archive.ics.uci.edu/ml/datasets/Wine</a>).</p><blockquote><p>Forina, M. et al, PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.</p><p>Bache, K. &amp; Lichman, M. (2013). UCI Machine Learning Repository [<a href="http://archive.ics.uci.edu/ml" target="_blank" rel="external">http://archive.ics.uci.edu/ml</a>]. Irvine, CA: University of California, School of Information and Computer Science.</p></blockquote><p>The Wine dataset consists of 3 different classes where each row correspond to a particular wine sample.</p><p>The class labels (1, 2, 3) are listed in the first column, and the columns 2-14 correspond to 13 different attributes (features):</p><p>1) Alcohol<br>2) Malic acid<br>‚Ä¶</p><h4 id="Loading-the-wine-dataset"><a href="#Loading-the-wine-dataset" class="headerlink" title="Loading the wine dataset"></a>Loading the wine dataset</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">df = pd.io.parsers.read_csv(</div><div class="line">    <span class="string">'https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/wine_data.csv'</span>,</div><div class="line">     header=<span class="keyword">None</span>,</div><div class="line">     usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]</div><div class="line">    )</div><div class="line"></div><div class="line">df.columns=[<span class="string">'Class label'</span>, <span class="string">'Alcohol'</span>, <span class="string">'Malic acid'</span>]</div><div class="line"></div><div class="line">df.head()</div></pre></td></tr></table></figure><table><thead><tr><th></th><th>Class label</th><th>Alcohol</th><th>Malic acid</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>14.23</td><td>1.71</td></tr><tr><td>1</td><td>1</td><td>13.20</td><td>1.78</td></tr><tr><td>2</td><td>1</td><td>13.16</td><td>2.36</td></tr><tr><td>3</td><td>1</td><td>14.37</td><td>1.95</td></tr><tr><td>4</td><td>1</td><td>13.24</td><td>2.59</td></tr></tbody></table><p>As we can see in the table above, the features <strong>Alcohol</strong> (percent/volumne) and <strong>Malic acid</strong> (g/l) are measured on different scales, so that <strong>Feature Scaling</strong> is necessary important prior to any comparison or combination of these data.</p><h4 id="Standardization-and-Min-Max-scaling"><a href="#Standardization-and-Min-Max-scaling" class="headerlink" title="Standardization and Min-Max scaling"></a>Standardization and Min-Max scaling</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"></div><div class="line">std_scale = preprocessing.StandardScaler().fit(df[[<span class="string">'Alcohol'</span>, <span class="string">'Malic acid'</span>]])</div><div class="line">df_std = std_scale.transform(df[[<span class="string">'Alcohol'</span>, <span class="string">'Malic acid'</span>]])</div><div class="line"></div><div class="line">minmax_scale = preprocessing.MinMaxScaler().fit(df[[<span class="string">'Alcohol'</span>, <span class="string">'Malic acid'</span>]])</div><div class="line">df_minmax = minmax_scale.transform(df[[<span class="string">'Alcohol'</span>, <span class="string">'Malic acid'</span>]])</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">'Mean after standardization:\nAlcohol=&#123;:.2f&#125;, Malic acid=&#123;:.2f&#125;'</span></div><div class="line">      .format(df_std[:,<span class="number">0</span>].mean(), df_std[:,<span class="number">1</span>].mean()))</div><div class="line">print(<span class="string">'\nStandard deviation after standardization:\nAlcohol=&#123;:.2f&#125;, Malic acid=&#123;:.2f&#125;'</span></div><div class="line">      .format(df_std[:,<span class="number">0</span>].std(), df_std[:,<span class="number">1</span>].std()))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Mean after standardization:</div><div class="line">Alcohol=<span class="number">0.00</span>, Malic acid=<span class="number">0.00</span></div><div class="line"></div><div class="line">Standard deviation after standardization:</div><div class="line">Alcohol=<span class="number">1.00</span>, Malic acid=<span class="number">1.00</span></div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">'Min-value after min-max scaling:\nAlcohol=&#123;:.2f&#125;, Malic acid=&#123;:.2f&#125;'</span></div><div class="line">      .format(df_minmax[:,<span class="number">0</span>].min(), df_minmax[:,<span class="number">1</span>].min()))</div><div class="line">print(<span class="string">'\nMax-value after min-max scaling:\nAlcohol=&#123;:.2f&#125;, Malic acid=&#123;:.2f&#125;'</span></div><div class="line">      .format(df_minmax[:,<span class="number">0</span>].max(), df_minmax[:,<span class="number">1</span>].max()))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Min-value after min-max scaling:</div><div class="line">Alcohol=<span class="number">0.00</span>, Malic acid=<span class="number">0.00</span></div><div class="line"></div><div class="line">Max-value after min-max scaling:</div><div class="line">Alcohol=<span class="number">1.00</span>, Malic acid=<span class="number">1.00</span></div></pre></td></tr></table></figure><h4 id="Plotting"><a href="#Plotting" class="headerlink" title="Plotting"></a>Plotting</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot</span><span class="params">()</span>:</span></div><div class="line">    plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</div><div class="line"></div><div class="line">    plt.scatter(df[<span class="string">'Alcohol'</span>], df[<span class="string">'Malic acid'</span>],</div><div class="line">            color=<span class="string">'green'</span>, label=<span class="string">'input scale'</span>, alpha=<span class="number">0.5</span>)</div><div class="line"></div><div class="line">    plt.scatter(df_std[:,<span class="number">0</span>], df_std[:,<span class="number">1</span>], color=<span class="string">'red'</span>,</div><div class="line">            label=<span class="string">'Standardized [$$N  (\mu=0, \; \sigma=1)$$]'</span>, alpha=<span class="number">0.3</span>)</div><div class="line"></div><div class="line">    plt.scatter(df_minmax[:,<span class="number">0</span>], df_minmax[:,<span class="number">1</span>],</div><div class="line">            color=<span class="string">'blue'</span>, label=<span class="string">'min-max scaled [min=0, max=1]'</span>, alpha=<span class="number">0.3</span>)</div><div class="line"></div><div class="line">    plt.title(<span class="string">'Alcohol and Malic Acid content of the wine dataset'</span>)</div><div class="line">    plt.xlabel(<span class="string">'Alcohol'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Malic Acid'</span>)</div><div class="line">    plt.legend(loc=<span class="string">'upper left'</span>)</div><div class="line">    plt.grid()</div><div class="line"></div><div class="line">    plt.tight_layout()</div><div class="line"></div><div class="line">plot()</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="http://sebastianraschka.com/images/blog/2014/about_standardization_normalization/about_standardization_normalization_44_0.png" alt="png"></p><p>The plot above includes the wine datapoints on all three different scales: the input scale where the alcohol content was measured in volume-percent (green), the standardized features (red), and the normalized features (blue). In the following plot, we will zoom in into the three different axis-scales.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">fig, ax = plt.subplots(<span class="number">3</span>, figsize=(<span class="number">6</span>,<span class="number">14</span>))</div><div class="line"></div><div class="line"><span class="keyword">for</span> a,d,l <span class="keyword">in</span> zip(range(len(ax)),</div><div class="line">               (df[[<span class="string">'Alcohol'</span>, <span class="string">'Malic acid'</span>]].values, df_std, df_minmax),</div><div class="line">               (<span class="string">'Input scale'</span>,</div><div class="line">                <span class="string">'Standardized [$$N  (\mu=0, \; \sigma=1)$$]'</span>,</div><div class="line">                <span class="string">'min-max scaled [min=0, max=1]'</span>)</div><div class="line">                ):</div><div class="line">    <span class="keyword">for</span> i,c <span class="keyword">in</span> zip(range(<span class="number">1</span>,<span class="number">4</span>), (<span class="string">'red'</span>, <span class="string">'blue'</span>, <span class="string">'green'</span>)):</div><div class="line">        ax[a].scatter(d[df[<span class="string">'Class label'</span>].values == i, <span class="number">0</span>],</div><div class="line">                  d[df[<span class="string">'Class label'</span>].values == i, <span class="number">1</span>],</div><div class="line">                  alpha=<span class="number">0.5</span>,</div><div class="line">                  color=c,</div><div class="line">                  label=<span class="string">'Class %s'</span> %i</div><div class="line">                  )</div><div class="line">    ax[a].set_title(l)</div><div class="line">    ax[a].set_xlabel(<span class="string">'Alcohol'</span>)</div><div class="line">    ax[a].set_ylabel(<span class="string">'Malic Acid'</span>)</div><div class="line">    ax[a].legend(loc=<span class="string">'upper left'</span>)</div><div class="line">    ax[a].grid()</div><div class="line"></div><div class="line">plt.tight_layout()</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="http://sebastianraschka.com/images/blog/2014/about_standardization_normalization/about_standardization_normalization_48_0.png" alt="png"></p><h2 id="Bottom-up-approaches"><a href="#Bottom-up-approaches" class="headerlink" title="Bottom-up approaches"></a>Bottom-up approaches</h2><p>Of course, we can also code the equations for standardization and 0-1 Min-Max scaling ‚Äúmanually‚Äù. However, the scikit-learn methods are still useful if you are working with test and training data sets and want to scale them equally.</p><p>E.g.,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">std_scale = preprocessing.StandardScaler().fit(X_train)</div><div class="line">X_train = std_scale.transform(X_train)</div><div class="line">X_test = std_scale.transform(X_test)</div></pre></td></tr></table></figure><p>Below, we will perform the calculations using ‚Äúpure‚Äù Python code, and an more convenient NumPy solution, which is especially useful if we attempt to transform a whole matrix.</p><h3 id="Vanilla-Python"><a href="#Vanilla-Python" class="headerlink" title="Vanilla Python"></a>Vanilla Python</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Standardization</span></div><div class="line"></div><div class="line">x = [<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">3</span>]</div><div class="line">mean = sum(x)/len(x)</div><div class="line">std_dev = (<span class="number">1</span>/len(x) * sum([ (x_i - mean)**<span class="number">2</span> <span class="keyword">for</span> x_i <span class="keyword">in</span> x]))**<span class="number">0.5</span></div><div class="line"></div><div class="line">z_scores = [(x_i - mean)/std_dev <span class="keyword">for</span> x_i <span class="keyword">in</span> x]</div><div class="line"></div><div class="line"><span class="comment"># Min-Max scaling</span></div><div class="line"></div><div class="line">minmax = [(x_i - min(x)) / (max(x) - min(x)) <span class="keyword">for</span> x_i <span class="keyword">in</span> x]</div></pre></td></tr></table></figure><h3 id="NumPy"><a href="#NumPy" class="headerlink" title="NumPy"></a>NumPy</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># Standardization</span></div><div class="line"></div><div class="line">x_np = np.asarray(x)</div><div class="line">z_scores_np = (x_np - x_np.mean()) / x_np.std()</div><div class="line"></div><div class="line"><span class="comment"># Min-Max scaling</span></div><div class="line"></div><div class="line">np_minmax = (x_np - x_np.min()) / (x_np.max() - x_np.min())</div></pre></td></tr></table></figure><h3 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h3><p>Just to make sure that our code works correctly, let us plot the results via matplotlib.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">10</span>,<span class="number">5</span>))</div><div class="line"></div><div class="line">y_pos = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x))]</div><div class="line"></div><div class="line">ax1.scatter(z_scores, y_pos, color=<span class="string">'g'</span>)</div><div class="line">ax1.set_title(<span class="string">'Python standardization'</span>, color=<span class="string">'g'</span>)</div><div class="line"></div><div class="line">ax2.scatter(minmax, y_pos, color=<span class="string">'g'</span>)</div><div class="line">ax2.set_title(<span class="string">'Python Min-Max scaling'</span>, color=<span class="string">'g'</span>)</div><div class="line"></div><div class="line">ax3.scatter(z_scores_np, y_pos, color=<span class="string">'b'</span>)</div><div class="line">ax3.set_title(<span class="string">'Python NumPy standardization'</span>, color=<span class="string">'b'</span>)</div><div class="line"></div><div class="line">ax4.scatter(np_minmax, y_pos, color=<span class="string">'b'</span>)</div><div class="line">ax4.set_title(<span class="string">'Python NumPy Min-Max scaling'</span>, color=<span class="string">'b'</span>)</div><div class="line"></div><div class="line">plt.tight_layout()</div><div class="line"></div><div class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> (ax1, ax2, ax3, ax4):</div><div class="line">    ax.get_yaxis().set_visible(<span class="keyword">False</span>)</div><div class="line">    ax.grid()</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="http://sebastianraschka.com/images/blog/2014/about_standardization_normalization/about_standardization_normalization_64_0.png" alt="png"></p><h2 id="The-effect-of-standardization-on-PCA-in-a-pattern-classification-task"><a href="#The-effect-of-standardization-on-PCA-in-a-pattern-classification-task" class="headerlink" title="The effect of standardization on PCA in a pattern classification task"></a>The effect of standardization on PCA in a pattern classification task</h2><p>Earlier, I mentioned the Principal Component Analysis (PCA) as an example where standardization is crucial, since it is ‚Äúanalyzing‚Äù the variances of the different features.<br>Now, let us see how the standardization affects PCA and a following supervised classification on the whole wine dataset.</p><p>In the following section, we will go through the following steps:</p><ul><li>Reading in the dataset</li><li>Dividing the dataset into a separate training and test dataset</li><li>Standardization of the features</li><li>Principal Component Analysis (PCA) to reduce the dimensionality</li><li>Training a naive Bayes classifier</li><li>Evaluating the classification accuracy with and without standardization</li></ul><h3 id="Reading-in-the-dataset"><a href="#Reading-in-the-dataset" class="headerlink" title="Reading in the dataset"></a>Reading in the dataset</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.io.parsers.read_csv(</div><div class="line">    <span class="string">'https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/wine_data.csv'</span>,</div><div class="line">    header=<span class="keyword">None</span>,</div><div class="line">    )</div></pre></td></tr></table></figure><h3 id="Dividing-the-dataset-into-a-separate-training-and-test-dataset"><a href="#Dividing-the-dataset-into-a-separate-training-and-test-dataset" class="headerlink" title="Dividing the dataset into a separate training and test dataset"></a>Dividing the dataset into a separate training and test dataset</h3><p>In this step, we will randomly divide the wine dataset into a training dataset and a test dataset where the training dataset will contain 70% of the samples and the test dataset will contain 30%, respectively.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line">X_wine = df.values[:,<span class="number">1</span>:]</div><div class="line">y_wine = df.values[:,<span class="number">0</span>]</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine,</div><div class="line">    test_size=<span class="number">0.30</span>, random_state=<span class="number">12345</span>)</div></pre></td></tr></table></figure><h3 id="Feature-Scaling-Standardization"><a href="#Feature-Scaling-Standardization" class="headerlink" title="Feature Scaling - Standardization"></a>Feature Scaling - Standardization</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"></div><div class="line">std_scale = preprocessing.StandardScaler().fit(X_train)</div><div class="line">X_train_std = std_scale.transform(X_train)</div><div class="line">X_test_std = std_scale.transform(X_test)</div></pre></td></tr></table></figure><h3 id="Dimensionality-reduction-via-Principal-Component-Analysis-PCA"><a href="#Dimensionality-reduction-via-Principal-Component-Analysis-PCA" class="headerlink" title="Dimensionality reduction via Principal Component Analysis (PCA)"></a>Dimensionality reduction via Principal Component Analysis (PCA)</h3><p>Now, we perform a PCA on the standardized and the non-standardized datasets to transform the dataset onto a 2-dimensional feature subspace.<br>In a real application, a procedure like cross-validation would be done in order to find out what choice of features would yield a optimal balance between ‚Äúpreserving information‚Äù and ‚Äúoverfitting‚Äù for different classifiers. However, we will omit this step since we don‚Äôt want to train a perfect classifier here, but merely compare the effects of standardization.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</div><div class="line"></div><div class="line"><span class="comment"># on non-standardized data</span></div><div class="line">pca = PCA(n_components=<span class="number">2</span>).fit(X_train)</div><div class="line">X_train = pca.transform(X_train)</div><div class="line">X_test = pca.transform(X_test)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># om standardized data</span></div><div class="line">pca_std = PCA(n_components=<span class="number">2</span>).fit(X_train_std)</div><div class="line">X_train_std = pca_std.transform(X_train_std)</div><div class="line">X_test_std = pca_std.transform(X_test_std)</div></pre></td></tr></table></figure><p>Let us quickly visualize how our new feature subspace looks like (note that class labels are not considered in a PCA - in contrast to a Linear Discriminant Analysis - but I will add them in the plot for clarity).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">fig, (ax1, ax2) = plt.subplots(ncols=<span class="number">2</span>, figsize=(<span class="number">10</span>,<span class="number">4</span>))</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">for</span> l,c,m <span class="keyword">in</span> zip(range(<span class="number">1</span>,<span class="number">4</span>), (<span class="string">'blue'</span>, <span class="string">'red'</span>, <span class="string">'green'</span>), (<span class="string">'^'</span>, <span class="string">'s'</span>, <span class="string">'o'</span>)):</div><div class="line">    ax1.scatter(X_train[y_train==l, <span class="number">0</span>], X_train[y_train==l, <span class="number">1</span>],</div><div class="line">        color=c,</div><div class="line">        label=<span class="string">'class %s'</span> %l,</div><div class="line">        alpha=<span class="number">0.5</span>,</div><div class="line">        marker=m</div><div class="line">        )</div><div class="line"></div><div class="line"><span class="keyword">for</span> l,c,m <span class="keyword">in</span> zip(range(<span class="number">1</span>,<span class="number">4</span>), (<span class="string">'blue'</span>, <span class="string">'red'</span>, <span class="string">'green'</span>), (<span class="string">'^'</span>, <span class="string">'s'</span>, <span class="string">'o'</span>)):</div><div class="line">    ax2.scatter(X_train_std[y_train==l, <span class="number">0</span>], X_train_std[y_train==l, <span class="number">1</span>],</div><div class="line">        color=c,</div><div class="line">        label=<span class="string">'class %s'</span> %l,</div><div class="line">        alpha=<span class="number">0.5</span>,</div><div class="line">        marker=m</div><div class="line">        )</div><div class="line"></div><div class="line">ax1.set_title(<span class="string">'Transformed NON-standardized training dataset after PCA'</span>)    </div><div class="line">ax2.set_title(<span class="string">'Transformed standardized training dataset after PCA'</span>)    </div><div class="line"></div><div class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> (ax1, ax2):</div><div class="line"></div><div class="line">    ax.set_xlabel(<span class="string">'1st principal component'</span>)</div><div class="line">    ax.set_ylabel(<span class="string">'2nd principal component'</span>)</div><div class="line">    ax.legend(loc=<span class="string">'upper right'</span>)</div><div class="line">    ax.grid()</div><div class="line">plt.tight_layout()</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="http://sebastianraschka.com/images/blog/2014/about_standardization_normalization/about_standardization_normalization_89_0.png" alt="png"></p><h3 id="Training-a-naive-Bayes-classifier"><a href="#Training-a-naive-Bayes-classifier" class="headerlink" title="Training a naive Bayes classifier"></a>Training a naive Bayes classifier</h3><p>We will use a naive Bayes classifier for the classification task. If you are not familiar with it, the term ‚Äúnaive‚Äù comes from the assumption that all features are ‚Äúindependent‚Äù.<br>All in all, it is a simple but robust classifier based on Bayes‚Äô rule</p><p>I don‚Äôt want to get into more detail about Bayes‚Äô rule in this article, but if you are interested in a more detailed collection of examples, please have a look at the <a href="https://github.com/rasbt/pattern_classification#statistical-pattern-recognition-examples" target="_blank" rel="external">Statistical Patter Classification</a> in my pattern classification repository.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</div><div class="line"></div><div class="line"><span class="comment"># on non-standardized data</span></div><div class="line">gnb = GaussianNB()</div><div class="line">fit = gnb.fit(X_train, y_train)</div><div class="line"></div><div class="line"><span class="comment"># on standardized data</span></div><div class="line">gnb_std = GaussianNB()</div><div class="line">fit_std = gnb_std.fit(X_train_std, y_train)</div></pre></td></tr></table></figure><h3 id="Evaluating-the-classification-accuracy-with-and-without-standardization"><a href="#Evaluating-the-classification-accuracy-with-and-without-standardization" class="headerlink" title="Evaluating the classification accuracy with and without standardization"></a>Evaluating the classification accuracy with and without standardization</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div><div class="line"></div><div class="line">pred_train = gnb.predict(X_train)</div><div class="line"></div><div class="line">print(<span class="string">'\nPrediction accuracy for the training dataset'</span>)</div><div class="line">print(<span class="string">'&#123;:.2%&#125;'</span>.format(metrics.accuracy_score(y_train, pred_train)))</div><div class="line"></div><div class="line">pred_test = gnb.predict(X_test)</div><div class="line"></div><div class="line">print(<span class="string">'\nPrediction accuracy for the test dataset'</span>)</div><div class="line">print(<span class="string">'&#123;:.2%&#125;\n'</span>.format(metrics.accuracy_score(y_test, pred_test)))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Prediction accuracy <span class="keyword">for</span> the training dataset</div><div class="line"><span class="number">81.45</span>%</div><div class="line"></div><div class="line">Prediction accuracy <span class="keyword">for</span> the test dataset</div><div class="line"><span class="number">64.81</span>%</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">pred_train_std = gnb_std.predict(X_train_std)</div><div class="line"></div><div class="line">print(<span class="string">'\nPrediction accuracy for the training dataset'</span>)</div><div class="line">print(<span class="string">'&#123;:.2%&#125;'</span>.format(metrics.accuracy_score(y_train, pred_train_std)))</div><div class="line"></div><div class="line">pred_test_std = gnb_std.predict(X_test_std)</div><div class="line"></div><div class="line">print(<span class="string">'\nPrediction accuracy for the test dataset'</span>)</div><div class="line">print(<span class="string">'&#123;:.2%&#125;\n'</span>.format(metrics.accuracy_score(y_test, pred_test_std)))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Prediction accuracy <span class="keyword">for</span> the training dataset</div><div class="line"><span class="number">96.77</span>%</div><div class="line"></div><div class="line">Prediction accuracy <span class="keyword">for</span> the test dataset</div><div class="line"><span class="number">98.15</span>%</div></pre></td></tr></table></figure><p>As we can see, the standardization prior to the PCA definitely led to an decrease in the empirical error rate on classifying samples from test dataset.</p><h2 id="Appendix-A-The-effect-of-scaling-and-mean-centering-of-variables-prior-to-PCA"><a href="#Appendix-A-The-effect-of-scaling-and-mean-centering-of-variables-prior-to-PCA" class="headerlink" title="Appendix A: The effect of scaling and mean centering of variables prior to PCA"></a>Appendix A: The effect of scaling and mean centering of variables prior to PCA</h2><p>Let us think about whether it matters or not if the variables are centered for applications such as Principal Component Analysis (PCA) if the PCA is calculated from the covariance matrix (i.e., the kkprincipal components are the eigenvectors of the covariance matrix that correspond to the kk largest eigenvalues.</p><h3 id="1-Mean-centering-does-not-affect-the-covariance-matrix"><a href="#1-Mean-centering-does-not-affect-the-covariance-matrix" class="headerlink" title="1. Mean centering does not affect the covariance matrix"></a>1. Mean centering does not affect the covariance matrix</h3><p>Here, the rational is: If the covariance is the same whether the variables are centered or not, the result of the PCA will be the same.</p><p>Let‚Äôs assume we have the 2 variables $x$ and $y$ Then the covariance between the attributes is calculated as<br>$$<br>\sigma_{xy} = \frac{1}{n-1} \sum_{i}^{n} (x_i - \bar{x})(y_i - \bar{y})<br>$$<br>Let us write the centered variables as<br>$$<br>x‚Äô = x - \bar{x} \text{ and } y‚Äô = y - \bar{y}<br>$$<br>The centered covariance would then be calculated as follows:<br>$$<br>\sigma_{xy}‚Äô = \frac{1}{n-1} \sum_{i}^{n} (x_i‚Äô - \bar{x}‚Äô)(y_i‚Äô - \bar{y}‚Äô)<br>$$<br>But since after centering, $\bar{x}‚Äô = 0$ and $\bar{y}‚Äô = 0$ we have</p><p>$\sigma_{xy}‚Äô = \frac{1}{n-1} \sum_{i}^{n} x_i‚Äô y_i‚Äô$ which is our original covariance matrix if we resubstitute back the terms $x‚Äô = x - \bar{x} \text{ and } y‚Äô = y - \bar{y}$.</p><p>Even centering only one variable, e.g., xx wouldn‚Äôt affect the covariance:</p><p>$$<br>\sigma_{\text{xy}} = \frac{1}{n-1} \sum_{i}^{n} (x_i‚Äô - \bar{x}‚Äô)(y_i - \bar{y})<br>$$</p><h3 id="2-Scaling-of-variables-does-affect-the-covariance-matrix"><a href="#2-Scaling-of-variables-does-affect-the-covariance-matrix" class="headerlink" title="2. Scaling of variables does affect the covariance matrix"></a>2. Scaling of variables does affect the covariance matrix</h3><p>If one variable is scaled, e.g, from pounds into kilogram (1 pound = 0.453592 kg), it does affect the covariance and therefore influences the results of a PCA.</p><p>Let cc be the scaling factor for $x$</p><p>Given that the ‚Äúoriginal‚Äù covariance is calculated as</p><p>$$<br>\sigma_{xy} = \frac{1}{n-1} \sum_{i}^{n} (x_i - \bar{x})(y_i - \bar{y})<br>$$<br>the covariance after scaling would be calculated as:</p><p>$$<br>\sigma_{xy}‚Äô = \frac{1}{n-1} \sum_{i}^{n} (c \cdot x_i - c \cdot \bar{x})(y_i - \bar{y}) = \frac{c}{n-1} \sum_{i}^{n} (x_i - \bar{x})(y_i - \bar{y}) \Rightarrow \sigma_{xy}‚Äô = c \cdot \sigma_{xy}<br>$$<br>Therefore, the covariance after scaling one attribute by the constant $c$ will result in a rescaled covariance $c \sigma_{xy}$ So if we‚Äôd scaled $x$ from pounds to kilograms, the covariance between $x$ and $y$ will be 0.453592 times smaller.</p><h3 id="3-Standardizing-affects-the-covariance"><a href="#3-Standardizing-affects-the-covariance" class="headerlink" title="3. Standardizing affects the covariance"></a>3. Standardizing affects the covariance</h3><p>Standardization of features will have an effect on the outcome of a PCA (assuming that the variables are originally not standardized). This is because we are scaling the covariance between every pair of variables by the product of the standard deviations of each pair of variables.</p><p>The equation for standardization of a variable is written as</p><p>$$<br>z = \frac{x_i - \bar{x}}{\sigma}<br>$$<br>The ‚Äúoriginal‚Äù covariance matrix:</p><p>$$<br>\sigma_{xy} = \frac{1}{n-1} \sum_{i}^{n} (x_i - \bar{x})(y_i - \bar{y})<br>$$<br>And after standardizing both variables:</p><p>$$<br>x‚Äô = \frac{x - \bar{x}}{\sigma_x} \text{ and } y‚Äô =\frac{y - \bar{y}}{\sigma_y}<br>$$</p><p>$$<br>\sigma_{xy}‚Äô = \frac{1}{n-1} \sum_{i}^{n} (x_i‚Äô - 0)(y_i‚Äô - 0) = \frac{1}{n-1} \sum_{i}^{n} \bigg(\frac{x - \bar{x}}{\sigma_x}\bigg)\bigg(\frac{y - \bar{y}}{\sigma_y}\bigg) = \frac{1}{(n-1) \cdot \sigma_x \sigma_y} \sum_{i}^{n} (x_i - \bar{x})(y_i - \bar{y})<br>$$</p><p>$$<br>\Rightarrow \sigma_{xy}‚Äô = \frac{\sigma_{xy}}{\sigma_x \sigma_y}<br>$$</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;About-standardization&quot;&gt;&lt;a href=&quot;#About-standardization&quot; class=&quot;headerlink&quot; title=&quot;About standardization&quot;&gt;&lt;/a&gt;About standardization&lt;/
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Install SerpentAI on Windows 10</title>
    <link href="http://yoursite.com/2018/06/07/Install-SerpentAI-on-Windows-10/"/>
    <id>http://yoursite.com/2018/06/07/Install-SerpentAI-on-Windows-10/</id>
    <published>2018-06-07T13:50:00.000Z</published>
    <updated>2018-06-08T06:45:10.253Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Python-Environment"><a href="#Python-Environment" class="headerlink" title="Python Environment"></a>Python Environment</h2><h3 id="Python-3-6-with-Anaconda"><a href="#Python-3-6-with-Anaconda" class="headerlink" title="Python 3.6+ (with Anaconda)"></a>Python 3.6+ (with Anaconda)</h3><p>Serpent.AI was developed taking full advantage of Python 3.6 so it is only natural that the Python requirement be for versions 3.6 and up.</p><p>Installing regular Python 3.6+ isn‚Äôt exactly difficult but Serpent.AI relies on a good amount of scientific computing libraries that are extremely difficult / impossible to compile on your own on Windows. Thankfully, the <a href="https://www.anaconda.com/distribution" target="_blank" rel="external">Anaconda Distribution</a> exists and takes this huge weight off our collective shoulders.</p><h4 id="Installing-Anaconda-5-2-0-Python-3-6"><a href="#Installing-Anaconda-5-2-0-Python-3-6" class="headerlink" title="Installing Anaconda 5.2.0 (Python 3.6)"></a>Installing Anaconda 5.2.0 (Python 3.6)</h4><p><a href="https://www.anaconda.com/download/" target="_blank" rel="external">Download</a> the Python 3.6 version of Anaconda 5.2.0 and run the graphical installer.</p><p>The following commands are to be performed in an <em>Anaconda Prompt</em> with elevated privileges (Right click and <strong>Run as Administrator</strong>). It is recommended to create a shortcut to this prompt because every Python and Serpent command will have to be performed from there starting now.</p><h4 id="Creating-a-Conda-Env-for-Serpent-AI"><a href="#Creating-a-Conda-Env-for-Serpent-AI" class="headerlink" title="Creating a Conda Env for Serpent.AI"></a>Creating a Conda Env for Serpent.AI</h4><p><code>conda create --name serpent python=3.6</code> (‚Äòserpent‚Äô can be replaced with another name)</p><h4 id="Creating-a-directory-for-your-Serpent-AI-projects"><a href="#Creating-a-directory-for-your-Serpent-AI-projects" class="headerlink" title="Creating a directory for your Serpent.AI projects"></a>Creating a directory for your Serpent.AI projects</h4><p><code>mkdir SerpentAI &amp;&amp; cd SerpentAI</code></p><h4 id="Activating-the-Conda-Env"><a href="#Activating-the-Conda-Env" class="headerlink" title="Activating the Conda Env"></a>Activating the Conda Env</h4><p><code>conda activate serpent</code></p><h2 id="3rd-Party-Dependencies"><a href="#3rd-Party-Dependencies" class="headerlink" title="3rd-Party Dependencies"></a>3rd-Party Dependencies</h2><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>Redis is used in the framework as the in-memory store for the captured frame buffers as well as the temporary storage of analytics events. It is not meant to be compatible with Windows! Microsoft used to <a href="https://github.com/MicrosoftArchive/redis" target="_blank" rel="external">maintain a port</a> but it‚Äôs been abandoned since. This being said, that Redis version is sufficient and it outperforms stuff like running it in WSL on Windows 10. It will install as a Windows Service. Make sure you set it to start automatically.</p><h4 id="Install-Windows-Subsystem-for-Linux-WSL"><a href="#Install-Windows-Subsystem-for-Linux-WSL" class="headerlink" title="Install Windows Subsystem for Linux (WSL)"></a><a href="https://msdn.microsoft.com/en-us/commandline/wsl/install_guide" target="_blank" rel="external">Install Windows Subsystem for Linux (WSL)</a></h4><ol><li>From Start, search for <strong>Turn Windows features on or off</strong> (type <code>turn</code>)</li><li><strong>Select Windows Subsystem for Linux (beta)</strong></li></ol><p><a href="https://raw.githubusercontent.com/ServiceStack/Assets/master/img/redis/install-wsl.png" target="_blank" rel="external"><img src="https://raw.githubusercontent.com/ServiceStack/Assets/master/img/redis/install-wsl.png" alt="img"></a></p><p>Once installed you can run bash on Ubuntu by typing <strong>bash</strong> from a Windows Command Prompt. To install the latest version of Redis we‚Äôll need to use a repository that maintains up-to-date packages for Ubuntu and Debian servers like <a href="https://www.dotdeb.org/" target="_blank" rel="external">https://www.dotdeb.org</a> which you can add to Ubuntu‚Äôs apt-get sources with:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ echo deb http://packages.dotdeb.org wheezy all &gt;&gt; dotdeb.org.list</div><div class="line">$ echo deb-src http://packages.dotdeb.org wheezy all &gt;&gt; dotdeb.org.list</div><div class="line">$ sudo mv dotdeb.org.list /etc/apt/sources.list.d</div><div class="line">$ wget -q -O - http://www.dotdeb.org/dotdeb.gpg | sudo apt-key add -</div></pre></td></tr></table></figure><p>Then after updating our APT cache we can install Redis with:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get update</div><div class="line">$ sudo apt-get install redis-server</div></pre></td></tr></table></figure><p>You‚Äôll then be able to launch redis with:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ redis-server --daemonize yes</div></pre></td></tr></table></figure><p>Which will run redis in the background freeing your shell so you can play with it using the redis client:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ redis-cli</div><div class="line">$ 127.0.0.1:6379&gt; SET foo bar</div><div class="line">OK</div><div class="line">$ 127.0.0.1:6379&gt; GET foo</div><div class="line">&quot;bar&quot;</div></pre></td></tr></table></figure><p>Which you can connect to from within bash or from your Windows desktop using the <a href="https://github.com/ServiceStack/redis-windows#option-3-running-microsofts-native-port-of-redis" target="_blank" rel="external">redis-cli native Windows binary from MSOpenTech</a>.</p><h3 id="Build-Tools-for-Visual-Studio-2017"><a href="#Build-Tools-for-Visual-Studio-2017" class="headerlink" title="Build Tools for Visual Studio 2017"></a>Build Tools for Visual Studio 2017</h3><p>Some of the packages that will be installed alongside Serpent.AI are not pre-compiled binaries and will be need to be built from source. This is a little more problematic for Windows but with the correct C++ Build Tools for Visual Studio it all goes down smoothly.</p><p>You can get the proper installer by visiting <a href="https://www.visualstudio.com/downloads/" target="_blank" rel="external">https://www.visualstudio.com/downloads/</a> and scrolling down to the <em>Build Tools for Visual Studio 2017</em> download. Download, run, select the <em>Visual C++ build tools</em> section and make sure the following components are checked (VSs are not installed):</p><ul><li>Visual C++ Build Tools core features</li><li>VC++ 2017 version 15.7 v14.14 latest v141 tools</li><li>Visual C++ 2017 Redistributable Update</li><li>VC++ 2015.3 v14.00 (v140) toolset for desktop</li><li>Windows 10 SDK (10.0.17134.0)</li><li>Windows Universal CRT SDK</li></ul><h2 id="Installing-Serpent-AI"><a href="#Installing-Serpent-AI" class="headerlink" title="Installing Serpent.AI"></a>Installing Serpent.AI</h2><p>Once all of the above had been installed and set up, you are ready to install the framework. Remember that PATH changes in Windows are not reflected in your command prompts that were opened while you made the changes. Open a fresh Anaconda prompt before continuing to avoid installation issues.</p><p>Go back to the directory you created earlier for your Serpent.AI projects. Make sure you are scoped in your Conda Env.</p><p>Run <code>pip install SerpentAI</code></p><p>Then run <code>serpent setup</code> to install the remaining dependencies automatically.</p><h2 id="Installing-Optional-Modules"><a href="#Installing-Optional-Modules" class="headerlink" title="Installing Optional Modules"></a>Installing Optional Modules</h2><p>In the spirit of keeping the initial installation on the light side, some specialized / niche components with extra dependencies have been isolated from the core. It is recommended to only focus on installing them once you reach a point where you actually need them. The framework will provide a warning when a feature you are trying to use requires one of those modules.</p><h3 id="OCR"><a href="#OCR" class="headerlink" title="OCR"></a>OCR</h3><p>A module to provide OCR functionality in your game agents.</p><h4 id="Tesseract"><a href="#Tesseract" class="headerlink" title="Tesseract"></a>Tesseract</h4><p>Serpent.AI leverages Tesseract for its OCR functionality. You can install Tesseract for Windows by following these steps:</p><ol><li>Visit <a href="https://github.com/UB-Mannheim/tesseract/wiki" target="_blank" rel="external">https://github.com/UB-Mannheim/tesseract/wiki</a></li><li>Download the .exe for version 3</li><li>Run the graphical installer (Remember the install path!)</li><li>Add the path to <em>tesseract.exe</em> to your %PATH% environment variable</li></ol><p>You can test your Tesseract installation by opening an Anaconda Prompt and executing <code>tesseract --list-langs</code>.</p><h4 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h4><p>Once you‚Äôve validated that Tesseract has been properly set up, you can install the module with <code>serpent setup ocr</code></p><h3 id="GUI"><a href="#GUI" class="headerlink" title="GUI"></a>GUI</h3><p>A module to allow Serpent.AI desktop app to run.</p><h4 id="Kivy"><a href="#Kivy" class="headerlink" title="Kivy"></a>Kivy</h4><p>Kivy is the GUI framework used in the framework.</p><p>Once you are ready to test your Kivy, you can install the module with <code>serpent setup gui</code> and try to run <code>serpent visual_debugger</code></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Python-Environment&quot;&gt;&lt;a href=&quot;#Python-Environment&quot; class=&quot;headerlink&quot; title=&quot;Python Environment&quot;&gt;&lt;/a&gt;Python Environment&lt;/h2&gt;&lt;h3 id=&quot;P
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Matching Networks for One Shot Learning</title>
    <link href="http://yoursite.com/2018/06/02/Matching-Networks-for-One-Shot-Learning/"/>
    <id>http://yoursite.com/2018/06/02/Matching-Networks-for-One-Shot-Learning/</id>
    <published>2018-06-02T14:35:08.000Z</published>
    <updated>2018-06-02T14:39:51.593Z</updated>
    
    <content type="html"><![CDATA[<p>By DeepMind crew: <strong>Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra</strong></p><p>This is a paper on <strong>one-shot</strong> learning, where we‚Äôd like to learn a class based on very few (or indeed, 1) training examples. E.g. it suffices to show a child a single giraffe, not a few hundred thousands before it can recognize more giraffes.</p><p>This paper falls into a category of <em>‚Äúduh of course‚Äù</em> kind of paper, something very interesting, powerful, but somehow obvious only in retrospect. I like it.</p><p>Suppose you‚Äôre given a single example of some class and would like to label it in test images.</p><ul><li><strong>Observation 1</strong>: a standard approach might be to train an Exemplar SVM for this one (or few) examples vs. all the other training examples - i.e. a linear classifier. But this requires optimization.</li><li><strong>Observation 2:</strong> known non-parameteric alternatives (e.g. k-Nearest Neighbor) don‚Äôt suffer from this problem. E.g. I could immediately use a Nearest Neighbor to classify the new class without having to do any optimization whatsoever. However, NN is gross because it depends on an (arbitrarily-chosen) metric, e.g. L2 distance. Ew.</li><li><strong>Core idea</strong>: lets train a fully end-to-end nearest neighbor classifer!<img src="https://raw.githubusercontent.com/karpathy/paper-notes/master/img/matching_networks/Screen%20Shot%202016-08-07%20at%2010.08.44%20PM.png" alt="Screen Shot 2016-08-07 at 10.08.44 PM"></li></ul><h2 id="The-training-protocol"><a href="#The-training-protocol" class="headerlink" title="The training protocol"></a>The training protocol</h2><p>As the authors amusingly point out in the conclusion (and this is the <em>duh of course</em> part), <em>‚Äúone-shot learning is much easier if you train the network to do one-shot learning‚Äù</em>. Therefore, we want the test-time protocol (given N novel classes with only k examples each (e.g. k = 1 or 5), predict new instances to one of N classes) to exactly match the training time protocol.</p><p>To create each ‚Äúepisode‚Äù of training from a dataset of examples then:</p><ol><li>Sample a task T from the training data, e.g. select 5 labels, and up to 5 examples per label (i.e. 5-25 examples).</li><li>To form one episode sample a label set L (e.g. {cats, dogs}) and then use L to sample the support set S and a batch B of examples to evaluate loss on.</li></ol><p>The idea on high level is clear but the writing here is a bit unclear on details, of exactly how the sampling is done.</p><h2 id="The-model"><a href="#The-model" class="headerlink" title="The model"></a>The model</h2><p>I find the paper‚Äôs model description slightly wordy and unclear, but basically we‚Äôre building a <strong>differentiable nearest neighbor++</strong>. The output \hat{y} for a test example \hat{x} is computed very similar to what you might see in Nearest Neighbors:<img src="https://raw.githubusercontent.com/karpathy/paper-notes/master/img/matching_networks/Screen%20Shot%202016-08-07%20at%2011.14.26%20PM.png" alt="Screen Shot 2016-08-07 at 11.14.26 PM"><br>where <strong>a</strong> acts as a kernel, computing the extent to which \hat{x} is similar to a training example x_i, and then the labels from the training examples (y_i) are weight-blended together accordingly. The paper doesn‚Äôt mention this but I assume for classification y_i would presumbly be one-hot vectors.</p><p>Now, we‚Äôre going to embed both the training examples x_i and the test example \hat{x}, and we‚Äôll interpret their inner products (or here a cosine similarity) as the ‚Äúmatch‚Äù, and pass that through a softmax to get normalized mixing weights so they add up to 1. No surprises here, this is quite natural:</p><p><img src="https://raw.githubusercontent.com/karpathy/paper-notes/master/img/matching_networks/Screen%20Shot%202016-08-07%20at%2011.20.29%20PM.png" alt="Screen Shot 2016-08-07 at 11.20.29 PM"><br>Here <strong>c()</strong> is cosine distance, which I presume is implemented by normalizing the two input vectors to have unit L2 norm and taking a dot product. I assume the authors tried skipping the normalization too and it did worse? Anyway, now all that‚Äôs left to define is the function <strong>f</strong> (i.e. how do we embed the test example into a vector) and the function <strong>g</strong> (i.e. how do we embed each training example into a vector?).</p><p><strong>Embedding the training examples.</strong> This (the function <strong>g</strong>) is a bidirectional LSTM over the examples:</p><p><img src="https://raw.githubusercontent.com/karpathy/paper-notes/master/img/matching_networks/Screen%20Shot%202016-08-07%20at%2011.57.10%20PM.png" alt="Screen Shot 2016-08-07 at 11.57.10 PM"></p><p>i.e. encoding of i‚Äôth example x_i is a function of its ‚Äúraw‚Äù embedding g‚Äô(x_i) and the embedding of its friends, communicated through the bidirectional network‚Äôs hidden states. i.e. each training example is a function of not just itself but all of its friends in the set. This is part of the ++ above, because in a normal nearest neighbor you wouldn‚Äôt change the representation of an example as a function of the other data points in the training set.</p><p>It‚Äôs odd that the <strong>order</strong> is not mentioned, I assume it‚Äôs random? This is a bit gross because order matters to a bidirectional LSTM; you‚Äôd get different embeddings if you permute the examples.</p><p><strong>Embedding the test example.</strong> This (the function <strong>f</strong>) is a an LSTM that processes for a fixed amount (K time steps) and at each point also <em>attends</em> over the examples in the training set. The encoding is the last hidden state of the LSTM. Again, this way we‚Äôre allowing the network to change its encoding of the test example as a function of the training examples. Nifty: <img src="https://raw.githubusercontent.com/karpathy/paper-notes/master/img/matching_networks/Screen%20Shot%202016-08-08%20at%2012.11.15%20AM.png" alt="Screen Shot 2016-08-08 at 12.11.15 AM"></p><p>That looks scary at first but it‚Äôs really just a vanilla LSTM with attention where the input at each time step is constant (f‚Äô(\hat{x}), an encoding of the test example all by itself) and the hidden state is a function of previous hidden state but also a concatenated readout vector <strong>r</strong>, which we obtain by attending over the encoded training examples (encoded with <strong>g</strong> from above).</p><p>Oh and I assume there is a typo in equation (5), it should say r_k = ‚Ä¶ without the -1 on LHS.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p><strong>Task</strong>: N-way k-shot learning task. i.e. we‚Äôre given k (e.g. 1 or 5) labelled examples for N classes that we have not previously trained on and asked to classify new instances into he N classes.</p><p><strong>Baselines:</strong> an ‚Äúobvious‚Äù strategy of using a pretrained ConvNet and doing nearest neighbor based on the codes. An option of finetuning the network on the new examples as well (requires training and careful and strong regularization!).</p><p><strong>MANN</strong> of Santoro et al. [21]: Also a DeepMind paper, a fun NTM-like Meta-Learning approach that is fed a sequence of examples and asked to predict their labels.</p><p><strong>Siamese network</strong> of Koch et al. [11]: A siamese network that takes two examples and predicts whether they are from the same class or not with logistic regression. A test example is labeled with a nearest neighbor: with the class it matches best according to the siamese net (requires iteration over all training examples one by one). Also, this approach is less end-to-end than the one here because it requires the ad-hoc nearest neighbor matching, while here the <em>exact</em> end task is optimized for. It‚Äôs beautiful.</p><h3 id="Omniglot-experiments"><a href="#Omniglot-experiments" class="headerlink" title="Omniglot experiments"></a>Omniglot experiments</h3><h3><a href="#" class="headerlink"></a><img src="https://github.com/karpathy/paper-notes/raw/master/img/matching_networks/Screen%20Shot%202016-08-08%20at%2010.21.45%20AM.png" alt="Screen Shot 2016-08-08 at 10.21.45 AM"></h3><p>Omniglot of <a href="http://www.cs.toronto.edu/~rsalakhu/papers/LakeEtAl2015Science.pdf" target="_blank" rel="external">Lake et al. [14]</a> is a MNIST-like scribbles dataset with 1623 characters with 20 examples each.</p><p>Image encoder is a CNN with 4 modules of [3x3 CONV 64 filters, batchnorm, ReLU, 2x2 max pool]. The original image is claimed to be so resized from original 28x28 to 1x1x64, which doesn‚Äôt make sense because factor of 2 downsampling 4 times is reduction of 16, and 28/16 is a non-integer &gt;1. I‚Äôm assuming they use VALID convs?</p><p>Results: <img src="https://github.com/karpathy/paper-notes/raw/master/img/matching_networks/Screen%20Shot%202016-08-08%20at%2010.27.46%20AM.png" alt="Screen Shot 2016-08-08 at 10.27.46 AM"></p><p>Matching nets do best. Fully Conditional Embeddings (FCE) by which I mean they the ‚ÄúFull Context Embeddings‚Äù of Section 2.1.2 instead are not used here, mentioned to not work much better. Finetuning helps a bit on baselines but not with Matching nets (weird).</p><p>The comparisons in this table are somewhat confusing:</p><ul><li>I can‚Äôt find the MANN numbers of 82.8% and 94.9% in their paper [21]; not clear where they come from. E.g. for 5 classes and 5-shot they seem to report 88.4% not 94.9% as seen here. I must be missing something.</li><li>I also can‚Äôt find the numbers reported here in the Siamese Net [11] paper. As far as I can tell in their Table 2 they report one-shot accuracy, 20-way classification to be 92.0, while here it is listed as 88.1%?</li><li>The results of Lake et al. [14] who proposed Omniglot are also missing from the table. If I‚Äôm understanding this correctly they report 95.2% on 1-shot 20-way, while matching nets here show 93.8%, and humans are estimated at 95.5%. That is, the results here appear weaker than those of Lake et al., but one should keep in mind that the method here is significantly more generic and does not make any assumptions about the existence of strokes, etc., and it‚Äôs a simple, single fully-differentiable blob of neural stuff.</li></ul><p>(skipping ImageNet/LM experiments as there are few surprises)</p><h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>Good paper, effectively develops a differentiable nearest neighbor trained end-to-end. It‚Äôs something new, I like it!</p><p>A few concerns:</p><ul><li><p>A bidirectional LSTMs (not order-invariant compute) is applied over sets of training examples to encode them. The authors don‚Äôt talk about the order actually used, which presumably is random, or mention this potentially unsatisfying feature. This can be solved by using a recurrent attentional mechanism instead, as the authors are certainly aware of and as has been discussed at length in <a href="https://arxiv.org/abs/1511.06391" target="_blank" rel="external">ORDER MATTERS: SEQUENCE TO SEQUENCE FOR SETS</a>, where Oriol is also the first author. I wish there was a comment on this point in the paper somewhere.</p></li><li><p>The approach also gets quite a bit slower as the number of training examples grow, but once this number is large one would presumable switch over to a parameteric approach.</p></li><li><p>It‚Äôs also potentially concerning that during training the method uses a specific number of examples, e.g. 5-25, so this is the number of that must also be used at test time. What happens if we want the size of our training set to grow online? It appears that we need to retrain the network because the encoder LSTM for the training data is not ‚Äúused to‚Äù seeing inputs of more examples? That is unless you fall back to iteratively subsampling the training data, doing multiple inference passes and averaging, or something like that. If we don‚Äôt use FCE it can still be that the attention mechanism LSTM can still not be ‚Äúused to‚Äù attending over many more examples, but it‚Äôs not clear how much this matters. An interesting experiment would be to not use FCE and try to use 100 or 1000 training examples, while only training on up to 25 (with and fithout FCE). Discussion surrounding this point would be interesting.</p></li><li><p>Not clear what happened with the Omniglot experiments, with incorrect numbers for [11], [21], and the exclusion of Lake et al. [14] comparison.</p></li><li><p>A baseline that is missing would in my opinion also include training of an <a href="https://www.cs.cmu.edu/~tmalisie/projects/iccv11/" target="_blank" rel="external">Exemplar SVM</a>, which is a much more powerful approach than encode-with-a-cnn-and-nearest-neighbor.</p><p>‚Äã</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;By DeepMind crew: &lt;strong&gt;Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This is a p
    
    </summary>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="one-shot learning" scheme="http://yoursite.com/tags/one-shot-learning/"/>
    
  </entry>
  
  <entry>
    <title>One Shot Learning and Siamese Networks in Keras</title>
    <link href="http://yoursite.com/2018/06/02/One-Shot-Learning-and-Siamese-Networks-in-Keras/"/>
    <id>http://yoursite.com/2018/06/02/One-Shot-Learning-and-Siamese-Networks-in-Keras/</id>
    <published>2018-06-02T14:21:29.000Z</published>
    <updated>2018-06-02T14:32:48.308Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background:"></a>Background:</h2><p>Conventional wisdom says that deep neural networks are really good at learning from high dimensional data like images or spoken language, but only when they have huge amounts of labelled examples to train on. Humans on the other hand, are capable of <em>one-shot learning</em> - if you take a human who‚Äôs never seen a spatula before, and show them a single picture of a spatula, they will probably be able to distinguish spatulas from other kitchen utensils with astoundingly high precision.</p><p><a href="https://sorenbouma.github.io/images/spatula.jpg" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/spatula.jpg" alt="image"></a></p><p>Never been inside a kitchen before? Now‚Äôs your chance to test your one shot learning ability! which of the images on the right is of the same type as the big image? Email me for the correct answer.</p><p>..Yet another one of the <a href="https://dspace.mit.edu/handle/1721.1/6125" target="_blank" rel="external">things</a> humans can do that seemed trivial to us right up until we tried to make an algorithm do it.</p><p>This ability to rapidly learn from very little data seems like it‚Äôs obviously desirable for machine learning systems to have because collecting and labelling data is expensive. I also think this is an important step on the long road towards general intelligence.</p><p>Recently there have been <a href="https://arxiv.org/abs/1703.07326" target="_blank" rel="external">many</a> <a href="https://sorenbouma.github.io/blog/oneshot/%22%22" target="_blank" rel="external">interesting</a> <a href="https://sorenbouma.github.io/blog/oneshot/%22%22" target="_blank" rel="external">papers</a> about one-shot learning with neural nets and they‚Äôve gotten some good results. This is a new area that really excites me, so I wanted to make a gentle introduction to make it more accessible to fellow newcomers to deep learning.</p><p>In this post, I want to:</p><ul><li>Introduce and formulate the problem of one-shot learning</li><li>Describe benchmarks for one-shot classification and give a baseline for performance</li><li>Give an example of deep one-shot learning by partially reimplementing the model in <a href="http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" target="_blank" rel="external">this paper</a> with keras.</li><li>Hopefully point out some small insights that aren‚Äôt obvious to everyone</li></ul><h2 id="Formulating-the-Problem-N-way-One-Shot-Learning"><a href="#Formulating-the-Problem-N-way-One-Shot-Learning" class="headerlink" title="Formulating the Problem - N-way One-Shot Learning"></a>Formulating the Problem - N-way One-Shot Learning</h2><p>Before we try to solve any problem, we should first precisely state what the problem actually is, so here is the problem of one-shot classification expressed symbolically:</p><p>Our model is given a tiny labelled training set SS, which has N examples, each vectors of the same dimension with a distinct label yy.<br>$$<br>S={(x_1,y_1),‚Ä¶,(x_N,y_N)}<br>$$<br>It is also given $\hat{x}$, the test example it has to classify. Since exactly one example in the support set has the right class, the aim is to correctly predict which $y \in S$ is the same as $\hat{x}$ ‚Äòs label, $\hat{y}$.</p><p>There are fancier ways of defining the problem, but this one is ours. Here are some things to make note of:</p><ul><li>Real world problems might not always have the constraint that exactly one image has the correct class</li><li>It‚Äôs easy to generalize this to k-shot learning by having there be k examples for each yiyirather than just one.</li><li>When N is higher, there are more possible classes that $\hat{x}$ can belong to, so it‚Äôs harder to predict the correct one.</li><li>Random guessing will average $\frac{100}{n}\%$ accuracy.</li></ul><p>Here are some examples of one-shot learning tasks on the Omniglot dataset, which I‚Äôll describe in the next section.</p><p><a href="https://sorenbouma.github.io/images/task_9.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/task_9.png" alt="image"></a><a href="https://sorenbouma.github.io/images/task_25.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/task_25.png" alt="image"></a><a href="hhttps://sorenbouma.github.io/images/task_36.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/task_36.png" alt="image"></a>9, 25 and 36 way one-shot learnng tasks.</p><h2 id="About-the-data-Omniglot"><a href="#About-the-data-Omniglot" class="headerlink" title="About the data - Omniglot! :"></a>About the data - Omniglot! :</h2><p>The <a href="https://github.com/brendenlake/omniglot" target="_blank" rel="external">Omniglot dataset</a> is a collection of 1623 hand drawn characters from 50 alphabets. For every character there are just 20 examples, each drawn by a different person at resolution 105x105.</p><p><a href="https://sorenbouma.github.io/images/alphabets/Braille.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/alphabets/Braille.png" alt="image"></a><a href="https://sorenbouma.github.io/images/alphabets/Bengali.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/alphabets/Bengali.png" alt="image"></a><a href="https://sorenbouma.github.io/images/alphabets/Sanskrit.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/alphabets/Sanskrit.png" alt="image"></a><a href="https://sorenbouma.github.io/images/alphabets/Greek.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/alphabets/Greek.png" alt="image"></a><a href="https://sorenbouma.github.io/images/alphabets/Futurama.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/alphabets/Futurama.png" alt="image"></a><a href="https://sorenbouma.github.io/images/alphabets/Hebrew.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/alphabets/Hebrew.png" alt="image"></a>A few of the alphabets from the omniglot dataset. As you can see, there‚Äôs a huge variety of different symbols.</p><p>If you like machine learning, you‚Äôve probably heard of the <a href="https://en.wikipedia.org/wiki/MNIST_database" target="_blank" rel="external">MNIST dataset</a>. Omniglot is sometimes referred to as the <em>transpose</em> of mnist, since it has 1623 types of character with only 20 examples each, in contrast to MNIST having thousands of examples for only 10 digits. There is also data about the strokes used to create each character, but we won‚Äôt be using that. Usually, it‚Äôs split into 30 training alphabets and 20 evaluation alphabets. All those different characters make for lots of possible one-shot tasks, so it‚Äôs a really good benchmark for one-shot learning algorithms.</p><h4 id="A-One-Shot-Learning-Baseline-1-Nearest-Neighbour"><a href="#A-One-Shot-Learning-Baseline-1-Nearest-Neighbour" class="headerlink" title="A One-Shot Learning Baseline / 1 Nearest Neighbour"></a>A One-Shot Learning Baseline / 1 Nearest Neighbour</h4><p>The simplest way of doing classification is with k-nearest neighbours, but since there is only one example per class we have to do 1 nearest neighbour. This is very simple, just calculate the Euclidean distance of the test example from each training example and pick the closest one:<br>$$<br>C(\hat{x})={\arg \min}_{c\in S}||\hat{x} ‚àí x_c||<br>$$<br>According to Koch et al, 1-nn gets ~28% accuracy in 20 way one shot classification on omniglot. 28% doesn‚Äôt sound great, but it‚Äôs nearly six times more accurate than random guessing(5%). This is a good baseline or ‚Äúsanity check‚Äù to compare future one-shot algorithms with.</p><p><a href="http://cims.nyu.edu/~brenden/LakeEtAlNips2013.pdf" target="_blank" rel="external">Hierarchical Bayesian Program Learning</a> from Lake et al gets 95.2% - very impressive! The ~30% of this paper which I understood was very interesting. Comparing it with deep learning results that train on raw pixels is kind of ‚Äúapples and oranges‚Äù though, because:</p><ol><li>HBPL used data about the strokes, not just the raw pixels</li><li>HBPL on omniglot involved learning a generative model for strokes. The algorithm requires data with more complicated annotation, so unlike deep learning it can‚Äôt easily be tweaked to one-shot learn from raw pixels of dogs/trucks/brain scans/spatulas and other objects that aren‚Äôt made up of brushstrokes.</li></ol><p>Lake et al also says that humans get 95.5% accuracy in 20 way classification on omniglot, only beating HBPL by a tiny margin. In the spirit of nullius in verba, I tried testing myself on the 20 way tasks and managed to average 97.2%. I wasn‚Äôt always doing true one-shot learning though - I saw several symbols I recognised, since I‚Äôm familiar with the greek alphabet, hiragana and katakana. I removed those alphabets and tried again but still managed 96.7%. My hypothesis is that having to read my own terrible handwriting has endowed me with superhuman symbol recognition ability.</p><h4 id="Ways-to-use-deep-networks-for-one-shot-learning"><a href="#Ways-to-use-deep-networks-for-one-shot-learning" class="headerlink" title="Ways to use deep networks for one shot learning?!"></a>Ways to use deep networks for one shot learning?!</h4><p>If we naively train a neural network on a one-shot as a vanilla cross-entropy-loss softmax classifier, it will <em>severely</em> overfit. Heck, even if it was a <em>hundred</em> shot learning a modern neural net would still probably overfit. Big neural networks have millions of parameters to adjust to their data and so they can learn a huge space of possible functions. (More formally, they have a high <a href="https://en.wikipedia.org/wiki/VC_dimension" target="_blank" rel="external">VC dimension</a>, which is part of why they do so well at learning from complex data with high dimensionality.) Unfortunately this strength also appears to be their undoing for one-shot learning. When there are millions of parameters to gradient descend upon, and a staggeringly huge number of possible mappings that can be learned, how can we make a network learn one that generalizes when there‚Äôs just a single example to learn from?</p><p>It‚Äôs easier for humans to one-shot learn the concept of a spatula or the letter ŒòŒò because they have spent a lifetime observing and learning from similar objects. It‚Äôs not really fair to compare the performance of a human who‚Äôs spent a lifetime having to classify objects and symbols with that of a randomly initialized neural net, which imposes a very weak prior about the structure of the mapping to be learned from the data. This is why most of the one-shot learning papers I‚Äôve seen take the approach of <em>knowledge transfer</em> from other tasks.</p><p>Neural nets are really good at extracting useful features from structurally complex/high dimensional data, such as images. If a neural network is given training data that is similar to (but not the same as) that in the one-shot task, it might be able to learn useful features which can be used in a simple learning algorithm that doesn‚Äôt require adjusting these parameters. It still counts as one-shot learning as long as the training examples are of different classes to the examples used for one-shot testing.</p><p>(NOTE: Here a <em>feature</em> means a ‚Äútransformation of the data that is useful for learning‚Äù.)</p><p>So now an interesting problem is <em>how do we get a neural network to learn the features?</em> The most obvious way of doing this (if there‚Äôs labelled data) is just vanilla transfer learning - train a softmax classifier on the training set, then fine-tune the weights of the last layer on the support set of the one-shot task. In practice, neural net classifiers don‚Äôt work too well for data like omniglot where there are few examples per class, and even fine tuning only the weights in the last layer is enough to overfit the support set. Still works quite a lot better than L2 distance nearest neighbour though! (See <a href="https://arxiv.org/pdf/1606.04080" target="_blank" rel="external">Matching Networks for One Shot learning</a> for a comparison table of various deep one-shot learning methods and their accuracy.)</p><p>There‚Äôs a better way of doing it though! Remember 1 nearest neighbour? This simple, non-parametric one-shot learner just classifies the test example with the same class of whatever support example is the closest in L2 distance. This works ok, but L2 Distance suffers from the ominous sounding <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" target="_blank" rel="external">curse of dimensionality</a> and so won‚Äôt work well for data with thousands of dimensions like omniglot. Also, if you have two nearly identical images and move one over a few pixels to the right the L2 distance can go from being almost zero to being really high. L2 distance is a metric that is just woefully inadequate for this task. Deep learning to the rescue? We can use a deep convolutional network to learn some kind of similarity function that a non-parametric classifer like nearest neighbor can use.</p><h3 id="Siamese-networks"><a href="#Siamese-networks" class="headerlink" title="Siamese networks"></a>Siamese networks</h3><p><a href="https://sorenbouma.github.io/images/cats.jpg" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/cats.jpg" alt="image"></a>I originally planned to have craniopagus conjoined twins as the accompanying image for this section but ultimately decided that siamese cats would go over better..</p><p><a href="http://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" target="_blank" rel="external">This wonderful paper</a> is what I will be implementing in this tutorial. Koch et al‚Äôs approach to getting a neural net to do one-shot classification is to give it two images and train it to guess whether they have the same category. Then when doing a one-shot classification task described above, the network can compare the test image to each image in the support set, and pick which one it thinks is most likely to be of the same category. So we want a neural net architecture that takes two images as input and outputs the probability they share the same class.</p><p>Say x1 and x2 are two images in our dataset, and let x1‚àòx2 mean ‚Äúx1 and x2 are images with the same class‚Äù. Note that x1‚àòx2 is the same as x2‚àòx1 - this means that if we reverse the order of the inputs to the neural network, the output should be the same - p(x1‚àòx2) should equal p(x2‚àòx1). This property is called <em>symmetry</em> and siamese nets are designed around having it.</p><p>Symmetry is important because it‚Äôs required for learning a distance metric - the distance from x1 to x2 should equal the distance x2 to x1.</p><p>If we just concatenate two examples together and use them as a single input to a neural net, each example will be matrix multiplied(or convolved) with a different set of weights, which breaks symmetry. Sure it‚Äôs possible it will eventually manage to learn the exact same weights for each input, but it would be much easier to learn a single set of weights applied to both inputs. So we could propagate both inputs through identical twin neural nets with shared parameters, then use the absolute difference as the input to a linear classifier - this is essentially what a siamese net is. Two identical twins, joined at the head, hence the name.</p><h4 id="Network-architecture"><a href="#Network-architecture" class="headerlink" title="Network architecture"></a>Network architecture</h4><p><em>Unfortunately, properly explaining how and why a convolutional neural net work would make this post twice as long. If you want to understand convnets work, I suggest checking out cs231n and then colah. For any non-dl people who are reading this, the best summary I can give of a CNN is this: An image is a 3D array of pixels. A convolutional layer is where you have a neuron connected to a tiny subgrid of pixels or neurons, and use copies of that neuron across all parts of the image/block to make another 3d array of neuron activations. A max pooling layer makes a block of activations spatially smaller. Lots of these stacked on top of one another can be trained with gradient descent and are really good at learning from images.</em></p><p>I‚Äôm going to describe the architecture pretty briefly because it‚Äôs not the important part of the paper. Koch et al uses a <em>convolutional</em> siamese network to classify pairs of omniglot images, so the twin networks are both convolutional neural nets(CNNs). The twins each have the following architecture: convolution with 64 10x10 filters, relu -&gt; max pool -&gt; convolution with 128 7x7 filters, relu -&gt; max pool -&gt; convolution with 128 4x4 filters, relu -&gt; max pool -&gt; convolution with 256 4x4 filters. The twin networks reduce their inputs down to smaller and smaller 3d tensors, finally their is a fully connected layer with 4096 units. The absolute difference between the two vectors is used as input to a linear classifier. All up, the network has 38,951,745 parameters - 96% of which belong to the fully connected layer. This is quite a lot, so the network has high capacity to overfit, but as I show below, pairwse training means the dataset size is huge so this won‚Äôt be a problem.</p><p><a href="https://sorenbouma.github.io/images/Siamese_diagram_2.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/Siamese_diagram_2.png" alt="image"></a>Hastily made architecture diagram.</p><p>The output is squashed into [0,1] with a sigmoid function to make it a probability. We use the target t=1t=1 when the images have the same class and t=0t=0 for a different class. It‚Äôs trained with logistic regression. This means the loss function should be binary cross entropy between the predictions and targets. There is also a L2 weight decay term in the loss to encourage the network to learn smaller/less noisy weights and possibly improve generalization:<br>$$<br>L(x_1,x_2,t)=t‚ãÖ\log(p(x_1‚àòx_2))+(1‚àít)‚ãÖ\log(1‚àíp(x_1‚àòx_2))+Œª‚ãÖ||w||^2<br>$$<br>When it does a one-shot task, the siamese net simply classifies the test image as whatever image in the support set it thinks is most similar to the test image:<br>$$<br>C(\hat{x},S) = {\arg\max}_c P(\hat{x}‚àòx_c),x_c‚ààS<br>$$<br>This uses an argmax unlike nearest neighbour which uses an argmin, because a <em>metric</em> like L2 is higher the more ‚Äúdifferent‚Äù the examples are, but this models outputs p(x1‚àòx2), so we want the highest. This approach has one flaw that‚Äôs obvious to me: for any xaxa in the support set,the probability $\hat{x}‚àòx_a$ is independent of every other example in the support set! This means the probabilities won‚Äôt sum to 1, ignores important information, namely that the test image will be the same type as exactly <em>one</em> x‚ààS‚Ä¶</p><h4 id="Observation-effective-dataset-size-in-pairwise-training"><a href="#Observation-effective-dataset-size-in-pairwise-training" class="headerlink" title="Observation: effective dataset size in pairwise training"></a>Observation: effective dataset size in pairwise training</h4><p>EDIT: After discussing this with a PhD student at UoA, I think this bit might be overstated or even just wrong. Emperically, my implementation <em>did</em> overfit, even though it wasn‚Äôt trained for enough iterations to sample every possible pair, which kind of contradicts this section. I‚Äôm leaving it up in the spirit of being wrong loudly.</p><p>One cool thing I noticed about training on pairs is that there are quadratically many possible pairs of images to train the model on, making it hard to overfit. Say we have CC examples each of EE classes. Since there are C‚ãÖEC‚ãÖE images total, the total number of possible pairs is given by<br>$$<br>Npairs=(C‚ãÖE 2)=(C‚ãÖE)!/2!(C‚ãÖE‚àí2)!<br>$$<br>For omniglot with its 20 examples of 964 training classes, this leads to 185,849,560 possible pairs, which is huge! However, the siamese network needs examples of both same and different class pairs. There are E examples per class, so there will be (E 2) pairs for every class, which means there are Nsame=(E 2)‚ãÖC possible pairs with the same class - 183,160 pairs for omniglot. Even though 183,160 example pairs is plenty, it‚Äôs only a thousandth of the possible pairs, and the number of same-class pairs increases quadratically with E but only linearly with C. This is important because the siamese network should be given a 1:1 ratio of same-class and different-class pairs to train on - perhaps it implies that pairwise training is easier on datasets with lots of examples per class.</p><h3 id="The-Code"><a href="#The-Code" class="headerlink" title="The Code:"></a>The Code:</h3><p><a href="https://github.com/sorenbouma/keras-oneshot" target="_blank" rel="external">Prefer to just play with a jupyter notebook? I got you fam</a></p><p>Here is the model definition, it should be pretty easy to follow if you‚Äôve seen keras before. I only define the twin network‚Äôs architecture once as a Sequential() model and then call it with respect to each of two input layers, this way the same parameters are used for both inputs. Then merge them together with absolute distance and add an output layer, and compile the model with binary cross entropy loss.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, Sequential</div><div class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div><div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD,Adam</div><div class="line"><span class="keyword">from</span> keras.losses <span class="keyword">import</span> binary_crossentropy</div><div class="line"><span class="keyword">import</span> numpy.random <span class="keyword">as</span> rng</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> dill <span class="keyword">as</span> pickle</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn.utils <span class="keyword">import</span> shuffle</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">W_init</span><span class="params">(shape,name=None)</span>:</span></div><div class="line">    <span class="string">"""Initialize weights as in paper"""</span></div><div class="line">    values = rng.normal(loc=<span class="number">0</span>,scale=<span class="number">1e-2</span>,size=shape)</div><div class="line">    <span class="keyword">return</span> K.variable(values,name=name)</div><div class="line"><span class="comment">#//<span class="doctag">TODO:</span> figure out how to initialize layer biases in keras.</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">b_init</span><span class="params">(shape,name=None)</span>:</span></div><div class="line">    <span class="string">"""Initialize bias as in paper"""</span></div><div class="line">    values=rng.normal(loc=<span class="number">0.5</span>,scale=<span class="number">1e-2</span>,size=shape)</div><div class="line">    <span class="keyword">return</span> K.variable(values,name=name)</div><div class="line"></div><div class="line">input_shape = (<span class="number">105</span>, <span class="number">105</span>, <span class="number">1</span>)</div><div class="line">left_input = Input(input_shape)</div><div class="line">right_input = Input(input_shape)</div><div class="line"><span class="comment">#build convnet to use in each siamese 'leg'</span></div><div class="line">convnet = Sequential()</div><div class="line">convnet.add(Conv2D(<span class="number">64</span>,(<span class="number">10</span>,<span class="number">10</span>),activation=<span class="string">'relu'</span>,input_shape=input_shape,</div><div class="line">                   kernel_initializer=W_init,kernel_regularizer=l2(<span class="number">2e-4</span>)))</div><div class="line">convnet.add(MaxPooling2D())</div><div class="line">convnet.add(Conv2D(<span class="number">128</span>,(<span class="number">7</span>,<span class="number">7</span>),activation=<span class="string">'relu'</span>,</div><div class="line">                   kernel_regularizer=l2(<span class="number">2e-4</span>),kernel_initializer=W_init,bias_initializer=b_init))</div><div class="line">convnet.add(MaxPooling2D())</div><div class="line">convnet.add(Conv2D(<span class="number">128</span>,(<span class="number">4</span>,<span class="number">4</span>),activation=<span class="string">'relu'</span>,kernel_initializer=W_init,kernel_regularizer=l2(<span class="number">2e-4</span>),bias_initializer=b_init))</div><div class="line">convnet.add(MaxPooling2D())</div><div class="line">convnet.add(Conv2D(<span class="number">256</span>,(<span class="number">4</span>,<span class="number">4</span>),activation=<span class="string">'relu'</span>,kernel_initializer=W_init,kernel_regularizer=l2(<span class="number">2e-4</span>),bias_initializer=b_init))</div><div class="line">convnet.add(Flatten())</div><div class="line">convnet.add(Dense(<span class="number">4096</span>,activation=<span class="string">"sigmoid"</span>,kernel_regularizer=l2(<span class="number">1e-3</span>),kernel_initializer=W_init,bias_initializer=b_init))</div><div class="line"><span class="comment">#encode each of the two inputs into a vector with the convnet</span></div><div class="line">encoded_l = convnet(left_input)</div><div class="line">encoded_r = convnet(right_input)</div><div class="line"><span class="comment">#merge two encoded inputs with the l1 distance between them</span></div><div class="line">L1_distance = <span class="keyword">lambda</span> x: K.abs(x[<span class="number">0</span>]-x[<span class="number">1</span>])</div><div class="line">both = merge([encoded_l,encoded_r], mode = L1_distance, output_shape=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])</div><div class="line">prediction = Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>,bias_initializer=b_init)(both)</div><div class="line">siamese_net = Model(input=[left_input,right_input],output=prediction)</div><div class="line"><span class="comment">#optimizer = SGD(0.0004,momentum=0.6,nesterov=True,decay=0.0003)</span></div><div class="line"></div><div class="line">optimizer = Adam(<span class="number">0.00006</span>)</div><div class="line"><span class="comment">#//<span class="doctag">TODO:</span> get layerwise learning rates and momentum annealing scheme described in paperworking</span></div><div class="line">siamese_net.compile(loss=<span class="string">"binary_crossentropy"</span>,optimizer=optimizer)</div><div class="line"></div><div class="line">siamese_net.count_params()</div></pre></td></tr></table></figure><p>The original paper used layerwise learning rates and momentum - I skipped this because it; was kind of messy to implement in keras and the hyperparameters aren‚Äôt the interesting part of the paper. Koch et al adds examples to the dataset by distorting the images and runs experiments with a fixed training set of up to 150,000 pairs. Since that won‚Äôt fit in my computers memory, I decided to just randomly sample pairs. Loading image pairs was probably the hardest part of this to implement. Since there were 20 examples for every class, I reshaped the data into N_classes x 20 x 105 x 105 arrays, to make it easier to index by category.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Siamese_Loader</span>:</span></div><div class="line">    <span class="string">"""For loading batches and testing tasks to a siamese net"""</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,Xtrain,Xval)</span>:</span></div><div class="line">        self.Xval = Xval</div><div class="line">        self.Xtrain = Xtrain</div><div class="line">        self.n_classes,self.n_examples,self.w,self.h = Xtrain.shape</div><div class="line">        self.n_val,self.n_ex_val,_,_ = Xval.shape</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_batch</span><span class="params">(self,n)</span>:</span></div><div class="line">        <span class="string">"""Create batch of n pairs, half same class, half different class"""</span></div><div class="line">        categories = rng.choice(self.n_classes,size=(n,),replace=<span class="keyword">False</span>)</div><div class="line">        pairs=[np.zeros((n, self.h, self.w,<span class="number">1</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>)]</div><div class="line">        targets=np.zeros((n,))</div><div class="line">        targets[n//<span class="number">2</span>:] = <span class="number">1</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</div><div class="line">            category = categories[i]</div><div class="line">            idx_1 = rng.randint(<span class="number">0</span>,self.n_examples)</div><div class="line">            pairs[<span class="number">0</span>][i,:,:,:] = self.Xtrain[category,idx_1].reshape(self.w,self.h,<span class="number">1</span>)</div><div class="line">            idx_2 = rng.randint(<span class="number">0</span>,self.n_examples)</div><div class="line">            <span class="comment">#pick images of same class for 1st half, different for 2nd</span></div><div class="line">            category_2 = category <span class="keyword">if</span> i &gt;= n//<span class="number">2</span> <span class="keyword">else</span> (category + rng.randint(<span class="number">1</span>,self.n_classes)) % self.n_classes</div><div class="line">            pairs[<span class="number">1</span>][i,:,:,:] = self.Xtrain[category_2,idx_2].reshape(self.w,self.h,<span class="number">1</span>)</div><div class="line">        <span class="keyword">return</span> pairs, targets</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_oneshot_task</span><span class="params">(self,N)</span>:</span></div><div class="line">        <span class="string">"""Create pairs of test image, support set for testing N way one-shot learning. """</span></div><div class="line">        categories = rng.choice(self.n_val,size=(N,),replace=<span class="keyword">False</span>)</div><div class="line">        indices = rng.randint(<span class="number">0</span>,self.n_ex_val,size=(N,))</div><div class="line">        true_category = categories[<span class="number">0</span>]</div><div class="line">        ex1, ex2 = rng.choice(self.n_examples,replace=<span class="keyword">False</span>,size=(<span class="number">2</span>,))</div><div class="line">        test_image = np.asarray([self.Xval[true_category,ex1,:,:]]*N).reshape(N,self.w,self.h,<span class="number">1</span>)</div><div class="line">        support_set = self.Xval[categories,indices,:,:]</div><div class="line">        support_set[<span class="number">0</span>,:,:] = self.Xval[true_category,ex2]</div><div class="line">        support_set = support_set.reshape(N,self.w,self.h,<span class="number">1</span>)</div><div class="line">        pairs = [test_image,support_set]</div><div class="line">        targets = np.zeros((N,))</div><div class="line">        targets[<span class="number">0</span>] = <span class="number">1</span></div><div class="line">        <span class="keyword">return</span> pairs, targets</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_oneshot</span><span class="params">(self,model,N,k,verbose=<span class="number">0</span>)</span>:</span></div><div class="line">        <span class="string">"""Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks"""</span></div><div class="line">        <span class="keyword">pass</span></div><div class="line">        n_correct = <span class="number">0</span></div><div class="line">        <span class="keyword">if</span> verbose:</div><div class="line">            print(<span class="string">"Evaluating model on &#123;&#125; unique &#123;&#125; way one-shot learning tasks ..."</span>.format(k,N))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</div><div class="line">            inputs, targets = self.make_oneshot_task(N)</div><div class="line">            probs = model.predict(inputs)</div><div class="line">            <span class="keyword">if</span> np.argmax(probs) == <span class="number">0</span>:</div><div class="line">                n_correct+=<span class="number">1</span></div><div class="line">        percent_correct = (<span class="number">100.0</span>*n_correct / k)</div><div class="line">        <span class="keyword">if</span> verbose:</div><div class="line">            print(<span class="string">"Got an average of &#123;&#125;% &#123;&#125; way one-shot learning accuracy"</span>.format(percent_correct,N))</div><div class="line">        <span class="keyword">return</span> percent_correct</div></pre></td></tr></table></figure><p>..And now the training loop. Nothing unusual here, except for that I monitor one-shot tasks validation accuracy to test performance, rather than loss on the validation set.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">evaluate_every = <span class="number">7000</span></div><div class="line">loss_every=<span class="number">300</span></div><div class="line">batch_size = <span class="number">32</span></div><div class="line">N_way = <span class="number">20</span></div><div class="line">n_val = <span class="number">550</span></div><div class="line">siamese_net.load_weights(<span class="string">"PATH"</span>)</div><div class="line">best = <span class="number">76.0</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">900000</span>):</div><div class="line">    (inputs,targets)=loader.get_batch(batch_size)</div><div class="line">    loss=siamese_net.train_on_batch(inputs,targets)</div><div class="line">    <span class="keyword">if</span> i % evaluate_every == <span class="number">0</span>:</div><div class="line">        val_acc = loader.test_oneshot(siamese_net,N_way,n_val,verbose=<span class="keyword">True</span>)</div><div class="line">        <span class="keyword">if</span> val_acc &gt;= best:</div><div class="line">            print(<span class="string">"saving"</span>)</div><div class="line">            siamese_net.save(<span class="string">'PATH'</span>)</div><div class="line">            best=val_acc</div><div class="line"></div><div class="line">    <span class="keyword">if</span> i % loss_every == <span class="number">0</span>:</div><div class="line">        print(<span class="string">"iteration &#123;&#125;, training loss: &#123;:.2f&#125;,"</span>.format(i,loss))</div></pre></td></tr></table></figure><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>Once the learning curve flattened out, I used the weights which got the best validation 20 way accuracy for testing. My network averaged ~83% accuracy for tasks from the evaluation set, compared to 93% in the original paper. Probably this difference is because I didn‚Äôt implement many of the performance enhancing tricks from the original paper, like layerwise learning rates/momentum, data augmentation with distortions, bayesian hyperparemeter optimization and I also probably trained for less epochs. I‚Äôm not too worried about this because this tutorial was more about introducing one-shot learning in general, than squeezing the last few % performance out of a classifier. There is no shortage of resources on that!</p><p>I was curious to see how accuracy varied over different values of ‚ÄúN‚Äù in N way one shot learning, so I plotted it, with comparisons to 1 nearest neighbours, random guessing and training set performance.</p><p><a href="https://sorenbouma.github.io/images/results1.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/results1.png" alt="image"></a>results.</p><p>As you can see, it performs worse on tasks from the validaiton set than the train set, especially for high values of N, so there must be overfitting. It would be interesting to see how well traditional regularization methods like dropout work when the validation set is made of completely different classes to the training set. It works better than I expected for large N, still averaging above 65% accuracy for 50-60 way tasks.</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>We‚Äôve just trained a neural network trained to do same-different pairwise classification on symbols. More importantly, we‚Äôve shown that it can then get reasonable accuracy in 20 way one-shot learning on symbols from unseen alphabets. Of course, this is not the only way to use deep networks for one-shot learning.</p><p>As I touched on earlier, I think a major flaw of this siamese approach is that it only compares the test image to every support image individualy, when it should be comparing it to the support set as a whole. When the network compares the test image to any image x1, p(x^‚àòx1) is the same no matter what else is the support set. This is silly. Say you‚Äôre doing a one-shot task and you see an image that looks similar to the test image. You should be much less confident they have the same class if there is another image in the support set that also looks similar to the test image. The training objective is different to the test objective. It might work better to have a model that can compare the test image to the support set as a whole and use the constraint that only one support image has the same class.</p><p><a href="https://arxiv.org/pdf/1606.04080.pdf" target="_blank" rel="external">Matching Networks for One Shot learning</a> does exactly that. Rather than learning a similarity function, they have a deep model learn a full nearest neighbour classifier end to end, training directly on oneshot tasks rather than on image pairs. <a href="https://github.com/karpathy/paper-notes/blob/master/matching_networks.md" target="_blank" rel="external">Andrej Karpathy‚Äôs notes</a> explain it much better than I can. Since you are learning a machine classifier, this can be seen as a kind of <em>meta-learning</em>. <a href="https://arxiv.org/pdf/1605.06065.pdf" target="_blank" rel="external">One-shot Learning with Memory-Augmented Neural Networks</a> explores the connection between one-shot learning and meta learning and trains a memory augmented network on omniglot, though I confess I had trouble understanding this paper.</p><h3 id="What-next"><a href="#What-next" class="headerlink" title="What next?"></a>What next?</h3><p>The omniglot dataset has been around since 2015, and already there are scalable ML algorithms getting within the ballpark of human level performance on certain one-shot learning tasks. Hopefully one day it will be seen as a mere ‚Äúsanity check‚Äù for one-shot classification algorithms much like MNIST is for supervised learning now.</p><p>Image classification is cool but I don‚Äôt think it‚Äôs the most interesting problem in machine learning. Now that we know deep one-shot learning can work pretty good, I think it would be cool to see attempts at one-shot learning for other, more exotic tasks.</p><p>Ideas from one-shot learning could be used for more sample efficient reinforcement learning, especially for problems like OpenAI‚Äôs Universe, where there are lots of MDPs/environments that have similar visual features and dynamics. - It would be cool to have an RL agent that could efficiently explore a new environment after learning in similar MDPs.</p><p><a href="https://sorenbouma.github.io/images/worldofbits.png" target="_blank" rel="external"><img src="https://sorenbouma.github.io/images/worldofbits.jpg" alt="image"></a>OpenAI‚Äôs world of bits environments.</p><p><a href="https://arxiv.org/abs/1703.07326" target="_blank" rel="external">One-shot Imitation learning</a> is one of my favourite one-shot learning papers. The goal is to have an agent learn a robust policy for solving a task from a single human demonstration of that task.This is done by:</p><ol><li>Having a neural net map from the current state and a sequence of states(the human demonstration) to an action</li><li>Training it on pairs of human demonstrations on slightly different variants of the same task, with the goal of reproducing the second demonstration based on the first.</li></ol><p>This strikes me as a really promising path to one day having broadly applicable, learning based robots!</p><p>Bringing one-shot learning to NLP tasks is a cool idea too. <em>Matching Networks for One-Shot learning</em> has an attempt at one-shot language modeling, filling a missing word in a test sentence given a small set of support sentences, and it seems to work pretty well. Exciting!</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Anyway, thanks for reading! I hope you‚Äôve managed to one-shot learn the concept of one-shot learning :) If not, I‚Äôd love to hear feedback or answer any questions you have!</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background:&quot;&gt;&lt;/a&gt;Background:&lt;/h2&gt;&lt;p&gt;Conventional wisdom says that deep n
    
    </summary>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="one-shot learning" scheme="http://yoursite.com/tags/one-shot-learning/"/>
    
  </entry>
  
  <entry>
    <title>Anaconda uses socket proxy on Windows 10</title>
    <link href="http://yoursite.com/2018/05/17/Anaconda-uses-socket-proxy-on-Windows-10/"/>
    <id>http://yoursite.com/2018/05/17/Anaconda-uses-socket-proxy-on-Windows-10/</id>
    <published>2018-05-17T09:54:53.000Z</published>
    <updated>2018-05-17T09:58:52.027Z</updated>
    
    <content type="html"><![CDATA[<p>you need to create a <strong>.condarc</strong> file in you Windows user area:</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">C:\Users\&lt;username&gt;\</div></pre></td></tr></table></figure><p>The file should contain (if you are using shadowsocks):</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">channels:</div><div class="line">- defaults</div><div class="line"></div><div class="line"><span class="comment"># Show channel URLs when displaying what is going to be downloaded and</span></div><div class="line"><span class="comment"># in 'conda list'. The default is False.</span></div><div class="line">show_channel_urls: True</div><div class="line">allow_other_channels: True</div><div class="line"></div><div class="line">proxy_servers:</div><div class="line">    http: socks5://<span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">1080</span></div><div class="line">    https: socks5://<span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">1080</span></div><div class="line"></div><div class="line">ssl_verify: False</div></pre></td></tr></table></figure><p>Noticed that you cannot create a file that begins with a dot in Windows directly.</p><p>To <strong>create/rename on windows explorer</strong>, just rename to <code>.name.</code> - The additional dot at the end is necessary, and will be removed by Windows Explorer.</p><p>To create a new file begins with a dot, on command prompt:</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">echo testing &gt; .name</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;you need to create a &lt;strong&gt;.condarc&lt;/strong&gt; file in you Windows user area:&lt;/p&gt;&lt;figure class=&quot;highlight powershell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td clas
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Paper Note: Selective Search for Object Recognition</title>
    <link href="http://yoursite.com/2018/05/03/Paper-Note-Selective-Search-for-Object-Recognition/"/>
    <id>http://yoursite.com/2018/05/03/Paper-Note-Selective-Search-for-Object-Recognition/</id>
    <published>2018-05-03T05:59:00.000Z</published>
    <updated>2018-05-03T06:08:07.390Z</updated>
    
    <content type="html"><![CDATA[<p>‰∏é Selective Search ÂàùÊ¨°ËßÅÈù¢ÊòØÂú®ËëóÂêçÁöÑÁâ©‰ΩìÊ£ÄÊµãËÆ∫Êñá <code>Rich feature hierarchies for accurate object detection and semantic segmentation</code> ÔºåÂõ†Ê≠§ÔºåËøôÁØáËÆ∫ÊñáÁÆóÊòØÈòÖËØª R-CNN ÁöÑÂáÜÂ§á„ÄÇ</p><p>ËøôÁØáËÆ∫ÊñáÁöÑÊ†áÈ¢òËôΩÁÑ∂‰πüÊèêÂà∞‰∫Ü Object Recognition Ôºå‰ΩÜÂ∞±ÂàõÊñ∞ÁÇπËÄåË®ÄÔºåÂÖ∂ÂÆûÂú® Selective Search „ÄÇÊâÄ‰ª•ÔºåËøôÈáåÂè™ÁÆÄÂçï‰ªãÁªç Selective Search ÁöÑÊÄùÊÉ≥ÂíåÁÆóÊ≥ïËøáÁ®ãÔºåÂØπ‰∫é Object Recognition Âàô‰∏çÂÜçËµòËø∞„ÄÇ</p><h3 id="‰ªÄ‰πàÊòØ-Selective-Search"><a href="#‰ªÄ‰πàÊòØ-Selective-Search" class="headerlink" title="‰ªÄ‰πàÊòØ Selective Search"></a>‰ªÄ‰πàÊòØ Selective Search</h3><p>Selective SearchÔºåËØ¥ÁöÑÁÆÄÂçïÁÇπÔºåÂ∞±ÊòØ‰ªéÂõæÁâá‰∏≠ÊâæÂá∫Áâ©‰ΩìÂèØËÉΩÂ≠òÂú®ÁöÑÂå∫Âüü„ÄÇ</p><p><a href="http://jermmy.xyz/images/2017-5-4/result.png" target="_blank" rel="external"><img src="http://jermmy.xyz/images/2017-5-4/result.png" alt="result"></a>result</p><p>‰∏äÈù¢ËøôÂπÖÂÆáËà™ÂëòÁöÑÂõæÁâá‰∏≠ÔºåÈÇ£‰∫õÁ∫¢Ëâ≤ÁöÑÊ°ÜÂ∞±ÊòØ Selective Search ÊâæÂá∫Êù•ÁöÑÂèØËÉΩÂ≠òÂú®Áâ©‰ΩìÁöÑÂå∫Âüü„ÄÇ</p><p>Âú®Ëøõ‰∏ÄÊ≠•Êé¢ËÆ®ÂÆÉÁöÑÂéüÁêÜ‰πãÂâçÔºåÊàë‰ª¨ÂàÜÊûê‰∏Ä‰∏ãÔºåÂ¶Ç‰ΩïÂà§Âà´Âì™‰∫õ region Â±û‰∫é‰∏Ä‰∏™Áâ©‰ΩìÔºü</p><p><a href="http://jermmy.xyz/images/2017-5-4/image%20seg.png" target="_blank" rel="external"><img src="http://jermmy.xyz/images/2017-5-4/image%20seg.png" alt="image seg"></a>image seg</p><p>‰ΩúËÄÖÂú®ËÆ∫Êñá‰∏≠Áî®‰ª•‰∏äÂõõÂπÖÂõæÔºåÂàÜÂà´ÊèèËø∞‰∫ÜÂõõÁßçÂèØËÉΩÁöÑÊÉÖÂÜµÔºö</p><ol><li>Âõæ a ÔºåÁâ©‰Ωì‰πãÈó¥ÂèØËÉΩÂ≠òÂú®Â±ÇÁ∫ßÂÖ≥Á≥ªÔºåÊØîÂ¶ÇÔºöÁ¢óÈáåÊúâ‰∏™Âã∫Ôºõ</li><li>Âõæ bÔºåÊàë‰ª¨ÂèØ‰ª•Áî®È¢úËâ≤Êù•ÂàÜÂºÄ‰∏§Âè™Áå´ÔºåÂç¥Ê≤°Ê≥ïÁî®Á∫πÁêÜÊù•Âå∫ÂàÜÔºõ</li><li>Âõæ cÔºåÊàë‰ª¨ÂèØ‰ª•Áî®Á∫πÁêÜÊù•Âå∫ÂàÜÂèòËâ≤ÈæôÔºåÂç¥Ê≤°Ê≥ïÁî®È¢úËâ≤Êù•Âå∫ÂàÜÔºõ</li><li>Âõæ dÔºåËΩÆËÉéÊòØËΩ¶ÁöÑ‰∏ÄÈÉ®ÂàÜÔºå‰∏çÊòØÂõ†‰∏∫ÂÆÉ‰ª¨È¢úËâ≤Áõ∏Ëøë„ÄÅÁ∫πÁêÜÁõ∏ËøëÔºåËÄåÊòØÂõ†‰∏∫ËΩÆËÉéÂåÖÂê´Âú®ËΩ¶‰∏ä„ÄÇ</li></ol><p>ÊâÄ‰ª•ÔºåÊàë‰ª¨Ê≤°Ê≥ïÁî®Âçï‰∏ÄÁöÑÁâπÂæÅÊù•ÂÆö‰ΩçÁâ©‰ΩìÔºåÈúÄË¶ÅÁªºÂêàËÄÉËôëÂ§öÁßçÁ≠ñÁï•ÔºåËøô‰∏ÄÁÇπÊòØ Selective Search Á≤æË¶ÅÊâÄÂú®„ÄÇ</p><h3 id="ÈúÄË¶ÅËÄÉËôëÁöÑÈóÆÈ¢ò"><a href="#ÈúÄË¶ÅËÄÉËôëÁöÑÈóÆÈ¢ò" class="headerlink" title="ÈúÄË¶ÅËÄÉËôëÁöÑÈóÆÈ¢ò"></a>ÈúÄË¶ÅËÄÉËôëÁöÑÈóÆÈ¢ò</h3><p>Âú®Â≠¶‰π† Selective Search ÁÆóÊ≥ï‰πãÂâçÔºåÊàëÊõæÂú®ËÆ°ÁÆóÊú∫ËßÜËßâËØæ‰∏äÂ≠¶Âà∞ËøáÂÖ≥‰∫éÁâ©‰ΩìÔºà‰∏ªË¶ÅÊòØ‰∫∫ËÑ∏ÔºâÊ£ÄÊµãÁöÑÊñπÊ≥ï„ÄÇÈÄöÂ∏∏Êù•ËØ¥ÔºåÊúÄÂ∏∏ËßÑ‰πüÊòØÊúÄÁÆÄÂçïÁ≤óÊö¥ÁöÑÊñπÊ≥ïÔºåÂ∞±ÊòØÁî®‰∏çÂêåÂ∞∫ÂØ∏ÁöÑÁü©ÂΩ¢Ê°ÜÔºå‰∏ÄË°å‰∏ÄË°åÂú∞Êâ´ÊèèÊï¥Âº†ÂõæÂÉèÔºåÈÄöËøáÊèêÂèñÁü©ÂΩ¢Ê°ÜÂÜÖÁöÑÁâπÂæÅÂà§Êñ≠ÊòØÂê¶ÊòØÂæÖÊ£ÄÊµãÁâ©‰Ωì„ÄÇËøôÁßçÊñπÊ≥ïÁöÑÂ§çÊùÇÂ∫¶ÊûÅÈ´òÔºåÊâÄ‰ª•ÂèàË¢´Áß∞‰∏∫ <strong>exhaustive search</strong>„ÄÇÂú®‰∫∫ËÑ∏ËØÜÂà´‰∏≠ÔºåÁî±‰∫é‰ΩøÁî®‰∫Ü Haar ÁâπÂæÅÔºåÂõ†Ê≠§ÂèØ‰ª•ÂÄüÂä© <strong>Paul Viola</strong> Âíå <strong>Michael Jones</strong> ‰∏§‰ΩçÂ§ßÁâõÊèêÂá∫ÁöÑÁßØÂàÜÂõæÔºå‰ΩøÊ£ÄÊµãÂú®Â∏∏ËßÑÊó∂Èó¥ÂÜÖÂÆåÊàê„ÄÇ‰ΩÜÂπ∂‰∏çÊòØÊØèÁßçÁâπÂæÅÈÉΩÈÄÇÁî®‰∫éÁßØÂàÜÂõæÔºåÂ∞§ÂÖ∂Âú®Á•ûÁªèÁΩëÁªú‰∏≠ÔºåÁßØÂàÜÂõæËøôÁßçÂä®ÊÄÅËßÑÂàíÁöÑÊÄùË∑ØÂ∞±Ê≤°‰ªÄ‰πà‰ΩúÁî®‰∫Ü„ÄÇ</p><p>ÈíàÂØπ‰º†ÁªüÊñπÊ≥ïÁöÑ‰∏çË∂≥ÔºåSelective Search ‰ªé‰∏â‰∏™ËßíÂ∫¶ÊèêÂá∫‰∫ÜÊîπËøõÔºö</p><ol><li>Êàë‰ª¨Ê≤°Ê≥ï‰∫ãÂÖàÂæóÁü•Áâ©‰ΩìÁöÑÂ§ßÂ∞èÔºåÂú®‰º†ÁªüÊñπÊ≥ï‰∏≠ÈúÄË¶ÅÁî®‰∏çÂêåÂ∞∫ÂØ∏ÁöÑÁü©ÂΩ¢Ê°ÜÊ£ÄÊµãÁâ©‰ΩìÔºåÈò≤Ê≠¢ÈÅóÊºè„ÄÇËÄå Selective Search ÈááÁî®‰∫Ü‰∏ÄÁßçÂÖ∑Â§áÂ±ÇÊ¨°ÁªìÊûÑÁöÑÁÆóÊ≥ïÊù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºõ</li><li>Ê£ÄÊµãÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶ÂèØËÉΩ‰ºöÂæàÈ´ò„ÄÇSelective Search ÈÅµÂæ™ÁÆÄÂçïÂç≥ÊòØÁæéÁöÑÂéüÂàôÔºåÂè™Ë¥üË¥£Âø´ÈÄüÂú∞ÁîüÊàêÂèØËÉΩÊòØÁâ©‰ΩìÁöÑÂå∫ÂüüÔºåËÄå‰∏çÂÅöÂÖ∑‰ΩìÁöÑÊ£ÄÊµãÔºõ</li><li>Âè¶Â§ñÔºåÁªìÂêà‰∏ä‰∏ÄËäÇÊèêÂá∫ÁöÑÔºåÈááÁî®Â§öÁßçÂÖàÈ™åÁü•ËØÜÊù•ÂØπÂêÑ‰∏™Âå∫ÂüüËøõË°åÁÆÄÂçïÁöÑÂà§Âà´ÔºåÈÅøÂÖç‰∏Ä‰∫õÊó†Áî®ÁöÑÊêúÁ¥¢ÔºåÊèêÈ´òÈÄüÂ∫¶ÂíåÁ≤æÂ∫¶„ÄÇ</li></ol><h3 id="ÁÆóÊ≥ïÊ°ÜÊû∂"><a href="#ÁÆóÊ≥ïÊ°ÜÊû∂" class="headerlink" title="ÁÆóÊ≥ïÊ°ÜÊû∂"></a>ÁÆóÊ≥ïÊ°ÜÊû∂</h3><p><a href="http://jermmy.xyz/images/2017-5-4/algorithm.png" target="_blank" rel="external"><img src="http://jermmy.xyz/images/2017-5-4/algorithm.png" alt="algorithm"></a>algorithm</p><p>ËÆ∫Êñá‰∏≠ÁªôÂá∫ÁöÑËøô‰∏™ÁÆóÊ≥ïÊ°ÜÊû∂ËøòÊòØÂæàËØ¶ÁªÜÁöÑÔºåËøôÈáåÂÜçÁÆÄÂçïÁøªËØë‰∏Ä‰∏ã„ÄÇ</p><ul><li>ËæìÂÖ•ÔºöÂΩ©Ëâ≤ÂõæÁâá„ÄÇ</li><li>ËæìÂá∫ÔºöÁâ©‰ΩìÂèØËÉΩÁöÑ‰ΩçÁΩÆÔºåÂÆûÈôÖ‰∏äÊòØÂæàÂ§öÁöÑÁü©ÂΩ¢ÂùêÊ†á„ÄÇ</li><li>È¶ñÂÖàÔºåÊàë‰ª¨‰ΩøÁî®ËøôÁØá<a href="http://cs.brown.edu/~pff/segment/" target="_blank" rel="external">ËÆ∫Êñá</a>ÁöÑÊñπÊ≥ïÂ∞ÜÂõæÁâáÂàùÂßãÂåñ‰∏∫ÂæàÂ§öÂ∞èÂå∫Âüü $R=r_i, \cdots, r_n$„ÄÇÁî±‰∫éÊàë‰ª¨ÁöÑÈáçÁÇπÊòØ Selective SearchÔºåÂõ†Ê≠§ÊàëÁõ¥Êé•Â∞ÜËØ•ËÆ∫ÊñáÁöÑÁÆóÊ≥ïÂΩìÊàê‰∏Ä‰∏™ÈªëÁõíÂ≠ê„ÄÇ</li><li>ÂàùÂßãÂåñ‰∏Ä‰∏™Áõ∏‰ººÈõÜÂêà‰∏∫Á©∫ÈõÜÔºö $S=‚àÖ$„ÄÇ</li><li>ËÆ°ÁÆóÊâÄÊúâÁõ∏ÈÇªÂå∫Âüü‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶ÔºàÁõ∏‰ººÂ∫¶ÂáΩÊï∞‰πãÂêé‰ºöÈáçÁÇπÂàÜÊûêÔºâÔºåÊîæÂÖ•ÈõÜÂêà S ‰∏≠ÔºåÈõÜÂêà S ‰øùÂ≠òÁöÑÂÖ∂ÂÆûÊòØ‰∏Ä‰∏™<strong>Âå∫ÂüüÂØπ</strong>‰ª•ÂèäÂÆÉ‰ª¨‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶„ÄÇ</li><li>ÊâæÂá∫ S ‰∏≠Áõ∏‰ººÂ∫¶ÊúÄÈ´òÁöÑÂå∫ÂüüÂØπÔºåÂ∞ÜÂÆÉ‰ª¨ÂêàÂπ∂ÔºåÂπ∂‰ªé S ‰∏≠Âà†Èô§‰∏éÂÆÉ‰ª¨Áõ∏ÂÖ≥ÁöÑÊâÄÊúâÁõ∏‰ººÂ∫¶ÂíåÂå∫ÂüüÂØπ„ÄÇÈáçÊñ∞ËÆ°ÁÆóËøô‰∏™Êñ∞Âå∫Âüü‰∏éÂë®Âõ¥Âå∫ÂüüÁöÑÁõ∏‰ººÂ∫¶ÔºåÊîæÂÖ•ÈõÜÂêà S ‰∏≠ÔºåÂπ∂Â∞ÜËøô‰∏™Êñ∞ÂêàÂπ∂ÁöÑÂå∫ÂüüÊîæÂÖ•ÈõÜÂêà R ‰∏≠„ÄÇÈáçÂ§çËøô‰∏™Ê≠•È™§Áõ¥Âà∞ S ‰∏∫Á©∫„ÄÇ</li><li>‰ªé R ‰∏≠ÊâæÂá∫ÊâÄÊúâÂå∫ÂüüÁöÑ bounding boxÔºàÂç≥ÂåÖÂõ¥ËØ•Âå∫ÂüüÁöÑÊúÄÂ∞èÁü©ÂΩ¢Ê°ÜÔºâÔºåËøô‰∫õ box Â∞±ÊòØÁâ©‰ΩìÂèØËÉΩÁöÑÂå∫Âüü„ÄÇ</li></ul><p>Âè¶Â§ñÔºå‰∏∫‰∫ÜÊèêÈ´òÈÄüÂ∫¶ÔºåÊñ∞ÂêàÂπ∂Âå∫ÂüüÁöÑ feature ÂèØ‰ª•ÈÄöËøá‰πãÂâçÁöÑ‰∏§‰∏™Âå∫ÂüüËé∑ÂæóÔºåËÄå‰∏çÂøÖÈáçÊñ∞ÈÅçÂéÜÊñ∞Âå∫ÂüüÁöÑÂÉèÁ¥†ÁÇπËøõË°åËÆ°ÁÆó„ÄÇËøô‰∏™ feature ‰ºöË¢´Áî®‰∫éËÆ°ÁÆóÁõ∏‰ººÂ∫¶„ÄÇ</p><h3 id="Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ï"><a href="#Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ï" class="headerlink" title="Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ï"></a>Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ï</h3><p>Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÊñπÊ≥ïÂ∞ÜÁõ¥Êé•ÂΩ±ÂìçÂêàÂπ∂Âå∫ÂüüÁöÑÈ°∫Â∫èÔºåËøõËÄåÂΩ±ÂìçÂà∞Ê£ÄÊµãÁªìÊûúÁöÑÂ•ΩÂùè„ÄÇ</p><p>ËÆ∫Êñá‰∏≠ÊØîËæÉ‰∫ÜÂÖ´ÁßçÈ¢úËâ≤Á©∫Èó¥ÁöÑÁâπÁÇπÔºåÂú®ÂÆûÈôÖÊìç‰Ωú‰∏≠ÔºåÂè™ÈÄâÊã©‰∏Ä‰∏™È¢úËâ≤Á©∫Èó¥ÔºàÊØîÂ¶ÇÔºöRGB Á©∫Èó¥ÔºâËøõË°åËÆ°ÁÆó„ÄÇ</p><p>Ê≠£Â¶Ç‰∏ÄÂºÄÂßãÊèêÂá∫ÁöÑÈÇ£Ê†∑ÔºåÊàë‰ª¨ÈúÄË¶ÅÁªºÂêàÂ§öÁßç‰ø°ÊÅØÊù•Âà§Êñ≠„ÄÇ‰ΩúËÄÖÂ∞ÜÁõ∏‰ººÂ∫¶Â∫¶ÈáèÂÖ¨ÂºèÂàÜ‰∏∫Âõõ‰∏™Â≠êÂÖ¨ÂºèÔºåÁß∞‰∏∫<strong>‰∫íË°•Áõ∏‰ººÂ∫¶ÊµãÈáè(Complementary Similarity Measures)</strong> „ÄÇËøôÂõõ‰∏™Â≠êÂÖ¨ÂºèÁöÑÂÄºÈÉΩË¢´ÂΩí‰∏ÄÂåñÂà∞Âå∫Èó¥ [0, 1] ÂÜÖ„ÄÇ</p><h4 id="1-È¢úËâ≤Áõ∏‰ººÂ∫¶scolor-ri-rj-scolor-ri-rj"><a href="#1-È¢úËâ≤Áõ∏‰ººÂ∫¶scolor-ri-rj-scolor-ri-rj" class="headerlink" title="1. È¢úËâ≤Áõ∏‰ººÂ∫¶scolor (ri,rj)scolor (ri,rj)"></a>1. È¢úËâ≤Áõ∏‰ººÂ∫¶scolor (ri,rj)scolor (ri,rj)</h4><p>Ê≠£Â¶ÇÊú¨Êñá‰∏ÄÂºÄÂßãÊèêÂà∞ÁöÑÔºåÈ¢úËâ≤ÊòØ‰∏Ä‰∏™ÂæàÈáçË¶ÅÁöÑÂå∫ÂàÜÁâ©‰ΩìÁöÑÂõ†Á¥†„ÄÇËÆ∫Êñá‰∏≠Â∞ÜÊØè‰∏™ region ÁöÑÂÉèÁ¥†Êåâ‰∏çÂêåÈ¢úËâ≤ÈÄöÈÅìÁªüËÆ°ÊàêÁõ¥ÊñπÂõæÔºåÂÖ∂‰∏≠ÔºåÊØè‰∏™È¢úËâ≤ÈÄöÈÅìÁöÑÁõ¥ÊñπÂõæ‰∏∫ 25 bins ÔºàÊØîÂ¶ÇÔºåÂØπ‰∫é 0 ÔΩû 255 ÁöÑÈ¢úËâ≤ÈÄöÈÅìÊù•ËØ¥ÔºåÂ∞±ÊØèÈöî 9(255/25=9) ‰∏™Êï∞ÂÄºÁªüËÆ°ÂÉèÁ¥†Êï∞ÈáèÔºâ„ÄÇËøôÊ†∑Ôºå‰∏â‰∏™ÈÄöÈÅìÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™ 75 Áª¥ÁöÑÁõ¥ÊñπÂõæÂêëÈáè $C_i={c_{i}^{1}, ‚Ä¶, c_{i}^{n}}$ÔºåÂÖ∂‰∏≠ n = 75„ÄÇ‰πãÂêéÔºåÊàë‰ª¨Áî® <strong>L1 ËåÉÊï∞</strong>ÔºàÁªùÂØπÂÄº‰πãÂíåÔºâÂØπÁõ¥ÊñπÂõæËøõË°åÂΩí‰∏ÄÂåñ„ÄÇÁî±Áõ¥ÊñπÂõæÊàë‰ª¨Â∞±ÂèØ‰ª•ËÆ°ÁÆó‰∏§‰∏™Âå∫ÂüüÁöÑÈ¢úËâ≤Áõ∏‰ººÂ∫¶Ôºö<br>$$<br>s_{color}(r_i, r_j) =\sum_{k=1}^{n}{min(c_{i}^{k}, c_{j}^{k})}<br>$$<br>Ëøô‰∏™È¢úËâ≤Áõ¥ÊñπÂõæÂèØ‰ª•Âú®ÂêàÂπ∂Âå∫ÂüüÁöÑÊó∂ÂÄôÔºåÂæàÊñπ‰æøÂú∞‰º†ÈÄíÁªô‰∏ã‰∏ÄÁ∫ßÂå∫Âüü„ÄÇÂç≥ÂÆÉ‰ª¨ÂêàÂπ∂ÂêéÁöÑÂå∫ÂüüÁöÑÁõ¥ÊñπÂõæÂêëÈáè‰∏∫Ôºö<br>$$<br>C_t=\frac{size(r_i)<em>C_i+size(r_j)</em>C_j}{size(r_i)+size(r_j)}<br>$$<br>ÔºåÂÖ∂‰∏≠$size(r_i)$ Ë°®Á§∫Âå∫Âüü $r_i$ ÁöÑÈù¢ÁßØÔºåÂêàÂπ∂ÂêéÁöÑÂå∫Âüü‰∏∫ $size(r_t)=size(r_i)+size(r_j)$„ÄÇ</p><h4 id="2-Á∫πÁêÜÁõ∏‰ººÂ∫¶-s-texture-r-i-r-j"><a href="#2-Á∫πÁêÜÁõ∏‰ººÂ∫¶-s-texture-r-i-r-j" class="headerlink" title="2. Á∫πÁêÜÁõ∏‰ººÂ∫¶$s_{texture}(r_i,r_j)$"></a>2. Á∫πÁêÜÁõ∏‰ººÂ∫¶$s_{texture}(r_i,r_j)$</h4><p>Âè¶‰∏Ä‰∏™ÈúÄË¶ÅËÄÉËôëÁöÑÂõ†Á¥†ÊòØÁ∫πÁêÜÔºåÂç≥ÂõæÂÉèÁöÑÊ¢ØÂ∫¶‰ø°ÊÅØ„ÄÇ</p><p>ËÆ∫Êñá‰∏≠ÂØπÁ∫πÁêÜÁöÑËÆ°ÁÆóÈááÁî®‰∫Ü SIFT-like ÁâπÂæÅÔºåËØ•ÁâπÂæÅÂÄüÈâ¥‰∫Ü SIFT ÁöÑËÆ°ÁÆóÊÄùË∑ØÔºåÂØπÊØè‰∏™È¢úËâ≤ÈÄöÈÅìÁöÑÂÉèÁ¥†ÁÇπÔºåÊ≤øÂë®Âõ¥ 8 ‰∏™ÊñπÂêëËÆ°ÁÆóÈ´òÊñØ‰∏ÄÈò∂ÂØºÊï∞(œÉ=1œÉ=1)ÔºåÊØè‰∏™ÊñπÂêëÁªüËÆ°‰∏Ä‰∏™Áõ¥ÊñπÂõæÔºàbin = 10ÔºâÔºåËøôÊ†∑Ôºå‰∏Ä‰∏™È¢úËâ≤ÈÄöÈÅìÁªüËÆ°ÂæóÂà∞ÁöÑÁõ¥ÊñπÂõæÂêëÈáè‰∏∫ 80 Áª¥Ôºå‰∏â‰∏™ÈÄöÈÅìÂ∞±ÊòØ 240 Áª¥Ôºö$T_i={t_i^{(1)}, ‚Ä¶, t_i^{(n)}}$ÔºåÂÖ∂‰∏≠ n = 240„ÄÇÊ≥®ÊÑèËøô‰∏™Áõ¥ÊñπÂõæË¶ÅÁî® <strong>L1 ËåÉÊï∞</strong>ÂΩí‰∏ÄÂåñ„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÊåâÁÖßÈ¢úËâ≤Áõ∏‰ººÂ∫¶ÁöÑËÆ°ÁÆóÊÄùË∑ØËÆ°ÁÆó‰∏§‰∏™Âå∫ÂüüÁöÑÁ∫πÁêÜÁõ∏‰ººÂ∫¶Ôºö<br>$$<br>s_{texture}(r_i, r_j) =\sum_{k=1}^{n}{min(t_{i}^{k}, t_{j}^{k})}<br>$$</p><h4 id="3-Â∞∫ÂØ∏Áõ∏‰ººÂ∫¶-s-size-r-i-r-j"><a href="#3-Â∞∫ÂØ∏Áõ∏‰ººÂ∫¶-s-size-r-i-r-j" class="headerlink" title="3. Â∞∫ÂØ∏Áõ∏‰ººÂ∫¶$s_{size} (r_i,r_j)$"></a>3. Â∞∫ÂØ∏Áõ∏‰ººÂ∫¶$s_{size} (r_i,r_j)$</h4><p>Âú®ÂêàÂπ∂Âå∫ÂüüÁöÑÊó∂ÂÄôÔºåËÆ∫Êñá‰ºòÂÖàËÄÉËôëÂ∞èÂå∫ÂüüÁöÑÂêàÂπ∂ÔºåËøôÁßçÂÅöÊ≥ïÂèØ‰ª•Âú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏ä‰øùËØÅÊØèÊ¨°ÂêàÂπ∂ÁöÑÂå∫ÂüüÈù¢ÁßØÈÉΩÊØîËæÉÁõ∏‰ººÔºåÈò≤Ê≠¢Â§ßÂå∫ÂüüÂØπÂ∞èÂå∫ÂüüÁöÑÈÄêÊ≠•ËöïÈ£ü„ÄÇËøô‰πàÂÅöÁöÑÁêÜÁî±‰πüÂæàÁÆÄÂçïÔºåÊàë‰ª¨Ë¶ÅÂùáÂåÄÂú∞Âú®ÂõæÁâáÁöÑÊØè‰∏™ËßíËêΩÁîüÊàê‰∏çÂêåÂ∞∫ÂØ∏ÁöÑÂå∫ÂüüÔºå‰ΩúÁî®Áõ∏ÂΩì‰∫é <strong>exhaustive search</strong> ‰∏≠Áî®‰∏çÂêåÂ∞∫ÂØ∏ÁöÑÁü©ÂΩ¢Êâ´ÊèèÂõæÁâá„ÄÇÂÖ∑‰ΩìÁöÑÁõ∏‰ººÂ∫¶ËÆ°ÁÆóÂÖ¨Âºè‰∏∫Ôºö<br>$$<br>s_{size}(r_i, r_j)=1-\frac{size(r_i) + size(r_j)}{size(im)}<br>$$<br>ÂÖ∂‰∏≠Ôºå$size(im)$ Ë°®Á§∫ÂéüÂõæÁâáÁöÑÂÉèÁ¥†Êï∞Èáè„ÄÇ</p><h4 id="4-Â°´ÂÖÖÁõ∏‰ººÂ∫¶-s-fill-r-i-r-j"><a href="#4-Â°´ÂÖÖÁõ∏‰ººÂ∫¶-s-fill-r-i-r-j" class="headerlink" title="4. Â°´ÂÖÖÁõ∏‰ººÂ∫¶$s_{fill}(r_i,r_j)$"></a>4. Â°´ÂÖÖÁõ∏‰ººÂ∫¶$s_{fill}(r_i,r_j)$</h4><p>Â°´ÂÖÖÁõ∏‰ººÂ∫¶‰∏ªË¶ÅÁî®Êù•ÊµãÈáè‰∏§‰∏™Âå∫Âüü‰πãÈó¥ fit ÁöÑÁ®ãÂ∫¶Ôºå‰∏™‰∫∫ËßâÂæóËøô‰∏ÄÁÇπÊòØË¶ÅËß£ÂÜ≥ÊñáÁ´†ÊúÄÂºÄÂßãÊèêÂá∫ÁöÑÁâ©‰Ωì‰πãÈó¥ÁöÑÂåÖÂê´ÂÖ≥Á≥ªÔºàÊØîÂ¶ÇÔºöËΩÆËÉéÂåÖÂê´Âú®Ê±ΩËΩ¶‰∏äÔºâ„ÄÇÂú®ÁªôÂá∫Â°´ÂÖÖÁõ∏‰ººÂ∫¶ÁöÑÂÖ¨ÂºèÂâçÔºåÊàë‰ª¨ÈúÄË¶ÅÂÆö‰πâ‰∏Ä‰∏™Áü©ÂΩ¢Âå∫Âüü $BB_{ij}$ÔºåÂÆÉË°®Á§∫ÂåÖÂê´ $r_i$ Âíå $r_j$ ÁöÑÊúÄÂ∞èÁöÑ bounding box„ÄÇÂü∫‰∫éÊ≠§ÔºåÊàë‰ª¨ÁªôÂá∫Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÂÖ¨Âºè‰∏∫Ôºö<br>$$<br>s_{fill}(r_i, r_j)=1-\frac{size(BB_{ij})-size(r_i)-size(r_j)}{size(im)}<br>$$<br>‰∏∫‰∫ÜÈ´òÊïàÂú∞ËÆ°ÁÆó $BB_{ij}$ÔºåÊàë‰ª¨ÂèØ‰ª•Âú®ËÆ°ÁÆóÊØè‰∏™ region ÁöÑÊó∂ÂÄôÔºåÈÉΩ‰øùÂ≠òÂÆÉ‰ª¨ÁöÑ bounding box ÁöÑ‰ΩçÁΩÆÔºåËøôÊ†∑Ôºå$BB_{ij}$ Â∞±ÂèØ‰ª•ÂæàÂø´Âú∞Áî±‰∏§‰∏™Âå∫ÂüüÁöÑ bounding box Êé®Âá∫Êù•„ÄÇ</p><h4 id="5-Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÂÖ¨Âºè"><a href="#5-Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÂÖ¨Âºè" class="headerlink" title="5. Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÂÖ¨Âºè"></a>5. Áõ∏‰ººÂ∫¶ËÆ°ÁÆóÂÖ¨Âºè</h4><p>ÁªºÂêà‰∏äÈù¢Âõõ‰∏™Â≠êÂÖ¨ÂºèÔºåÊàë‰ª¨ÂèØ‰ª•ÂæóÂà∞ËÆ°ÁÆóÁõ∏‰ººÂ∫¶ÁöÑÊúÄÁªàÂÖ¨ÂºèÔºö<br>$$<br>s(r_i, r_j) = a_1 s_{color}(r_i, r_j) +a_2s_{texture}(r_i, r_j) \\\\ +a_3s_{size}(r_i, r_j)+a_4s_{fill}(r_i, r_j)<br>$$<br>ÂÖ∂‰∏≠Ôºå$a_i$ÁöÑÂèñÂÄº‰∏∫ 0 Êàñ 1ÔºåË°®Á§∫Êüê‰∏™Áõ∏‰ººÂ∫¶ÊòØÂê¶Ë¢´ÈááÁ∫≥„ÄÇ</p><h3 id="Combining-Locations"><a href="#Combining-Locations" class="headerlink" title="Combining Locations"></a>Combining Locations</h3><p>ÂâçÈù¢Êàë‰ª¨Âü∫Êú¨ÂÆåÊàê‰∫Ü Selective Search ÁöÑÊµÅÁ®ãÔºå‰ªéÂõæÁâá‰∏≠ÊèêÂèñÂá∫‰∫ÜÁâ©‰ΩìÂèØËÉΩÁöÑ‰ΩçÁΩÆ„ÄÇÁé∞Âú®ÔºåÊàë‰ª¨ÊÉ≥ÂÆåÂñÑÊúÄÂêé‰∏Ä‰∏™ÈóÆÈ¢òÔºåÈÇ£Â∞±ÊòØÁªôËøô‰∫õ‰ΩçÁΩÆÊéí‰∏™Â∫è„ÄÇÂõ†‰∏∫ÊèêÂèñÂá∫Êù•ÁöÑÁü©ÂΩ¢Ê°ÜÊï∞ÈáèÂ∑®Â§ßÔºåËÄåÁî®Êà∑ÂèØËÉΩÂè™ÈúÄË¶ÅÂÖ∂‰∏≠ÁöÑÂá†‰∏™ÔºåËøô‰∏™Êó∂ÂÄôÊàë‰ª¨Â∞±ÂæàÊúâÂøÖË¶ÅÂØπËøô‰∫õÁü©ÂΩ¢Ê°ÜËµã‰∫à‰ºòÂÖàÁ∫ßÔºåÊåâÁÖß‰ºòÂÖàÁ∫ßÈ´ò‰ΩéËøîÂõûÁªôÁî®Êà∑„ÄÇÂéüÊñá‰∏≠‰ΩúËÄÖÁß∞Ëøô‰∏ÄÊ≠•‰∏∫ <strong>Combining Locations</strong>ÔºåÊàëÊâæ‰∏çÂá∫ÂêàÈÄÇÁöÑÁøªËØëÔºåÂ∞±Âßë‰∏î‰øùÁïôËã±ÊñáÂéüÊñá„ÄÇ</p><p>Ëøô‰∏™ÊéíÂ∫èÁöÑÊñπÊ≥ï‰πüÂæàÁÆÄÂçï„ÄÇ‰ΩúËÄÖÂÖàÁªôÂêÑ‰∏™ region ‰∏Ä‰∏™Â∫èÂè∑ÔºåÂâçÈù¢ËØ¥‰∫ÜÔºåSelective Search ÊòØ‰∏Ä‰∏™ÈÄêÊ≠•ÂêàÂπ∂ÁöÑÂ±ÇÁ∫ßÁªìÊûÑÔºåÂõ†Ê≠§ÔºåÊàë‰ª¨Â∞ÜË¶ÜÁõñÊï¥‰∏™Âå∫ÂüüÁöÑ region ÁöÑÂ∫èÂè∑Ê†áËÆ∞‰∏∫ 1ÔºåÂêàÊàêËøô‰∏™Âå∫ÂüüÁöÑ‰∏§‰∏™Â≠êÂå∫ÂüüÁöÑÂ∫èÂè∑‰∏∫ 2Ôºå‰ª•Ê≠§Á±ªÊé®„ÄÇ‰ΩÜÂ¶ÇÊûú‰ªÖÊåâÂ∫èÂè∑ÊéíÂ∫èÔºå‰ºöÂ≠òÂú®‰∏Ä‰∏™ÊºèÊ¥ûÔºåÈÇ£Â∞±ÊòØÂå∫ÂüüÈù¢ÁßØÂ§ßÁöÑ‰ºöÊéíÂú®ÂâçÈù¢Ôºå‰∏∫‰∫ÜÈÅøÂÖçËøô‰∏™ÊºèÊ¥ûÔºå‰ΩúËÄÖÂèàÂú®ÊØè‰∏™Â∫èÂè∑Ââç‰πò‰∏ä‰∏Ä‰∏™ÈöèÊú∫Êï∞ $RND‚àà[0,1]$ÔºåÈÄöËøáËøô‰∏™Êñ∞ËÆ°ÁÆóÂá∫Êù•ÁöÑÊï∞ÂÄºÔºåÊåâ‰ªéÂ∞èÂà∞Â§ßÁöÑÈ°∫Â∫èÂæóÂá∫ region ÊúÄÁªàÁöÑÊéíÂ∫èÁªìÊûú„ÄÇ</p><h3 id="ÂèÇËÄÉ"><a href="#ÂèÇËÄÉ" class="headerlink" title="ÂèÇËÄÉ"></a>ÂèÇËÄÉ</h3><ul><li><a href="http://blog.csdn.net/langb2014/article/details/52575507" target="_blank" rel="external">Selective Search for Object Recognition(ÈòÖËØª)</a></li><li><a href="http://cs.brown.edu/~pff/segment/" target="_blank" rel="external">Efficient Graph-Based Image Segmentation</a></li></ul><blockquote><p><strong>Êú¨Êñá‰ΩúËÄÖÔºö</strong> Jermmy</p><p><strong>Êú¨ÊñáÈìæÊé•Ôºö</strong> <a href="https://jermmy.github.io/2017/05/04/2017-5-4-paper-notes-selective-search/" target="_blank" rel="external">https://jermmy.github.io/2017/05/04/2017-5-4-paper-notes-selective-search/</a></p><p><strong>ÁâàÊùÉÂ£∞ÊòéÔºö </strong>Êú¨ÂçöÂÆ¢ÊâÄÊúâÊñáÁ´†Èô§ÁâπÂà´Â£∞ÊòéÂ§ñÔºåÂùáÈááÁî® <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" target="_blank" rel="external">CC BY-NC-SA 3.0</a> ËÆ∏ÂèØÂçèËÆÆ„ÄÇËΩ¨ËΩΩËØ∑Ê≥®ÊòéÂá∫Â§ÑÔºÅ</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;‰∏é Selective Search ÂàùÊ¨°ËßÅÈù¢ÊòØÂú®ËëóÂêçÁöÑÁâ©‰ΩìÊ£ÄÊµãËÆ∫Êñá &lt;code&gt;Rich feature hierarchies for accurate object detection and semantic segmentation&lt;/code&gt; ÔºåÂõ†Ê≠§ÔºåËøôÁØáËÆ∫Êñá
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Micro- and Macro-average of Precision, Recall and F-Score</title>
    <link href="http://yoursite.com/2018/04/27/Micro-and-Macro-average-of-Precision-Recall-and-F-Score/"/>
    <id>http://yoursite.com/2018/04/27/Micro-and-Macro-average-of-Precision-Recall-and-F-Score/</id>
    <published>2018-04-27T06:36:15.000Z</published>
    <updated>2018-04-27T06:37:49.011Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Micro-average-Method"><a href="#Micro-average-Method" class="headerlink" title="Micro-average Method"></a><strong>Micro-average Method</strong></h3><p>In Micro-average method, you sum up the individual true positives, false positives, and false negatives of the system for different sets and the apply them to get the statistics. For example, for a set of data, the system‚Äôs</p><p>True positive (TP1)= 12<br>False positive (FP1)=9<br>False negative (FN1)=3</p><p>Then precision (P1) and recall (R1) will be 57.14 and 80</p><p>and for a different set of data, the system‚Äôs</p><p>True positive (TP2)= 50<br>False positive (FP2)=23<br>False negative (FN2)=9</p><p>Then precision (P2) and recall (R2) will be 68.49 and 84.75</p><p>Now, the average precision and recall of the system using the Micro-average method is</p><p>Micro-average of precision = (TP1+TP2)/(TP1+TP2+FP1+FP2) = (12+50)/(12+50+9+23) = 65.96<br>Micro-average of recall = (TP1+TP2)/(TP1+TP2+FN1+FN2) = (12+50)/(12+50+3+9) = 83.78</p><p>The Micro-average F-Score will be simply the harmonic mean of these two figures.</p><h3 id="Macro-average-Method"><a href="#Macro-average-Method" class="headerlink" title="Macro-average Method"></a><strong>Macro-average Method</strong></h3><p>The method is straight forward. Just take the average of the precision and recall of the system on different sets. For example, the macro-average precision and recall of the system for the given example is</p><p>Macro-average precision = (P1+P2)/2 = (57.14+68.49)/2 = 62.82<br>Macro-average recall = (R1+R2)/2 = (80+84.75)/2 = 82.25</p><p>The Macro-average F-Score will be simply the harmonic mean of these two figures.</p><p>Suitability<br>Macro-average method can be used when you want to know how the system performs overall across the sets of data. You should not come up with any specific decision with this average.</p><p>On the other hand, micro-average can be a useful measure when your dataset varies in size.</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Micro-average-Method&quot;&gt;&lt;a href=&quot;#Micro-average-Method&quot; class=&quot;headerlink&quot; title=&quot;Micro-average Method&quot;&gt;&lt;/a&gt;&lt;strong&gt;Micro-average Meth
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Get financial data from Tushare</title>
    <link href="http://yoursite.com/2018/04/11/Get-financial-data-from-Tushare/"/>
    <id>http://yoursite.com/2018/04/11/Get-financial-data-from-Tushare/</id>
    <published>2018-04-11T11:42:46.000Z</published>
    <updated>2018-04-11T12:12:04.409Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>TuShare is a famous free, open source python financial data interface package. Its official home page is: <a href="http://tushare.waditu.com/" target="_blank" rel="external">TuShare - financial data interface package</a>. The interface package now provides a large amount of financial data covering a wide range of data such as stocks, fundamentals, macros, news, etc. (Please check the official website for details) and keep updating. At present, the length of the stock‚Äôs data is three years. Although it is a bit short, it can basically meet the needs of quantitative beginners for testing.</p><h1 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h1><h2 id="Install-and-Import"><a href="#Install-and-Import" class="headerlink" title="Install and Import"></a>Install and Import</h2><p><strong>You need to install first:</strong></p><ul><li>Pandas</li><li>lxml</li></ul><p><strong>Two way to install tushare:</strong></p><ol><li><code>pip install tushare</code></li><li>visit <a href="https://pypi.python.org/pypi/Tushare/" target="_blank" rel="external">https://pypi.python.org/pypi/Tushare/</a>, download and install</li></ol><p><strong>How to update:</strong></p><p><code>pip install tushare --upgrade</code></p><p><strong>Import package and view package version:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tushare</div><div class="line"></div><div class="line">print(tushare.__version__)</div></pre></td></tr></table></figure><h2 id="Use-some-simple-function"><a href="#Use-some-simple-function" class="headerlink" title="Use some simple function"></a>Use some simple function</h2><h3 id="Stock-data"><a href="#Stock-data" class="headerlink" title="Stock data"></a>Stock data</h3><p><strong>updateÔºöMany of the quotes returned by the <code>get_hist_data</code> function are wrong, but both <code>get_h_data</code> and <code>get_k_data</code> can be used</strong></p><p>We should still master how to use <code>tushare</code> to obtain stock market data, using the <code>ts.get_hist_data()</code> function whose <strong>input parameters</strong> are:</p><ul><li><strong>code: </strong>Stock code, ie 6-digit code, or index code (sh = Shanghai index sz = Shenzhen index hs300 = CSI 300 index sz50 = SSE 50 zxb = small and medium board cyb = board)</li><li><strong>start: </strong>Start date, format YYYY-MM-DD</li><li><strong>end: </strong>End date, format YYYY-MM-DD</li><li><strong>ktype: </strong>Data type, D = day k line W = week M = month 5 = 5 minutes 15 = 15 minutes 30 = 30 minutes 60 = 60 minutes, the default is D</li><li><strong>retry_count: </strong>The number of retries after the network is abnormal. The default is 3</li><li><strong>pause: </strong>Pause seconds when retrying, default is 0</li></ul><p><strong>Return values:</strong></p><ul><li><strong>date</strong>Ôºödate</li><li><strong>open</strong>ÔºöOpening price</li><li><strong>high</strong>ÔºöHighest price</li><li><strong>close</strong>ÔºöClosing price</li><li><strong>low</strong>ÔºöLowest price</li><li><strong>volume</strong>ÔºöVolume</li><li><strong>price_change</strong>Ôºöprice fluncuation</li><li><strong>p_change</strong>ÔºöQuote change</li><li><strong>ma5</strong>Ôºö5-day average price</li><li><strong>ma10</strong>Ôºö10-day average price</li><li><strong>ma20</strong>: 20-day average price</li><li><strong>v_ma5</strong>: 5-day average volume</li><li><strong>v_ma10</strong>: 10-day average volume</li><li><strong>v_ma20</strong>: 20-day average volume</li><li><strong>turnover</strong>: Change in hand rate [Note: Index does not have this item]</li></ul><h4 id="Specific-examples"><a href="#Specific-examples" class="headerlink" title="Specific examples:"></a>Specific examples:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">ts.get_hist_data(<span class="string">'600848'</span>)</div><div class="line"></div><div class="line"> date       open    high   close     low     volume    p_change   ma5    </div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-11</span>   <span class="number">6.880</span>   <span class="number">7.380</span>   <span class="number">7.060</span>   <span class="number">6.880</span>   <span class="number">14129.96</span>     <span class="number">2.62</span>   <span class="number">7.060</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-12</span>   <span class="number">7.050</span>   <span class="number">7.100</span>   <span class="number">6.980</span>   <span class="number">6.900</span>    <span class="number">7895.19</span>    <span class="number">-1.13</span>   <span class="number">7.020</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-13</span>   <span class="number">6.950</span>   <span class="number">7.000</span>   <span class="number">6.700</span>   <span class="number">6.690</span>    <span class="number">6611.87</span>    <span class="number">-4.01</span>   <span class="number">6.913</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-16</span>   <span class="number">6.680</span>   <span class="number">6.750</span>   <span class="number">6.510</span>   <span class="number">6.480</span>    <span class="number">2941.63</span>    <span class="number">-2.84</span>   <span class="number">6.813</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-17</span>   <span class="number">6.660</span>   <span class="number">6.880</span>   <span class="number">6.860</span>   <span class="number">6.460</span>    <span class="number">8642.57</span>     <span class="number">5.38</span>   <span class="number">6.822</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-18</span>   <span class="number">7.000</span>   <span class="number">7.300</span>   <span class="number">6.890</span>   <span class="number">6.880</span>   <span class="number">13075.40</span>     <span class="number">0.44</span>   <span class="number">6.788</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-19</span>   <span class="number">6.690</span>   <span class="number">6.950</span>   <span class="number">6.890</span>   <span class="number">6.680</span>    <span class="number">6117.32</span>     <span class="number">0.00</span>   <span class="number">6.770</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-20</span>   <span class="number">6.870</span>   <span class="number">7.080</span>   <span class="number">7.010</span>   <span class="number">6.870</span>    <span class="number">6813.09</span>     <span class="number">1.74</span>   <span class="number">6.832</span></div><div class="line"></div><div class="line">date         ma10    ma20      v_ma5     v_ma10     v_ma20     turnover</div><div class="line"></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-11</span>   <span class="number">7.060</span>   <span class="number">7.060</span>   <span class="number">14129.96</span>   <span class="number">14129.96</span>   <span class="number">14129.96</span>     <span class="number">0.48</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-12</span>   <span class="number">7.020</span>   <span class="number">7.020</span>   <span class="number">11012.58</span>   <span class="number">11012.58</span>   <span class="number">11012.58</span>     <span class="number">0.27</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-13</span>   <span class="number">6.913</span>   <span class="number">6.913</span>    <span class="number">9545.67</span>    <span class="number">9545.67</span>    <span class="number">9545.67</span>     <span class="number">0.23</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-16</span>   <span class="number">6.813</span>   <span class="number">6.813</span>    <span class="number">7894.66</span>    <span class="number">7894.66</span>    <span class="number">7894.66</span>     <span class="number">0.10</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-17</span>   <span class="number">6.822</span>   <span class="number">6.822</span>    <span class="number">8044.24</span>    <span class="number">8044.24</span>    <span class="number">8044.24</span>     <span class="number">0.30</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-18</span>   <span class="number">6.833</span>   <span class="number">6.833</span>    <span class="number">7833.33</span>    <span class="number">8882.77</span>    <span class="number">8882.77</span>     <span class="number">0.45</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-19</span>   <span class="number">6.841</span>   <span class="number">6.841</span>    <span class="number">7477.76</span>    <span class="number">8487.71</span>    <span class="number">8487.71</span>     <span class="number">0.21</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-20</span>   <span class="number">6.863</span>   <span class="number">6.863</span>    <span class="number">7518.00</span>    <span class="number">8278.38</span>    <span class="number">8278.38</span>     <span class="number">0.23</span></div></pre></td></tr></table></figure><p>You can also set the start time and end time of historical data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">ts.get_hist_data(<span class="string">'600848'</span>,start=<span class="string">'2015-01-05'</span>,end=<span class="string">'2015-01-09'</span>)</div><div class="line"></div><div class="line"> date       open    high   close     low    volume   p_change   ma5    ma10</div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">11.160</span>  <span class="number">11.390</span>  <span class="number">11.260</span>  <span class="number">10.890</span>  <span class="number">46383.57</span>     <span class="number">1.26</span>  <span class="number">11.156</span>  <span class="number">11.212</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">11.130</span>  <span class="number">11.660</span>  <span class="number">11.610</span>  <span class="number">11.030</span>  <span class="number">59199.93</span>     <span class="number">3.11</span>  <span class="number">11.182</span>  <span class="number">11.155</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-07</span>  <span class="number">11.580</span>  <span class="number">11.990</span>  <span class="number">11.920</span>  <span class="number">11.480</span>  <span class="number">86681.38</span>     <span class="number">2.67</span>  <span class="number">11.366</span>  <span class="number">11.251</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-08</span>  <span class="number">11.700</span>  <span class="number">11.920</span>  <span class="number">11.670</span>  <span class="number">11.640</span>  <span class="number">56845.71</span>    <span class="number">-2.10</span>  <span class="number">11.516</span>  <span class="number">11.349</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-09</span>  <span class="number">11.680</span>  <span class="number">11.710</span>  <span class="number">11.230</span>  <span class="number">11.190</span>  <span class="number">44851.56</span>    <span class="number">-3.77</span>  <span class="number">11.538</span>  <span class="number">11.363</span></div><div class="line"> date        ma20     v_ma5    v_ma10     v_ma20      turnover</div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">11.198</span>  <span class="number">58648.75</span>  <span class="number">68429.87</span>   <span class="number">97141.81</span>     <span class="number">1.59</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">11.382</span>  <span class="number">54854.38</span>  <span class="number">63401.05</span>   <span class="number">98686.98</span>     <span class="number">2.03</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-07</span>  <span class="number">11.543</span>  <span class="number">55049.74</span>  <span class="number">61628.07</span>  <span class="number">103010.58</span>     <span class="number">2.97</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-08</span>  <span class="number">11.647</span>  <span class="number">57268.99</span>  <span class="number">61376.00</span>  <span class="number">105823.50</span>     <span class="number">1.95</span></div></pre></td></tr></table></figure><p>Others:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'W'</span>) <span class="comment"># Get weekly k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'M'</span>) <span class="comment"># Get monthly k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'5'</span>) <span class="comment"># Get 5 minutes k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'15'</span>) <span class="comment"># Get 15 minutes k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'30'</span>) <span class="comment"># Get 30 minutes k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'60'</span>) <span class="comment"># Get 60 minutes k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'sh'</span>Ôºâ<span class="comment"># Get data on the Shanghai index k-line, other parameters consistent with the stocks, the same below</span></div><div class="line">ts.get_hist_data(<span class="string">'sz'</span>Ôºâ<span class="comment"># Get Shenzhen Chengzhi k line data</span></div><div class="line">ts.get_hist_data(<span class="string">'hs300'</span>Ôºâ<span class="comment"># Get the CSI 300 k line data</span></div><div class="line">ts.get_hist_data(<span class="string">'sz50'</span>Ôºâ<span class="comment"># Get SSE 50 Index k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'zxb'</span>Ôºâ<span class="comment"># Get the k-line data of small and medium board indices</span></div><div class="line">ts.get_hist_data(<span class="string">'cyb'</span>Ôºâ<span class="comment"># Get GEM Index k-line data</span></div></pre></td></tr></table></figure><h3 id="Fundamental-data"><a href="#Fundamental-data" class="headerlink" title="Fundamental data"></a>Fundamental data</h3><p>With <code>tushare</code> we can also get fundamental data through <code>ts.get_stock_basics()</code> (shown in the results section):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">ts.get_stock_basics()</div><div class="line"></div><div class="line">code    name      industry  area     pe     outstanding    totals   totalAssets                                                                   </div><div class="line"><span class="number">300563</span>    NÁ•ûÂÆá  ÈÄö‰ø°ËÆæÂ§á   Ê±üËãè    <span class="number">26.73</span>      <span class="number">2000.00</span>     <span class="number">8000.00</span>  <span class="number">4.216000e+04</span>   </div><div class="line"><span class="number">601882</span>   Êµ∑Â§©Á≤æÂ∑•     Êú∫Â∫äÂà∂ÈÄ†   ÊµôÊ±ü    <span class="number">26.83</span>      <span class="number">5220.00</span>    <span class="number">52200.00</span>  <span class="number">1.877284e+05</span> </div><div class="line"><span class="number">601880</span>    Â§ßËøûÊ∏Ø       Ê∏ØÂè£   ËæΩÂÆÅ    <span class="number">76.40</span>    <span class="number">773582.00</span>  <span class="number">1289453.63</span>  <span class="number">3.263012e+06</span>   </div><div class="line"><span class="number">300556</span>   ‰∏ùË∑ØËßÜËßâ     ËΩØ‰ª∂ÊúçÂä°   Ê∑±Âú≥   <span class="number">101.38</span>      <span class="number">2780.00</span>    <span class="number">11113.33</span>  <span class="number">4.448248e+04</span> </div><div class="line"><span class="number">600528</span>   ‰∏≠ÈìÅ‰∫åÂ±Ä     Âª∫Á≠ëÊñΩÂ∑•   ÂõõÂ∑ù   <span class="number">149.34</span>    <span class="number">145920.00</span>   <span class="number">145920.00</span>  <span class="number">5.709568e+06</span> </div><div class="line"><span class="number">002495</span>   ‰Ω≥ÈöÜËÇ°‰ªΩ       È£üÂìÅ   Âπø‰∏ú   <span class="number">202.12</span>     <span class="number">66611.13</span>    <span class="number">93562.56</span>  <span class="number">1.169174e+05</span> </div><div class="line"><span class="number">600917</span>   ÈáçÂ∫ÜÁáÉÊ∞î     ‰æõÊ∞î‰æõÁÉ≠   ÈáçÂ∫Ü    <span class="number">76.87</span>     <span class="number">15600.00</span>   <span class="number">155600.00</span>  <span class="number">8.444600e+05</span> </div><div class="line"><span class="number">002752</span>   ÊòáÂÖ¥ËÇ°‰ªΩ     ÂπøÂëäÂåÖË£Ö   Á¶èÂª∫    <span class="number">75.14</span>     <span class="number">12306.83</span>    <span class="number">63000.00</span>  <span class="number">2.387493e+05</span> </div><div class="line"><span class="number">002346</span>   Êüò‰∏≠ËÇ°‰ªΩ     ÁîµÊ∞îËÆæÂ§á   ‰∏äÊµ∑   <span class="number">643.97</span>      <span class="number">7980.00</span>    <span class="number">44157.53</span>  <span class="number">2.263010e+05</span> </div><div class="line"><span class="number">000680</span>   Â±±Êé®ËÇ°‰ªΩ     Â∑•Á®ãÊú∫Ê¢∞   Â±±‰∏ú     <span class="number">0.00</span>    <span class="number">105694.97</span>   <span class="number">124078.75</span>  <span class="number">9.050701e+05</span></div><div class="line">...</div></pre></td></tr></table></figure><h3 id="Macro-data"><a href="#Macro-data" class="headerlink" title="Macro data"></a>Macro data</h3><p>We use the resident consumer index as an example, which can be obtained through the <code>ts.get_cpi()</code> function (it will get 322 items at a time, some of them will be displayed):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> ts.get_cpi()</div><div class="line"></div><div class="line">       month     cpi</div><div class="line"><span class="number">0</span>    <span class="number">2016.10</span>  <span class="number">102.10</span></div><div class="line"><span class="number">1</span>     <span class="number">2016.9</span>  <span class="number">101.90</span></div><div class="line"><span class="number">2</span>     <span class="number">2016.8</span>  <span class="number">101.34</span></div><div class="line"><span class="number">3</span>     <span class="number">2016.7</span>  <span class="number">101.77</span></div><div class="line"><span class="number">4</span>     <span class="number">2016.6</span>  <span class="number">101.88</span></div><div class="line"><span class="number">5</span>     <span class="number">2016.5</span>  <span class="number">102.04</span></div><div class="line"><span class="number">6</span>     <span class="number">2016.4</span>  <span class="number">102.33</span></div><div class="line"><span class="number">7</span>     <span class="number">2016.3</span>  <span class="number">102.30</span></div><div class="line"><span class="number">8</span>     <span class="number">2016.2</span>  <span class="number">102.28</span></div><div class="line"><span class="number">9</span>     <span class="number">2016.1</span>  <span class="number">101.75</span></div><div class="line"><span class="number">10</span>   <span class="number">2015.12</span>  <span class="number">101.64</span></div><div class="line">...</div></pre></td></tr></table></figure><h3 id="Recent-news"><a href="#Recent-news" class="headerlink" title="Recent news"></a>Recent news</h3><p>The <code>tushare</code> package can use the <code>ts.get_latest_news()</code> function to view the latest news, and it will return 80. For reasons of space, we only show the first 15 here. We can see that it is all Sina Finance‚Äôs news data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> ts.get_latest_news();</div><div class="line"></div><div class="line">   classify                         title         time  \</div><div class="line"><span class="number">0</span>        ÁæéËÇ°            ‚ÄúÁâπÊúóÊôÆÈÄöËÉÄ‚ÄùÈ¢ÑÊúüÂçáÊ∏© ÁæéÂõΩÂõΩÂÄ∫‰∏ãÊå´  <span class="number">11</span><span class="number">-14</span> <span class="number">23</span>:<span class="number">10</span>   </div><div class="line"><span class="number">1</span>        ÁæéËÇ°          ÁâπÊúóÊôÆÔºöËÑ∏‰π¶„ÄÅÊé®ÁâπÁ≠âÁ§æ‰∫§Â™í‰ΩìÂä©ÊàëÂÖ•‰∏ªÁôΩÂÆ´  <span class="number">11</span><span class="number">-14</span> <span class="number">23</span>:<span class="number">10</span>   </div><div class="line"><span class="number">2</span>        ËØÅÂà∏                <span class="number">11</span>Êúà<span class="number">14</span>Êó•ÊôöÂ¢ûÂáèÊåÅÊØèÊó•ÈÄüËßà  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">54</span>   </div><div class="line"><span class="number">3</span>        ÁæéËÇ°          Ë¥¢ÁªèËßÇÂØüÔºöÊó•Êú¨‰∏∫‰ΩïÊÄ•‰∫éÊé®Âä®TPPÊâπÂáÜÁ®ãÂ∫è  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">54</span>   </div><div class="line"><span class="number">4</span>        ÁæéËÇ°              Êñ∞ÊÄªÁªüË∞úÈ¢òÔºöÁâπÊúóÊôÆ‰ºöËøûÁª≠Âä†ÊÅØÂêóÔºü  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">52</span>   </div><div class="line"><span class="number">5</span>        ËØÅÂà∏      Á•ûÂ∑û‰∏ìËΩ¶Ë¥¢Êä•ÈÅ≠Ë¥®Áñë Â¢ûÂèë<span class="number">100</span>‰∫øËÇ°‰∏úÈÄÄÂá∫ÈúÄ<span class="number">50</span>Âπ¥  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">41</span>   </div><div class="line"><span class="number">6</span>        ËØÅÂà∏           ÊÅíÂ§ßÈó™ÁîµÊùÄÂõûÈ©¨Êû™ÈîÅ‰ªìÂçäÂπ¥ ÊàíÁü≠ÁÇí‰∫ÜÂêóÔºü  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">38</span>   </div><div class="line"><span class="number">7</span>      ÂõΩÂÜÖË¥¢Áªè         Ê•ºÁªß‰ºüÂäõÊé®ÊîπÈù©ÂÅöÊ¥æ ÊàñÂä†Âø´ÂõΩÊúâËµÑÊú¨ÂàíÊã®Á§æ‰øù  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">36</span>   </div><div class="line"><span class="number">8</span>        ÁæéËÇ°            ÂºÄÁõòÔºöÁæéËÇ°Âë®‰∏ÄÂ∞èÂπÖÈ´òÂºÄ Âª∂Áª≠‰∏äÂë®Ê∂®Âäø  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">32</span>   </div><div class="line"><span class="number">9</span>        ÁæéËÇ°            ÂñúËææÂ±ãÂàõÂßã‰∫∫ÔºöÂΩìÂ•ΩÊÄªÁªüÂ∞±Ë¶ÅËµ∞‰∏≠Â∫∏‰πãÈÅì  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">24</span>   </div><div class="line"><span class="number">10</span>       ËØÅÂà∏              Âåó‰∫¨È´òÂçéÔºöÂ∞Ü‰πêËßÜÁΩëËØÑÁ∫ß‰∏ãË∞ÉËá≥‰∏≠ÊÄß  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">09</span>   </div><div class="line"><span class="number">11</span>       ÁæéËÇ°             <span class="number">11</span>Êúà<span class="number">14</span>Êó•<span class="number">22</span>ÁÇπ‰∫§ÊòìÂëòÊ≠£ÂÖ≥Ê≥®Ë¶ÅÈóª  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">02</span>   </div><div class="line"><span class="number">12</span>       ÁæéËÇ°           Êë©Ê†πÂ§ßÈÄöÔºöÊñ∞ÂÖ¥Â∏ÇÂú∫ËÇ°Â∏Ç„ÄÅË¥ßÂ∏ÅÁöÑÂâçÊôØÊÇ≤ËßÇ  <span class="number">11</span><span class="number">-14</span> <span class="number">21</span>:<span class="number">55</span>   </div><div class="line"><span class="number">13</span>     ÂõΩÂÜÖË¥¢Áªè        ‰∫∫Ê∞ëÊó•Êä•ÂàäÊñáË∞àÂÖ®Èù¢Ê∑±ÂåñÊîπÈù©Ëøô‰∏âÂπ¥ÔºöÂïÉ‰∏ãÁ°¨È™®Â§¥  <span class="number">11</span><span class="number">-14</span> <span class="number">21</span>:<span class="number">46</span>   </div><div class="line"><span class="number">14</span>       ËØÅÂà∏       Ê≥ΩÂπ≥ÂÆèËßÇÔºöÁªèÊµéLÂûãÂª∂Áª≠ Âú∞‰∫ßÈîÄÈáèÂõûËêΩÊäïËµÑË∂ÖÈ¢ÑÊúü  <span class="number">11</span><span class="number">-14</span> <span class="number">21</span>:<span class="number">43</span>   </div><div class="line"><span class="number">15</span>       ËØÅÂà∏       ÈªÑÁáïÈì≠Á≠â‰∫îÂ§ßÂà∏ÂïÜÂ§ß‰Ω¨ÂëäËØâ‰Ω† <span class="number">2017</span>Âπ¥‰π∞ÁÇπÂï•Ôºü  <span class="number">11</span><span class="number">-14</span> <span class="number">21</span>:<span class="number">41</span>   </div><div class="line"></div><div class="line">url  </div><div class="line"><span class="number">0</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">1</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">2</span>   http://finance.sina.com.cn/stock/y/<span class="number">2016</span><span class="number">-11</span><span class="number">-14</span>/...  </div><div class="line"><span class="number">3</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">4</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">5</span>   http://finance.sina.com.cn/stock/marketresearc...  </div><div class="line"><span class="number">6</span>   http://finance.sina.com.cn/stock/marketresearc...  </div><div class="line"><span class="number">7</span>   http://finance.sina.com.cn/china/gncj/<span class="number">2016</span><span class="number">-11</span>-...  </div><div class="line"><span class="number">8</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">9</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">10</span>  http://finance.sina.com.cn/stock/s/<span class="number">2016</span><span class="number">-11</span><span class="number">-14</span>/...  </div><div class="line"><span class="number">11</span>  http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">12</span>  http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">13</span>  http://finance.sina.com.cn/china/gncj/<span class="number">2016</span><span class="number">-11</span>-...  </div><div class="line"><span class="number">14</span>  http://finance.sina.com.cn/stock/marketresearc...  </div><div class="line"><span class="number">15</span>  http://finance.sina.com.cn/stock/marketresearc...</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;TuShare is a famous free, open
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Some Paper Summaries of Semantic Segmentation with Deep Learning</title>
    <link href="http://yoursite.com/2018/04/10/Some-Paper-Summaries-of-Semantic-Segmentation-with-Deep-Learning/"/>
    <id>http://yoursite.com/2018/04/10/Some-Paper-Summaries-of-Semantic-Segmentation-with-Deep-Learning/</id>
    <published>2018-04-10T12:01:58.000Z</published>
    <updated>2018-04-10T12:04:49.436Z</updated>
    
    <content type="html"><![CDATA[<h3 id="What-exactly-is-semantic-segmentation"><a href="#What-exactly-is-semantic-segmentation" class="headerlink" title="What exactly is semantic segmentation?"></a>What exactly is semantic segmentation?</h3><p>Semantic segmentation is understanding an image at pixel level i.e, we want to assign each pixel in the image an object class. For example, check out the following images.</p><p><img src="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/images/21.jpg" alt="biker"> <img src="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/images/21_class.png" alt="biker"><br><em>Left</em>: Input image. <em>Right</em>: It‚Äôs semantic segmentation. <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/index.html" target="_blank" rel="external">Source.</a></p><p>Apart from recognizing the bike and the person riding it, we also have to delineate the boundaries of each object. Therefore, unlike classification, we need dense pixel-wise predictions from our models.</p><p><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/" target="_blank" rel="external">VOC2012</a> and <a href="http://mscoco.org/explore/" target="_blank" rel="external">MSCOCO</a> are the most important datasets for semantic segmentation.</p><h3 id="What-are-the-different-approaches"><a href="#What-are-the-different-approaches" class="headerlink" title="What are the different approaches?"></a>What are the different approaches?</h3><p>Before deep learning took over computer vision, people used approaches like <a href="http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2008-CVPR-semantic-texton-forests.pdf" target="_blank" rel="external">TextonForest</a> and <a href="http://www.cse.chalmers.se/edu/year/2011/course/TDA361/Advanced%20Computer%20Graphics/BodyPartRecognition.pdf" target="_blank" rel="external">Random Forest based classifiers</a> for semantic segmentation. As with image classification, convolutional neural networks (CNN) have had enormous success on segmentation problems.</p><p>One of the popular initial deep learning approaches was <a href="http://people.idsia.ch/~juergen/nips2012.pdf" target="_blank" rel="external">patch classification</a> where each pixel was separately classified into classes using a patch of image around it. Main reason to use patches was that classification networks usually have full connected layers and therefore required fixed size images.</p><p>In 2014, <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn" target="_blank" rel="external">Fully Convolutional Networks (FCN)</a> by Long et al. from Berkeley, popularized CNN architectures for dense predictions without any fully connected layers. This allowed segmentation maps to be generated for image of any size and was also much faster compared to the patch classification approach. Almost all the subsequent state of the art approaches on semantic segmentation adopted this paradigm.</p><p>Apart from fully connected layers, one of the main problems with using CNNs for segmentation is <em>pooling layers</em>. Pooling layers increase the field of view and are able to aggregate the context while discarding the ‚Äòwhere‚Äô information. However, semantic segmentation requires the exact alignment of class maps and thus, needs the ‚Äòwhere‚Äô information to be preserved. Two different classes of architectures evolved in the literature to tackle this issue.</p><p>First one is encoder-decoder architecture. Encoder gradually reduces the spatial dimension with pooling layers and decoder gradually recovers the object details and spatial dimension. There are usually shortcut connections from encoder to decoder to help decoder recover the object details better. <a href="https://arxiv.org/abs/1505.04597" target="_blank" rel="external">U-Net</a> is a popular architecture from this class.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/unet.png" alt="U-Net architecture"><br>U-Net: An encoder-decoder architecture. <a href="https://arxiv.org/abs/1505.04597" target="_blank" rel="external">Source</a>.</p><p>Architectures in the second class use what are called as <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated/atrous convolutions</a>and do away with pooling layers.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/dilated_conv.png" alt="Dilated/atrous convolutions"><br>Dilated/atrous convolutions. rate=1 is same as normal convolutions. <a href="https://arxiv.org/abs/1706.05587" target="_blank" rel="external">Source</a>.</p><p><a href="https://arxiv.org/abs/1210.5644" target="_blank" rel="external">Conditional Random Field (CRF) postprocessing</a> are usually used to improve the segmentation. CRFs are graphical models which ‚Äòsmooth‚Äô segmentation based on the underlying image intensities. They work based on the observation that similar intensity pixels tend to be labeled as the same class. CRFs can boost scores by 1-2%.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/crf.png" alt="CRF"><br>CRF illustration. (b) Unary classifiers is the segmentation input to the CRF. (c, d, e) are variants of CRF with (e) being the widely used one. <a href="https://arxiv.org/abs/1210.5644" target="_blank" rel="external">Source</a>.</p><p>In the next section, I‚Äôll summarize a few papers that represent the evolution of segmentation architectures starting from FCN. All these architectures are benchmarked on <a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php" target="_blank" rel="external">VOC2012 evaluation server</a>.</p><h3 id="Summaries"><a href="#Summaries" class="headerlink" title="Summaries"></a>Summaries</h3><p>Following papers are summarized (in chronological order):</p><ol><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn" target="_blank" rel="external">FCN</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#segnet" target="_blank" rel="external">SegNet</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">Dilated Convolutions</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLab (v1 &amp; v2)</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#refinenet" target="_blank" rel="external">RefineNet</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#pspnet" target="_blank" rel="external">PSPNet</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#large-kernel" target="_blank" rel="external">Large Kernel Matters</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplabv3" target="_blank" rel="external">DeepLab v3</a></li></ol><p>For each of these papers, I list down their key contributions and explain them. I also show their benchmark scores (mean IOU) on VOC2012 test dataset.</p><h4 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h4><ul><li>Fully Convolutional Networks for Semantic Segmentation</li><li>Submitted on 14 Nov 2014</li><li><a href="https://arxiv.org/abs/1411.4038" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Popularize the use of end to end convolutional networks for semantic segmentation</li><li>Re-purpose imagenet pretrained networks for segmentation</li><li>Upsample using <em>deconvolutional</em> layers</li><li>Introduce skip connections to improve over the coarseness of upsampling</li></ul><p><em>Explanation</em>:</p><p>Key observation is that fully connected layers in classification networks can be viewed as convolutions with kernels that cover their entire input regions. This is equivalent to evaluating the original classification network on overlapping input patches but is much more efficient because computation is shared over the overlapping regions of patches. Although this observation is not unique to this paper (see <a href="https://arxiv.org/abs/1312.6229" target="_blank" rel="external">overfeat</a>, <a href="https://plus.google.com/+PierreSermanet/posts/VngsFR3tug9" target="_blank" rel="external">this post</a>), it improved the state of the art on VOC2012 significantly.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/FCN%20-%20illustration.png" alt="FCN architecture"><br>Fully connected layers as a convolution. <a href="https://arxiv.org/abs/1411.4038" target="_blank" rel="external">Source</a>.</p><p>After convolutionalizing fully connected layers in a imagenet pretrained network like VGG, feature maps still need to be upsampled because of pooling operations in CNNs. Instead of using simple bilinear interpolation, <em>deconvolutional layers</em> can learn the interpolation. This layer is also known as upconvolution, full convolution, transposed convolution or fractionally-strided convolution.</p><p>However, upsampling (even with deconvolutional layers) produces coarse segmentation maps because of loss of information during pooling. Therefore, shortcut/skip connections are introduced from higher resolution feature maps.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>62.2</td><td>-</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&amp;challengeid=11&amp;compid=6&amp;submid=6103#KEY_FCN-8s" target="_blank" rel="external">leaderboard</a></td></tr><tr><td>67.2</td><td>More momentum. Not described in paper</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&amp;challengeid=11&amp;compid=6&amp;submid=6103#KEY_FCN-8s-heavy" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><p><em>My Comments</em>:</p><ul><li>This was an important contribution but state of the art has improved a lot by now though.</li></ul><h4 id="SegNet"><a href="#SegNet" class="headerlink" title="SegNet"></a>SegNet</h4><ul><li>SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</li><li>Submitted on 2 Nov 2015</li><li><a href="https://arxiv.org/abs/1511.00561" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Maxpooling indices transferred to decoder to improve the segmentation resolution.</li></ul><p><em>Explanation</em>:</p><p>FCN, despite upconvolutional layers and a few shortcut connections produces coarse segmentation maps. Therefore, more shortcut connections are introduced. However, instead of copying the encoder features as in FCN, indices from maxpooling are copied. This makes SegNet more memory efficient than FCN.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/segnet_architecture.png" alt="SegNet Architecture"><br>Segnet Architecture. <a href="https://arxiv.org/abs/1511.00561" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>59.9</td><td>-</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_SegNet" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><p><em>My comments</em>:</p><ul><li>FCN and SegNet are one of the first encoder-decoder architectures.</li><li>Benchmarks for SegNet are not good enough to be used anymore.</li></ul><h4 id="Dilated-Convolutions"><a href="#Dilated-Convolutions" class="headerlink" title="Dilated Convolutions"></a>Dilated Convolutions</h4><ul><li>Multi-Scale Context Aggregation by Dilated Convolutions</li><li>Submitted on 23 Nov 2015</li><li><a href="https://arxiv.org/abs/1511.07122" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Use dilated convolutions, a convolutional layer for dense predictions.</li><li>Propose ‚Äòcontext module‚Äô which uses dilated convolutions for multi scale aggregation.</li></ul><p><em>Explanation</em>:</p><p>Pooling helps in classification networks because receptive field increases. But this is not the best thing to do for segmentation because pooling decreases the resolution. Therefore, authors use <em>dilated convolution</em> layer which works like this:</p><p><img src="https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/dilation.gif" alt="Dilated/Atrous Convolutions"><br>Dilated/Atrous Convolutions. <a href="https://github.com/vdumoulin/conv_arithmetic" target="_blank" rel="external">Source</a></p><p>Dilated convolutional layer (also called as atrous convolution in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLab</a>) allows for exponential increase in field of view without decrease of spatial dimensions.</p><p>Last two pooling layers from pretrained classification network (here, VGG) are removed and subsequent convolutional layers are replaced with dilated convolutions. In particular, convolutions between the pool-3 and pool-4 have dilation 2 and convolutions after pool-4 have dilation 4. With this module (called <em>frontend module</em> in the paper), dense predictions are obtained without any increase in number of parameters.</p><p>A module (called <em>context module</em> in the paper) is trained separately with the outputs of frontend module as inputs. This module is a cascade of dilated convolutions of different dilations so that multi scale context is aggregated and predictions from frontend are improved.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>71.3</td><td>frontend</td><td>reported in the paper</td></tr><tr><td>73.5</td><td>frontend + context</td><td>reported in the paper</td></tr><tr><td>74.7</td><td>frontend + context + CRF</td><td>reported in the paper</td></tr><tr><td>75.3</td><td>frontend + context + CRF-RNN</td><td>reported in the paper</td></tr></tbody></table><p><em>My comments</em>:</p><ul><li>Note that predicted segmentation map‚Äôs size is 1/8th of that of the image. This is the case with almost all the approaches. They are interpolated to get the final segmentation map.</li></ul><h4 id="DeepLab-v1-amp-v2"><a href="#DeepLab-v1-amp-v2" class="headerlink" title="DeepLab (v1 &amp; v2)"></a>DeepLab (v1 &amp; v2)</h4><ul><li><strong>v1</strong> : Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs</li><li>Submitted on 22 Dec 2014</li><li><a href="https://arxiv.org/abs/1412.7062" target="_blank" rel="external">Arxiv Link</a></li><li></li><li><strong>v2</strong> : DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</li><li>Submitted on 2 Jun 2016</li><li><a href="https://arxiv.org/abs/1606.00915" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Use atrous/dilated convolutions.</li><li>Propose atrous spatial pyramid pooling (ASPP)</li><li>Use Fully connected CRF</li></ul><p><em>Explanation</em>:</p><p>Atrous/Dilated convolutions increase the field of view without increasing the number of parameters. Net is modified like in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated convolutions paper</a>.</p><p>Multiscale processing is achieved either by passing multiple rescaled versions of original images to parallel CNN branches (Image pyramid) and/or by using multiple parallel atrous convolutional layers with different sampling rates (ASPP).</p><p>Structured prediction is done by fully connected CRF. CRF is trained/tuned separately as a post processing step.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/deeplabv2.png" alt="DeepLab2 Pipeline"><br>DeepLab2 Pipeline. <a href="https://arxiv.org/abs/1606.00915" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>79.7</td><td>ResNet-101 + atrous Convolutions + ASPP + CRF</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&amp;challengeid=11&amp;compid=6&amp;submid=6103#KEY_DeepLabv2-CRF" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><h4 id="RefineNet"><a href="#RefineNet" class="headerlink" title="RefineNet"></a>RefineNet</h4><ul><li>RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation</li><li>Submitted on 20 Nov 2016</li><li><a href="https://arxiv.org/abs/1611.06612" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Encoder-Decoder architecture with well thought-out decoder blocks</li><li>All the components follow residual connection design</li></ul><p><em>Explanation</em>:</p><p>Approach of using dilated/atrous convolutions are not without downsides. Dilated convolutions are computationally expensive and take a lot of memory because they have to be applied on large number of high resolution feature maps. This hampers the computation of high-res predictions. <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLab‚Äôs</a> predictions, for example are 1/8th the size of original input.</p><p>So, the paper proposes to use encoder-decoder architecture. Encoder part is ResNet-101 blocks. Decoder has RefineNet blocks which concatenate/fuse high resolution features from encoder and low resolution features from previous RefineNet block.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/refinenet%20-%20architecture.png" alt="RefineNet Architecture"><br>RefineNet Architecture. <a href="https://arxiv.org/abs/1611.06612" target="_blank" rel="external">Source</a>.</p><p>Each RefineNet block has a component to fuse the multi resolution features by upsampling the lower resolution features and a component to capture context based on repeated 5 x 5 <em>stride 1</em> pool layers. Each of these components employ the residual connection design following the identity map mindset.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/refinenet%20-%20block.png" alt="RefineNet Block"><br>RefineNet Block. <a href="https://arxiv.org/abs/1611.06612" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>84.2</td><td>Uses CRF, Multiscale inputs, COCO pretraining</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_Multipath-RefineNet" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><h4 id="PSPNet"><a href="#PSPNet" class="headerlink" title="PSPNet"></a>PSPNet</h4><ul><li>Pyramid Scene Parsing Network</li><li>Submitted on 4 Dec 2016</li><li><a href="https://arxiv.org/abs/1612.01105" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Propose pyramid pooling module to aggregate the context.</li><li>Use auxiliary loss</li></ul><p><em>Explanation</em>:</p><p>Global scene categories matter because it provides clues on the distribution of the segmentation classes. Pyramid pooling module captures this information by applying large kernel pooling layers.</p><p>Dilated convolutions are used as in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated convolutions paper</a> to modify Resnet and a pyramid pooling module is added to it. This module concatenates the feature maps from ResNet with upsampled output of parallel pooling layers with kernels covering whole, half of and small portions of image.</p><p>An auxiliary loss, additional to the loss on main branch, is applied after the fourth stage of ResNet (i.e input to pyramid pooling module). This idea was also called as intermediate supervision elsewhere.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/pspnet.png" alt="PSPNet Architecture"><br>PSPNet Architecture. <a href="https://arxiv.org/abs/1612.01105" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>85.4</td><td>MSCOCO pretraining, multi scale input, no CRF</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_PSPNet" target="_blank" rel="external">leaderboard</a></td></tr><tr><td>82.6</td><td>no MSCOCO pretraining, multi scale input, no CRF</td><td>reported in the paper</td></tr></tbody></table><h4 id="Large-Kernel-Matters"><a href="#Large-Kernel-Matters" class="headerlink" title="Large Kernel Matters"></a>Large Kernel Matters</h4><ul><li>Large Kernel Matters ‚Äì Improve Semantic Segmentation by Global Convolutional Network</li><li>Submitted on 8 Mar 2017</li><li><a href="https://arxiv.org/abs/1703.02719" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Propose a encoder-decoder architecture with very large kernels convolutions</li></ul><p><em>Explanation</em>:</p><p>Semantic segmentation requires both segmentation and classification of the segmented objects. Since fully connected layers cannot be present in a segmentation architecture, convolutions with very large kernels are adopted instead.</p><p>Another reason to adopt large kernels is that although deeper networks like ResNet have very large receptive field, <a href="https://arxiv.org/abs/1412.6856" target="_blank" rel="external">studies</a> show that the network tends to gather information from a much smaller region (valid receptive filed).</p><p>Larger kernels are computationally expensive and have a lot of parameters. Therefore, k x k convolution is approximated with sum of 1 x k + k x 1 and k x 1 and 1 x k convolutions. This module is called as <em>Global Convolutional Network</em> (GCN) in the paper.</p><p>Coming to architecture, ResNet(without any dilated convolutions) forms encoder part of the architecture while GCNs and deconvolutions form decoder. A simple residual block called <em>Boundary Refinement</em> (BR) is also used.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/large_kernel_matter.png" alt="GCN Architecture"><br>GCN Architecture. <a href="https://arxiv.org/abs/1703.02719" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>82.2</td><td>-</td><td>reported in the paper</td></tr><tr><td>83.6</td><td>Improved training, not described in the paper</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_Large_Kernel_Matters" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><h4 id="DeepLab-v3"><a href="#DeepLab-v3" class="headerlink" title="DeepLab v3"></a>DeepLab v3</h4><ul><li>Rethinking Atrous Convolution for Semantic Image Segmentation</li><li>Submitted on 17 Jun 2017</li><li><a href="https://arxiv.org/abs/1706.05587" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Improved atrous spatial pyramid pooling (ASPP)</li><li>Module which employ atrous convolutions in cascade</li></ul><p><em>Explanation</em>:</p><p>ResNet model is modified to use dilated/atrous convolutions as in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLabv2</a> and <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated convolutions</a>. Improved ASPP involves concatenation of image-level features, a 1x1 convolution and three 3x3 atrous convolutions with different rates. Batch normalization is used after each of the parallel convolutional layers.</p><p>Cascaded module is a resnet block except that component convolution layers are made atrous with different rates. This module is similar to context module used in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated convolutions paper</a> but this is applied directly on intermediate feature maps instead of belief maps (belief maps are final CNN feature maps with channels equal to number of classes).</p><p>Both the proposed models are evaluated independently and attempt to combine the both did not improve the performance. Both of them performed very similarly on val set with ASPP performing slightly better. CRF is not used.</p><p>Both these models outperform the best model from <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLabv2</a>. Authors note that the improvement comes from the batch normalization and better way to encode multi scale context.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/deeplabv3.png" alt="DeepLabv3 ASPP"><br>DeepLabv3 ASPP (used for submission). <a href="https://arxiv.org/abs/1706.05587" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>85.7</td><td>used ASPP (no cascaded modules)</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_DeepLabv3" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><p>Reblog from <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#sec-2" target="_blank" rel="external">here</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;What-exactly-is-semantic-segmentation&quot;&gt;&lt;a href=&quot;#What-exactly-is-semantic-segmentation&quot; class=&quot;headerlink&quot; title=&quot;What exactly is se
    
    </summary>
    
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="semantic segmentation" scheme="http://yoursite.com/tags/semantic-segmentation/"/>
    
  </entry>
  
  <entry>
    <title>A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN</title>
    <link href="http://yoursite.com/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/"/>
    <id>http://yoursite.com/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/</id>
    <published>2018-04-10T08:34:47.000Z</published>
    <updated>2018-04-10T12:05:59.651Z</updated>
    
    <content type="html"><![CDATA[<p>Ever since <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="external">Alex Krizhevsky, Geoff Hinton, and Ilya Sutskever won ImageNet in 2012</a>, Convolutional Neural Networks(CNNs) have become the gold standard for image classification. In fact, since then, CNNs have improved to the point where they now outperform humans on the ImageNet challenge!</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*bGTawFxQwzc5yV1_szDrwQ.png" alt="img"></p><p>CNNs now outperform humans on the ImageNet challenge. The y-axis in the above graph is the error rate on ImageNet.</p><p>While these results are impressive, image classification is far simpler than the complexity and diversity of true human visual understanding.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*8GVucX9yhnL21KCtcyFDRQ.png" alt="img"></p><p>An example of an image used in the classification challenge. Note how the image is well framed and has just one object.</p><p>In classification, there‚Äôs generally an image with a single object as the focus and the task is to say what that image is (see above). But when we look at the world around us, we carry out far more complex tasks.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*eJjj2TVUVZDiVSTcnzh7fA.png" alt="img"></p><p>Sights in real life are often composed of a multitude of different, overlapping objects, backgrounds, and actions.</p><p>We see complicated sights with multiple overlapping objects, and different backgrounds and we not only classify these different objects but also identify their boundaries, differences, and relations to one another!</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*NdwfHMrW3rpj5SW_VQtWVw.png" alt="img"></p><p>In image segmentation, our goal is to classify the different objects in the image, and identify their boundaries. Source: Mask R-CNN paper.</p><p>Can CNNs help us with such complex tasks? Namely, given a more complicated image, can we use CNNs to identify the different objects in the image, and their boundaries? As has been shown by Ross Girshick and his peers over the last few years, the answer is conclusively yes.</p><h4 id="Goals-of-this-Post"><a href="#Goals-of-this-Post" class="headerlink" title="Goals of this Post"></a>Goals of this Post</h4><p>Through this post, we‚Äôll cover the intuition behind some of the main techniques used in object detection and segmentation and see how they‚Äôve evolved from one implementation to the next. In particular, we‚Äôll cover R-CNN (Regional CNN), the original application of CNNs to this problem, along with its descendants Fast R-CNN, and Faster R-CNN. Finally, we‚Äôll cover Mask R-CNN, a paper released recently by Facebook Research that extends such object detection techniques to provide pixel level segmentation. Here are the papers referenced in this post:</p><ol><li>R-CNN: <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="external">https://arxiv.org/abs/1311.2524</a></li><li>Fast R-CNN: <a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="external">https://arxiv.org/abs/1504.08083</a></li><li>Faster R-CNN: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a></li><li>Mask R-CNN: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a></li></ol><hr><h4 id="2014-R-CNN-An-Early-Application-of-CNNs-to-Object-Detection"><a href="#2014-R-CNN-An-Early-Application-of-CNNs-to-Object-Detection" class="headerlink" title="2014: R-CNN - An Early Application of CNNs to Object Detection"></a>2014: R-CNN - An Early Application of CNNs to Object Detection</h4><p><img src="https://cdn-images-1.medium.com/max/1000/1*r9ELExnk1B1zHnRReDW9Ow.png" alt="img"></p><p>Object detection algorithms such as R-CNN take in an image and identify the locations and classifications of the main objects in the image. Source: <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="external">https://arxiv.org/abs/1311.2524</a>.</p><p>Inspired by the research of Hinton‚Äôs lab at the University of Toronto, a small team at UC Berkeley, led by Professor Jitendra Malik, asked themselves what today seems like an inevitable question:</p><blockquote><p>To what extent do [Krizhevsky et. al‚Äôs results] generalize to object detection?</p></blockquote><p>Object detection is the task of finding the different objects in an image and classifying them (as seen in the image above). The team, comprised of Ross Girshick (a name we‚Äôll see again), Jeff Donahue, and Trevor Darrel found that this problem can be solved with Krizhevsky‚Äôs results by testing on the PASCAL VOC Challenge, a popular object detection challenge akin to ImageNet. They write,</p><blockquote><p>This paper is the first to show that a CNN can lead to dramatically higher object detection performance on PASCAL VOC as compared to systems based on simpler HOG-like features.</p></blockquote><p>Let‚Äôs now take a moment to understand how their architecture, Regions With CNNs (R-CNN) works.</p><p><strong>Understanding R-CNN</strong></p><p>The goal of R-CNN is to take in an image, and correctly identify where the main objects (via a bounding box) in the image.</p><ul><li><strong>Inputs</strong>: Image</li><li><strong>Outputs</strong>: Bounding boxes + labels for each object in the image.</li></ul><p>But how do we find out where these bounding boxes are? R-CNN does what we might intuitively do as well - <strong>propose</strong> <strong>a bunch of boxes in the image and see if any of them actually correspond to an object</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*ZQ03Ib84bYioFKoho5HnKg.png" alt="img"></p><p>Selective Search looks through windows of multiple scales and looks for adjacent pixels that share textures, colors, or intensities. Image source: <a href="https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf" target="_blank" rel="external">https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf</a></p><p>R-CNN creates these bounding boxes, or region proposals, using a process called Selective Search which you can read about <a href="http://www.cs.cornell.edu/courses/cs7670/2014sp/slides/VisionSeminar14.pdf" target="_blank" rel="external">here</a>. At a high level, Selective Search (shown in the image above) looks at the image through windows of different sizes, and for each size tries to group together adjacent pixels by texture, color, or intensity to identify objects.</p><p><img src="https://cdn-images-1.medium.com/max/1000/0*Sdj6sKDRQyZpO6oH." alt="img"></p><p>After creating a set of region proposals, R-CNN passes the image through a modified version of AlexNet to determine whether or not it is a valid region. Source: <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="external">https://arxiv.org/abs/1311.2524</a>.</p><p>Once the proposals are created, R-CNN warps the region to a standard square size and passes it through to a modified version of AlexNet (the winning submission to ImageNet 2012 that inspired R-CNN), as shown above.</p><p>On the final layer of the CNN, R-CNN adds a Support Vector Machine (SVM) that simply classifies whether this is an object, and if so what object. This is step 4 in the image above.</p><p><strong>Improving the Bounding Boxes</strong></p><p>Now, having found the object in the box, can we tighten the box to fit the true dimensions of the object? We can, and this is the final step of R-CNN. R-CNN runs a simple linear regression on the region proposal to generate tighter bounding box coordinates to get our final result. Here are the inputs and outputs of this regression model:</p><ul><li><strong>Inputs</strong>: sub-regions of the image corresponding to objects.</li><li><strong>Outputs</strong>: New bounding box coordinates for the object in the sub-region.</li></ul><p>So, to summarize, R-CNN is just the following steps:</p><ol><li>Generate a set of proposals for bounding boxes.</li><li>Run the images in the bounding boxes through a pre-trained AlexNet and finally an SVM to see what object the image in the box is.</li><li>Run the box through a linear regression model to output tighter coordinates for the box once the object has been classified.</li></ol><hr><h4 id="2015-Fast-R-CNN-Speeding-up-and-Simplifying-R-CNN"><a href="#2015-Fast-R-CNN-Speeding-up-and-Simplifying-R-CNN" class="headerlink" title="2015: Fast R-CNN - Speeding up and Simplifying R-CNN"></a>2015: Fast R-CNN - Speeding up and Simplifying R-CNN</h4><p><img src="https://cdn-images-1.medium.com/max/1000/1*3xnXHBEAz6FGzb-EehXtkA.png" alt="img"></p><p>Ross Girshick wrote both R-CNN and Fast R-CNN. He continues to push the boundaries of Computer Vision at Facebook Research.</p><p>R-CNN works really well, but is really quite slow for a few simple reasons:</p><ol><li>It requires a forward pass of the CNN (AlexNet) for every single region proposal for every single image (that‚Äôs around 2000 forward passes per image!).</li><li>It has to train three different models separately - the CNN to generate image features, the classifier that predicts the class, and the regression model to tighten the bounding boxes. This makes the pipeline extremely hard to train.</li></ol><p>In 2015, Ross Girshick, the first author of R-CNN, solved both these problems, leading to the second algorithm in our short history - Fast R-CNN. Let‚Äôs now go over its main insights.</p><p><strong>Fast R-CNN Insight 1: RoI (Region of Interest) Pooling</strong></p><p>For the forward pass of the CNN, Girshick realized that for each image, a lot of proposed regions for the image invariably overlapped causing us to run the same CNN computation again and again (~2000 times!). His insight was simple‚Ää‚Äî‚Ää<strong>Why not run the CNN just once per image and then find a way to share that computation across the ~2000 proposals?</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/1*4K_Bq1AhAsTe9vlT0wsdXQ.png" alt="img"></p><p>In RoIPool, a full forward pass of the image is created and the conv features for each region of interest are extracted from the resulting forward pass. Source: Stanford‚Äôs CS231N slides by Fei Fei Li, Andrei Karpathy, and Justin Johnson.</p><p>This is exactly what Fast R-CNN does using a technique known as RoIPool (Region of Interest Pooling). At its core, RoIPool shares the forward pass of a CNN for an image across its subregions. In the image above, notice how the CNN features for each region are obtained by selecting a corresponding region from the CNN‚Äôs feature map. Then, the features in each region are pooled (usually using max pooling). So all it takes us is one pass of the original image as opposed to ~2000!</p><p><strong>Fast R-CNN Insight 2: Combine All Models into One Network</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/1*E_P1vAEbGT4HNYjqMtIz4g.png" alt="img"></p><p>Fast R-CNN combined the CNN, classifier, and bounding box regressor into one, single network. Source: <a href="https://www.slideshare.net/simplyinsimple/detection-52781995" target="_blank" rel="external">https://www.slideshare.net/simplyinsimple/detection-52781995</a>.</p><p>The second insight of Fast R-CNN is to jointly train the CNN, classifier, and bounding box regressor in a single model. Where earlier we had different models to extract image features (CNN), classify (SVM), and tighten bounding boxes (regressor), <strong>Fast R-CNN instead used a single network to compute all three.</strong></p><p>You can see how this was done in the image above. Fast R-CNN replaced the SVM classifier with a softmax layer on top of the CNN to output a classification. It also added a linear regression layer parallel to the softmax layer to output bounding box coordinates. In this way, all the outputs needed came from one single network! Here are the inputs and outputs to this overall model:</p><ul><li><strong>Inputs</strong>: Images with region proposals.</li><li><strong>Outputs</strong>: Object classifications of each region along with tighter bounding boxes.</li></ul><hr><h4 id="2016-Faster-R-CNN-Speeding-Up-Region-Proposal"><a href="#2016-Faster-R-CNN-Speeding-Up-Region-Proposal" class="headerlink" title="2016: Faster R-CNN - Speeding Up Region Proposal"></a>2016: Faster R-CNN - Speeding Up Region Proposal</h4><p>Even with all these advancements, there was still one remaining bottleneck in the Fast R-CNN process‚Ää‚Äî‚Ääthe region proposer. As we saw, the very first step to detecting the locations of objects is generating a bunch of potential bounding boxes or regions of interest to test. In Fast R-CNN, these proposals were created using <strong>Selective Search</strong>, a fairly slow process that was found to be the bottleneck of the overall process.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*xY9rmw06KZWQlNIPk6ItqA.png" alt="img"></p><p>Jian Sun, a principal researcher at Microsoft Research, led the team behind Faster R-CNN. Source: <a href="https://blogs.microsoft.com/next/2015/12/10/microsoft-researchers-win-imagenet-computer-vision-challenge/#sm.00017fqnl1bz6fqf11amuo0d9ttdp" target="_blank" rel="external">https://blogs.microsoft.com/next/2015/12/10/microsoft-researchers-win-imagenet-computer-vision-challenge/#sm.00017fqnl1bz6fqf11amuo0d9ttdp</a></p><p>In the middle 2015, a team at Microsoft Research composed of Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun, found a way to make the region proposal step almost cost free through an architecture they (creatively) named Faster R-CNN.</p><p>The insight of Faster R-CNN was that region proposals depended on features of the image that were already calculated with the forward pass of the CNN (first step of classification). <strong>So why not reuse those same CNN results for region proposals instead of running a separate selective search algorithm?</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/0*_nNI03ESXm2P6YXO." alt="img"></p><p>In Faster R-CNN, a single CNN is used for region proposals, and classifications. Source: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a>.</p><p>Indeed, this is just what the Faster R-CNN team achieved. In the image above, you can see how a single CNN is used to both carry out region proposals and classification. This way, <strong>only one CNN needs to be trained</strong> and we get region proposals almost for free! The authors write:</p><blockquote><p>Our observation is that the convolutional feature maps used by region-based detectors, like Fast R- CNN, can also be used for generating region proposals [thus enabling nearly cost-free region proposals].</p></blockquote><p>Here are the inputs and outputs of their model:</p><ul><li><strong>Inputs</strong>: Images (Notice how region proposals are not needed).</li><li><strong>Outputs</strong>: Classifications and bounding box coordinates of objects in the images.</li></ul><p><strong>How the Regions are Generated</strong></p><p>Let‚Äôs take a moment to see how Faster R-CNN generates these region proposals from CNN features. Faster R-CNN adds a Fully Convolutional Network on top of the features of the CNN creating what‚Äôs known as the <strong>Region Proposal Network</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/0*n6pZEyvW47nlcdQz." alt="img"></p><p>The Region Proposal Network slides a window over the features of the CNN. At each window location, the network outputs a score and a bounding box per anchor (hence 4k box coordinates where k is the number of anchors). Source: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a>.</p><p>The Region Proposal Network works by passing a sliding window over the CNN feature map and at each window, outputting <strong>k </strong>potential bounding boxes and scores for how good each of those boxes is expected to be. What do these <strong>k </strong>boxes represent?</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*pJ3OTVXjtp9vWfBOPsnWIw.png" alt="img"></p><p>We know that the bounding boxes for people tend to be rectangular and vertical. We can use this intuition to guide our Region Proposal networks through creating an anchor of such dimensions. Image Source: <a href="http://vlm1.uta.edu/~athitsos/courses/cse6367_spring2011/assignments/assignment1/bbox0062.jpg" target="_blank" rel="external">http://vlm1.uta.edu/~athitsos/courses/cse6367_spring2011/assignments/assignment1/bbox0062.jpg</a>.</p><p>Intuitively, we know that objects in an image should fit certain common aspect ratios and sizes. For instance, we know that we want some rectangular boxes that resemble the shapes of humans. Likewise, we know we won‚Äôt see many boxes that are very very thin. In such a way, we create <strong>k</strong> such common aspect ratios we call <strong>anchor boxes</strong>. For each such anchor box, we output one bounding box and score per position in the image.</p><p>With these anchor boxes in mind, let‚Äôs take a look at the inputs and outputs to this Region Proposal Network:</p><ul><li><strong>Inputs</strong>: CNN Feature Map.</li><li><strong>Outputs</strong>: A bounding box per anchor. A score representing how likely the image in that bounding box will be an object.</li></ul><p>We then pass each such bounding box that is likely to be an object into Fast R-CNN to generate a classification and tightened bounding boxes.</p><hr><h4 id="2017-Mask-R-CNN-Extending-Faster-R-CNN-for-Pixel-Level-Segmentation"><a href="#2017-Mask-R-CNN-Extending-Faster-R-CNN-for-Pixel-Level-Segmentation" class="headerlink" title="2017: Mask R-CNN - Extending Faster R-CNN for Pixel Level Segmentation"></a>2017: Mask R-CNN - Extending Faster R-CNN for Pixel Level Segmentation</h4><p><img src="https://cdn-images-1.medium.com/max/1000/1*E_5qBTrotLzclyaxsekBmQ.png" alt="img"></p><p>The goal of image instance segmentation is to identify, at a pixel level, what the different objets in a scene are. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><p>So far, we‚Äôve seen how we‚Äôve been able to use CNN features in many interesting ways to effectively locate different objects in an image with bounding boxes.</p><p>Can we extend such techniques to go one step further and locate exact pixels of each object instead of just bounding boxes? This problem, known as image segmentation, is what Kaiming He and a team of researchers, including Girshick, explored at Facebook AI using an architecture known as <strong>Mask R-CNN</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*cYW3EdKx75Stl1EreATdfw.png" alt="img"></p><p>Kaiming He, a researcher at Facebook AI, is lead author of Mask R-CNN and also a coauthor of Faster R-CNN.</p><p>Much like Fast R-CNN, and Faster R-CNN, Mask R-CNN‚Äôs underlying intuition is straight forward. Given that Faster R-CNN works so well for object detection, could we extend it to also carry out pixel level segmentation?</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*BiRpf-ogjxARQf5LxI17Jw.png" alt="img"></p><p>In Mask R-CNN, a Fully Convolutional Network (FCN) is added on top of the CNN features of Faster R-CNN to generate a mask (segmentation output). Notice how this is in parallel to the classification and bounding box regression network of Faster R-CNN. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><p>Mask R-CNN does this by adding a branch to Faster R-CNN that outputs a binary mask that says whether or not a given pixel is part of an object. The branch (in white in the above image), as before, is just a Fully Convolutional Network on top of a CNN based feature map. Here are its inputs and outputs:</p><ul><li><strong>Inputs</strong>: CNN Feature Map.</li><li><strong>Outputs</strong>: Matrix with 1s on all locations where the pixel belongs to the object and 0s elsewhere (this is known as a <a href="https://en.wikipedia.org/wiki/Mask_%28computing%29" target="_blank" rel="external">binary mask</a>).</li></ul><p>But the Mask R-CNN authors had to make one small adjustment to make this pipeline work as expected.</p><p><strong>RoiAlign - Realigning RoIPool to be More Accurate</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/0*KtaZfpUErYqwH4RX." alt="img"></p><p>Instead of RoIPool, the image gets passed through RoIAlign so that the regions of the feature map selected by RoIPool correspond more precisely to the regions of the original image. This is needed because pixel level segmentation requires more fine-grained alignment than bounding boxes. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><p>When run without modifications on the original Faster R-CNN architecture, the Mask R-CNN authors realized that the regions of the feature map selected by RoIPool were slightly misaligned from the regions of the original image. Since image segmentation requires pixel level specificity, unlike bounding boxes, this naturally led to inaccuracies.</p><p>The authors were able to solve this problem by cleverly adjusting RoIPool to be more precisely aligned using a method known as RoIAlign.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*VDGql5VDbLWU3jOhRmzwFQ.jpeg" alt="img"></p><p>How do we accurately map a region of interest from the original image onto the feature map?</p><p>Imagine we have an image of size <strong>128x128</strong> and a feature map of size <strong>25x25</strong>. Let‚Äôs imagine we want features the region corresponding to the top-left <strong>15x15</strong>pixels in the original image (see above). How might we select these pixels from the feature map?</p><p>We know each pixel in the original image corresponds to ~ 25/128 pixels in the feature map. To select 15 pixels from the original image, we just select 15 <em>25/128 ~= <em>*2.93</em></em> pixels.</p><p>In RoIPool, we would round this down and select 2 pixels causing a slight misalignment. However, in RoIAlign, <strong>we avoid such rounding.</strong> Instead, we use <a href="https://en.wikipedia.org/wiki/Bilinear_interpolation" target="_blank" rel="external">bilinear interpolation</a> to get a precise idea of what would be at pixel 2.93. This, at a high level, is what allows us to avoid the misalignments caused by RoIPool.</p><p>Once these masks are generated, Mask R-CNN combines them with the classifications and bounding boxes from Faster R-CNN to generate such wonderfully precise segmentations:</p><p><img src="https://cdn-images-1.medium.com/max/1250/1*6CClgIKH8zhZjmcftfNoEQ.png" alt="img"></p><p>Mask R-CNN is able to segment as well as classify the objects in an image. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><hr><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>If you‚Äôre interested in trying out these algorithms yourselves, here are relevant repositories:</p><p><strong>Faster R-CNN</strong></p><ul><li>Caffe: <a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="external">https://github.com/rbgirshick/py-faster-rcnn</a></li><li>PyTorch: <a href="https://github.com/longcw/faster_rcnn_pytorch" target="_blank" rel="external">https://github.com/longcw/faster_rcnn_pytorch</a></li><li>MatLab: <a href="https://github.com/ShaoqingRen/faster_rcnn" target="_blank" rel="external">https://github.com/ShaoqingRen/faster_rcnn</a></li></ul><p><strong>Mask R-CNN</strong></p><ul><li>PyTorch: <a href="https://github.com/felixgwu/mask_rcnn_pytorch" target="_blank" rel="external">https://github.com/felixgwu/mask_rcnn_pytorch</a></li><li>TensorFlow: <a href="https://github.com/CharlesShang/FastMaskRCNN" target="_blank" rel="external">https://github.com/CharlesShang/FastMaskRCNN</a></li></ul><p>Reblog from <a href="https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4" target="_blank" rel="external">here</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Ever since &lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks&quot; target=&quot;_blank&quot; re
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="Deep learning" scheme="http://yoursite.com/tags/Deep-learning/"/>
    
      <category term="CNN" scheme="http://yoursite.com/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>Understanding nested list comprehension syntax in Python</title>
    <link href="http://yoursite.com/2018/03/27/Understanding-nested-list-comprehension-syntax-in-Python/"/>
    <id>http://yoursite.com/2018/03/27/Understanding-nested-list-comprehension-syntax-in-Python/</id>
    <published>2018-03-27T13:04:02.000Z</published>
    <updated>2018-03-27T13:06:48.955Z</updated>
    
    <content type="html"><![CDATA[<p>List comprehensions are one of the really nice and powerful features of Python. It is actually a smart way to introduce new users to functional programming concepts (after all a list comprehension is just a combination of map and filter) and compact statements.</p><p>However, one thing that always troubled me when using list comprehensions is their non intuitive syntax when nesting was needed. For example, let‚Äôs say that we just want to flatten a list of lists using a nested list comprehension:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">non_flat = [ [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>] ]</div></pre></td></tr></table></figure><p>To write that, somebody would think: For a simple list comprehension I need to write <code>[ x for x in non_flat ]</code> to get all its items - however I want to retrieve each element of the <code>x</code> list so I‚Äôll write something like this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>[y <span class="keyword">for</span> y <span class="keyword">in</span> x <span class="keyword">for</span> x <span class="keyword">in</span> non_flat]</div><div class="line">[<span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>]</div></pre></td></tr></table></figure><p>Well duh! At this time I‚Äôd need research google for a working list comprehension syntax and adjust it to my needs (or give up and write it as a double for loop).</p><p>Here‚Äôs the correct nested list comprehension people wondering:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>[y <span class="keyword">for</span> x <span class="keyword">in</span> non_flat <span class="keyword">for</span> y <span class="keyword">in</span> x]</div><div class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</div></pre></td></tr></table></figure><p>What if I wanted to add a third level of nesting or an if? Well I‚Äôd just bite the bullet and use for loops!</p><p>However, if you take a look at the document describing list comprehensions in python (PEP202) you‚Äôll see the following phrase:</p><blockquote><p>It is proposed to allow conditional construction of list literals using for and if clauses. <strong>They would nest in the same way for loops and if statements nest now.</strong></p></blockquote><p>This statement explains everything! <em>Just think in for-loops syntax</em>. So, If I used for loops for the previous flattening, I‚Äôd do something like:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> x <span class="keyword">in</span> non_flat:</div><div class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> x:</div><div class="line">        y</div></pre></td></tr></table></figure><p>which, if y is moved to the front and joined in one line would be the correct nested list comprehension!</p><p>So that‚Äôs the way‚Ä¶ What If I wanted to include only lists with more than 2 elements in the flattening (so [7,8] should not be included)? I‚Äôll write it with for loops first:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> x <span class="keyword">in</span> non_flat:</div><div class="line">    <span class="keyword">if</span> len(x) &gt; <span class="number">2</span></div><div class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> x:</div><div class="line">            y</div></pre></td></tr></table></figure><p>so by convering this to list comprehension we get:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>[ y <span class="keyword">for</span> x <span class="keyword">in</span> non_flat <span class="keyword">if</span> len(x) &gt; <span class="number">2</span> <span class="keyword">for</span> y <span class="keyword">in</span> x ]</div><div class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</div></pre></td></tr></table></figure><p>Success!</p><p>One final, more complex example: Let‚Äôs say that we have a list of lists of words and we want to get a list of all the letters of these words along with the index of the list they belong to but only for words with more than two characters. Using the same for-loop syntax for the nested list comprehensions we‚Äôll get:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>strings = [ [<span class="string">'foo'</span>, <span class="string">'bar'</span>], [<span class="string">'baz'</span>, <span class="string">'taz'</span>], [<span class="string">'w'</span>, <span class="string">'koko'</span>] ]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[ (letter, idx) <span class="keyword">for</span> idx, lst <span class="keyword">in</span> enumerate(strings) <span class="keyword">for</span> word <span class="keyword">in</span> lst <span class="keyword">if</span> len(word)&gt;<span class="number">2</span> <span class="keyword">for</span> letter <span class="keyword">in</span> word]</div><div class="line">[(<span class="string">'f'</span>, <span class="number">0</span>), (<span class="string">'o'</span>, <span class="number">0</span>), (<span class="string">'o'</span>, <span class="number">0</span>), (<span class="string">'b'</span>, <span class="number">0</span>), (<span class="string">'a'</span>, <span class="number">0</span>), (<span class="string">'r'</span>, <span class="number">0</span>), (<span class="string">'b'</span>, <span class="number">1</span>), (<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'z'</span>, <span class="number">1</span>), (<span class="string">'t'</span>, <span class="number">1</span>), (<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'z'</span>, <span class="number">1</span>), (<span class="string">'k'</span>, <span class="number">2</span>), (<span class="string">'o'</span>, <span class="number">2</span>), (<span class="string">'k'</span>, <span class="number">2</span>), (<span class="string">'o'</span>, <span class="number">2</span>)]</div></pre></td></tr></table></figure><hr><p>source blog is <a href="https://spapas.github.io/2016/04/27/python-nested-list-comprehensions/" target="_blank" rel="external">here</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;List comprehensions are one of the really nice and powerful features of Python. It is actually a smart way to introduce new users to func
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>PythonÂ§öÊ†∏ÁºñÁ®ãmpi4pyÂÆûË∑µ</title>
    <link href="http://yoursite.com/2018/03/19/Python%E5%A4%9A%E6%A0%B8%E7%BC%96%E7%A8%8Bmpi4py%E5%AE%9E%E8%B7%B5/"/>
    <id>http://yoursite.com/2018/03/19/PythonÂ§öÊ†∏ÁºñÁ®ãmpi4pyÂÆûË∑µ/</id>
    <published>2018-03-19T05:25:36.000Z</published>
    <updated>2018-03-19T05:39:28.570Z</updated>
    
    <content type="html"><![CDATA[<p>ËΩ¨ËΩΩËá™<a href="http://blog.csdn.net/ztf312/article/details/74997939" target="_blank" rel="external">ËøôÁØáÂçöÊñá</a>.</p><h1 id="Ê¶ÇËø∞"><a href="#Ê¶ÇËø∞" class="headerlink" title="Ê¶ÇËø∞"></a>Ê¶ÇËø∞</h1><p>‚Äã CPU‰ªé‰∏âÂçÅÂ§öÂπ¥ÂâçÁöÑ8086ÔºåÂà∞ÂçÅÂπ¥ÂâçÁöÑÂ•îËÖæÔºåÂÜçÂà∞ÂΩì‰∏ãÁöÑÂ§öÊ†∏i7„ÄÇ‰∏ÄÂºÄÂßãÔºå‰ª•ÂçïÊ†∏cpuÁöÑ‰∏ªÈ¢ë‰∏∫ÁõÆÊ†áÔºåÊû∂ÊûÑÁöÑÊîπËâØÂíåÈõÜÊàêÁîµË∑ØÂ∑•Ëâ∫ÁöÑËøõÊ≠•‰ΩøÂæócpuÁöÑÊÄßËÉΩÈ´òÈÄü‰∏äÂçáÔºåÂçïÊ†∏cpuÁöÑ‰∏ªÈ¢ë‰ªéËÄÅÁà∑ËΩ¶ÁöÑMHzÈò∂ÊÆµ‰∏ÄÂ∫¶Êé•Ëøë4GHzÈ´òÂú∞„ÄÇÁÑ∂ËÄåÔºå‰πüÂõ†‰∏∫Â∑•Ëâ∫ÂíåÂäüËÄóÁ≠âÁöÑÈôêÂà∂ÔºåÂçïÊ†∏cpuÈÅáÂà∞‰∫Ü‰∫∫ÁîüÁöÑÂ§©Ëä±ÊùøÔºåÊÄ•ÈúÄËΩ¨Êç¢ÊÄùÁª¥Ôºå‰ª•Êª°Ë∂≥Êó†Ê≠¢Â¢ÉÁöÑÊÄßËÉΩÈúÄÊ±Ç„ÄÇÂ§öÊ†∏cpuÂú®Ê≠§Áôª‰∏äÂéÜÂè≤ËàûÂè∞„ÄÇÁªô‰Ω†ÁöÑËÄÅÁà∑ËΩ¶Â§öÂä†‰∏§‰∏™ÂºïÊìéÔºåËÆ©‰Ω†ÊúâÊ≥ïÊãâÂà©ÁöÑÊÑüËßâ„ÄÇÁé∞Êó∂‰ª£ÔºåËøûÊâãÊú∫ÈÉΩÂà∞Â§ÑÂè´Âö£Ëá™Â∑±Êúâ4Ê†∏8Ê†∏Â§ÑÁêÜÂô®ÁöÑÊó∂‰ª£ÔºåPCÂ∞±Êõ¥‰∏çÁî®ËØ¥‰∫Ü„ÄÇ</p><p>‚Äã ÊâØËøú‰∫ÜÔºåanywayÔºåÂØπ‰∫é‰ø∫‰ª¨Á®ãÂ∫èÂëòÊù•ËØ¥ÔºåÂ¶Ç‰ΩïÂà©Áî®Â¶ÇÊ≠§Âº∫Â§ßÁöÑÂºïÊìéÂÆåÊàêÊàë‰ª¨ÁöÑ‰ªªÂä°ÊâçÊòØÊàë‰ª¨Ë¶ÅËÄÉËôëÁöÑ„ÄÇÈöèÁùÄÂ§ßËßÑÊ®°Êï∞ÊçÆÂ§ÑÁêÜ„ÄÅÂ§ßËßÑÊ®°ÈóÆÈ¢òÂíåÂ§çÊùÇÁ≥ªÁªüÊ±ÇËß£ÈúÄÊ±ÇÁöÑÂ¢ûÂä†Ôºå‰ª•ÂâçÁöÑÂçïÊ†∏ÁºñÁ®ãÂ∑≤ÁªèÊúâÂøÉÊó†Âäõ‰∫Ü„ÄÇÂ¶ÇÊûúÁ®ãÂ∫è‰∏ÄË∑ëÂ∞±ÂæóÂá†‰∏™Â∞èÊó∂ÔºåÁîöËá≥‰∏ÄÂ§©ÔºåÊÉ≥ÊÉ≥ÈÉΩÊó†Ê≥ïÂéüË∞ÖËá™Â∑±„ÄÇÈÇ£Â¶Ç‰ΩïËÆ©Ëá™Â∑±Êõ¥Âø´ÁöÑËøáÂ∫¶Âà∞È´òÂ§ß‰∏äÁöÑÂ§öÊ†∏Âπ∂Ë°åÁºñÁ®ã‰∏≠ÂéªÂë¢ÔºüÂìàÂìàÔºåÂπøÂ§ß‰∫∫Ê∞ëÁöÑÂäõÈáèÔºÅ</p><p>‚Äã ÁõÆÂâçÂ∑•‰Ωú‰∏≠ÊàëÊâÄÊé•Ëß¶Âà∞ÁöÑÂπ∂Ë°åÂ§ÑÁêÜÊ°ÜÊû∂‰∏ªË¶ÅÊúâMPI„ÄÅOpenMPÂíåMapReduce(Hadoop)‰∏â‰∏™ÔºàCUDAÂ±û‰∫éGPUÂπ∂Ë°åÁºñÁ®ãÔºåËøôÈáå‰∏çÊèêÂèäÔºâ„ÄÇMPIÂíåHadoopÈÉΩÂèØ‰ª•Âú®ÈõÜÁæ§‰∏≠ËøêË°åÔºåËÄåOpenMPÂõ†‰∏∫ÂÖ±‰∫´Â≠òÂÇ®ÁªìÊûÑÁöÑÂÖ≥Á≥ªÔºå‰∏çËÉΩÂú®ÈõÜÁæ§‰∏äËøêË°åÔºåÂè™ËÉΩÂçïÊú∫„ÄÇÂè¶Â§ñÔºåMPIÂèØ‰ª•ËÆ©Êï∞ÊçÆ‰øùÁïôÂú®ÂÜÖÂ≠ò‰∏≠ÔºåÂèØ‰ª•‰∏∫ËäÇÁÇπÈó¥ÁöÑÈÄö‰ø°ÂíåÊï∞ÊçÆ‰∫§‰∫í‰øùÂ≠ò‰∏ä‰∏ãÊñáÔºåÊâÄ‰ª•ËÉΩÊâßË°åËø≠‰ª£ÁÆóÊ≥ïÔºåËÄåHadoopÂç¥‰∏çÂÖ∑ÊúâËøô‰∏™ÁâπÊÄß„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶ÅËø≠‰ª£ÁöÑÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ïÂ§ßÂ§ö‰ΩøÁî®MPIÊù•ÂÆûÁé∞„ÄÇÂΩìÁÑ∂‰∫ÜÔºåÈÉ®ÂàÜÊú∫Âô®Â≠¶‰π†ÁÆóÊ≥ï‰πüÊòØÂèØ‰ª•ÈÄöËøáËÆæËÆ°‰ΩøÁî®HadoopÊù•ÂÆåÊàêÁöÑ„ÄÇÔºàÊµÖËßÅÔºåÂ¶ÇÊûúÈîôËØØÔºåÂ∏åÊúõÂêÑ‰Ωç‰∏çÂêùÊåáÂá∫ÔºåË∞¢Ë∞¢Ôºâ„ÄÇ</p><p>‚Äã Êú¨Êñá‰∏ªË¶Å‰ªãÁªçPythonÁéØÂ¢É‰∏ãMPIÁºñÁ®ãÁöÑÂÆûË∑µÂü∫Á°Ä„ÄÇ</p><h1 id="MPI‰∏émpi4py"><a href="#MPI‰∏émpi4py" class="headerlink" title="MPI‰∏émpi4py"></a>MPI‰∏émpi4py</h1><p>‚Äã MPIÊòØMessage Passing InterfaceÁöÑÁÆÄÁß∞Ôºå‰πüÂ∞±ÊòØÊ∂àÊÅØ‰º†ÈÄí„ÄÇÊ∂àÊÅØ‰º†ÈÄíÊåáÁöÑÊòØÂπ∂Ë°åÊâßË°åÁöÑÂêÑ‰∏™ËøõÁ®ãÂÖ∑ÊúâËá™Â∑±Áã¨Á´ãÁöÑÂ†ÜÊ†àÂíå‰ª£Á†ÅÊÆµÔºå‰Ωú‰∏∫‰∫í‰∏çÁõ∏ÂÖ≥ÁöÑÂ§ö‰∏™Á®ãÂ∫èÁã¨Á´ãÊâßË°åÔºåËøõÁ®ã‰πãÈó¥ÁöÑ‰ø°ÊÅØ‰∫§‰∫íÂÆåÂÖ®ÈÄöËøáÊòæÁ§∫Âú∞Ë∞ÉÁî®ÈÄö‰ø°ÂáΩÊï∞Êù•ÂÆåÊàê„ÄÇ</p><p>‚Äã Mpi4pyÊòØÊûÑÂª∫Âú®mpi‰πã‰∏äÁöÑpythonÂ∫ìÔºå‰ΩøÂæópythonÁöÑÊï∞ÊçÆÁªìÊûÑÂèØ‰ª•Âú®ËøõÁ®ãÔºàÊàñËÄÖÂ§ö‰∏™cpuÔºâ‰πãÈó¥ËøõË°å‰º†ÈÄí„ÄÇ</p><h2 id="MPIÁöÑÂ∑•‰ΩúÊñπÂºè"><a href="#MPIÁöÑÂ∑•‰ΩúÊñπÂºè" class="headerlink" title="MPIÁöÑÂ∑•‰ΩúÊñπÂºè"></a>MPIÁöÑÂ∑•‰ΩúÊñπÂºè</h2><p>‚Äã ÂæàÁÆÄÂçïÔºåÂ∞±ÊòØ‰Ω†ÂêØÂä®‰∫Ü‰∏ÄÁªÑMPIËøõÁ®ãÔºåÊØè‰∏™ËøõÁ®ãÈÉΩÊòØÊâßË°åÂêåÊ†∑ÁöÑ‰ª£Á†ÅÔºÅÁÑ∂ÂêéÊØè‰∏™ËøõÁ®ãÈÉΩÊúâ‰∏Ä‰∏™IDÔºå‰πüÂ∞±ÊòØrankÊù•Ê†áËÆ∞ÊàëÊòØË∞Å„ÄÇ‰ªÄ‰πàÊÑèÊÄùÂë¢ÔºüÂÅáËÆæ‰∏Ä‰∏™CPUÊòØ‰Ω†ËØ∑ÁöÑ‰∏Ä‰∏™Â∑•‰∫∫ÔºåÂÖ±Êúâ10‰∏™Â∑•‰∫∫„ÄÇ‰Ω†Êúâ100ÂùóÁ†ñÂ§¥Ë¶ÅÊê¨ÔºåÁÑ∂ÂêéÂæàÂÖ¨Âπ≥ÔºåËÆ©ÊØè‰∏™Â∑•‰∫∫Êê¨10Âùó„ÄÇËøôÊó∂ÂÄôÔºå‰Ω†Êää‰ªªÂä°ÂÜôÂà∞‰∏Ä‰∏™‰ªªÂä°Âç°ÈáåÈù¢ÔºåËÆ©10‰∏™Â∑•‰∫∫ÈÉΩÊâßË°åËøô‰∏™‰ªªÂä°Âç°‰∏≠ÁöÑ‰ªªÂä°Ôºå‰πüÂ∞±ÊòØÊê¨Á†ñÔºÅËøô‰∏™‰ªªÂä°Âç°‰∏≠ÁöÑ‚ÄúÊê¨Á†ñ‚ÄùÂ∞±ÊòØ‰Ω†ÂÜôÁöÑ‰ª£Á†Å„ÄÇÁÑ∂Âêé10‰∏™CPUÊâßË°åÂêå‰∏ÄÊÆµ‰ª£Á†Å„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºå‰ª£Á†ÅÈáåÈù¢ÁöÑÊâÄÊúâÂèòÈáèÈÉΩÊòØÊØè‰∏™ËøõÁ®ãÁã¨ÊúâÁöÑÔºåËôΩÁÑ∂ÂêçÂ≠óÁõ∏Âêå„ÄÇ</p><p>‚Äã ‰æãÂ¶ÇÔºå‰∏Ä‰∏™ËÑöÊú¨test.pyÔºåÈáåÈù¢ÂåÖÂê´‰ª•‰∏ã‰ª£Á†ÅÔºö</p><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from mpi4py import MPI  </div><div class="line">print("hello world'')  </div><div class="line">print("my rank is: %d" %MPI.rank)</div></pre></td></tr></table></figure><p>‚Äã ÁÑ∂ÂêéÊàë‰ª¨Âú®ÂëΩ‰ª§Ë°åÈÄöËøá‰ª•‰∏ãÊñπÂºèËøêË°åÔºö</p><p>‚Äã <code>mpirun ‚Äìnp 5 python test.py</code></p><p>‚Äã <code>-np5</code> ÊåáÂÆöÂêØÂä®5‰∏™mpiËøõÁ®ãÊù•ÊâßË°åÂêéÈù¢ÁöÑÁ®ãÂ∫è„ÄÇÁõ∏ÂΩì‰∫éÂØπËÑöÊú¨Êã∑Ë¥ù‰∫Ü5‰ªΩÔºåÊØè‰∏™ËøõÁ®ãËøêË°å‰∏Ä‰ªΩÔºå‰∫í‰∏çÂπ≤Êâ∞„ÄÇÂú®ËøêË°åÁöÑÊó∂ÂÄô‰ª£Á†ÅÈáåÈù¢ÂîØ‰∏ÄÁöÑ‰∏çÂêåÔºåÂ∞±ÊòØÂêÑËá™ÁöÑrank‰πüÂ∞±ÊòØID‰∏ç‰∏ÄÊ†∑„ÄÇÊâÄ‰ª•Ëøô‰∏™‰ª£Á†ÅÂ∞±‰ºöÊâìÂç∞5‰∏™hello worldÂíå5‰∏™‰∏çÂêåÁöÑrankÂÄºÔºå‰ªé0Âà∞4.</p><h2 id="ÁÇπÂØπÁÇπÈÄö‰ø°"><a href="#ÁÇπÂØπÁÇπÈÄö‰ø°" class="headerlink" title="ÁÇπÂØπÁÇπÈÄö‰ø°"></a>ÁÇπÂØπÁÇπÈÄö‰ø°</h2><p>‚Äã ÁÇπÂØπÁÇπÈÄö‰ø°ÔºàPoint-to-PointCommunicationÔºâÁöÑËÉΩÂäõÊòØ‰ø°ÊÅØ‰º†ÈÄíÁ≥ªÁªüÊúÄÂü∫Êú¨ÁöÑË¶ÅÊ±Ç„ÄÇÊÑèÊÄùÂ∞±ÊòØËÆ©‰∏§‰∏™ËøõÁ®ãÁõ¥Êé•ÂèØ‰ª•‰º†ËæìÊï∞ÊçÆÔºå‰πüÂ∞±ÊòØ‰∏Ä‰∏™ÂèëÈÄÅÊï∞ÊçÆÔºåÂè¶‰∏Ä‰∏™Êé•Êî∂Êï∞ÊçÆ„ÄÇÊé•Âè£Â∞±‰∏§‰∏™ÔºåsendÂíårecvÔºåÊù•‰∏™‰æãÂ≠êÔºö</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="comment"># point to point communication  </span></div><div class="line">data_send = [comm_rank]*<span class="number">5</span>  </div><div class="line">comm.send(data_send,dest=(comm_rank+<span class="number">1</span>)%comm_size)  </div><div class="line">data_recv =comm.recv(source=(comm_rank<span class="number">-1</span>)%comm_size)  </div><div class="line">print(<span class="string">"my rank is %d, and Ireceived:"</span> % comm_rank)  </div><div class="line"><span class="keyword">print</span> data_recv</div></pre></td></tr></table></figure><p>‚Äã ÂêØÂä®5‰∏™ËøõÁ®ãËøêË°å‰ª•‰∏ä‰ª£Á†ÅÔºåÁªìÊûúÂ¶Ç‰∏ãÔºö</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">my rank <span class="keyword">is</span> <span class="number">0</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]  </div><div class="line">my rank <span class="keyword">is</span> <span class="number">1</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]  </div><div class="line">my rank <span class="keyword">is</span> <span class="number">2</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]  </div><div class="line">my rank <span class="keyword">is</span> <span class="number">3</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]  </div><div class="line">my rank <span class="keyword">is</span> <span class="number">4</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]</div></pre></td></tr></table></figure><p>‚Äã ÂèØ‰ª•ÁúãÂà∞ÔºåÊØè‰∏™ËøõÁ®ãÈÉΩÂàõÂª∫‰∫Ü‰∏Ä‰∏™Êï∞ÁªÑÔºåÁÑ∂ÂêéÊääÂÆÉ‰º†ÈÄíÁªô‰∏ã‰∏Ä‰∏™ËøõÁ®ãÔºåÊúÄÂêéÁöÑÈÇ£‰∏™ËøõÁ®ã‰º†ÈÄíÁªôÁ¨¨‰∏Ä‰∏™ËøõÁ®ã„ÄÇ<code>comm_size</code>Â∞±ÊòØmpiÁöÑËøõÁ®ã‰∏™Êï∞Ôºå‰πüÂ∞±ÊòØ<code>-np</code>ÊåáÂÆöÁöÑÈÇ£‰∏™Êï∞„ÄÇ<code>MPI.COMM_WORLD</code>Ë°®Á§∫ËøõÁ®ãÊâÄÂú®ÁöÑÈÄö‰ø°ÁªÑ„ÄÇ</p><p>‚Äã ‰ΩÜËøôÈáåÈù¢Êúâ‰∏™ÈúÄË¶ÅÊ≥®ÊÑèÁöÑÈóÆÈ¢òÔºåÂ¶ÇÊûúÊàë‰ª¨Ë¶ÅÂèëÈÄÅÁöÑÊï∞ÊçÆÊØîËæÉÂ∞èÁöÑËØùÔºåmpi‰ºöÁºìÂ≠òÊàë‰ª¨ÁöÑÊï∞ÊçÆÔºå‰πüÂ∞±ÊòØËØ¥ÊâßË°åÂà∞<code>send</code>Ëøô‰∏™‰ª£Á†ÅÁöÑÊó∂ÂÄôÔºå‰ºöÁºìÂ≠òË¢´sendÁöÑÊï∞ÊçÆÔºåÁÑ∂ÂêéÁªßÁª≠ÊâßË°åÂêéÈù¢ÁöÑÊåá‰ª§ÔºåËÄå‰∏ç‰ºöÁ≠âÂæÖÂØπÊñπËøõÁ®ãÊâßË°å<code>recv</code>Êåá‰ª§Êé•Êî∂ÂÆåËøô‰∏™Êï∞ÊçÆ„ÄÇ‰ΩÜÊòØÔºåÂ¶ÇÊûúË¶ÅÂèëÈÄÅÁöÑÊï∞ÊçÆÂæàÂ§ßÔºåÈÇ£‰πàËøõÁ®ãÂ∞±ÊòØÊåÇËµ∑Á≠âÂæÖÔºåÁõ¥Âà∞Êé•Êî∂ËøõÁ®ãÊâßË°å‰∫Ü<code>recv</code>Êåá‰ª§Êé•Êî∂‰∫ÜËøô‰∏™Êï∞ÊçÆÔºåËøõÁ®ãÊâçÁªßÁª≠ÂæÄ‰∏ãÊâßË°å„ÄÇÊâÄ‰ª•‰∏äËø∞ÁöÑ‰ª£Á†ÅÂèëÈÄÅ[rank]<em>5Ê≤°Âï•ÈóÆÈ¢òÔºåÂ¶ÇÊûúÂèëÈÄÅ[rank]</em>500Á®ãÂ∫èÂ∞±‰ºöÂçäÊ≠ª‰∏çÊ¥ªÁöÑÊ†∑Â≠ê‰∫Ü„ÄÇÂõ†‰∏∫ÊâÄÊúâÁöÑËøõÁ®ãÈÉΩ‰ºöÂç°Âú®ÂèëÈÄÅËøôÊù°Êåá‰ª§ÔºåÁ≠âÂæÖ‰∏ã‰∏Ä‰∏™ËøõÁ®ãÂèëËµ∑Êé•Êî∂ÁöÑËøô‰∏™Êåá‰ª§Ôºå‰ΩÜÊòØËøõÁ®ãÊòØÊâßË°åÂÆåÂèëÈÄÅÁöÑÊåá‰ª§ÊâçËÉΩÊâßË°åÊé•Êî∂ÁöÑÊåá‰ª§ÔºåËøôÂ∞±ÂíåÊ≠ªÈîÅÂ∑Æ‰∏çÂ§ö‰∫Ü„ÄÇÊâÄ‰ª•‰∏ÄËà¨ÔºåÊàë‰ª¨Â∞ÜÂÖ∂‰øÆÊîπÊàê‰ª•‰∏ãÁöÑÊñπÂºèÔºö</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line">data_send = [comm_rank]*<span class="number">5</span>  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   comm.send(data_send, dest=(comm_rank+<span class="number">1</span>)%comm_size)  </div><div class="line"><span class="keyword">if</span> comm_rank &gt; <span class="number">0</span>:  </div><div class="line">   data_recv = comm.recv(source=(comm_rank<span class="number">-1</span>)%comm_size)  </div><div class="line">   comm.send(data_send, dest=(comm_rank+<span class="number">1</span>)%comm_size)  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data_recv = comm.recv(source=(comm_rank<span class="number">-1</span>)%comm_size)  </div><div class="line">print(<span class="string">"my rank is %d, and Ireceived:"</span> % comm_rank)  </div><div class="line"><span class="keyword">print</span> data_recv</div></pre></td></tr></table></figure><p>‚Äã Á¨¨‰∏Ä‰∏™ËøõÁ®ã‰∏ÄÂºÄÂßãÂ∞±ÂèëÈÄÅÊï∞ÊçÆÔºåÂÖ∂‰ªñËøõÁ®ã‰∏ÄÂºÄÂßãÈÉΩÊòØÂú®Á≠âÂæÖÊé•Êî∂Êï∞ÊçÆÔºåËøôÊó∂ÂÄôËøõÁ®ã1Êé•Êî∂‰∫ÜËøõÁ®ã0ÁöÑÊï∞ÊçÆÔºåÁÑ∂ÂêéÂèëÈÄÅËøõÁ®ã1ÁöÑÊï∞ÊçÆÔºåËøõÁ®ã2Êé•Êî∂‰∫ÜÔºåÂÜçÂèëÈÄÅËøõÁ®ã2ÁöÑÊï∞ÊçÆ‚Ä¶‚Ä¶Áü•ÈÅìÊúÄÂêéËøõÁ®ã0Êé•Êî∂ÊúÄÂêé‰∏Ä‰∏™ËøõÁ®ãÁöÑÊï∞ÊçÆÔºå‰ªéËÄåÈÅøÂÖç‰∫Ü‰∏äËø∞ÈóÆÈ¢ò„ÄÇ</p><p>‚Äã ‰∏Ä‰∏™ÊØîËæÉÂ∏∏Áî®ÁöÑÊñπÊ≥ïÊòØÂ∞Å‰∏Ä‰∏™ÁªÑÈïøÔºå‰πüÂ∞±ÊòØ‰∏Ä‰∏™‰∏ªËøõÁ®ãÔºå‰∏ÄËà¨ÊòØËøõÁ®ã0‰Ωú‰∏∫‰∏ªËøõÁ®ãleader„ÄÇ‰∏ªËøõÁ®ãÂ∞ÜÊï∞ÊçÆÂèëÈÄÅÁªôÂÖ∂‰ªñÁöÑËøõÁ®ãÔºåÂÖ∂‰ªñÁöÑËøõÁ®ãÂ§ÑÁêÜÊï∞ÊçÆÔºåÁÑ∂ÂêéËøîÂõûÁªìÊûúÁªôËøõÁ®ã0„ÄÇÊç¢Âè•ËØùËØ¥ÔºåÂ∞±ÊòØËøõÁ®ã0Êù•ÊéßÂà∂Êï¥‰∏™Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã„ÄÇ</p><h2 id="Áæ§‰ΩìÈÄö‰ø°"><a href="#Áæ§‰ΩìÈÄö‰ø°" class="headerlink" title="Áæ§‰ΩìÈÄö‰ø°"></a>Áæ§‰ΩìÈÄö‰ø°</h2><p>‚Äã ÁÇπÂØπÁÇπÈÄö‰ø°ÊòØAÂèëÈÄÅÁªôBÔºå‰∏Ä‰∏™‰∫∫Â∞ÜËá™Â∑±ÁöÑÁßòÂØÜÂëäËØâÂè¶‰∏Ä‰∏™‰∫∫ÔºåÁæ§‰ΩìÈÄö‰ø°ÔºàCollective CommunicationsÔºâÂÉèÊòØÊãø‰∏™Â§ßÂñáÂè≠Ôºå‰∏ÄÊ¨°ÊÄßÂëäËØâÊâÄÊúâÁöÑ‰∫∫„ÄÇÂâçËÄÖÊòØ‰∏ÄÂØπ‰∏ÄÔºåÂêéËÄÖÊòØ‰∏ÄÂØπÂ§ö„ÄÇ‰ΩÜÊòØÔºåÁæ§‰ΩìÈÄö‰ø°ÊòØ‰ª•Êõ¥ÊúâÊïàÁöÑÊñπÂºèÂ∑•‰ΩúÁöÑ„ÄÇÂÆÉÁöÑÂéüÂàôÂ∞±‰∏Ä‰∏™ÔºöÂ∞ΩÈáèÊääÊâÄÊúâÁöÑËøõÁ®ãÂú®ÊâÄÊúâÁöÑÊó∂ÂàªÈÉΩ‰ΩøÁî®‰∏äÔºÅÊàë‰ª¨Âú®‰∏ãÈù¢ÁöÑbcastÂ∞èËäÇËÆ≤Ëø∞„ÄÇ</p><p>‚Äã Áæ§‰ΩìÈÄö‰ø°ËøòÊòØÂèëÈÄÅÂíåÊé•Êî∂‰∏§Á±ªÔºå‰∏Ä‰∏™ÊòØ‰∏ÄÊ¨°ÊÄßÊääÊï∞ÊçÆÂèëÁªôÊâÄÊúâ‰∫∫ÔºåÂè¶‰∏Ä‰∏™ÊòØ‰∏ÄÊ¨°ÊÄß‰ªéÊâÄÊúâ‰∫∫ÈÇ£ÈáåÂõûÊî∂ÁªìÊûú„ÄÇ</p><h3 id="ÂπøÊí≠bcast"><a href="#ÂπøÊí≠bcast" class="headerlink" title="ÂπøÊí≠bcast"></a>ÂπøÊí≠bcast</h3><p>‚Äã Â∞Ü‰∏Ä‰ªΩÊï∞ÊçÆÂèëÈÄÅÁªôÊâÄÊúâÁöÑËøõÁ®ã„ÄÇ‰æãÂ¶ÇÊàëÊúâ200‰ªΩÊï∞ÊçÆÔºåÊúâ10‰∏™ËøõÁ®ãÔºåÈÇ£‰πàÊØè‰∏™ËøõÁ®ãÈÉΩ‰ºöÂæóÂà∞Ëøô200‰ªΩÊï∞ÊçÆ„ÄÇ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data = range(comm_size)  </div><div class="line">data = comm.bcast(data <span class="keyword">if</span> comm_rank == <span class="number">0</span><span class="keyword">else</span> <span class="keyword">None</span>, root=<span class="number">0</span>)  </div><div class="line"><span class="keyword">print</span> <span class="string">'rank %d, got:'</span> % (comm_rank)  </div><div class="line"><span class="keyword">print</span> data</div></pre></td></tr></table></figure><p>‚Äã ÁªìÊûúÂ¶Ç‰∏ãÔºö</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">rank <span class="number">0</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">1</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">2</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">3</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">4</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</div></pre></td></tr></table></figure><p>‚Äã RootËøõÁ®ãËá™Â∑±Âª∫‰∫Ü‰∏Ä‰∏™ÂàóË°®ÔºåÁÑ∂ÂêéÂπøÊí≠ÁªôÊâÄÊúâÁöÑËøõÁ®ã„ÄÇËøôÊ†∑ÊâÄÊúâÁöÑËøõÁ®ãÈÉΩÊã•Êúâ‰∫ÜËøô‰∏™ÂàóË°®„ÄÇÁÑ∂ÂêéÁà±Âπ≤ÂòõÂ∞±Âπ≤Âòõ‰∫Ü„ÄÇ</p><p>‚Äã ÂØπÂπøÊí≠ÊúÄÁõ¥ËßÇÁöÑËßÇÁÇπÊòØÊüê‰∏™ÁâπÂÆöËøõÁ®ãÂ∞ÜÊï∞ÊçÆ‰∏Ä‰∏ÄÂèëÈÄÅÁªôÊØè‰∏™ËøõÁ®ã„ÄÇÂÅáËÆæÊúân‰∏™ËøõÁ®ãÔºåÈÇ£‰πàÂÅáËÆæÊàë‰ª¨ÁöÑÊï∞ÊçÆÂú®0ËøõÁ®ãÔºåÈÇ£‰πà0ËøõÁ®ãÂ∞±ÈúÄË¶ÅÂ∞ÜÊï∞ÊçÆÂèëÈÄÅÁªôÂâ©‰∏ãÁöÑn-1‰∏™ËøõÁ®ãÔºåËøôÊòØÈùûÂ∏∏‰ΩéÊïàÁöÑÔºåÂ§çÊùÇÂ∫¶ÊòØO(n)„ÄÇÈÇ£ÊúâÊ≤°ÊúâÈ´òÊïàÁöÑÊñπÂºèÔºü‰∏Ä‰∏™ÊúÄÂ∏∏Áî®‰πüÊòØÈùûÂ∏∏È´òÊïàÁöÑÊâãÊÆµÊòØËßÑÁ∫¶Ê†ëÂπøÊí≠ÔºöÊî∂Âà∞ÂπøÊí≠Êï∞ÊçÆÁöÑÊâÄÊúâËøõÁ®ãÈÉΩÂèÇ‰∏éÂà∞Êï∞ÊçÆÂπøÊí≠ÁöÑËøáÁ®ã‰∏≠„ÄÇÈ¶ñÂÖàÂè™Êúâ‰∏Ä‰∏™ËøõÁ®ãÊúâÊï∞ÊçÆÔºåÁÑ∂ÂêéÂÆÉÊääÂÆÉÂèëÈÄÅÁªôÁ¨¨‰∏Ä‰∏™ËøõÁ®ãÔºåÊ≠§Êó∂Êúâ‰∏§‰∏™ËøõÁ®ãÊúâÊï∞ÊçÆÔºõÁÑ∂ÂêéËøô‰∏§‰∏™ËøõÁ®ãÈÉΩÂèÇ‰∏éÂà∞‰∏ã‰∏ÄÊ¨°ÁöÑÂπøÊí≠‰∏≠ÔºåËøôÊó∂Â∞±‰ºöÊúâ4‰∏™ËøõÁ®ãÊúâÊï∞ÊçÆÔºå‚Ä¶‚Ä¶Ôºå‰ª•Ê≠§Á±ªÊé®ÔºåÊØèÊ¨°ÈÉΩ‰ºöÊúâ2ÁöÑÊ¨°Êñπ‰∏™ËøõÁ®ãÊúâÊï∞ÊçÆ„ÄÇÈÄöËøáËøôÁßçËßÑÁ∫¶Ê†ëÁöÑÂπøÊí≠ÊñπÊ≥ïÔºåÂπøÊí≠ÁöÑÂ§çÊùÇÂ∫¶Èôç‰∏∫O(log n)„ÄÇËøôÂ∞±ÊòØ‰∏äÈù¢ËØ¥ÁöÑÁæ§‰ΩìÈÄö‰ø°ÁöÑÈ´òÊïàÂéüÂàôÔºöÂÖÖÂàÜÂà©Áî®ÊâÄÊúâÁöÑËøõÁ®ãÊù•ÂÆûÁé∞Êï∞ÊçÆÁöÑÂèëÈÄÅÂíåÊé•Êî∂„ÄÇ</p><h3 id="Êï£Êí≠scatter"><a href="#Êï£Êí≠scatter" class="headerlink" title="Êï£Êí≠scatter"></a>Êï£Êí≠scatter</h3><p>‚Äã Â∞Ü‰∏Ä‰ªΩÊï∞ÊçÆÂπ≥ÂàÜÁªôÊâÄÊúâÁöÑËøõÁ®ã„ÄÇ‰æãÂ¶ÇÊàëÊúâ200‰ªΩÊï∞ÊçÆÔºåÊúâ10‰∏™ËøõÁ®ãÔºåÈÇ£‰πàÊØè‰∏™ËøõÁ®ã‰ºöÂàÜÂà´ÂæóÂà∞20‰ªΩÊï∞ÊçÆ„ÄÇ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data = range(comm_size)  </div><div class="line">   <span class="keyword">print</span> data  </div><div class="line"><span class="keyword">else</span>:  </div><div class="line">   data = <span class="keyword">None</span>  </div><div class="line">local_data = comm.scatter(data, root=<span class="number">0</span>)  </div><div class="line"><span class="keyword">print</span> <span class="string">'rank %d, got:'</span> % comm_rank  </div><div class="line"><span class="keyword">print</span> local_data</div></pre></td></tr></table></figure><p>‚Äã ÁªìÊûúÂ¶Ç‰∏ãÔºö</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">0</span>, got:  </div><div class="line"><span class="number">0</span>  </div><div class="line">rank <span class="number">1</span>, got:  </div><div class="line"><span class="number">1</span>  </div><div class="line">rank <span class="number">2</span>, got:  </div><div class="line"><span class="number">2</span>  </div><div class="line">rank <span class="number">3</span>, got:  </div><div class="line"><span class="number">3</span>  </div><div class="line">rank <span class="number">4</span>, got:  </div><div class="line"><span class="number">4</span></div></pre></td></tr></table></figure><p>‚Äã ËøôÈáårootËøõÁ®ãÂàõÂª∫‰∫Ü‰∏Ä‰∏™listÔºåÁÑ∂ÂêéÂ∞ÜÂÆÉÊï£Êí≠ÁªôÊâÄÊúâÁöÑËøõÁ®ãÔºåÁõ∏ÂΩì‰∫éÂØπËøô‰∏™listÂÅö‰∫ÜÂàíÂàÜÔºåÊØè‰∏™ËøõÁ®ãËé∑ÂæóÁ≠âÂàÜÁöÑÊï∞ÊçÆÔºåËøôÈáåÂ∞±ÊòØlistÁöÑÊØè‰∏Ä‰∏™Êï∞„ÄÇÔºà‰∏ªË¶ÅÊ†πÊçÆlistÁöÑÁ¥¢ÂºïÊù•ÂàíÂàÜÔºålistÁ¥¢Âºï‰∏∫Á¨¨i‰ªΩÁöÑÊï∞ÊçÆÂ∞±ÂèëÈÄÅÁªôÁ¨¨i‰∏™ËøõÁ®ãÔºâ„ÄÇÂ¶ÇÊûúÊòØÁü©ÈòµÔºåÈÇ£‰πàÂ∞±Á≠âÂàÜÁöÑÂàíÂàÜË°åÔºåÊØè‰∏™ËøõÁ®ãËé∑ÂæóÁõ∏ÂêåÁöÑË°åÊï∞ËøõË°åÂ§ÑÁêÜ„ÄÇ</p><p>‚Äã ÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåMPIÁöÑÂ∑•‰ΩúÊñπÂºèÊòØÊØè‰∏™ËøõÁ®ãÈÉΩ‰ºöÊâßË°åÊâÄÊúâÁöÑ‰ª£Á†ÅÔºåÊâÄ‰ª•ÊØè‰∏™ËøõÁ®ãÈÉΩ‰ºöÊâßË°åscatterËøô‰∏™Êåá‰ª§Ôºå‰ΩÜÂè™ÊúârootÊâßË°åÂÆÉÁöÑÊó∂ÂÄôÔºåÂÆÉÊâçÂÖºÂ§áÂèëÈÄÅËÄÖÂíåÊé•Êî∂ËÄÖÁöÑË∫´‰ªΩÔºàroot‰πü‰ºöÂæóÂà∞Â±û‰∫éËá™Â∑±ÁöÑÊï∞ÊçÆÔºâÔºåÂØπ‰∫éÂÖ∂‰ªñËøõÁ®ãÊù•ËØ¥Ôºå‰ªñ‰ª¨ÈÉΩÂè™ÊòØÊé•Êî∂ËÄÖËÄåÂ∑≤„ÄÇ</p><h3 id="Êî∂ÈõÜgather"><a href="#Êî∂ÈõÜgather" class="headerlink" title="Êî∂ÈõÜgather"></a>Êî∂ÈõÜgather</h3><p>‚Äã ÈÇ£ÊúâÂèëÈÄÅÔºåÂ∞±Êúâ‰∏ÄËµ∑ÂõûÊî∂ÁöÑÂáΩÊï∞„ÄÇGatherÊòØÂ∞ÜÊâÄÊúâËøõÁ®ãÁöÑÊï∞ÊçÆÊî∂ÈõÜÂõûÊù•ÔºåÂêàÂπ∂Êàê‰∏Ä‰∏™ÂàóË°®„ÄÇ‰∏ãÈù¢ËÅîÂêàscatterÂíågatherÁªÑÊàê‰∏Ä‰∏™ÂÆåÊàêÁöÑÂàÜÂèëÂíåÊî∂ÂõûËøáÁ®ãÔºö</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data = range(comm_size)  </div><div class="line">   <span class="keyword">print</span> data  </div><div class="line"><span class="keyword">else</span>:  </div><div class="line">   data = <span class="keyword">None</span>  </div><div class="line">local_data = comm.scatter(data, root=<span class="number">0</span>)  </div><div class="line">local_data = local_data * <span class="number">2</span>  </div><div class="line"><span class="keyword">print</span> <span class="string">'rank %d, got and do:'</span> % comm_rank  </div><div class="line"><span class="keyword">print</span> local_data  </div><div class="line">combine_data = comm.gather(local_data,root=<span class="number">0</span>)  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">printcombine_data</div></pre></td></tr></table></figure><p>‚Äã ÁªìÊûúÂ¶Ç‰∏ãÔºö</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">0</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">0</span>  </div><div class="line">rank <span class="number">1</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">2</span>  </div><div class="line">rank <span class="number">2</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">4</span>  </div><div class="line">rank <span class="number">4</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">8</span>  </div><div class="line">rank <span class="number">3</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">6</span>  </div><div class="line">[<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]</div></pre></td></tr></table></figure><p>‚Äã RootËøõÁ®ãÂ∞ÜÊï∞ÊçÆÈÄöËøáscatterÁ≠âÂàÜÂèëÁªôÊâÄÊúâÁöÑËøõÁ®ãÔºåÁ≠âÂæÖÊâÄÊúâÁöÑËøõÁ®ãÈÉΩÂ§ÑÁêÜÂÆåÂêéÔºàËøôÈáåÂè™ÊòØÁÆÄÂçïÁöÑ‰πò‰ª•2ÔºâÔºårootËøõÁ®ãÂÜçÈÄöËøágatherÂõûÊî∂‰ªñ‰ª¨ÁöÑÁªìÊûúÔºåÂíåÂàÜÂèëÁöÑÂéüÂàô‰∏ÄÊ†∑ÔºåÁªÑÊàê‰∏Ä‰∏™list„ÄÇGatherËøòÊúâ‰∏Ä‰∏™Âèò‰ΩìÂ∞±ÊòØallgatherÔºåÂèØ‰ª•ÁêÜËß£‰∏∫ÂÆÉÂú®gatherÁöÑÂü∫Á°Ä‰∏äÂ∞ÜgatherÁöÑÁªìÊûúÂÜçbcast‰∫Ü‰∏ÄÊ¨°„ÄÇÂï•ÊÑèÊÄùÔºüÊÑèÊÄùÊòØrootËøõÁ®ãÂ∞ÜÊâÄÊúâËøõÁ®ãÁöÑÁªìÊûúÈÉΩÂõûÊî∂ÁªüËÆ°ÂÆåÂêéÔºåÂÜçÊääÊï¥‰∏™ÁªüËÆ°ÁªìÊûúÂëäËØâÂ§ßÂÆ∂„ÄÇËøôÊ†∑Ôºå‰∏ç‰ªÖrootÂèØ‰ª•ËÆøÈóÆcombine_dataÔºåÊâÄÊúâÁöÑËøõÁ®ãÈÉΩÂèØ‰ª•ËÆøÈóÆcombine_data‰∫Ü„ÄÇ</p><h3 id="ËßÑÁ∫¶reduce"><a href="#ËßÑÁ∫¶reduce" class="headerlink" title="ËßÑÁ∫¶reduce"></a>ËßÑÁ∫¶reduce</h3><p>‚Äã ËßÑÁ∫¶ÊòØÊåá‰∏ç‰ΩÜÂ∞ÜÊâÄÊúâÁöÑÊï∞ÊçÆÊî∂ÈõÜÂõûÊù•ÔºåÊî∂ÈõÜÂõûÊù•ÁöÑËøáÁ®ã‰∏≠ËøòËøõË°å‰∫ÜÁÆÄÂçïÁöÑËÆ°ÁÆóÔºå‰æãÂ¶ÇÊ±ÇÂíåÔºåÊ±ÇÊúÄÂ§ßÂÄºÁ≠âÁ≠â„ÄÇ‰∏∫‰ªÄ‰πàË¶ÅÊúâËøô‰∏™Âë¢ÔºüÊàë‰ª¨‰∏çÊòØÂèØ‰ª•Áõ¥Êé•Áî®gatherÂÖ®ÈÉ®Êî∂ÈõÜÂõûÊù•‰∫ÜÔºåÂÜçÂØπÂàóË°®Ê±Ç‰∏™sumÊàñËÄÖmaxÂ∞±ÂèØ‰ª•‰∫ÜÂêóÔºüËøôÊ†∑‰∏çÊòØÁ¥ØÊ≠ªÁªÑÈïøÂêóÔºü‰∏∫‰ªÄ‰πà‰∏çÂÖÖÂàÜ‰ΩøÁî®ÊØè‰∏™Â∑•‰∫∫Âë¢ÔºüËßÑÁ∫¶ÂÆûÈôÖ‰∏äÊòØ‰ΩøÁî®ËßÑÁ∫¶Ê†ëÊù•ÂÆûÁé∞ÁöÑ„ÄÇ‰æãÂ¶ÇÊ±ÇmaxÔºåÂÆåÊàêÂèØ‰ª•ËÆ©Â∑•‰∫∫‰∏§‰∏§pkÂêéÔºåÂÜçËøîÂõû‰∏§‰∏§pkÁöÑÊúÄÂ§ßÂÄºÔºåÁÑ∂ÂêéÂÜçÂØπÁ¨¨‰∫åÂ±ÇÁöÑÊúÄÂ§ßÂÄº‰∏§‰∏§pkÔºåÁõ¥Âà∞ËøîÂõû‰∏Ä‰∏™ÊúÄÁªàÁöÑmaxÁªôÁªÑÈïø„ÄÇÁªÑÈïøÂ∞±ÈùûÂ∏∏ËÅ™ÊòéÁöÑÂ∞ÜÂ∑•‰ΩúÂàÜÈÖç‰∏ãÂ∑•‰∫∫È´òÊïàÁöÑÂÆåÊàê‰∫Ü„ÄÇËøôÊòØO(n)ÁöÑÂ§çÊùÇÂ∫¶Ôºå‰∏ãÈôçÂà∞O(log n)ÔºàÂ∫ïÊï∞‰∏∫2ÔºâÁöÑÂ§çÊùÇÂ∫¶„ÄÇ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data = range(comm_size)  </div><div class="line">   <span class="keyword">print</span> data  </div><div class="line"><span class="keyword">else</span>:  </div><div class="line">   data = <span class="keyword">None</span>  </div><div class="line">local_data = comm.scatter(data, root=<span class="number">0</span>)  </div><div class="line">local_data = local_data * <span class="number">2</span>  </div><div class="line"><span class="keyword">print</span> <span class="string">'rank %d, got and do:'</span> % comm_rank  </div><div class="line"><span class="keyword">print</span> local_data  </div><div class="line">all_sum = comm.reduce(local_data, root=<span class="number">0</span>,op=MPI.SUM)  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line"><span class="keyword">print</span> <span class="string">'sumis:%d'</span> % all_sum</div></pre></td></tr></table></figure><p>‚Äã ÁªìÊûúÂ¶Ç‰∏ãÔºö</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">0</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">0</span>  </div><div class="line">rank <span class="number">1</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">2</span>  </div><div class="line">rank <span class="number">2</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">4</span>  </div><div class="line">rank <span class="number">3</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">6</span>  </div><div class="line">rank <span class="number">4</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">8</span>  </div><div class="line">sum <span class="keyword">is</span>:<span class="number">20</span></div></pre></td></tr></table></figure><p>‚Äã ÂèØ‰ª•ÁúãÂà∞ÔºåÊúÄÂêéÂèØ‰ª•ÂæóÂà∞‰∏Ä‰∏™sumÂÄº„ÄÇ</p><h1 id="Â∏∏ËßÅÁî®Ê≥ï"><a href="#Â∏∏ËßÅÁî®Ê≥ï" class="headerlink" title="Â∏∏ËßÅÁî®Ê≥ï"></a>Â∏∏ËßÅÁî®Ê≥ï</h1><h2 id="ÂØπ‰∏Ä‰∏™Êñá‰ª∂ÁöÑÂ§ö‰∏™Ë°åÂπ∂Ë°åÂ§ÑÁêÜ"><a href="#ÂØπ‰∏Ä‰∏™Êñá‰ª∂ÁöÑÂ§ö‰∏™Ë°åÂπ∂Ë°åÂ§ÑÁêÜ" class="headerlink" title="ÂØπ‰∏Ä‰∏™Êñá‰ª∂ÁöÑÂ§ö‰∏™Ë°åÂπ∂Ë°åÂ§ÑÁêÜ"></a>ÂØπ‰∏Ä‰∏™Êñá‰ª∂ÁöÑÂ§ö‰∏™Ë°åÂπ∂Ë°åÂ§ÑÁêÜ</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!usr/bin/env python  </span></div><div class="line"><span class="comment">#-*- coding: utf-8 -*-  </span></div><div class="line">   </div><div class="line"><span class="keyword">import</span> sys  </div><div class="line"><span class="keyword">import</span> os  </div><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </div><div class="line">   </div><div class="line">   </div><div class="line"><span class="comment">#  </span></div><div class="line"><span class="comment">#  Global variables for MPI  </span></div><div class="line"><span class="comment">#  </span></div><div class="line">   </div><div class="line"><span class="comment"># instance for invoking MPI relatedfunctions  </span></div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line"><span class="comment"># the node rank in the whole community  </span></div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line"><span class="comment"># the size of the whole community, i.e.,the total number of working nodes in the MPI cluster  </span></div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line">   </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:  </div><div class="line">   <span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">       sys.stderr.write(<span class="string">"processor root starts reading data...\n"</span>)  </div><div class="line">       all_lines = sys.stdin.readlines()  </div><div class="line">   all_lines = comm.bcast(all_lines <span class="keyword">if</span> comm_rank == <span class="number">0</span> <span class="keyword">else</span> <span class="keyword">None</span>, root = <span class="number">0</span>)  </div><div class="line">   num_lines = len(all_lines)  </div><div class="line">   local_lines_offset = np.linspace(<span class="number">0</span>, num_lines, comm_size +<span class="number">1</span>).astype(<span class="string">'int'</span>)  </div><div class="line">   local_lines = all_lines[local_lines_offset[comm_rank] :local_lines_offset[comm_rank + <span class="number">1</span>]]  </div><div class="line">   sys.stderr.write(<span class="string">"%d/%d processor gets %d/%d data \n"</span> %(comm_rank, comm_size, len(local_lines), num_lines))  </div><div class="line">   cnt = <span class="number">0</span>  </div><div class="line">   <span class="keyword">for</span> line <span class="keyword">in</span> local_lines:  </div><div class="line">       fields = line.strip().split(<span class="string">'\t'</span>)  </div><div class="line">       cnt += <span class="number">1</span>  </div><div class="line">       <span class="keyword">if</span> cnt % <span class="number">100</span> == <span class="number">0</span>:  </div><div class="line">           sys.stderr.write(<span class="string">"processor %d has processed %d/%d lines \n"</span> %(comm_rank, cnt, len(local_lines)))  </div><div class="line">       output = line.strip() + <span class="string">' process every line here'</span>  </div><div class="line">       <span class="keyword">print</span> output</div></pre></td></tr></table></figure><h2 id="ÂØπÂ§ö‰∏™Êñá‰ª∂Âπ∂Ë°åÂ§ÑÁêÜ"><a href="#ÂØπÂ§ö‰∏™Êñá‰ª∂Âπ∂Ë°åÂ§ÑÁêÜ" class="headerlink" title="ÂØπÂ§ö‰∏™Êñá‰ª∂Âπ∂Ë°åÂ§ÑÁêÜ"></a>ÂØπÂ§ö‰∏™Êñá‰ª∂Âπ∂Ë°åÂ§ÑÁêÜ</h2><p>‚Äã Â¶ÇÊûúÊàë‰ª¨ÁöÑÊñá‰ª∂Â§™Â§ßÔºå‰æãÂ¶ÇÂá†ÂçÉ‰∏áË°åÔºåÈÇ£‰πàmpiÊòØÊ≤°ÂäûÊ≥ïÂ∞ÜËøô‰πàÂ§ßÁöÑÊï∞ÊçÆbcastÁªôÊâÄÊúâÁöÑËøõÁ®ãÁöÑÔºåÊâÄ‰ª•Êàë‰ª¨ÂèØ‰ª•ÂÖàÊääÂ§ßÁöÑÊñá‰ª∂splitÊàêÂ∞èÁöÑÊñá‰ª∂ÔºåÂÜçËÆ©ÊØè‰∏™ËøõÁ®ãÂ§ÑÁêÜÂ∞ëÊï∞ÁöÑÊñá‰ª∂„ÄÇ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!usr/bin/env python  </span></div><div class="line"><span class="comment">#-*- coding: utf-8 -*-  </span></div><div class="line">   </div><div class="line"><span class="keyword">import</span> sys  </div><div class="line"><span class="keyword">import</span> os  </div><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </div><div class="line">   </div><div class="line"><span class="comment">#  </span></div><div class="line"><span class="comment">#  Global variables for MPI  </span></div><div class="line"><span class="comment">#  </span></div><div class="line">   </div><div class="line"><span class="comment"># instance for invoking MPI relatedfunctions  </span></div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line"><span class="comment"># the node rank in the whole community  </span></div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line"><span class="comment"># the size of the whole community, i.e.,the total number of working nodes in the MPI cluster  </span></div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line">   </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:  </div><div class="line">   <span class="keyword">if</span> len(sys.argv) != <span class="number">2</span>:  </div><div class="line">       sys.stderr.write(<span class="string">"Usage: python *.py directoty_with_files\n"</span>)  </div><div class="line">       sys.exit(<span class="number">1</span>)  </div><div class="line">   path = sys.argv[<span class="number">1</span>]  </div><div class="line">   <span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">       file_list = os.listdir(path)  </div><div class="line">       sys.stderr.write(<span class="string">"%d files\n"</span> % len(file_list))  </div><div class="line">   file_list = comm.bcast(file_list <span class="keyword">if</span> comm_rank == <span class="number">0</span> <span class="keyword">else</span> <span class="keyword">None</span>, root = <span class="number">0</span>)  </div><div class="line">   num_files = len(file_list)  </div><div class="line">   local_files_offset = np.linspace(<span class="number">0</span>, num_files, comm_size +<span class="number">1</span>).astype(<span class="string">'int'</span>)  </div><div class="line">   local_files = file_list[local_files_offset[comm_rank] :local_files_offset[comm_rank + <span class="number">1</span>]]  </div><div class="line">   sys.stderr.write(<span class="string">"%d/%d processor gets %d/%d data \n"</span> %(comm_rank, comm_size, len(local_files), num_files))  </div><div class="line">    cnt = <span class="number">0</span>  </div><div class="line">   <span class="keyword">for</span> file_name <span class="keyword">in</span> local_files:  </div><div class="line">       hd = open(os.path.join(path, file_name))  </div><div class="line">       <span class="keyword">for</span> line <span class="keyword">in</span> hd:  </div><div class="line">           output = line.strip() + <span class="string">' process every line here'</span>  </div><div class="line">           <span class="keyword">print</span> output  </div><div class="line">       cnt += <span class="number">1</span>  </div><div class="line">       sys.stderr.write(<span class="string">"processor %d has processed %d/%d files \n"</span> %(comm_rank, cnt, len(local_files)))  </div><div class="line">       hd.close()</div></pre></td></tr></table></figure><h2 id="ËÅîÂêànumpyÂØπÁü©ÈòµÁöÑÂ§ö‰∏™Ë°åÊàñËÄÖÂ§öÂàóÂπ∂Ë°åÂ§ÑÁêÜ"><a href="#ËÅîÂêànumpyÂØπÁü©ÈòµÁöÑÂ§ö‰∏™Ë°åÊàñËÄÖÂ§öÂàóÂπ∂Ë°åÂ§ÑÁêÜ" class="headerlink" title="ËÅîÂêànumpyÂØπÁü©ÈòµÁöÑÂ§ö‰∏™Ë°åÊàñËÄÖÂ§öÂàóÂπ∂Ë°åÂ§ÑÁêÜ"></a>ËÅîÂêànumpyÂØπÁü©ÈòµÁöÑÂ§ö‰∏™Ë°åÊàñËÄÖÂ§öÂàóÂπ∂Ë°åÂ§ÑÁêÜ</h2><p>‚Äã Mpi4py‰∏Ä‰∏™ÈùûÂ∏∏‰ºòÁßÄÁöÑÁâπÊÄßÊòØÂÆåÁæéÊîØÊåÅnumpyÔºÅ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os, sys, time  </div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </div><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">   </div><div class="line"><span class="comment">#  </span></div><div class="line"><span class="comment">#  Global variables for MPI  </span></div><div class="line"><span class="comment">#  </span></div><div class="line">   </div><div class="line">   </div><div class="line"><span class="comment"># instance for invoking MPI relatedfunctions  </span></div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line"><span class="comment"># the node rank in the whole community  </span></div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line"><span class="comment"># the size of the whole community, i.e.,the total number of working nodes in the MPI cluster  </span></div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="comment"># test MPI  </span></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:  </div><div class="line">    <span class="comment">#create a matrix  </span></div><div class="line">   <span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">       all_data = np.arange(<span class="number">20</span>).reshape(<span class="number">4</span>, <span class="number">5</span>)  </div><div class="line">       <span class="keyword">print</span> <span class="string">"************ data ******************"</span>  </div><div class="line">       <span class="keyword">print</span> all_data  </div><div class="line">     </div><div class="line">    <span class="comment">#broadcast the data to all processors  </span></div><div class="line">   all_data = comm.bcast(all_data <span class="keyword">if</span> comm_rank == <span class="number">0</span> <span class="keyword">else</span> <span class="keyword">None</span>, root = <span class="number">0</span>)  </div><div class="line">     </div><div class="line">    <span class="comment">#divide the data to each processor  </span></div><div class="line">   num_samples = all_data.shape[<span class="number">0</span>]  </div><div class="line">   local_data_offset = np.linspace(<span class="number">0</span>, num_samples, comm_size + <span class="number">1</span>).astype(<span class="string">'int'</span>)  </div><div class="line">     </div><div class="line">    <span class="comment">#get the local data which will be processed in this processor  </span></div><div class="line">   local_data = all_data[local_data_offset[comm_rank] :local_data_offset[comm_rank + <span class="number">1</span>]]  </div><div class="line">   <span class="keyword">print</span> <span class="string">"****** %d/%d processor gets local data ****"</span> %(comm_rank, comm_size)  </div><div class="line">   <span class="keyword">print</span> local_data  </div><div class="line">     </div><div class="line">    <span class="comment">#reduce to get sum of elements  </span></div><div class="line">   local_sum = local_data.sum()  </div><div class="line">   all_sum = comm.reduce(local_sum, root = <span class="number">0</span>, op = MPI.SUM)  </div><div class="line">     </div><div class="line">    <span class="comment">#process in local  </span></div><div class="line">   local_result = local_data ** <span class="number">2</span>  </div><div class="line">     </div><div class="line">    <span class="comment">#gather the result from all processors and broadcast it  </span></div><div class="line">   result = comm.allgather(local_result)  </div><div class="line">   result = np.vstack(result)  </div><div class="line">     </div><div class="line">   <span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">       <span class="keyword">print</span> <span class="string">"*** sum: "</span>, all_sum  </div><div class="line">       <span class="keyword">print</span> <span class="string">"************ result ******************"</span>  </div><div class="line">       <span class="keyword">print</span> result</div></pre></td></tr></table></figure><h1 id="MPIÂíåmpi4pyÁöÑÁéØÂ¢ÉÊê≠Âª∫"><a href="#MPIÂíåmpi4pyÁöÑÁéØÂ¢ÉÊê≠Âª∫" class="headerlink" title="MPIÂíåmpi4pyÁöÑÁéØÂ¢ÉÊê≠Âª∫"></a>MPIÂíåmpi4pyÁöÑÁéØÂ¢ÉÊê≠Âª∫</h1><p>‚Äã ËøôÁ´†ÊîæÂà∞ËøôÈáåÊòØ‰Ωú‰∏∫‰∏Ä‰∏™ÈôÑÂΩï„ÄÇÊàë‰ª¨ÁöÑÁéØÂ¢ÉÊòØlinuxÔºåÈúÄË¶ÅÂÆâË£ÖÁöÑÂåÖÊúâpython„ÄÅopenmpi„ÄÅnumpy„ÄÅcpythonÂíåmpi4pyÔºåËøáÁ®ãÂ¶Ç‰∏ãÔºö</p><h2 id="ÂÆâË£ÖPython"><a href="#ÂÆâË£ÖPython" class="headerlink" title="ÂÆâË£ÖPython"></a>ÂÆâË£ÖPython</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">tar xzvf Python-2.7.tgz  </div><div class="line">cd Python-2.7  </div><div class="line">./configure--prefix=/home/work/vis/zouxiaoyi/my_tools  </div><div class="line">make  </div><div class="line">make install</div></pre></td></tr></table></figure><p>‚Äã ÂÖàÂ∞ÜPythonÊîæÂà∞ÁéØÂ¢ÉÂèòÈáèÈáåÈù¢ÔºåËøòÊúâPythonÁöÑÊèí‰ª∂Â∫ì</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">exportPATH=/home/work/vis/zouxiaoyi/my_tools/bin:$PATH  </div><div class="line">exportLD_LIBRARY_PATH=/home/work/vis/zouxiaoyi/my_tools/lib:$LD_LIBRARY_PATH</div></pre></td></tr></table></figure><p>‚Äã ÊâßË°å<code>python</code>ÔºåÂ¶ÇÊûúÁúãÂà∞ÂèØÁà±ÁöÑ&gt;&gt;&gt;Âá∫Êù•ÔºåÂ∞±Ë°®Á§∫ÊàêÂäü‰∫Ü„ÄÇÊåâ<code>crtl+d</code>ÈÄÄÂá∫</p><h2 id="ÂÆâË£Öopenmpi"><a href="#ÂÆâË£Öopenmpi" class="headerlink" title="ÂÆâË£Öopenmpi"></a>ÂÆâË£Öopenmpi</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">wget http://www.open-mpi.org/software/ompi/v1.4/downloads/openmpi-1.4.1.tar.gz  </div><div class="line">tar xzvf openmpi-1.4.1.tar.gz  </div><div class="line">cd openmpi-1.4.1  </div><div class="line">./configure--prefix=/home/work/vis/zouxiaoyi/my_tools  </div><div class="line">make -j 8  </div><div class="line">make install</div></pre></td></tr></table></figure><p>‚Äã ÁÑ∂ÂêéÊääbinË∑ØÂæÑÂä†Âà∞ÁéØÂ¢ÉÂèòÈáèÈáåÈù¢Ôºö</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">exportPATH=/home/work/vis/zouxiaoyi/my_tools/bin:$PATH  </div><div class="line">exportLD_LIBRARY_PATH=/home/work/vis/zouxiaoyi/my_tools/lib:$LD_LIBRARY_PATH</div></pre></td></tr></table></figure><p>‚Äã ÊâßË°å<code>mpirun</code>ÔºåÂ¶ÇÊûúÊúâÂ∏ÆÂä©‰ø°ÊÅØÊâìÂç∞Âá∫Êù•ÔºåÂ∞±Ë°®Á§∫ÂÆâË£ÖÂ•Ω‰∫Ü„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÆâË£Ö‰∫ÜÂá†‰∏™ÁâàÊú¨ÈÉΩÊ≤°ÊúâÊàêÂäüÔºåÊúÄÂêéÂÆâË£Ö‰∫Ü1.4.1Ëøô‰∏™ÁâàÊú¨ÊâçËÉΩÊàêÂäüÔºåÂõ†Ê≠§Â∞±Áúã‰Ω†ÁöÑ‰∫∫ÂìÅ‰∫Ü„ÄÇ</p><h2 id="ÂÆâË£ÖnumpyÂíåCython"><a href="#ÂÆâË£ÖnumpyÂíåCython" class="headerlink" title="ÂÆâË£ÖnumpyÂíåCython"></a>ÂÆâË£ÖnumpyÂíåCython</h2><p>‚Äã ÂÆâË£ÖpythonÂ∫ìÁöÑÊñπÊ≥ïÂèØ‰ª•ÂèÇËÄÉ<a href="http://blog.csdn.net/zouxy09/article/details/48903179" target="_blank" rel="external">‰πãÂâçÁöÑÂçöÂÆ¢</a>„ÄÇËøáÁ®ã‰∏ÄËà¨Â¶Ç‰∏ãÔºö</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar ‚Äìxgvf Cython-0.20.2.tar.gz  </div><div class="line">cd Cython-0.20.2  </div><div class="line">python setup.py install</div></pre></td></tr></table></figure><p>‚Äã ÊâìÂºÄPythonÔºåimport CythonÔºåÂ¶ÇÊûúÊ≤°ÊúâÊä•ÈîôÔºåÂ∞±Ë°®Á§∫ÂÆâË£ÖÊàêÂäü‰∫Ü</p><h2 id="ÂÆâË£Ömpi4py"><a href="#ÂÆâË£Ömpi4py" class="headerlink" title="ÂÆâË£Ömpi4py"></a>ÂÆâË£Ömpi4py</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar ‚Äìxgvf mpi4py_1.3.1.tar.gz  </div><div class="line">cd mpi4py  </div><div class="line">vi mpi.cfg</div></pre></td></tr></table></figure><p>‚Äã Âú®68Ë°åÔºå<code>[openmpi]</code>‰∏ãÈù¢ÔºåÂ∞ÜÂàöÊâçÂ∑≤ÁªèÂÆâË£ÖÂ•ΩÁöÑopenmpiÁöÑÁõÆÂΩïÁªôÊîπ‰∏ä„ÄÇ</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mpi_dir = /home/work/vis/zouxiaoyi/my_tools  </div><div class="line">python setup.py install</div></pre></td></tr></table></figure><p>‚Äã ÊâìÂºÄPythonÔºå<code>import mpi4py as MPI</code>ÔºåÂ¶ÇÊûúÊ≤°ÊúâÊä•ÈîôÔºåÂ∞±Ë°®Á§∫ÂÆâË£ÖÊàêÂäü‰∫Ü</p><p>‚Äã ‰∏ãÈù¢Â∞±ÂèØ‰ª•ÂºÄÂßãÂ±û‰∫é‰Ω†ÁöÑÂπ∂Ë°å‰πãÊóÖ‰∫ÜÔºåÂãáÊï¢Êé¢Á¥¢Â§öÊ†∏ÁöÑ‰πêË∂£Âêß„ÄÇ</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ËΩ¨ËΩΩËá™&lt;a href=&quot;http://blog.csdn.net/ztf312/article/details/74997939&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ËøôÁØáÂçöÊñá&lt;/a&gt;.&lt;/p&gt;&lt;h1 id=&quot;Ê¶ÇËø∞&quot;&gt;&lt;a href=&quot;#Ê¶ÇËø∞&quot; c
    
    </summary>
    
    
  </entry>
  
</feed>
