<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Abracadabra</title>
  <subtitle>Do it yourself</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-07-04T02:36:15.327Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Ewan Li</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Temporal-Difference Learning</title>
    <link href="http://yoursite.com/2017/07/02/Temporal-Difference-Learning/"/>
    <id>http://yoursite.com/2017/07/02/Temporal-Difference-Learning/</id>
    <published>2017-07-02T04:44:00.000Z</published>
    <updated>2017-07-04T02:36:15.327Z</updated>
    
    <content type="html"><![CDATA[<p>If one had to identify one idea as central and novel to reinforcement learning, it would undoubtedly be <em>temporal-difference</em> (TD) learning. TD learning is a combination of Monte Carlo ideas and dynamic programming (DP) ideas. Like Monte Carlo methods, TD methods can learn directly from raw experience without a model of the environment’s dynamics. Like DP, TD methods update estimates based in part on other learned estimates, without waiting for a final outcome.</p><h3 id="TD-0"><a href="#TD-0" class="headerlink" title="TD(0)"></a><strong>TD(0)</strong></h3><p>Roughly speaking, Monte Carlo methods wait until the return following the visit is known, then use that return as a target for $V(S_t)$. A simple every-visit Monte Carlo method suitable for nonstationary environment is<br>$$<br>V(S_t) \leftarrow V(S_t) + \alpha [G_t - V(S_t)],<br>$$<br>where $G_t$ is the <strong>actual return</strong> following time $t$. Let us call this method $constant\text{-}\alpha \ MC$. Notice that, if we are in a stationary environment (like <a href="https://ewanlee.github.io/2017/06/02/Monte-Carlo-Methods-Reinforcement-Learning/" target="_blank" rel="external">earlier</a>. For some reason, don’t use incremental implementation), the $\alpha$ is equals to $\frac{1}{N(S_t)}$. whereas Monte Carlo methods must wait until the end of the episode to determine the increment to $V(S_t)$ (only then is $G_t$ known), TD methods need to wait only until the next time step. At time $t+1$ they immediately form a target and make a useful update using the observed reward $R_{t+1}$ and the estimate $V(S_{t+1})$. The simplest TD method makes the update<br>$$<br>V(S_t) \leftarrow V(S_t) + \alpha \left[ R_{t+1} + \gamma V(S_{t+1}) - V(S_t)\right]<br>$$<br>immediately on transition to $S_{t+1}$ and receiving $R_{t+1}$. In effect, the target for the Monte Carlo update is $G_t$, whereas the target for the TD update is $R_{t+1} + \gamma V(S_{t+1})$. This TD method is called $TD(0)$, or <strong>one-step</strong> TD. The box below specifies TD(0) completely in procedural form.</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/td_0.png" alt="td_0"></p><p>TD(0)’s backup diagram is as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/td0_bg.png" alt="td0bg"></p><p>Because the TD(0) bases its update in part on an existing estimate, we say that it is a <em>bootstrapping</em> method, like DP. We know that<br>$$<br>\begin{align}<br>v_{\pi}(s) &amp;\doteq \mathbb{E}_{\pi} [G_t \ | \ S_t=s] \\<br>&amp;= \mathbb{E}_{\pi} [R_{t+1} + \gamma G_{t+1} \ | \ S_t=s] \\<br>&amp;= \mathbb{E}_{\pi} [R_{t+1} + \gamma v_{\pi}(S_{t+1}) \ | \ S_t=s].<br>\end{align}<br>$$<br>Roughly speaking, Monte Carlo methods use an estimate of (3) as a target, whereas DP methods use an estimate of (5) as a target, The Monte Carlo target is an estimate because the expected value in (3) is not known; a sample return is used in place of the real expected return. The DP target is an estimate not because of the excepted value, which are assumed to be completely provided by a model of the environment (the environment is known for the DP methods), but because $v_{\pi}(S_{t+1})$ is not known and the current estimate, $V(S_{t+1})$, is used instead. The TD target is an estimate for both reasons.</p><p>Note that the quantity in brackets in the TD(0) update is a sort of error, measuring the difference between the estimated value of $S_t$ and the better estimate $R_{t+1} + \gamma V(S_{t+1})$. This quantity, called the <strong>TD error</strong>, arises in various forms throughout reinforcement learning:<br>$$<br>\delta_t \doteq R_{t+1} + \gamma V(S_{t+1}) - V(S_t).<br>$$<br>Notice that the TD error at each time is the error in the estimate <strong>made at that time</strong>. Because the TD error depends on the next state and the next reward, it is not actually available until one time step later. Also note that if the array $V$ does not change during the episode (as it does not in Monte Carlo methods), then the Monte Carlo error can be written as a sum of TD errors:<br>$$<br>\begin{align}<br>G_t - V(S_t) &amp;= R_{t+1} + \gamma G(S_{t+1}) - V(S_t) + \gamma V(S_{t+1} ) - \gamma V(S_{t+1}) \\<br>&amp;= \delta_t + \gamma (G_{t+1} - V(S_{t+1})) \\<br>&amp;= \delta_t + \gamma \delta_{t+1} + \gamma^2 (G_{t+1} - V(S_{t+1})) \\<br>&amp;= \delta_t + \gamma \delta_{t+1} + \gamma^2 (G_{t+1} - V(S_{t+1})) \\<br>&amp;= \delta_t + \gamma \delta_{t+1} + \gamma^2 \delta_{t+2} + \cdots + \gamma^{T-t-1} \delta_{T-1} + \gamma^{T-t}(G_t-V(S_T)) \\<br>&amp;= \delta_t + \gamma \delta_{t+1} + \gamma^2 \delta_{t+2} + \cdots + \gamma^{T-t-1} \delta_{T-1} + \gamma^{T-t}(0 -0) \\<br>&amp;= \sum_{k=t}^{T-1} \gamma^{k-t} \delta_k.<br>\end{align}<br>$$<br>This identity is not exact if $V$ is updated during the episode (as it is in TD(0)), but if the step size is small then it may still hold approximately. Generalizations of this identity play an important role in the theory and algorithms of temporal-difference learning.</p><h4 id="Example-Random-walk"><a href="#Example-Random-walk" class="headerlink" title="Example: Random walk"></a><strong>Example: Random walk</strong></h4><p>In this example we empirically compare the prediction abilities of TD(0) and constant-$\alpha$ MC applied to the small Markov reward process shown in the upper part of the figure below. All episodes start in the center state, <strong>C</strong>, and the proceed either left or right by one state on each step, with equal probability. This behavior can be thought of as due to the combined effect of a fixed policy and an environment’s state-transition probabilities, but we do not care which; we are concerned only with predicting returns however they are generated. Episodes terminates on the right, a reward of +1 occurs; all other reward are zero. For example, a typical episode might consist of the following state-and-reward sequence: <strong>C, 0, B, 0, C, 0, D, 0, E, 1.</strong> Because this task is undiscounted, the true value of each state is the probability of terminating on the right if starting from that state. Thus, the true value of the center state is $v_{\pi}(\text{C}) = 0.5$. The true values of all the states, <strong>A</strong> through <strong>E</strong>, are $\frac{1}{6}, \frac{2}{6}, \frac{3}{6}, \frac{4}{6}$, and $\frac{5}{6}$. In all cases the approximate value function was initialized to the intermediate value $V(s)=0.5$, for all $s$.</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/random_walk.png" alt="random_walk"></p><p>Now, let us develop the codes to solve problem.</p><p>The first, we initialize some truth.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 0 is the left terminal state</span></div><div class="line"><span class="comment"># 6 is the right terminal state</span></div><div class="line"><span class="comment"># 1 ... 5 represents A ... E</span></div><div class="line">states = np.zeros(<span class="number">7</span>)</div><div class="line">states[<span class="number">1</span>:<span class="number">6</span>] = <span class="number">0.5</span></div><div class="line"><span class="comment"># For convenience, we assume all rewards are 0</span></div><div class="line"><span class="comment"># and the left terminal state has value 0, the right terminal state has value 1</span></div><div class="line"><span class="comment"># This trick has been used in Gambler's Problem</span></div><div class="line">states[<span class="number">6</span>] = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># set up true state values</span></div><div class="line">trueValue = np.zeros(<span class="number">7</span>)</div><div class="line">trueValue[<span class="number">1</span>:<span class="number">6</span>] = np.arange(<span class="number">1</span>, <span class="number">6</span>) / <span class="number">6.0</span></div><div class="line">trueValue[<span class="number">6</span>] = <span class="number">1</span></div><div class="line"></div><div class="line">ACTION_LEFT = <span class="number">0</span></div><div class="line">ACTION_RIGHT = <span class="number">1</span></div></pre></td></tr></table></figure><p>The below box is the TD(0) algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">temporalDifference</span><span class="params">(states, alpha=<span class="number">0.1</span>, batch=False)</span>:</span></div><div class="line">    state = <span class="number">3</span></div><div class="line">    trajectory = [state]</div><div class="line">    rewards = [<span class="number">0</span>]</div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        oldState = state</div><div class="line">        <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, <span class="number">0.5</span>) == ACTION_LEFT:</div><div class="line">            state -= <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            state += <span class="number">1</span></div><div class="line">        <span class="comment"># Assume all rewards are 0</span></div><div class="line">        reward = <span class="number">0</span></div><div class="line">        trajectory.append(state)</div><div class="line">        <span class="comment"># TD update</span></div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> batch:</div><div class="line">            states[oldState] += alpha * (reward + states[state] - states[oldState])</div><div class="line">        <span class="keyword">if</span> state == <span class="number">6</span> <span class="keyword">or</span> state == <span class="number">0</span>:</div><div class="line">            <span class="keyword">break</span></div><div class="line">        rewards.append(reward)</div><div class="line">    <span class="keyword">return</span> trajectory, rewards</div></pre></td></tr></table></figure><p>And below box is the constant-$\alpha$ Monte Carlo algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">monteCarlo</span><span class="params">(states, alpha=<span class="number">0.1</span>, batch=False)</span>:</span></div><div class="line">    state = <span class="number">3</span></div><div class="line">    trajectory = [<span class="number">3</span>]</div><div class="line">    <span class="comment"># if end up with left terminal state, all returns are 0</span></div><div class="line">    <span class="comment"># if end up with right terminal state, all returns are 1</span></div><div class="line">    returns = <span class="number">0</span></div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, <span class="number">0.5</span>) == ACTION_LEFT:</div><div class="line">            state -= <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            state += <span class="number">1</span></div><div class="line">        trajectory.append(state)</div><div class="line">        <span class="keyword">if</span> state == <span class="number">6</span>:</div><div class="line">            returns = <span class="number">1.0</span></div><div class="line">            <span class="keyword">break</span></div><div class="line">        <span class="keyword">elif</span> state == <span class="number">0</span>:</div><div class="line">            returns = <span class="number">0.0</span></div><div class="line">            <span class="keyword">break</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> batch:</div><div class="line">        <span class="keyword">for</span> state_ <span class="keyword">in</span> trajectory[:<span class="number">-1</span>]:</div><div class="line">            <span class="comment"># MC update</span></div><div class="line">            states[state_] += alpha * (returns - states[state_])</div><div class="line">    <span class="keyword">return</span> trajectory, [returns] * (len(trajectory) - <span class="number">1</span>)</div></pre></td></tr></table></figure><p>First of all, let us test the performance of the TD(0) algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stateValue</span><span class="params">()</span>:</span></div><div class="line">    episodes = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</div><div class="line">    currentStates = np.copy(states)</div><div class="line">    plt.figure(<span class="number">1</span>)</div><div class="line">    axisX = np.arange(<span class="number">0</span>, <span class="number">7</span>)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, episodes[<span class="number">-1</span>] + <span class="number">1</span>):</div><div class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> episodes:</div><div class="line">            plt.plot(axisX, currentStates, label=str(i) + <span class="string">' episodes'</span>)</div><div class="line">        temporalDifference(currentStates)</div><div class="line">    plt.plot(axisX, trueValue, label=<span class="string">'true values'</span>)</div><div class="line">    plt.xlabel(<span class="string">'state'</span>)</div><div class="line">    plt.legend()</div><div class="line">    </div><div class="line">stateValue()</div></pre></td></tr></table></figure><p>Results are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/random_walk_td0.png" alt="random_walk_td0"></p><p>And then let us show the RMS error of the TD(0) algorithm and constant-$\alpha$ Monte Carlo algorithm, for various $\alpha$ values:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">RMSError</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># I'm lazy here, so do not let same alpha value appear in both arrays</span></div><div class="line">    <span class="comment"># For example, if in TD you want to use alpha = 0.2, then in MC you can use alpha = 0.201</span></div><div class="line">    TDAlpha = [<span class="number">0.15</span>, <span class="number">0.1</span>, <span class="number">0.05</span>]</div><div class="line">    MCAlpha = [<span class="number">0.01</span>, <span class="number">0.02</span>, <span class="number">0.03</span>, <span class="number">0.04</span>]</div><div class="line">    episodes = <span class="number">100</span> + <span class="number">1</span></div><div class="line">    runs = <span class="number">100</span></div><div class="line">    plt.figure(<span class="number">2</span>)</div><div class="line">    axisX = np.arange(<span class="number">0</span>, episodes)</div><div class="line">    <span class="keyword">for</span> alpha <span class="keyword">in</span> TDAlpha + MCAlpha:</div><div class="line">        totalErrors = np.zeros(episodes)</div><div class="line">        <span class="keyword">if</span> alpha <span class="keyword">in</span> TDAlpha:</div><div class="line">            method = <span class="string">'TD'</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            method = <span class="string">'MC'</span></div><div class="line">        <span class="keyword">for</span> run <span class="keyword">in</span> range(<span class="number">0</span>, runs):</div><div class="line">            errors = []</div><div class="line">            currentStates = np.copy(states)</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, episodes):</div><div class="line">                errors.append(np.sqrt(np.sum(np.power(trueValue - currentStates, <span class="number">2</span>)) / <span class="number">5.0</span>))</div><div class="line">                <span class="keyword">if</span> method == <span class="string">'TD'</span>:</div><div class="line">                    temporalDifference(currentStates, alpha=alpha)</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    monteCarlo(currentStates, alpha=alpha)</div><div class="line">            totalErrors += np.asarray(errors)</div><div class="line">        totalErrors /= runs</div><div class="line">        plt.plot(axisX, totalErrors, label=method + <span class="string">', alpha='</span> + str(alpha))</div><div class="line">    plt.xlabel(<span class="string">'episodes'</span>)</div><div class="line">    plt.legend()</div><div class="line">    </div><div class="line">RMSError()</div></pre></td></tr></table></figure><p>Results are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/random_walk_rmse.png" alt="random_walk_error"></p><p>We can see, the TD method was consistently better than the MC method on this task.</p><p>Now, suppose that there is available only a finite amount of experience, say 10 episodes or 100 time steps. In this case, a common approach with incremental learning method is to present the experience repeatedly until the method converges upon an answer. We call this <em>batch updating</em>.</p><h4 id="Example-Random-walk-under-batch-updating"><a href="#Example-Random-walk-under-batch-updating" class="headerlink" title="Example: Random walk under batch updating"></a><strong>Example: Random walk under batch updating</strong></h4><p>After each new episodes, all episodes seen so far were treated as a batch. They were repeatedly presented to the algorithm.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchUpdating</span><span class="params">(method, episodes, alpha=<span class="number">0.001</span>)</span>:</span></div><div class="line">    <span class="comment"># perform 100 independent runs</span></div><div class="line">    runs = <span class="number">100</span></div><div class="line">    totalErrors = np.zeros(episodes - <span class="number">1</span>)</div><div class="line">    <span class="keyword">for</span> run <span class="keyword">in</span> range(<span class="number">0</span>, runs):</div><div class="line">        currentStates = np.copy(states)</div><div class="line">        errors = []</div><div class="line">        <span class="comment"># track shown trajectories and reward/return sequences</span></div><div class="line">        trajectories = []</div><div class="line">        rewards = []</div><div class="line">        <span class="keyword">for</span> ep <span class="keyword">in</span> range(<span class="number">1</span>, episodes):</div><div class="line">            print(<span class="string">'Run:'</span>, run, <span class="string">'Episode:'</span>, ep)</div><div class="line">            <span class="keyword">if</span> method == <span class="string">'TD'</span>:</div><div class="line">                trajectory_, rewards_ = temporalDifference(currentStates, batch=<span class="keyword">True</span>)</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                trajectory_, rewards_ = monteCarlo(currentStates, batch=<span class="keyword">True</span>)</div><div class="line">            trajectories.append(trajectory_)</div><div class="line">            rewards.append(rewards_)</div><div class="line">            <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">                <span class="comment"># keep feeding our algorithm with trajectories seen so far until state value function converges</span></div><div class="line">                updates = np.zeros(<span class="number">7</span>)</div><div class="line">                <span class="keyword">for</span> trajectory_, rewards_ <span class="keyword">in</span> zip(trajectories, rewards):</div><div class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(trajectory_) - <span class="number">1</span>):</div><div class="line">                        <span class="keyword">if</span> method == <span class="string">'TD'</span>:</div><div class="line">                            updates[trajectory_[i]] += rewards_[i] + currentStates[trajectory_[i + <span class="number">1</span>]] - currentStates[trajectory_[i]]</div><div class="line">                        <span class="keyword">else</span>:</div><div class="line">                            updates[trajectory_[i]] += rewards_[i] - currentStates[trajectory_[i]]</div><div class="line">                updates *= alpha</div><div class="line">                <span class="keyword">if</span> np.sum(np.abs(updates)) &lt; <span class="number">1e-3</span>:</div><div class="line">                    <span class="keyword">break</span></div><div class="line">                <span class="comment"># perform batch updating</span></div><div class="line">                currentStates += updates</div><div class="line">            <span class="comment"># calculate rms error</span></div><div class="line">            errors.append(np.sqrt(np.sum(np.power(currentStates - trueValue, <span class="number">2</span>)) / <span class="number">5.0</span>))</div><div class="line">        totalErrors += np.asarray(errors)</div><div class="line">    totalErrors /= runs</div><div class="line">    <span class="keyword">return</span> totalErrors</div></pre></td></tr></table></figure><p>Notice that the core codes:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="comment"># keep feeding our algorithm with trajectories seen so far until state</span></div><div class="line">    <span class="comment"># value function converges</span></div><div class="line">    updates = np.zeros(<span class="number">7</span>)</div><div class="line">    <span class="keyword">for</span> trajectory_, rewards_ <span class="keyword">in</span> zip(trajectories, rewards):</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(trajectory_) - <span class="number">1</span>):</div><div class="line">            <span class="keyword">if</span> method == <span class="string">'TD'</span>:</div><div class="line">                updates[trajectory_[i]] += rewards_[i] + \</div><div class="line">                    currentStates[trajectory_[i + <span class="number">1</span>]] - currentStates[trajectory_[i]]</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                updates[trajectory_[i]] += rewards_[i] - currentStates[trajectory_[i]]</div><div class="line">    updates *= alpha</div><div class="line">    <span class="keyword">if</span> np.sum(np.abs(updates)) &lt; <span class="number">1e-3</span>:</div><div class="line">        <span class="keyword">break</span></div><div class="line">    <span class="comment"># perform batch updating</span></div><div class="line">    currentStates += updates</div></pre></td></tr></table></figure><p>Either TD methods or MC methods, the target is to minimize the TD error (or MC error, I say).</p><p>The result is as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/batch_update.png" alt="batch_update"></p><p>Under batch training, constant-$\alpha$ MC converges to value, $V(s)$, that are sample averages of the actual returns experienced after visiting each state $s$. These are optimal estimate in the sense that they minimize the mean-squared error from the actual returns in the training set. In this sense it is surprising that the batch TD method was able to perform better according to the root mean-squared error measure shown in the top figure. How is it that batch TD was able to perform better than this optimal methods? Consider the example in below box:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/example_6_4.png" alt="example6_4"></p><p>Example illustrates a general difference between the estimates founds by batch TD(0) and batch Monte Carlo methods. Batch Monte Carlo methods always find the estimates that minimize mean-squared error on the training set, whereas batch TD(0) always finds the estimates that would be exactly correct for the maximum-likelihood model of the Markov process. Given this model, we can compute the estimate of the value function that would be exactly correct if the model were exactly correct. This is called the <strong>certainty-equivalence estimate</strong>.</p><h3 id="Sarsa"><a href="#Sarsa" class="headerlink" title="Sarsa"></a><strong>Sarsa</strong></h3><p>$$<br>Q(S_t, A_t) \leftarrow Q(S_t, A_t) + \alpha \left[ R_{t+1} + \gamma Q(S_{t+1}, A_{t+1}) - Q(S_t, A_t)\right]<br>$$</p><p>This update is done after every transition from a nonterminal state $S_t$. If $S_{t+1}$ is terminal, then $Q(S_{t+1}, A_{t+1})$ is defined as zero. This rule uses every element of the quintuple of events, $(S_t, A_t, R_{t+1}, S_{t+1}, A_{t+1})$, that make up a transition from one state-action pair to the next. This quintuple gives rise to the name <em>Sarsa</em> for the algorithm. The backup diagram for Sarsa is as shown to the bottom.</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/sarsabg.png" alt="sarsa_bg"></p><p>The general form of the Sarsa control algorithm is given in the box below.</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/sarsa.png" alt="sarsa"></p><h4 id="Example-Windy-Gridworld"><a href="#Example-Windy-Gridworld" class="headerlink" title="Example: Windy Gridworld"></a><strong>Example: Windy Gridworld</strong></h4><p>The figure below is a standard grid-world, with start and goal states, but with one diﬀerence: there is a crosswind upward through the middle of the grid. The actions are the standard four—up, down,right, and left—but in the middle region the resultant next states are shifted upward by a “wind,” the strength of which varies from column to column. The strength of the wind is given below each column, in number of cells shifted upward. For example, if you are one cell to the right of the goal, then the action left takes you to the cell just above the goal. Let us treat this as an undiscounted episodic task, with constant rewards of −1 until the goal state is reached.</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/windy_gridworld.png" alt="windy_gridworld"></p><p>To demonstrate the problem clearly, we use the <a href="https://gym.openai.com/" target="_blank" rel="external">OpenAI gym</a> toolkit to develop the algorithm.</p><p>First of all, we need to define a environment (the windy grid world):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># represents every action as a integer</span></div><div class="line">UP = <span class="number">0</span></div><div class="line">RIGHT = <span class="number">1</span></div><div class="line">DOWN = <span class="number">2</span></div><div class="line">LEFT = <span class="number">3</span></div></pre></td></tr></table></figure><p>The environment is a class that inherit the gym default class <strong>discrete.DiscreteEnv</strong> (shows that the states are discrete):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">WindyGridworldEnv</span><span class="params">(discrete.DiscreteEnv)</span></span></div></pre></td></tr></table></figure><p>First we need to construct our world:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">    self.shape = (<span class="number">7</span>, <span class="number">10</span>)</div><div class="line"></div><div class="line">    <span class="comment"># the number of all states</span></div><div class="line">    nS = np.prod(self.shape)</div><div class="line">    <span class="comment"># the number of all actions</span></div><div class="line">    nA = <span class="number">4</span></div><div class="line"></div><div class="line">    <span class="comment"># Wind strength</span></div><div class="line">    winds = np.zeros(self.shape)</div><div class="line">    winds[:,[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">8</span>]] = <span class="number">1</span></div><div class="line">    winds[:,[<span class="number">6</span>,<span class="number">7</span>]] = <span class="number">2</span></div><div class="line"></div><div class="line">    <span class="comment"># Calculate transition probabilities</span></div><div class="line">    <span class="comment"># P is the transition matrix</span></div><div class="line">    P = &#123;&#125;</div><div class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> range(nS):</div><div class="line">        position = np.unravel_index(s, self.shape)</div><div class="line">        P[s] = &#123; a : [] <span class="keyword">for</span> a <span class="keyword">in</span> range(nA) &#125;</div><div class="line">        P[s][UP] = self._calculate_transition_prob(position, [<span class="number">-1</span>, <span class="number">0</span>], winds)</div><div class="line">        P[s][RIGHT] = self._calculate_transition_prob(position, [<span class="number">0</span>, <span class="number">1</span>], winds)</div><div class="line">        P[s][DOWN] = self._calculate_transition_prob(position, [<span class="number">1</span>, <span class="number">0</span>], winds)</div><div class="line">        P[s][LEFT] = self._calculate_transition_prob(position, [<span class="number">0</span>, <span class="number">-1</span>], winds)</div><div class="line"></div><div class="line">    <span class="comment"># We always start in state (3, 0)</span></div><div class="line">    isd = np.zeros(nS)</div><div class="line">    isd[np.ravel_multi_index((<span class="number">3</span>,<span class="number">0</span>), self.shape)] = <span class="number">1.0</span></div><div class="line"></div><div class="line">    super(WindyGridworldEnv, self).__init__(nS, nA, P, isd)</div></pre></td></tr></table></figure><p>This is natural, uh? Notice that there is a method called <strong>_calculate_transition_prob</strong>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calculate_transition_prob</span><span class="params">(self, current, delta, winds)</span>:</span></div><div class="line">        new_position = np.array(current) + np.array(delta) + np.array([<span class="number">-1</span>, <span class="number">0</span>]) * winds[tuple(current)]</div><div class="line">        new_position = self._limit_coordinates(new_position).astype(int)</div><div class="line">        new_state = np.ravel_multi_index(tuple(new_position), self.shape)</div><div class="line">        is_done = tuple(new_position) == (<span class="number">3</span>, <span class="number">7</span>)</div><div class="line">        <span class="keyword">return</span> [(<span class="number">1.0</span>, new_state, <span class="number">-1.0</span>, is_done)]</div></pre></td></tr></table></figure><p>and <strong>_limit_corrdinates</strong> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_limit_coordinates</span><span class="params">(self, coord)</span>:</span></div><div class="line">    coord[<span class="number">0</span>] = min(coord[<span class="number">0</span>], self.shape[<span class="number">0</span>] - <span class="number">1</span>)</div><div class="line">    coord[<span class="number">0</span>] = max(coord[<span class="number">0</span>], <span class="number">0</span>)</div><div class="line">    coord[<span class="number">1</span>] = min(coord[<span class="number">1</span>], self.shape[<span class="number">1</span>] - <span class="number">1</span>)</div><div class="line">    coord[<span class="number">1</span>] = max(coord[<span class="number">1</span>], <span class="number">0</span>)</div><div class="line">    <span class="keyword">return</span> coord</div></pre></td></tr></table></figure><p>It is worth to mention that the default gym environment class has some useful parameters: <strong>nS</strong>, <strong>nA</strong>, <strong>P</strong> and <strong>is_done</strong>. nS is the total number of states and nA is the total number of actions (here assume all states only could take the same fixed actions). P is the state transition matrix, the default environment class has a <strong>step</strong> method (accept a parameter <strong>action</strong>) that could generates episode automatically according the P and is_done that represents whether a state is terminal state or not.</p><p>Finally, we define a output method for pretty show the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_render</span><span class="params">(self, mode=<span class="string">'human'</span>, close=False)</span>:</span></div><div class="line">    <span class="keyword">if</span> close:</div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    outfile = StringIO() <span class="keyword">if</span> mode == <span class="string">'ansi'</span> <span class="keyword">else</span> sys.stdout</div><div class="line"></div><div class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> range(self.nS):</div><div class="line">        position = np.unravel_index(s, self.shape)</div><div class="line">        <span class="comment"># print(self.s)</span></div><div class="line">        <span class="keyword">if</span> self.s == s:</div><div class="line">            output = <span class="string">" x "</span></div><div class="line">        <span class="keyword">elif</span> position == (<span class="number">3</span>,<span class="number">7</span>):</div><div class="line">            output = <span class="string">" T "</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            output = <span class="string">" o "</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> position[<span class="number">1</span>] == <span class="number">0</span>:</div><div class="line">            output = output.lstrip()</div><div class="line">        <span class="keyword">if</span> position[<span class="number">1</span>] == self.shape[<span class="number">1</span>] - <span class="number">1</span>:</div><div class="line">            output = output.rstrip()</div><div class="line">            output += <span class="string">"\n"</span></div><div class="line"></div><div class="line">        outfile.write(output)</div><div class="line">    outfile.write(<span class="string">"\n"</span>)</div></pre></td></tr></table></figure><p>Then, let us test our model：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">env = WindyGridworldEnv()</div><div class="line"></div><div class="line">print(env.reset())</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">1</span>))</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">1</span>))</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">1</span>))</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">2</span>))</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">1</span>))</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">1</span>))</div><div class="line">env.render()</div></pre></td></tr></table></figure><p>The results are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/windy_render.png" alt="windy_show"></p><p>Each state transition, the step method return a tuple <strong>(next_state, reward, is_done, some_extra_info)</strong>.</p><p>Next, we define the episodes generation policy:</p><p>def make_epsilon_greedy_policy(Q, epsilon, nA):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="string">"""</span></div><div class="line">Creates an epsilon-greedy policy based on a given Q-function and epsilon.</div><div class="line"></div><div class="line">Args:</div><div class="line">    Q: A dictionary that maps from state -&gt; action-values.</div><div class="line">        Each value is a numpy array of length nA (see below)</div><div class="line">    epsilon: The probability to select a random action . float between 0 and 1.</div><div class="line">    nA: Number of actions in the environment.</div><div class="line"></div><div class="line">Returns:</div><div class="line">    A function that takes the observation as an argument and returns</div><div class="line">    the probabilities for each action in the form of a numpy array of length nA.</div><div class="line"></div><div class="line">"""</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">policy_fn</span><span class="params">(observation)</span>:</span></div><div class="line">    A = np.ones(nA, dtype=float) * epsilon / nA</div><div class="line">    best_action = np.argmax(Q[observation])</div><div class="line">    A[best_action] += (<span class="number">1.0</span> - epsilon)</div><div class="line">    <span class="keyword">return</span> A</div><div class="line"><span class="keyword">return</span> policy_fn</div></pre></td></tr></table></figure><p>Now, let us implement the sarsa algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sarsa</span><span class="params">(env, num_episodes, discount_factor=<span class="number">1.0</span>, alpha=<span class="number">0.5</span>, epsilon=<span class="number">0.1</span>)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    SARSA algorithm: On-policy TD control. Finds the optimal epsilon-greedy policy.</div><div class="line">    </div><div class="line">    Args:</div><div class="line">        env: OpenAI environment.</div><div class="line">        num_episodes: Number of episodes to run for.</div><div class="line">        discount_factor: Lambda time discount factor.</div><div class="line">        alpha: TD learning rate.</div><div class="line">        epsilon: Chance the sample a random action. Float betwen 0 and 1.</div><div class="line">    </div><div class="line">    Returns:</div><div class="line">        A tuple (Q, stats).</div><div class="line">        Q is the optimal action-value function, a dictionary mapping state -&gt; action values.</div><div class="line">        stats is an EpisodeStats object with two numpy arrays for episode_lengths and episode_rewards.</div><div class="line">    """</div><div class="line">    </div><div class="line">    <span class="comment"># The final action-value function.</span></div><div class="line">    <span class="comment"># A nested dictionary that maps state -&gt; (action -&gt; action-value).</span></div><div class="line">    Q = defaultdict(<span class="keyword">lambda</span>: np.zeros(env.action_space.n))</div><div class="line">    </div><div class="line">    <span class="comment"># Keeps track of useful statistics</span></div><div class="line">    stats = plotting.EpisodeStats(</div><div class="line">        episode_lengths=np.zeros(num_episodes),</div><div class="line">        episode_rewards=np.zeros(num_episodes))</div><div class="line"></div><div class="line">    <span class="comment"># The policy we're following</span></div><div class="line">    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)</div><div class="line">    </div><div class="line"></div><div class="line">    <span class="keyword">for</span> i_episode <span class="keyword">in</span> range(num_episodes):</div><div class="line">        <span class="comment"># Print out which episode we're on, useful for debugging.</span></div><div class="line">        <span class="keyword">if</span> (i_episode + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</div><div class="line">            print(<span class="string">"\rEpisode &#123;&#125;/&#123;&#125;."</span>.format(i_episode + <span class="number">1</span>, num_episodes), end=<span class="string">""</span>)</div><div class="line">            sys.stdout.flush()</div><div class="line">        </div><div class="line">        <span class="comment"># Implement this!</span></div><div class="line">        state = env.reset()</div><div class="line">        action_probs = policy(state)</div><div class="line">        action = np.random.choice(np.arange(len(action_probs)), p=action_probs)</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> itertools.count():</div><div class="line">            next_state, reward, is_done, _ = env.step(action)</div><div class="line">            next_action_probs = policy(next_state)</div><div class="line">            </div><div class="line">            stats.episode_rewards[i_episode] += reward</div><div class="line">            stats.episode_lengths[i_episode] = t</div><div class="line">            </div><div class="line">            next_action = np.random.choice(np.arange(len(next_action_probs)), p=next_action_probs)</div><div class="line">            Q[state][action] += alpha * (reward + discount_factor * Q[next_state][next_action] - Q[state][action])</div><div class="line">            </div><div class="line">            <span class="keyword">if</span> is_done:</div><div class="line">                <span class="keyword">break</span></div><div class="line">            </div><div class="line">            state = next_state</div><div class="line">            action = next_action</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> Q, stats</div></pre></td></tr></table></figure><p>For understand easily, we put the pesudo-code here again:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/sarsa.png" alt="sarsa"></p><p>The results (with $\varepsilon=0.1,\ \alpha=0.5$) are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/sarsa_result.png" alt="sarsa_result"></p><p>The increasing slope (bottom figure) of the graph shows that the goal is reached more and more quickly over time. Note that Monte Carlo methods cannot easily be used on this task because termination is not guaranteed for all policies. If a policy was ever found that caused the agent to stay in the same state, then the next episode would never end. Step-by-step learning methods such as Sarsa do not have this problem because they quickly learn <strong>during the episode</strong> that such<br>policies are poor, and switch to something else.</p><h3 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h3><p>One of the early breakthroughs in reinforcement learning was the development of an off-policy TD control algorithm known as Q-learning, defined by<br>$$<br>Q(S_t, A_t) \leftarrow Q(S_t, A_t) + \alpha \left[ R_{t+1} + \gamma \max_a Q(S_{t+1}, a) - Q(S_t, A_t)\right]<br>$$<br>The algorithm is shown in procedural form in the box below:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/q_learning.png" alt="q_learning"></p><p>And below is the backup diagram:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/q_bg.png" alt="q_bg"></p><h4 id="Example-Cliff-Walking"><a href="#Example-Cliff-Walking" class="headerlink" title="Example: Cliff Walking"></a>Example: Cliff Walking</h4><p>This grid world example compares Sarsa and Q-learning, highlighting the difference between on-policy (Sarsa) and off-policy (Q-learning) methods. Consider the grid world shown in the figure below:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/cliff_world.png" alt="cliff_world"></p><p>The same as earlier, we define the environment first. But the new environment just changes a little, so we just paste the code <a href="https://github.com/ewanlee/reinforcement-learning/blob/master/lib/envs/cliff_walking.py" target="_blank" rel="external">here</a>.</p><p>Let us test the environment first:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">env = CliffWalkingEnv()</div><div class="line"></div><div class="line">print(env.reset())</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">0</span>))</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">1</span>))</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">1</span>))</div><div class="line">env.render()</div><div class="line"></div><div class="line">print(env.step(<span class="number">2</span>))</div><div class="line">env.render()</div></pre></td></tr></table></figure><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/cliff_walk_show.png" alt="cliff_walk_show"></p><p>Not bad.</p><p>Then, let us develop the Q-learning algorithm (the episodes generation policy is not change):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">q_learning</span><span class="params">(env, num_episodes, discount_factor=<span class="number">1.0</span>, alpha=<span class="number">0.5</span>, epsilon=<span class="number">0.1</span>)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Q-Learning algorithm: Off-policy TD control. Finds the optimal greedy policy</div><div class="line">    while following an epsilon-greedy policy</div><div class="line">    </div><div class="line">    Args:</div><div class="line">        env: OpenAI environment.</div><div class="line">        num_episodes: Number of episodes to run for.</div><div class="line">        discount_factor: Lambda time discount factor.</div><div class="line">        alpha: TD learning rate.</div><div class="line">        epsilon: Chance the sample a random action. Float betwen 0 and 1.</div><div class="line">    </div><div class="line">    Returns:</div><div class="line">        A tuple (Q, episode_lengths).</div><div class="line">        Q is the optimal action-value function, a dictionary mapping state -&gt; action values.</div><div class="line">        stats is an EpisodeStats object with two numpy arrays for episode_lengths and episode_rewards.</div><div class="line">    """</div><div class="line">    </div><div class="line">    <span class="comment"># The final action-value function.</span></div><div class="line">    <span class="comment"># A nested dictionary that maps state -&gt; (action -&gt; action-value).</span></div><div class="line">    Q = defaultdict(<span class="keyword">lambda</span>: np.zeros(env.action_space.n))</div><div class="line"></div><div class="line">    <span class="comment"># Keeps track of useful statistics</span></div><div class="line">    stats = plotting.EpisodeStats(</div><div class="line">        episode_lengths=np.zeros(num_episodes),</div><div class="line">        episode_rewards=np.zeros(num_episodes))    </div><div class="line">    </div><div class="line">    <span class="comment"># The policy we're following</span></div><div class="line">    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> i_episode <span class="keyword">in</span> range(num_episodes):</div><div class="line">        <span class="comment"># Print out which episode we're on, useful for debugging.</span></div><div class="line">        <span class="keyword">if</span> (i_episode + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</div><div class="line">            print(<span class="string">"\rEpisode &#123;&#125;/&#123;&#125;."</span>.format(i_episode + <span class="number">1</span>, num_episodes), end=<span class="string">""</span>)</div><div class="line">            sys.stdout.flush()</div><div class="line">        </div><div class="line">        <span class="comment"># Reset the environment and pick the first action</span></div><div class="line">        state = env.reset()</div><div class="line">        </div><div class="line">        <span class="comment"># One step in the environment</span></div><div class="line">        <span class="comment"># total_reward = 0.0</span></div><div class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> itertools.count():</div><div class="line">            </div><div class="line">            <span class="comment"># Take a step</span></div><div class="line">            action_probs = policy(state)</div><div class="line">            action = np.random.choice(np.arange(len(action_probs)), p=action_probs)</div><div class="line">            next_state, reward, done, _ = env.step(action)</div><div class="line"></div><div class="line">            <span class="comment"># Update statistics</span></div><div class="line">            stats.episode_rewards[i_episode] += reward</div><div class="line">            stats.episode_lengths[i_episode] = t</div><div class="line">            </div><div class="line">            <span class="comment"># TD Update</span></div><div class="line">            best_next_action = np.argmax(Q[next_state])    </div><div class="line">            td_target = reward + discount_factor * Q[next_state][best_next_action]</div><div class="line">            td_delta = td_target - Q[state][action]</div><div class="line">            Q[state][action] += alpha * td_delta</div><div class="line">                </div><div class="line">            <span class="keyword">if</span> done:</div><div class="line">                <span class="keyword">break</span></div><div class="line">                </div><div class="line">            state = next_state</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> Q, stats</div></pre></td></tr></table></figure><p>Results ($\varepsilon=0.1$) are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/q_learning_result.png" alt="q_learning_result"></p><p>For compare convenience, we put the result of Sarsa here again:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/sarsa_result.png" alt="sarsa_result"></p><p>We can see, for average, After an initial transient, Q-learning learns values for the optimal policy, that which travels right along the edge of the cliﬀ. Unfortunately, this results in its occasionally falling oﬀ the cliﬀ because of the ε-greedy action selection. Sarsa, on the other hand, takes the action selection into account and learns the longer but safer path through the upper part of the<br>grid. Although Q-learning actually learns the values of the optimal policy, its online performance is worse than that of Sarsa, which learns the roundabout policy. Of course, if ε were gradually reduced, then both methods would asymptotically converge to the optimal policy.</p><h3 id="Expected-Sarsa"><a href="#Expected-Sarsa" class="headerlink" title="Expected Sarsa"></a>Expected Sarsa</h3><p>Consider the learning algorithm that is just like Q-learning except that instead of the maximum over next state-action pairs it uses the expected value, taking into account how likely each action is under the current policy. That is, consider the algorithm with the update rule<br>$$<br>\begin{align}<br>Q(S_t, A_t) &amp;\leftarrow Q(S_t, A_t) + \alpha \left [ R_{t+1} + \gamma \mathbb{E}[Q(S_{t+1}, A_{t+1} \ | \ S_{t+1})] - Q(S_t, A_t) \right ] \\<br>&amp;\leftarrow Q(S_t, A_t) + \alpha \left [ R_{t+1} + \gamma \sum_a \pi(a|S_{t+1})Q(S_{t+1}, a) - Q(S_t, A_t) \right ],<br>\end{align}<br>$$<br>but that otherwise follows the schema of Q-learning. Its backup diagram is shown below:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/esarsa_bg.png" alt="esarsa_bg"></p><p>For compare the results on the cliff-walking task with Excepted Sarsa with Sarsa and Q-learning, we develop another <a href="https://github.com/ewanlee/reinforcement-learning-an-introduction/blob/master/chapter06/CliffWalking.py" target="_blank" rel="external">codes</a> (here we are not use the OpenAI gym toolkit).</p><p>The first we define some truth of the environment:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># world height</span></div><div class="line">WORLD_HEIGHT = <span class="number">4</span></div><div class="line"></div><div class="line"><span class="comment"># world width</span></div><div class="line">WORLD_WIDTH = <span class="number">12</span></div><div class="line"></div><div class="line"><span class="comment"># probability for exploration</span></div><div class="line">EPSILON = <span class="number">0.1</span></div><div class="line"></div><div class="line"><span class="comment"># step size</span></div><div class="line">ALPHA = <span class="number">0.5</span></div><div class="line"></div><div class="line"><span class="comment"># gamma for Q-Learning and Expected Sarsa</span></div><div class="line">GAMMA = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># all possible actions</span></div><div class="line">ACTION_UP = <span class="number">0</span></div><div class="line">ACTION_DOWN = <span class="number">1</span></div><div class="line">ACTION_LEFT = <span class="number">2</span></div><div class="line">ACTION_RIGHT = <span class="number">3</span></div><div class="line">actions = [ACTION_UP, ACTION_DOWN, ACTION_LEFT, ACTION_RIGHT]</div><div class="line"></div><div class="line"><span class="comment"># initial state action pair values</span></div><div class="line">stateActionValues = np.zeros((WORLD_HEIGHT, WORLD_WIDTH, <span class="number">4</span>))</div><div class="line">startState = [<span class="number">3</span>, <span class="number">0</span>]</div><div class="line">goalState = [<span class="number">3</span>, <span class="number">11</span>]</div><div class="line"></div><div class="line"><span class="comment"># reward for each action in each state</span></div><div class="line">actionRewards = np.zeros((WORLD_HEIGHT, WORLD_WIDTH, <span class="number">4</span>))</div><div class="line">actionRewards[:, :, :] = <span class="number">-1.0</span></div><div class="line">actionRewards[<span class="number">2</span>, <span class="number">1</span>:<span class="number">11</span>, ACTION_DOWN] = <span class="number">-100.0</span></div><div class="line">actionRewards[<span class="number">3</span>, <span class="number">0</span>, ACTION_RIGHT] = <span class="number">-100.0</span></div></pre></td></tr></table></figure><p>And then we define the state transitions:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># set up destinations for each action in each state</span></div><div class="line">actionDestination = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_HEIGHT):</div><div class="line">    actionDestination.append([])</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_WIDTH):</div><div class="line">        destinaion = dict()</div><div class="line">        destinaion[ACTION_UP] = [max(i - <span class="number">1</span>, <span class="number">0</span>), j]</div><div class="line">        destinaion[ACTION_LEFT] = [i, max(j - <span class="number">1</span>, <span class="number">0</span>)]</div><div class="line">        destinaion[ACTION_RIGHT] = [i, min(j + <span class="number">1</span>, WORLD_WIDTH - <span class="number">1</span>)]</div><div class="line">        <span class="keyword">if</span> i == <span class="number">2</span> <span class="keyword">and</span> <span class="number">1</span> &lt;= j &lt;= <span class="number">10</span>:</div><div class="line">            destinaion[ACTION_DOWN] = startState</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            destinaion[ACTION_DOWN] = [min(i + <span class="number">1</span>, WORLD_HEIGHT - <span class="number">1</span>), j]</div><div class="line">        actionDestination[<span class="number">-1</span>].append(destinaion)</div><div class="line">actionDestination[<span class="number">3</span>][<span class="number">0</span>][ACTION_RIGHT] = startState</div></pre></td></tr></table></figure><p>We also need a policy to generate the next action according to the current state:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># choose an action based on epsilon greedy algorithm</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseAction</span><span class="params">(state, stateActionValues)</span>:</span></div><div class="line">    <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, EPSILON) == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> np.random.choice(actions)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> np.argmax(stateActionValues[state[<span class="number">0</span>], state[<span class="number">1</span>], :])</div></pre></td></tr></table></figure><p>The <strong>stateActionValues</strong> just is the Q.</p><p>Then, let us develop the Sarsa (and Excepted Sarsa) algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># an episode with Sarsa</span></div><div class="line"><span class="comment"># @stateActionValues: values for state action pair, will be updated</span></div><div class="line"><span class="comment"># @expected: if True, will use expected Sarsa algorithm</span></div><div class="line"><span class="comment"># @stepSize: step size for updating</span></div><div class="line"><span class="comment"># @return: total rewards within this episode</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sarsa</span><span class="params">(stateActionValues, expected=False, stepSize=ALPHA)</span>:</span></div><div class="line">    currentState = startState</div><div class="line">    currentAction = chooseAction(currentState, stateActionValues)</div><div class="line">    rewards = <span class="number">0.0</span></div><div class="line">    <span class="keyword">while</span> currentState != goalState:</div><div class="line">        newState = actionDestination[currentState[<span class="number">0</span>]][currentState[<span class="number">1</span>]][currentAction]</div><div class="line">        newAction = chooseAction(newState, stateActionValues)</div><div class="line">        reward = actionRewards[currentState[<span class="number">0</span>], currentState[<span class="number">1</span>], currentAction]</div><div class="line">        rewards += reward</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> expected:</div><div class="line">            valueTarget = stateActionValues[newState[<span class="number">0</span>], newState[<span class="number">1</span>], newAction]</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="comment"># calculate the expected value of new state</span></div><div class="line">            valueTarget = <span class="number">0.0</span></div><div class="line">            actions_list = stateActionValues[newState[<span class="number">0</span>], newState[<span class="number">1</span>], :]</div><div class="line">            bestActions = np.argwhere(actions_list == np.amax(actions_list)).flatten().tolist()</div><div class="line">            <span class="keyword">for</span> action <span class="keyword">in</span> actions:</div><div class="line">                <span class="keyword">if</span> action <span class="keyword">in</span> bestActions:</div><div class="line">                    valueTarget += ((<span class="number">1.0</span> - EPSILON) / len(bestActions) + EPSILON / len(actions)) * stateActionValues[newState[<span class="number">0</span>], newState[<span class="number">1</span>], action]</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    valueTarget += EPSILON / len(actions) * stateActionValues[newState[<span class="number">0</span>], newState[<span class="number">1</span>], action]</div><div class="line">        valueTarget *= GAMMA</div><div class="line">        <span class="comment"># Sarsa update</span></div><div class="line">        stateActionValues[currentState[<span class="number">0</span>], currentState[<span class="number">1</span>], currentAction] += stepSize * (reward +</div><div class="line">            valueTarget - stateActionValues[currentState[<span class="number">0</span>], currentState[<span class="number">1</span>], currentAction])</div><div class="line">        currentState = newState</div><div class="line">        currentAction = newAction</div><div class="line">    <span class="keyword">return</span> rewards</div></pre></td></tr></table></figure><p>Because we develop the Sarsa algorithm earlier, so we just concentrate on the Excepted Sarsa algorithm here:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># calculate the expected value of new state</span></div><div class="line">valueTarget = <span class="number">0.0</span></div><div class="line">actions_list = stateActionValues[newState[<span class="number">0</span>], newState[<span class="number">1</span>], :]</div><div class="line">bestActions = np.argwhere(actions_list == np.amax(actions_list)).flatten().tolist()</div><div class="line"><span class="keyword">for</span> action <span class="keyword">in</span> actions:</div><div class="line">    <span class="keyword">if</span> action <span class="keyword">in</span> bestActions:</div><div class="line">        valueTarget += ((<span class="number">1.0</span> - EPSILON) / len(bestActions) + EPSILON / len(actions)) * stateActionValues[newState[<span class="number">0</span>], newState[<span class="number">1</span>], action]</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        valueTarget += EPSILON / len(actions) * stateActionValues[newState[<span class="number">0</span>], newState[<span class="number">1</span>], action]</div></pre></td></tr></table></figure><p>By the way, let us develop the Q-learning algorithm again:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># an episode with Q-Learning</span></div><div class="line"><span class="comment"># @stateActionValues: values for state action pair, will be updated</span></div><div class="line"><span class="comment"># @expected: if True, will use expected Sarsa algorithm</span></div><div class="line"><span class="comment"># @stepSize: step size for updating</span></div><div class="line"><span class="comment"># @return: total rewards within this episode</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">qLearning</span><span class="params">(stateActionValues, stepSize=ALPHA)</span>:</span></div><div class="line">    currentState = startState</div><div class="line">    rewards = <span class="number">0.0</span></div><div class="line">    <span class="keyword">while</span> currentState != goalState:</div><div class="line">        currentAction = chooseAction(currentState, stateActionValues)</div><div class="line">        reward = actionRewards[currentState[<span class="number">0</span>], currentState[<span class="number">1</span>], currentAction]</div><div class="line">        rewards += reward</div><div class="line">        newState = actionDestination[currentState[<span class="number">0</span>]][currentState[<span class="number">1</span>]][currentAction]</div><div class="line">        <span class="comment"># Q-Learning update</span></div><div class="line">        stateActionValues[currentState[<span class="number">0</span>], currentState[<span class="number">1</span>], currentAction] += stepSize * (</div><div class="line">            reward + GAMMA * np.max(stateActionValues[newState[<span class="number">0</span>], newState[<span class="number">1</span>], :]) -</div><div class="line">            stateActionValues[currentState[<span class="number">0</span>], currentState[<span class="number">1</span>], currentAction])</div><div class="line">        currentState = newState</div><div class="line">    <span class="keyword">return</span> rewards</div></pre></td></tr></table></figure><p>Now we can see the optimal policy in each state of both algorithm (we are not mentioned earlier):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># print optimal policy</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">printOptimalPolicy</span><span class="params">(stateActionValues)</span>:</span></div><div class="line">    optimalPolicy = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_HEIGHT):</div><div class="line">        optimalPolicy.append([])</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_WIDTH):</div><div class="line">            <span class="keyword">if</span> [i, j] == goalState:</div><div class="line">                optimalPolicy[<span class="number">-1</span>].append(<span class="string">'G'</span>)</div><div class="line">                <span class="keyword">continue</span></div><div class="line">            bestAction = np.argmax(stateActionValues[i, j, :])</div><div class="line">            <span class="keyword">if</span> bestAction == ACTION_UP:</div><div class="line">                optimalPolicy[<span class="number">-1</span>].append(<span class="string">'U'</span>)</div><div class="line">            <span class="keyword">elif</span> bestAction == ACTION_DOWN:</div><div class="line">                optimalPolicy[<span class="number">-1</span>].append(<span class="string">'D'</span>)</div><div class="line">            <span class="keyword">elif</span> bestAction == ACTION_LEFT:</div><div class="line">                optimalPolicy[<span class="number">-1</span>].append(<span class="string">'L'</span>)</div><div class="line">            <span class="keyword">elif</span> bestAction == ACTION_RIGHT:</div><div class="line">                optimalPolicy[<span class="number">-1</span>].append(<span class="string">'R'</span>)</div><div class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> optimalPolicy:</div><div class="line">        print(row)</div><div class="line"></div><div class="line"><span class="comment"># averaging the reward sums from 10 successive episodes</span></div><div class="line">averageRange = <span class="number">10</span></div><div class="line"></div><div class="line"><span class="comment"># episodes of each run</span></div><div class="line">nEpisodes = <span class="number">500</span></div><div class="line"></div><div class="line"><span class="comment"># perform 20 independent runs</span></div><div class="line">runs = <span class="number">20</span></div><div class="line"></div><div class="line">rewardsSarsa = np.zeros(nEpisodes)</div><div class="line">rewardsQLearning = np.zeros(nEpisodes)</div><div class="line"><span class="keyword">for</span> run <span class="keyword">in</span> range(<span class="number">0</span>, runs):</div><div class="line">    stateActionValuesSarsa = np.copy(stateActionValues)</div><div class="line">    stateActionValuesQLearning = np.copy(stateActionValues)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nEpisodes):</div><div class="line">        <span class="comment"># cut off the value by -100 to draw the figure more elegantly</span></div><div class="line">        rewardsSarsa[i] += max(sarsa(stateActionValuesSarsa), <span class="number">-100</span>)</div><div class="line">        rewardsQLearning[i] += max(qLearning(stateActionValuesQLearning), <span class="number">-100</span>)</div><div class="line"></div><div class="line"><span class="comment"># averaging over independt runs</span></div><div class="line">rewardsSarsa /= runs</div><div class="line">rewardsQLearning /= runs</div><div class="line"></div><div class="line"><span class="comment"># averaging over successive episodes</span></div><div class="line">smoothedRewardsSarsa = np.copy(rewardsSarsa)</div><div class="line">smoothedRewardsQLearning = np.copy(rewardsQLearning)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(averageRange, nEpisodes):</div><div class="line">    smoothedRewardsSarsa[i] = np.mean(rewardsSarsa[i - averageRange: i + <span class="number">1</span>])</div><div class="line">    smoothedRewardsQLearning[i] = np.mean(rewardsQLearning[i - averageRange: i + <span class="number">1</span>])</div><div class="line"></div><div class="line"><span class="comment"># display optimal policy</span></div><div class="line">print(<span class="string">'Sarsa Optimal Policy:'</span>)</div><div class="line">printOptimalPolicy(stateActionValuesSarsa)</div><div class="line">print(<span class="string">'Q-Learning Optimal Policy:'</span>)</div><div class="line">printOptimalPolicy(stateActionValuesQLearning)</div></pre></td></tr></table></figure><p>The results are as follows (emits the results of the changes of reward):</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/cliff_walk_opti_policy.png" alt="cliff_walk_optimal_policy"></p><p>Now let us compare the three algorithms:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">stepSizes = np.arange(<span class="number">0.1</span>, <span class="number">1.1</span>, <span class="number">0.1</span>)</div><div class="line">    nEpisodes = <span class="number">1000</span></div><div class="line">    runs = <span class="number">10</span></div><div class="line"></div><div class="line">    ASY_SARSA = <span class="number">0</span></div><div class="line">    ASY_EXPECTED_SARSA = <span class="number">1</span></div><div class="line">    ASY_QLEARNING = <span class="number">2</span></div><div class="line">    INT_SARSA = <span class="number">3</span></div><div class="line">    INT_EXPECTED_SARSA = <span class="number">4</span></div><div class="line">    INT_QLEARNING = <span class="number">5</span></div><div class="line">    methods = range(<span class="number">0</span>, <span class="number">6</span>)</div><div class="line"></div><div class="line">    performace = np.zeros((<span class="number">6</span>, len(stepSizes)))</div><div class="line">    <span class="keyword">for</span> run <span class="keyword">in</span> range(<span class="number">0</span>, runs):</div><div class="line">        <span class="keyword">for</span> ind, stepSize <span class="keyword">in</span> zip(range(<span class="number">0</span>, len(stepSizes)), stepSizes):</div><div class="line">            stateActionValuesSarsa = np.copy(stateActionValues)</div><div class="line">            stateActionValuesExpectedSarsa = np.copy(stateActionValues)</div><div class="line">            stateActionValuesQLearning = np.copy(stateActionValues)</div><div class="line">            <span class="keyword">for</span> ep <span class="keyword">in</span> range(<span class="number">0</span>, nEpisodes):</div><div class="line">                print(<span class="string">'run:'</span>, run, <span class="string">'step size:'</span>, stepSize, <span class="string">'episode:'</span>, ep)</div><div class="line">                sarsaReward = sarsa(stateActionValuesSarsa, expected=<span class="keyword">False</span>, stepSize=stepSize)</div><div class="line">                expectedSarsaReward = sarsa(stateActionValuesExpectedSarsa, expected=<span class="keyword">True</span>, stepSize=stepSize)</div><div class="line">                qLearningReward = qLearning(stateActionValuesQLearning, stepSize=stepSize)</div><div class="line">                performace[ASY_SARSA, ind] += sarsaReward</div><div class="line">                performace[ASY_EXPECTED_SARSA, ind] += expectedSarsaReward</div><div class="line">                performace[ASY_QLEARNING, ind] += qLearningReward</div><div class="line"></div><div class="line">                <span class="keyword">if</span> ep &lt; <span class="number">100</span>:</div><div class="line">                    performace[INT_SARSA, ind] += sarsaReward</div><div class="line">                    performace[INT_EXPECTED_SARSA, ind] += expectedSarsaReward</div><div class="line">                    performace[INT_QLEARNING, ind] += qLearningReward</div><div class="line"></div><div class="line">    performace[:<span class="number">3</span>, :] /= nEpisodes * runs</div><div class="line">    performace[<span class="number">3</span>:, :] /= runs * <span class="number">100</span></div><div class="line">    labels = [<span class="string">'Asymptotic Sarsa'</span>, <span class="string">'Asymptotic Expected Sarsa'</span>, <span class="string">'Asymptotic Q-Learning'</span>,</div><div class="line">              <span class="string">'Interim Sarsa'</span>, <span class="string">'Interim Expected Sarsa'</span>, <span class="string">'Interim Q-Learning'</span>]</div><div class="line">    plt.figure(<span class="number">2</span>)</div><div class="line">    <span class="keyword">for</span> method, label <span class="keyword">in</span> zip(methods, labels):</div><div class="line">        plt.plot(stepSizes, performace[method, :], label=label)</div><div class="line">    plt.xlabel(<span class="string">'alpha'</span>)</div><div class="line">    plt.ylabel(<span class="string">'reward per episode'</span>)</div><div class="line">    plt.legend()</div></pre></td></tr></table></figure><p>The results are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/cliff_walk_3_results.png" alt="compare3algo_cliff_walk"></p><p>As an on-policy method, Expected Sarsa retains the signiﬁcant advantage of Sarsa over Q-learning on this problem. In addition, Expected Sarsa shows a signiﬁcant improvement over Sarsa over a wide range of values for the step-size parameter α. In cliﬀ walking the state transitions are all deterministic and all randomness comes from the policy. In such cases, Expected Sarsa can safely set α = 1 without suﬀering any degradation of asymptotic performance, whereas Sarsa can only perform well in the long run at a small value of α, at which short-term performance is poor. In this and other examples there is a consistent empirical advantage of Expected Sarsa over Sarsa. Except for the small additional computational cost, Expected Sarsa may completely dominate both of the other more-well-known TD control algorithms.</p><h3 id="Double-Q-learning"><a href="#Double-Q-learning" class="headerlink" title="Double Q-learning"></a>Double Q-learning</h3><p>All the control algorithms that we have discussed so far involve maximization in the construction of their target policies. For example, in Q-learning the target policy is the greedy policy given the current action values, which is deﬁned with a max, and in Sarsa the policy is often ε-greedy, which also involves a maximization operation. In these algorithms, a maximum over estimated values is used implicitly as an estimate of the maximum value, which can lead to a signiﬁcant positive bias. To see why, consider a single state s where there are many actions a whose true values, $q(s, a)$ are all zero but whose estimated values, $Q(s, a)$, are uncertain and thus distributed some above and some below zero. The maximum of the true values is zero, but the maximum of the estimates is positive, a positive bias. We call this maximization<br>bias.</p><h4 id="Example-Maximization-Bias"><a href="#Example-Maximization-Bias" class="headerlink" title="Example: Maximization Bias"></a>Example: Maximization Bias</h4><p>We have a small MDP:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/mb.png" alt="mb"></p><p>the expected return for any trajectory starting with left (from <strong>B</strong>) is −0.1, and thus taking left in state A is always a mistake. Nevertheless, our control methods may favor left because of maximization bias making B appear to have a positive value. The results (paste later) shows that Q-learning with ε-greedy action selection initially learns to strongly favor the left action on this example. Even at asymptote, Q-learning takes the left action about 5% more often than is optimal at our parameter settings (ε = 0.1, α = 0.1, and γ = 1).</p><p>We could use the Double Q-learning algorithm to avoid this problem. One way to view the problem is that it is due to using the same samples (plays) both to determine the maximizing action and to estimate its value. Suppose we divided the plays in two sets and used them to learn two independent estimates.</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/dbq.png" alt="dbq"></p><p>Of course there are also doubled versions of Sarsa and Expected Sarsa.</p><p>Now let us develop the both algorithms and compare their performance on the earlier example. First we define the problem environment:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># state A</span></div><div class="line">STATE_A = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="comment"># state B</span></div><div class="line">STATE_B = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># use one terminal state</span></div><div class="line">STATE_TERMINAL = <span class="number">2</span></div><div class="line"></div><div class="line"><span class="comment"># starts from state A</span></div><div class="line">STATE_START = STATE_A</div><div class="line"></div><div class="line"><span class="comment"># possible actions in A</span></div><div class="line">ACTION_A_RIGHT = <span class="number">0</span></div><div class="line">ACTION_A_LEFT = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># possible actions in B, maybe 10 actions</span></div><div class="line">actionsOfB = range(<span class="number">0</span>, <span class="number">10</span>)</div><div class="line"></div><div class="line"><span class="comment"># all possible actions</span></div><div class="line">stateActions = [[ACTION_A_RIGHT, ACTION_A_LEFT], actionsOfB]</div><div class="line"></div><div class="line"><span class="comment"># state action pair values, if a state is a terminal state, then the value is always 0</span></div><div class="line">stateActionValues = [np.zeros(<span class="number">2</span>), np.zeros(len(actionsOfB)), np.zeros(<span class="number">1</span>)]</div><div class="line"></div><div class="line"><span class="comment"># set up destination for each state and each action</span></div><div class="line">actionDestination = [[STATE_TERMINAL, STATE_B], [STATE_TERMINAL] * len(actionsOfB)]</div><div class="line"></div><div class="line"><span class="comment"># probability for exploration</span></div><div class="line">EPSILON = <span class="number">0.1</span></div><div class="line"></div><div class="line"><span class="comment"># step size</span></div><div class="line">ALPHA = <span class="number">0.1</span></div><div class="line"></div><div class="line"><span class="comment"># discount for max value</span></div><div class="line">GAMMA = <span class="number">1.0</span></div></pre></td></tr></table></figure><p>And we need a policy to take an action:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># choose an action based on epsilon greedy algorithm</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseAction</span><span class="params">(state, stateActionValues)</span>:</span></div><div class="line">    <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, EPSILON) == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> np.random.choice(stateActions[state])</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> argmax(stateActionValues[state])</div></pre></td></tr></table></figure><p>After take an action, we get the reward:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># take @action in @state, return the reward</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeAction</span><span class="params">(state, action)</span>:</span></div><div class="line">    <span class="keyword">if</span> state == STATE_A:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    <span class="keyword">return</span> np.random.normal(<span class="number">-0.1</span>, <span class="number">1</span>)</div></pre></td></tr></table></figure><p>Next, we develop the Double Q-learning algorithm:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># if there are two state action pair value array, use double Q-Learning</span></div><div class="line"><span class="comment"># otherwise use normal Q-Learning</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">qLearning</span><span class="params">(stateActionValues, stateActionValues2=None)</span>:</span></div><div class="line">    currentState = STATE_START</div><div class="line">    <span class="comment"># track the # of action left in state A</span></div><div class="line">    leftCount = <span class="number">0</span></div><div class="line">    <span class="keyword">while</span> currentState != STATE_TERMINAL:</div><div class="line">        <span class="keyword">if</span> stateActionValues2 <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            currentAction = chooseAction(currentState, stateActionValues)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="comment"># derive a action form Q1 and Q2</span></div><div class="line">            currentAction = chooseAction(currentState, [item1 + item2 <span class="keyword">for</span> item1, item2 <span class="keyword">in</span> zip(stateActionValues, stateActionValues2)])</div><div class="line">        <span class="keyword">if</span> currentState == STATE_A <span class="keyword">and</span> currentAction == ACTION_A_LEFT:</div><div class="line">            leftCount += <span class="number">1</span></div><div class="line">        reward = takeAction(currentState, currentAction)</div><div class="line">        newState = actionDestination[currentState][currentAction]</div><div class="line">        <span class="keyword">if</span> stateActionValues2 <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            currentStateActionValues = stateActionValues</div><div class="line">            targetValue = np.max(currentStateActionValues[newState])</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, <span class="number">0.5</span>) == <span class="number">1</span>:</div><div class="line">                currentStateActionValues = stateActionValues</div><div class="line">                anotherStateActionValues = stateActionValues2</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                currentStateActionValues = stateActionValues2</div><div class="line">                anotherStateActionValues = stateActionValues</div><div class="line">            bestAction = argmax(currentStateActionValues[newState])</div><div class="line">            targetValue = anotherStateActionValues[newState][bestAction]</div><div class="line"></div><div class="line">        <span class="comment"># Q-Learning update</span></div><div class="line">        currentStateActionValues[currentState][currentAction] += ALPHA * (</div><div class="line">            reward + GAMMA * targetValue - currentStateActionValues[currentState][currentAction])</div><div class="line">        currentState = newState</div><div class="line">    <span class="keyword">return</span> leftCount</div></pre></td></tr></table></figure><p>And now, let us solve the example problem:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># each independent run has 300 episodes</span></div><div class="line">    episodes = <span class="number">300</span></div><div class="line">    leftCountsQ = np.zeros(episodes)</div><div class="line">    leftCountsDoubleQ = np.zeros(episodes)</div><div class="line">    runs = <span class="number">1000</span></div><div class="line">    <span class="keyword">for</span> run <span class="keyword">in</span> range(<span class="number">0</span>, runs):</div><div class="line">        print(<span class="string">'run:'</span>, run)</div><div class="line">        stateActionValuesQ = [np.copy(item) <span class="keyword">for</span> item <span class="keyword">in</span> stateActionValues]</div><div class="line">        stateActionValuesDoubleQ1 = [np.copy(item) <span class="keyword">for</span> item <span class="keyword">in</span> stateActionValues]</div><div class="line">        stateActionValuesDoubleQ2 = [np.copy(item) <span class="keyword">for</span> item <span class="keyword">in</span> stateActionValues]</div><div class="line">        leftCountsQ_ = [<span class="number">0</span>]</div><div class="line">        leftCountsDoubleQ_ = [<span class="number">0</span>]</div><div class="line">        <span class="keyword">for</span> ep <span class="keyword">in</span> range(<span class="number">0</span>, episodes):</div><div class="line">            leftCountsQ_.append(leftCountsQ_[<span class="number">-1</span>] + qLearning(stateActionValuesQ))</div><div class="line">            leftCountsDoubleQ_.append(leftCountsDoubleQ_[<span class="number">-1</span>] + qLearning(stateActionValuesDoubleQ1, stateActionValuesDoubleQ2))</div><div class="line">        <span class="keyword">del</span> leftCountsQ_[<span class="number">0</span>]</div><div class="line">        <span class="keyword">del</span> leftCountsDoubleQ_[<span class="number">0</span>]</div><div class="line">        leftCountsQ += np.asarray(leftCountsQ_, dtype=<span class="string">'float'</span>) / np.arange(<span class="number">1</span>, episodes + <span class="number">1</span>)</div><div class="line">        leftCountsDoubleQ += np.asarray(leftCountsDoubleQ_, dtype=<span class="string">'float'</span>) / np.arange(<span class="number">1</span>, episodes + <span class="number">1</span>)</div><div class="line">    leftCountsQ /= runs</div><div class="line">    leftCountsDoubleQ /= runs</div><div class="line">    plt.figure()</div><div class="line">    plt.plot(leftCountsQ, label=<span class="string">'Q-Learning'</span>)</div><div class="line">    plt.plot(leftCountsDoubleQ, label=<span class="string">'Double Q-Learning'</span>)</div><div class="line">    plt.plot(np.ones(episodes) * <span class="number">0.05</span>, label=<span class="string">'Optimal'</span>)</div><div class="line">    plt.xlabel(<span class="string">'episodes'</span>)</div><div class="line">    plt.ylabel(<span class="string">'% left actions from A'</span>)</div><div class="line">    plt.legend()</div></pre></td></tr></table></figure><p>Ok, results are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/td/dbq_result.png" alt="dbq_result"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;If one had to identify one idea as central and novel to reinforcement learning, it would undoubtedly be &lt;em&gt;temporal-difference&lt;/em&gt; (TD)
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="TD" scheme="http://yoursite.com/tags/TD/"/>
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning Resources</title>
    <link href="http://yoursite.com/2017/06/30/Reinforcement-Learning-Resources/"/>
    <id>http://yoursite.com/2017/06/30/Reinforcement-Learning-Resources/</id>
    <published>2017-06-30T13:07:44.000Z</published>
    <updated>2017-06-30T13:16:39.391Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Books"><a href="#Books" class="headerlink" title="Books"></a>Books</h1><ul><li>Sutton’s book has new <a href="https://github.com/ewanlee/RL-Resources/blob/master/book/bookdraft2017june.pdf" target="_blank" rel="external">update</a> (draft, version 2017) !</li></ul><h1 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h1><ul><li>TBC…</li></ul><h1 id="Projects"><a href="#Projects" class="headerlink" title="Projects"></a>Projects</h1><ul><li>TBC…</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Books&quot;&gt;&lt;a href=&quot;#Books&quot; class=&quot;headerlink&quot; title=&quot;Books&quot;&gt;&lt;/a&gt;Books&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;Sutton’s book has new &lt;a href=&quot;https://github.com/ewa
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>A simple AI car</title>
    <link href="http://yoursite.com/2017/06/27/A-simple-AI-car/"/>
    <id>http://yoursite.com/2017/06/27/A-simple-AI-car/</id>
    <published>2017-06-27T05:56:15.000Z</published>
    <updated>2017-06-28T04:11:01.612Z</updated>
    
    <content type="html"><![CDATA[<h3 id="I-定义"><a href="#I-定义" class="headerlink" title="I. 定义"></a>I. 定义</h3><h4 id="项目概述"><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h4><p>项目地址：<a href="https://github.com/ewanlee/rl_car" target="_blank" rel="external">https://github.com/ewanlee/rl_car</a></p><p>最近，自动驾驶汽车十分火热。但是，自动驾驶问题是一个机器学习集大成的问题，十分的复杂。因此，我们希望可以设计出一个简单的学习环境能够对自动驾驶问题进行模拟，并且不需要GPU （主要是太贵）。</p><p>我们的学习环境借鉴了Matt Harvey’s virtual car[1] 的环境设置。运用了 TensorFlow， Python 2.7 以及 PyGame 5.0. 本项目中运用了深度Q强化学习算法，但是为了符合我们上面提到的要求，我们去掉了该算法中 “深度” 的部分。代码设计的一些思想借鉴了 songotrek’s Q学习算法的TensorFlow实现 [2].</p><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p><img src="https://github.com/drscott173/ml_capstone/raw/master/figures/game.jpg" alt="fig1"></p><p><em>图片来源于[1]</em></p><p>我们所要解决的问题就是设计一个算法使得模拟小车能够自动行驶。</p><p>上图就是我们实验用的环境。可以看出，它足够简单，但是足够进行一些强化学习算法的验证。最小的圆圈是我们模拟的小车，它拥有三个声纳感应器 （三条白色的虚线）。三个较大的圆圈代表障碍物，它会随着时间的变化缓慢移动。左上角的圆圈代表一只在环境中游走（速度相比于障碍物要快很多）的猫。圆圈上的缺口表示朝向。我们所要解决的问题就是希望小车可以尽可能长时间的运动，但不会撞到障碍物或者猫。</p><h4 id="环境需求"><a href="#环境需求" class="headerlink" title="环境需求"></a>环境需求</h4><ul><li>Anaconda Python Distribution 2.7 [3]</li><li>TensorFlow for Anaconda [4]</li><li>PyGame [5]，用于展示图形界面</li><li>PyMunk [6]，为了模拟游戏中的物理环境</li><li>Numpy [7]</li><li>Scipy [8]</li></ul><p>实验运行的环境为 Ubuntu 16.04 LTS 虚拟机， 虚拟机为VMware Workstation 12.5.2 build-4638234。虚拟机运行在Windows 10 Pro上。</p><h4 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h4><p>我们的baseline是一个随机（行为随机选择）小车，最后的评价指标是我们定义的指标score，代表小车存活的时间（在游戏中代表小车存活的frame）。并且，score是进行1000次实验的平均值。</p><h4 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h4><p>我们使用的是 Deep Q Learning [9] 论文中定义的 QMax 值。</p><p>QMax 值指的是在一定时间范围内，对于所有的训练样本，Q 函数（使用神经网络进行拟合）输出的最大的 Q-value。随着agent（模拟小车）不断进行学习，它将采取更加优秀的策略，因此存活时间会更长，那么 Q-value (在我们的实验中便是score) 会越大。如果我们的优化目标是增大 Q-value 的上界，也便相应的增大了 Q-value 值。</p><h4 id="学习过程监测"><a href="#学习过程监测" class="headerlink" title="学习过程监测"></a>学习过程监测</h4><p>我们使用的是Tensorflow自带的TensorBoard来监测QMax以及最大score的变化情况（希望整体趋势是逐渐增大的）</p><p>下面是运行过程中的截图：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl_car/tensdorboard_sing.png" alt="s"></p><p>下面是各网络参数的分布变化情况：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl_car/tensdorboard_h.png" alt="h"></p><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><h4 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h4><p>由于强化学习任务的数据集一般都是实验中产生的，因此不需要收集数据。在每一次迭代过程中，模拟环境提供以下数据（自己设计的）：</p><ul><li>s1, s2, s3 三个声纳传感器的数值，范围是[0, 40]，整数值，代表三个方向上障碍物的距离。范围确定为这样的原因是，为了检测障碍物，声纳传感器从源头开始，逐渐往外探测，每向外探测一次，距离就加1（可以看成虚线的点数，即虚线是由多少个点组成的）。</li><li>x 代表x轴的位置，范围是[0, 1]</li><li>y 代表y轴的位置，范围是[0, 1]</li><li>theta 代表小车的方向，弧度表示，范围是[0, 2$\pi$]</li></ul><p>小车能够采取的动作如下：</p><ul><li>0，代表直走</li><li>1， 往左转0.2弧度</li><li>2， 往右转0.2弧度</li></ul><p>小车每进行一次动作会使得状态发生变化，并且有以下返回值：</p><ul><li>Reward，一个[-100, 10]之间的整数，负数代表动作产生的结果不好，正数则相反</li><li>Termianl，布尔型数据，代表小车是否存活（是否撞到障碍物）</li></ul><p>我们和原始模型[1]不同的是，输了$s_1, s_2, s_3$三个特征之外，额外增加了$x, y, theta$三个特征。因为我们希望小车能够尽可能往地图中间运行，远离墙壁。并且当它们靠近障碍物时，能够选择更加合理的方向躲避。</p><p>值得说明的一点是，小车如何检测是否撞到障碍物的问题。实验中使用的方法是检测声纳传感器的数值，如果数值是1（而不是0）就认为小车撞上了障碍物，并给出一个-100的reward。此时实验将重新开始，小车位置的选择是根据物理定律模拟的，即根据碰撞的角度给小车一个反向的速度，并且小车的朝向随机变化。这样模拟出一种碰撞后的混乱状态。</p><h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>下面介绍Deep Q-learning算法。</p><p><img src="https://github.com/drscott173/ml_capstone/raw/master/figures/rel.png" alt="Reinforcement Learning"></p><p>以上的实验环境可以形式化的表述，如上图所示。我们拥有一个agent（小车），在时间$t$时必须要选择一个动作$a_t$。Agent采取动作与环境进行交互，使得在时间$t+1$时状态变为$s_{t+1}$。同时agent接收到环境给它的一个反馈$r_t$。这样agent就根据$(s_t, a_t, s_{t+1}, r_t)$来决定采取的动作$a_{t+1}$是什么。整个问题就是不断重复上述过程直到到达某个结束条件。</p><p>机器学习领域将这个问题称为强化学习问题。每一个动作通过reward被 “强化”，使得agent不断接近我们期望它到达的状态。但是在强化学习中存在一个reward延迟的问题，也就是说，某一个action的回报可能不是即时的，需要很多时间步之后才能确定。举个例子，下棋的过程中需要布局，但是这个布局并不会马上给你带来好处，需要在以后的某个特定时间，你的对上掉入了你很久前设置的陷阱里，这时候才给你带来好处。所以，我们需要采用一种方式来对这个问题进行建模。我们定义一个价值函数$Q(s_t, a_t)$，它表示在状态$s_t$是采取$a_t$这个动作带来的 “价值”，而不是reward，reward是即时的，但是价值是若干时间步带来的reward的某种综合考量，更具实际意义。那么接下来的问题就是价值函数应当如何定义。</p><p>最直观的想法就是，我们可以把强化学习问题定义为一个动态规划的问题。这里我直接列出公式，也就是非常著名的贝尔曼方程（Bellman equation）：</p><p><img src="https://github.com/drscott173/ml_capstone/raw/master/figures/bellman.png" alt="Bellman equation"></p><p>可以看到，解决强化学习问题是一个不断迭代的过程，那么如何初始化Q非常重要。但实际上，如果迭代次数趋紧无穷大时，Q的初始值对于最终的结果并没有影响，因此一般来说只要初始化为均值为0的高斯白噪音。</p><p>对于小规模的强化学习问题，由于状态的Q值随着迭代次数的增加会不断更新，那么我们需要一个地方来存储这些值。传统的强化学习算法一般采用一张表格（数组或字典）来存储这些值。但是随着问题规模的增大，状态会显著增加。对于我们的问题，状态空间更是无限的，因为状态是由浮点数组成的。这样我们就不可能把这些状态对应的Q值都存储下来。</p><p>我们采用一个如下所示的神经网络来代替这些表格，即找出状态和Q值之间的一个映射。这里值得说明的是，网络输出的是所有动作对应的Q值，这是Deep Q-learning算法的一个创新点。</p><p><img src="https://github.com/drscott173/ml_capstone/raw/master/figures/network.png" alt="Neural Network"></p><p>在我们的实验中，输入维度是6维（$s_1, s_2, s_3, x, y, theta$），输出是3维（对应三个动作0， 1， 2）。我们采用白噪音来初始化网络。具体来说，权重采用标准高斯噪音，偏差初始化为0.01。</p><p>至于训练过程，Deep Q-learning算法采用了一个trick。该算法采用了两个完全相同的网络，其中一个用来训练，另一个则用来预测。这样还可以防止过拟合。用于训练网络的训练集并不是agent当前的四元组$(s_t, a_t, s_{t+1}, r_t)$， 而是从最近四元组历史（之前某一个时间窗口中的所有四元组）中随机采样出的一个minibatch。我们通过这些训练样本来更新训练网络的参数，经过一定时间的训练之后，把训练网络的参数复制给预测网络，用预测网络来继续产生训练样本，供训练网络使用。整个算法就是不断重复上述过程直至收敛。具体算法的伪代码如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">Initialize replay memory D to size N</div><div class="line">Initialize action-value function Q <span class="keyword">with</span> random weights</div><div class="line"><span class="keyword">for</span> episode = <span class="number">1</span>, M do</div><div class="line">	Initialize state s_1</div><div class="line">	<span class="keyword">for</span> t = <span class="number">1</span>, T do</div><div class="line">		With probability ϵ select random action a_t</div><div class="line">		otherwise select a_t=argmax_a  Q(s_t,a; θ_i)</div><div class="line">		Execute action a_t <span class="keyword">in</span> emulator <span class="keyword">and</span> observe r_t <span class="keyword">and</span> s_(t+<span class="number">1</span>)</div><div class="line">		Store transition (s_t,a_t,r_t,s_(t+<span class="number">1</span>)) <span class="keyword">in</span> D</div><div class="line">		Sample a minibatch of transitions (s_j,a_j,r_j,s_(j+<span class="number">1</span>)) <span class="keyword">from</span> D</div><div class="line">		Set y_j:=</div><div class="line">			r_j <span class="keyword">for</span> terminal s_(j+<span class="number">1</span>)</div><div class="line">			r_j+γ*max_(a^<span class="string">') Q(s_(j+1),a'</span>; θ_i) <span class="keyword">for</span> non-terminal s_(j+<span class="number">1</span>)</div><div class="line">		Perform a gradient step on (y_j-Q(s_j,a_j; θ_i))^<span class="number">2</span> <span class="keyword">with</span> respect to θ</div><div class="line">	end <span class="keyword">for</span></div><div class="line">end <span class="keyword">for</span></div></pre></td></tr></table></figure><h4 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h4><p>我们希望算法能够比随机选择更好。下面是进行1000次实验随机算法的结果：</p><p><img src="https://github.com/drscott173/ml_capstone/raw/master/figures/table1.png" alt="Table1"></p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><p>我们在实验之前进行了数据的标准化，使得所有数据都处于0到1之间，这样可以避免梯度爆炸等现象的发生。</p><p>$x， y$ 这两个特征没有进行标准化，因为已经符合要求。$theta$通过除以$2\pi$进行标准化。在没有进行标准化之前，我们在实验中发现，$theta$的值会达到$10^3$这个数量级，使得网络发生了bias shift现象。$s_1, s_2, s_3$通过除以40来进行标准化。</p><p>我们同样试着能够将reward也进行标准化，将其范围缩小到[-1, 1]。因为DQN论文中同样使用了这种方法，使得该算法应用在不同的Atari游戏上时不用对算法进行参数的调整。但是，我们在网络训练的前一百万步并没有发现性能有明显的提升。因为reward的值更大的话，学习将会更容易，这样reward信号会更加明显，不会被淹没在网络的高斯噪声中。所以我们希望reward能够大一点，但是多大比较合适又是一个问题。</p><p>我们所借鉴的算法[1]，将这个reward的最小值设置成了-500（小车撞上了障碍物），但我们实验发现这个值设置的过小（下面将会解释），所以最后的范围调整为[-100, 10] （通过裁剪）。我们把这个过程称之为reward正则化。</p><h4 id="Reward-正则化"><a href="#Reward-正则化" class="headerlink" title="Reward 正则化"></a>Reward 正则化</h4><p>在网络训练（反向传播）的过程中，我们希望最小化代价函数。我们的代价函数选为训练网络输出的Q值与训练样本的Q值之间的MSE。在试验过程中，我们发现，对于$s_1, s_2, s_3$值都比较大的状态，其reward都会落在[0, 40]的范围内，并且均值为20。但是网络刚开始训练时，输出值为均值为0的高斯噪声。也就是说初始的loss处于[400-1600]的范围内（由于最后的loss需要除以样本的数量，所以loss等于一个样本的loss）。</p><p>现在我们假定网络处于一个最优点附近，这时候小车突然撞上了某个障碍物，那么唯一的可能就是猫出现在了小车后面。这时候就会引入一个250000的loss（如果将reward的最小值设置为-500）。但是网络初始时的loss都只处于[400, 1600]的范围内，这个loss是初始loss的100倍。这么大的loss所引入的梯度将会使得网络走一段非常大的距离，这就很可能直接跳过了局部最优点。不断如此的话，网络就会震荡的非常厉害。</p><p>让我们用数学的观点来解释这个问题。当reward的负值设置的过大，将会使得原始问题空间距离最优空间有一个非常大的偏差，很难通过梯度下降靠近。这个大的偏差在问题空间创造了一些非常陡峭的cliff。就像我们爬山一样，好不容易爬到了山顶附近，一不小心就掉下了悬崖，那么我们只能一步一步非常慢的爬上来，花很久的时间才能到达刚才的位置。如果一不小心又掉下去了，那么又要重新爬。</p><p>因此，减小reward的范围十分重要，这样可以减小cliff的坡度，使得网络训练更快更容易。但是又不能太小，以免被噪声淹没。最后我们选定了[-100, 10]这个范围。</p><h4 id="模型迭代过程"><a href="#模型迭代过程" class="headerlink" title="模型迭代过程"></a>模型迭代过程</h4><p>我们最开始直接采用现成的模型，是一个两层的神经网络（不包括输入层），效果已经不错了，但是小车总是撞上障碍物。因此我们做了一些改变：</p><ul><li>类似DQN，我们使用了最近四次的state，将其映射为一个input，这使得我们的QMax值提高到了120</li><li>我们继续进行改变，从使用最近四次改为最近16次，使得我们的QMax值提高到了140</li><li>我们尝试了使用一个更小的网络进行学习（2层，每层32维），并且只使用一个state进行输入，但是结果比随机算法更差。</li><li>继续尝试使用grid search选择模型，还是两层网络，每一层的维数从32到512，训练迭代次数为200, 000，但是最后的QMax值还是不能超过140。</li><li>我们尝试了更小的时间窗口，更大的minibatch，网络训练时震荡的十分厉害</li><li>我们尝试在小车的背面增加一个声纳传感器，发i按网络训练速度变快了，但是最后的QMax值还是不能达到更高。</li></ul><p>这些尝试说明应当是两层网络的特征表达能力不够，我们尝试使用更深的网络。最后使用的网络有8层（不算输入输出层），输入层和输出层各有32维，中间6层为64维。最后取得了很好的效果，QMax达到了之前的10倍。</p><p>同时，我们在每一层网络后都加入了一个20%的dropout层（除了输入层以及输出层之前），激活函数选用的ReLU函数。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>算法的训练过程如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">In(<span class="number">4</span>): ai.cycle()</div><div class="line">t= <span class="number">11000</span></div><div class="line">[<span class="number">654.53412</span>, <span class="number">322.84866</span>, <span class="number">86.578796</span>, <span class="number">1414.0239</span>]</div><div class="line">Games played  <span class="number">539</span></div><div class="line">Epoch Max score <span class="number">144</span></div><div class="line">Epoch Mean score <span class="number">30.3580705009</span></div><div class="line">t= <span class="number">21000</span></div><div class="line">[<span class="number">474.16202</span>, <span class="number">251.2959</span>, <span class="number">79.489487</span>, <span class="number">1243.3118</span>]</div><div class="line">Games played  <span class="number">774</span></div><div class="line">Epoch Max score <span class="number">223</span></div><div class="line">Epoch Mean score <span class="number">42.6255319149</span></div><div class="line">t= <span class="number">31000</span></div><div class="line">[<span class="number">388.32297</span>, <span class="number">202.05305</span>, <span class="number">79.290771</span>, <span class="number">1086.0581</span>]</div><div class="line">Games played  <span class="number">1020</span></div><div class="line">Epoch Max score <span class="number">153</span></div><div class="line">Epoch Mean score <span class="number">40.5081300813</span></div><div class="line">t= <span class="number">41000</span></div><div class="line">[<span class="number">470.96552</span>, <span class="number">234.70471</span>, <span class="number">129.87579</span>, <span class="number">1320.3688</span>]</div><div class="line">Games played  <span class="number">1281</span></div><div class="line">Epoch Max score <span class="number">251</span></div><div class="line">Epoch Mean score <span class="number">38.3908045977</span></div><div class="line">t= <span class="number">51000</span></div><div class="line">[<span class="number">549.32666</span>, <span class="number">203.20442</span>, <span class="number">176.22263</span>, <span class="number">1079.8307</span>]</div><div class="line">Games played  <span class="number">1546</span></div><div class="line">Epoch Max score <span class="number">226</span></div><div class="line">Epoch Mean score <span class="number">37.7773584906</span></div><div class="line">t= <span class="number">61000</span></div><div class="line">[<span class="number">610.16583</span>, <span class="number">232.79211</span>, <span class="number">224.97626</span>, <span class="number">1264.9712</span>]</div><div class="line">Games played  <span class="number">1759</span></div><div class="line">Epoch Max score <span class="number">484</span></div><div class="line">Epoch Mean score <span class="number">46.5774647887</span></div><div class="line">...</div></pre></td></tr></table></figure><p>实验结果：</p><p><img src="https://github.com/drscott173/ml_capstone/raw/master/figures/table2.png" alt="Table2"></p><p>可以看出，我们的算法性能完全超越了随机算法。</p><p>下面是我们训练大概250,000次后的结果：</p><p><img src="https://github.com/drscott173/ml_capstone/raw/master/figures/qmax_win.png" alt="Best Qmax"></p><p>关于随机算法以及Q-learning算法的动画展示可以参照项目地址。</p><p>但是我们发现小车还是会撞到障碍物，这经常发生在小车碰撞之后的恢复过程中。这时候小车可能到达地图的角落，充满障碍物。但是因为小车只有三个传感器，即使在背面加上还是太少了，所以信息捕捉不够。这是模型需要改进的地方。我们可以事先在小车中存储一个类似于地图的数据。</p><p>另外，由于小车一直是匀速行驶，如果加入加速，减速等过程，应当会使得性能更好。但是由于时间原因，我们并没有进一步改进。</p><h4 id="进一步工作"><a href="#进一步工作" class="headerlink" title="进一步工作"></a>进一步工作</h4><p>本次实验仅仅是在二维环境中进行的。但是严格来说并不是复杂环境的最佳简化。三维环境更加贴近现实情况，例如我们可以设计一个飞行的环境模拟。</p><h3 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h3><p>[1]. <a href="https://medium.com/@harvitronix/using-reinforcement-learning-in-python-to-teach-a-virtual-car-to-avoid-obstacles-6e782cc7d4c6#.58wi2s7ct" target="_blank" rel="external">https://medium.com/@harvitronix/using-reinforcement-learning-in-python-to-teach-a-virtual-car-to-avoid-obstacles-6e782cc7d4c6#.58wi2s7ct</a></p><p>[2]. <a href="https://github.com/songrotek/DQN-Atari-Tensorflow/blob/master/BrainDQN_Nature.py" target="_blank" rel="external">https://github.com/songrotek/DQN-Atari-Tensorflow/blob/master/BrainDQN_Nature.py</a></p><p>[3]. <a href="https://www.continuum.io/why-anaconda" target="_blank" rel="external">https://www.continuum.io/why-anaconda</a></p><p>[4]. <a href="https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#anaconda-installation" target="_blank" rel="external">https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#anaconda-installation</a></p><p>[5]. <a href="http://www.pygame.org/wiki/GettingStarted" target="_blank" rel="external">http://www.pygame.org/wiki/GettingStarted</a></p><p>[6]. <a href="http://www.pymunk.org/en/latest/" target="_blank" rel="external">http://www.pymunk.org/en/latest/</a></p><p>[7]. <a href="http://www.numpy.org/" target="_blank" rel="external">http://www.numpy.org/</a></p><p>[8]. <a href="http://www.scipy.org/" target="_blank" rel="external">http://www.scipy.org/</a></p><p>[9]. <a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf" target="_blank" rel="external">https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;I-定义&quot;&gt;&lt;a href=&quot;#I-定义&quot; class=&quot;headerlink&quot; title=&quot;I. 定义&quot;&gt;&lt;/a&gt;I. 定义&lt;/h3&gt;&lt;h4 id=&quot;项目概述&quot;&gt;&lt;a href=&quot;#项目概述&quot; class=&quot;headerlink&quot; title=&quot;项目概述&quot;&gt;&lt;
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Store Management System</title>
    <link href="http://yoursite.com/2017/06/27/Store-Management-System/"/>
    <id>http://yoursite.com/2017/06/27/Store-Management-System/</id>
    <published>2017-06-27T03:32:49.000Z</published>
    <updated>2017-06-27T05:32:52.802Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SMS"><a href="#SMS" class="headerlink" title="SMS"></a>SMS</h1><p>SMS (Store Management System), 一个简单的网店管理系统。</p><p>源码：<a href="https://github.com/ewanlee/sms" target="_blank" rel="external">https://github.com/ewanlee/sms</a></p><p>这是一个用于展示微服务的 proof-of-concept 应用，运用了Spring Boot, Spring Cloud 以及 Docker部署。</p><h2 id="核心服务"><a href="#核心服务" class="headerlink" title="核心服务"></a>核心服务</h2><p>SHOP 分成了三个核心微服务，它们都是独立开发的，采用了Spring MVC架构：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/services.png" alt="services"></p><p>Order service</p><p>进行订单的添加，删除，以及显示</p><table><thead><tr><th style="text-align:center">Method</th><th style="text-align:center">Path</th><th style="text-align:center">Description</th><th style="text-align:center">User authenticated</th><th style="text-align:center">Available from UI</th></tr></thead><tbody><tr><td style="text-align:center">GET</td><td style="text-align:center">/</td><td style="text-align:center">返回订单列表</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">GET</td><td style="text-align:center">/form</td><td style="text-align:center">增加订单，并进行用户选择</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">POST</td><td style="text-align:center">/line</td><td style="text-align:center">增加一条订单到数据库</td><td style="text-align:center">无</td><td style="text-align:center">无</td></tr><tr><td style="text-align:center">GET</td><td style="text-align:center">/{id}</td><td style="text-align:center">显示某一条订单的详情</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">POST</td><td style="text-align:center">/</td><td style="text-align:center">增加订单行为</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">DELETE</td><td style="text-align:center">/{id}</td><td style="text-align:center">删除订单</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr></tbody></table><p>Customer service</p><p>进行用户的添加，删除，以及显示</p><table><thead><tr><th style="text-align:center">Method</th><th style="text-align:center">Path</th><th style="text-align:center">Description</th><th style="text-align:center">User authenticated</th><th style="text-align:center">Available from UI</th></tr></thead><tbody><tr><td style="text-align:center">GET</td><td style="text-align:center">/list</td><td style="text-align:center">返回用户列表</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">GET</td><td style="text-align:center">/{id}</td><td style="text-align:center">返回指定id的用户详情</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">GET</td><td style="text-align:center">/form</td><td style="text-align:center">返回增加用户界面</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">POST</td><td style="text-align:center">/form</td><td style="text-align:center">增加用户</td><td style="text-align:center">无</td><td style="text-align:center">无</td></tr><tr><td style="text-align:center">PUT</td><td style="text-align:center">/{id}</td><td style="text-align:center">增加用户行为</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">DELETE</td><td style="text-align:center">/{id}</td><td style="text-align:center">删除用户</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr></tbody></table><p>Catalog service</p><p>进行商品的添加，删除，以及显示</p><table><thead><tr><th style="text-align:center">Method</th><th style="text-align:center">Path</th><th style="text-align:center">Description</th><th style="text-align:center">User authenticated</th><th style="text-align:center">Available from UI</th></tr></thead><tbody><tr><td style="text-align:center">GET</td><td style="text-align:center">/list</td><td style="text-align:center">返回商品列表</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">GET</td><td style="text-align:center">/{id}</td><td style="text-align:center">返回指定id的商品详情</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">GET</td><td style="text-align:center">/form</td><td style="text-align:center">返回增加商品界面</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">POST</td><td style="text-align:center">/form</td><td style="text-align:center">增加商品</td><td style="text-align:center">无</td><td style="text-align:center">无</td></tr><tr><td style="text-align:center">PUT</td><td style="text-align:center">/{id}</td><td style="text-align:center">增加商品行为</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">DELETE</td><td style="text-align:center">/{id}</td><td style="text-align:center">删除商品</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">TEXT_HTML_VALUE</td><td style="text-align:center">/searchForm</td><td style="text-align:center">返回搜索界面</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">TEXT_HTML_VALUE</td><td style="text-align:center">/searchByName</td><td style="text-align:center">返回搜索结果</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr></tbody></table><p>注意</p><ul><li>每个微服务都有自己的数据库，因此互相之间没有直接访问数据库的接口</li><li>这里的数据库使用的是spring框架自带的数据库</li><li>服务到服务的通信非常简单，通过暴露的接口即可</li></ul><h2 id="架构服务"><a href="#架构服务" class="headerlink" title="架构服务"></a>架构服务</h2><p>分布式系统中有一些通用的模式，Spring Cloud框架都有提供，在本项目中仅仅运用了一小部分：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/arch.png" alt="arch"></p><h3 id="API-网关"><a href="#API-网关" class="headerlink" title="API 网关"></a>API 网关</h3><p>可以看到，有三个核心服务，它将外部API暴露给客户端。在一个现实世界的系统中，核心服务的数量可以非常快速地增长，并且整个系统的复杂性更是急剧增加。实际上，一个复杂的网页可能需要渲染数百个服务。</p><p>理论上，客户端可以直接向每个微服务器发出请求。但是显然，这将面临很大的挑战以及限制。比如必须要知道所有端点的地址。</p><p>通常一个更好的方法是使用API网关。它是系统中的单个入口点，用于通过将请求路由到适当的后端服务或通过调用多个后端服务并聚合结果来处理请求。此外，它还可以用于认证，压力测试，服务迁移，静态响应处理，主动流量管理等</p><p>Netflix开辟了这样一个优势服务，现在使用Spring Cloud，我们可以通过一个@EnableZuulProxy注释来实现。在这个项目中使用了Zuul存储静态内容（ui应用程序），并将请求路由到适当的微服务器。</p><p>Zuul使用服务发现机制来定位服务实例以及断路器和负载平衡器，如下所述。</p><h3 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h3><p>另外一个众所周知的架构模式便是服务发现机制。它可以进行服务实例网络位置的动态检测。当应用需要扩展、容错或者升级的时候就可以自动为服务实例分配地址。</p><p>服务发现机制的核心是注册阶段。本项目使用了 Netflix Eureka。 Eureka是一个客户端的发现模式，因为很多网络应用都需要客户端自己去确定特定服务的地址（使用注册服务器）并且进行请求的负载均衡。</p><p>使用Spring Boot时，只要在pom文件中加入spring-cloud-starter-eureka-server依赖并且使用@EnableEurekaServer注解即可使用该服务。</p><h3 id="负载均衡、断路器以及Http客户端"><a href="#负载均衡、断路器以及Http客户端" class="headerlink" title="负载均衡、断路器以及Http客户端"></a>负载均衡、断路器以及Http客户端</h3><p>Netflix还提供了另外一些十分好用的工具。</p><h4 id="Ribbon"><a href="#Ribbon" class="headerlink" title="Ribbon"></a>Ribbon</h4><p>Ribbon 是一个客户端的负载均衡器。相比传统的均衡器，你可以之间链接到相关服务。Ribbon已经和Spring Cloud以及服务发现机制集成在了一起。 Eureka Client 提供了一个可用服务器的动态列表供 Ribbon 进行服务器之间的均衡。</p><h4 id="Hystrix"><a href="#Hystrix" class="headerlink" title="Hystrix"></a>Hystrix</h4><p>Hystrix 是断路器模式的具体实现，其可以调节网络访问依赖中经常出现的延迟以及错误。其主要目的是为了阻断在分布式环境中大量微服务极易出现的级联错误，使得系统尽快重新上线。Hystrix还提供了一个监控页面 （下面将会看到）。</p><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>前期准备：</p><ul><li>网络</li></ul><ul><li>安装 Docker 以及 Docker compose</li></ul><p>运行命令：</p><ul><li><code>cd microservice-demo/</code>执行<code>mvn clean package</code></li><li><code>cd ../docker/</code>执行<code>docker-compose build</code>以及<code>docker-compose up</code></li></ul><p>重要端口：</p><ul><li><a href="http://127.0.0.1:8080" target="_blank" rel="external">http://127.0.0.1:8080</a> - 网关</li><li><a href="http://127.0.0.1:8761" target="_blank" rel="external">http://127.0.0.1:8761</a> - Eureka Dashboard</li></ul><p>注意：</p><p><strong>应用启动之后如果遇到 Whitelabel Error Page 错误请刷新页面</strong></p><h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><p><strong>Index</strong></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/index_1.png" alt="index_1"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/index_2.png" alt="index_2"></p><p><strong>Customer Service</strong></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/customers_list.png" alt="customers_list"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/add_customer.png" alt="add_customer"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/successful.png" alt="success"></p><p><strong>Catalog Service</strong></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/items_list.png" alt="items_list"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/add_item.png" alt="add_item"></p><p><strong>Order Service</strong></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/orders_list.png" alt="orders_list"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/add_order.png" alt="add_order"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/order_details.png" alt="order_details"></p><p><strong>Eukera Service</strong></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/eukera.png" alt="eukera"></p><p><strong>Hystrix Dashboard</strong></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/microservice/lec-proj/ui/order_hystrix.png" alt="order_hystrix"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;SMS&quot;&gt;&lt;a href=&quot;#SMS&quot; class=&quot;headerlink&quot; title=&quot;SMS&quot;&gt;&lt;/a&gt;SMS&lt;/h1&gt;&lt;p&gt;SMS (Store Management System), 一个简单的网店管理系统。&lt;/p&gt;&lt;p&gt;源码：&lt;a href=&quot;http
    
    </summary>
    
    
      <category term="microservice" scheme="http://yoursite.com/tags/microservice/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="spring boot" scheme="http://yoursite.com/tags/spring-boot/"/>
    
      <category term="spring cloud" scheme="http://yoursite.com/tags/spring-cloud/"/>
    
      <category term="docker" scheme="http://yoursite.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Learning to act by predicting the future</title>
    <link href="http://yoursite.com/2017/06/14/Learning-to-act-by-predicting-the-future/"/>
    <id>http://yoursite.com/2017/06/14/Learning-to-act-by-predicting-the-future/</id>
    <published>2017-06-14T11:46:19.000Z</published>
    <updated>2017-06-15T09:41:12.096Z</updated>
    
    <content type="html"><![CDATA[<p><em>论文 <a href="https://openreview.net/forum?id=rJLS7qKel" target="_blank" rel="external">Learning to act by predicting the future</a></em></p><p>这篇论文提出的 DFP (Direct Future Prediction) 赢得了2016年 Virtual Doom AI Competition 的 “Full Deathmatch” 环节的比赛。Virtual Doom 是一个对战性的第一人称射击型游戏，根据玩家击杀数判定胜负。为了体现出模型的泛化能力， 训练过程中使用的地图不在比赛过程中出现。DFP的性能超出了第二名（Deep LSTM Q-Network）50%，并且其模型以及训练数据更加简洁，表现出了DFP模型的优越性。</p><p>机器学习问题可以分为监督学习问题，无监督学习问题以及强化学习问题。监督学习主要是学习一个输入到输出的映射函数，无监督学习更加关注如何挖掘数据本身的隐含结构，强化学习是一个面向目标的策略学习问题。</p><p>因此采用强化学习的方法使得机器人在Deathmatch游戏中表现良好十分合适。因为这是一个直接面向目标的问题 （在游戏中取得最大的击杀数）。所以 DQN 以及 A3C 这样的算法应运而生，并且取得了巨大的成功。但是这篇论文提出了一个不同的观点。它引用了Jordan &amp; Rumelhart (1992) 这篇论文中提出的一个观点：</p><blockquote><p>对于一个可以与环境进行交互的学习问题，如果环境提供的反馈是稀疏的标量 （例如，对于一个五子棋问题，反馈只在最后胜负已分时给出，并且只是一个类似+1，-1的标量反馈），采用传统的强化学习算法会十分有效；但是如果环境给出的反馈是一个即时密集的多维度反馈 （在短时间内具有很大的信息比特率），监督学习算法更具优势。</p></blockquote><p>由于监督学习方面的研究已经非常成熟，最近十分火热的深度学习更是在很多方面都取得了很好的结果，因此，如果我们能够把强化学习问题在某种程度上转化为一个监督学习问题，可以使得问题的求解大大简化。</p><p>那么现在的问题是，我们要如何设计模型，从而可以得到一个监督信号呢？可以想到，我们唯一拥有的数据就是机器人通过与环境的交互得到的状态转移 （对于游戏来说就是玩家在游戏中采取不同的行为得到的环境的反馈，例如，玩家使用一个血包可以是的生命值回复；向左转可以使得画面发生变化等等）。我们可以对这些数据进行特殊的设计，从而能够满足我们的要求。</p><p>具体来说，我们不再简单使用传统强化学习问题中单一的状态 （例如游戏中的一帧画面）与对应的回报。我们把单一的状态拆分开来，对于原始的图像，声音等信息原样保留，形成一个 ”感觉输入流 (sensory input stream)“ ，很明显它是一个高维的变量；另外，我们从这些原始的信息中提取出能够代表我们学习目标的测度 （例如健康度，剩余弹药数以及击杀数等），形成一个 ”测度流 (measurement stream)“ ，它是一个低维的变量 （因为只包含几个重要的变量）。<strong>注意，这里的stream不是代表了好几个时间步，而是代表它是多个测度的一个集合。</strong></p><p>这样做有什么好处呢？一个传统的强化学习问题，其训练对象就是最大化一个关于reward的函数。一般reward都是人为给定的 （还是拿五子棋举例，最后玩家赢了，回报就是一个正数， 反之就是负数），但是这就使得学习问题的方差变得很大，训练过程十分不稳定，收敛速度慢，甚至可能不收敛。因此，<strong>我们希望reward的值不要过于随机化，能够通过某些监督信号来减少其方差</strong>。这里就可以体现出我们之前进行状态分解的优势。我们可以将reward表示成 measurement stream 的函数，由于measurement是agent与真实环境进行交互时得到的，属于一种监督信号，这很好的满足了我们的需求。所以最后我们的训练对象由最大化一个关于reward的函数变成了最大化一个关于measurement stream的函数。而这个<strong>measurement stream可以认为是传统强化学习问题中的reward</strong>。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>现在我们正式地定义DFP模型。在每一个时间步$t$，agent接收一个观察 （转移到一个状态）$O_t$, 根据这个观察 （状态）的某些固有属性从可行的动作集合中选取一个动作执行。$O_t$详细定义如下：<br>$$<br>\mathbf{o}_t = (\mathbf{s}_t, \mathbf{m}_t)<br>$$<br>整个状态转移过程中，我们希望最大化目标，前面提到了，它是关于measurement stream的函数：<br>$$<br>\mathbf{f} = (\mathbf{m}_{t+\tau_1}-\mathbf{m}_t, \cdots, \mathbf{m}_{t+\tau_n}-\mathbf{m}_t)<br>$$<br>$\tau_1, \cdots, \tau_n$ 代表与当前时间步$t$的一个偏差。至于为什么不直接最大化measurement stream而是最大化一个差值，我认为作者可能是有如下考虑：</p><ol><li>借鉴了n-step Q-learning 的做法。</li><li>由于模型是为了预测当前时间步$t$的measurement stream，因此优化对象中应该包含当前的measurement stream。</li></ol><p>最后，<br>$$<br>\mathbf{Goal} \; = \; u(\mathbf{f};\mathbf{g})<br>$$<br>一般线性函数即可满足我们的需求，即<br>$$<br>u(\mathbf{f};\mathbf{g}) = \mathbf{g}^{\text{T}}\mathbf{f}<br>$$<br>注意到现在我们的问题变成了一个监督学习的问题。为了训练模型，我们需要预测目标，然后再与真实的目标比较，通过最小化误差来进行学习。那么我们现在定义这个预测过程。注意到，由于目标只是measurement stream的函数，而且<strong>参数一般都是确定的，不需要进行学习</strong>。因此，我们的预测对象是measurement stream而不是目标。下面我们定义一个预测器F:<br>$$<br>\mathbf{p}_t^a = F(\mathbf{o}_t, a, \mathbf{g};\theta)<br>$$<br><strong>注意，这里的$\text{g}$和(4)中是不一样的，它代表目标</strong>。$p_t^a$代表在$t$时间步下，执行行为$a$所得到的reward，也即measurement stream。</p><p>当训练完成的时候，我们就要用这个预测器F进行决策，策略定义如下：<br>$$<br>a_t = {\arg\max}_{a \in \mathcal{A}} \mathbf{g}^{\text{T}}F(\mathbf{o}_t, a, \mathbf{g};\theta)<br>$$<br>注意到，模型实际训练的过程中采用的是$\varepsilon\text{-greedy}$策略。这里可以看出，在训练过程中或者测试过程中，我们要手动的计算出$u(\text{f};\text{g})$的值。下面我们详细的剖析模型的训练过程。</p><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>对于传统的强化学习算法，例如Q-learning，其训练过程是一个在线学习的过程，也即其训练集是一个一个进行输入的，每输入一次都进行一次参数的更新。由于Q-learning以及DFP都是采用了MC (Monte Carlo) 策略，这种训练过程可能十分不稳定 （由于训练最开始时我们的训练数据是通过一个随机策略与环境交互产生的），致使收敛速度很慢，需要很多的episodes进行训练。这里采用了和DQN (Deep Q-Network) 相同的 experience replay技术。具体来说，就是保存每次agent与环境交互后产生的数据对</p><p>$\langle \mathbf{o}_i, a_i, \mathbf{g}_i, \mathbf{f}_i \rangle$ 到数据集$\mathcal{D}$中，即$\mathcal{D} = \{\langle \mathbf{o}_ i, a_i, \mathbf{g}_i, \mathbf{f}_i \rangle \}_{i=1}^N$. 注意这里的$N$个数据对并不是直接顺序产生的，而是从当前episode中到当前时间步时，所有的数据对中选取最近的$M$个，再从其中随机抽样$N$个。另外，每隔k步才进行一次参数的更新，因为$\mathbf{f}$的计算需要考虑到32个时间步之后的数据，因此$k \ge 32$（实验部分将详细介绍）。DQN 给出了具体的实现：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/dqn_alg.png" alt="dqn_alg"></p><p>另外需要注意的是</p><p>有了训练集，我们现在定义w代价函数：<br>$$<br>\mathcal{L}(\theta) = \sum_{i=1}^{N} |F(\mathbf{o}_i, a_i, \mathbf{g}_i;\theta) - \mathbf{f}_i|^2<br>$$<br>我们来对比一下 DQN 的代价函数：<br>$$<br>L_i(\theta_i)= \mathbb{E}_{s, a \sim \rho(\cdot)} \left[ y_i - Q(s, a;\theta_i) \right],<br>$$<br>其中$y_i = \mathbb{E}_{s^{\prime} \sim \varepsilon}[ r + \gamma \max_{a^{\prime}} Q(s^{\prime}, a^{\prime};\theta_{i-1}) ]$ 。</p><p>这里的$y_i$是上一次模型的输出，其值随着更新次数的增加也在不断变化。因此从这里也能看出DFP是一个监督学习算法。</p><p>训练过程中我们为了解决报告最开始提出的目标随着时间发生改变的问题，采用了两种目标进行测试：</p><ol><li>目标向量$\mathbf{g}$ （不是目标）在整个训练过程中不变</li><li>目标向量在每个episode结束时随机变化</li></ol><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>下图是DFP模型的网络结构：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/network.png" alt="network"></p><p>从图中可以看出，该网络有三个输入模块。一个感知模块$S(s)$，一个测度模型$M(m)$以及一个目标模块$G(g)$。在实验中，$s$代表一张图片，$S$代表一个卷积神经网络。测度模块以及目标模块都是由一个全连接神经网络构成。三者的输出连接在一起，形成一个联合的输入表示，供后续算法使用：<br>$$<br>\mathbf{j} = J(\mathbf{s, m, g}) = \langle S(\mathbf{s}), M(\mathbf{m}), G(\mathbf{g}) \rangle<br>$$<br>DFP网络采用了DQN的做法，一次性输出所有action对应的measurement stream。但是我们希望能够着重关注对action之间差异的学习。因此采用了Wang et al. (ICML 2016) 这篇文章中才去的做法，将预测模块分为两个stream，一个期望stream $E(\text{j})$ 以及一个action stream $A(\text{j})$。注意这两个stream都是一个全连接的神经网络。期望stream的目标是预测所有action能够获得的measurement stream的期望。Action stream关注不同action之间的差异。其中，$A(\text{j}) = \langle A^1(\text{j}), \cdots, A^{w}(\text{j}) \rangle$，$w = |\mathcal{A}|$代表所有可能action的个数。同时我们还在加入了一个正则化层：<br>$$<br>\overline{A^{i}}(\mathbf{j}) = A^{i}(\mathbf{j}) - \frac{1}{w}\sum_{k=1}^{w} A^{k}(\mathbf{j})<br>$$<br>正则化层对每一个action的预测值减去了所有action预测值的期望，这样就强制期望stream去学习这个期望，这样action stream就可以着重关注不同action之间的差异。最后，网络的输出如下：<br>$$<br>\mathbf{p} = \langle \mathbf{p}^{a_1}, \cdots, \mathbf{p}^{a_w} \rangle = \langle \overline{A^1}(\mathbf{j})+E(\mathbf{j}), \cdots, \overline{A^w}(\mathbf{j})+E(\mathbf{j}) \rangle<br>$$<br>为了验证网络中使用的三个辅助结构（measurement stream输入，expectation-action分解以及action正则化层）的作用，我们进行了测试。我们基于D3场景（下面实验部分提及）随机产生了100个地图场景用以训练。同时采用basic网络 （下面实验部分提及），最后的实验结果如下：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/t3.png" alt="t3"></p><p>可以看出，expectation-action分解的作用最大，同时我们设计的measurement stream也是十分重要的。</p><h2 id="实验及结果"><a href="#实验及结果" class="headerlink" title="实验及结果"></a>实验及结果</h2><p>具体的实验场景见下图：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/game.png" alt="game"></p><p>在前两个场景中，agent可以采取三个动作，向前移动、向左转、向右转。这样一共就有8种动作组合。采用的测度只有一种，就是血量。在后两个场景中，agent可以采取八个动作组合，分别是向前移动、向后移动、向左转、向右转、向左扫射，向右扫射、奔跑以及射击。这样一共就有256个动作组合。采用的测度一共有三种，血量，弹药数以及击杀数。这里我认为存在一个可以改进的地方，应该排除掉不合理的动作组合，例如同时向左转以及向右转。这样可以减少搜索空间，加速收敛，同时可以提高策略的质量。</p><p>实验中网络的结构与DQN的结构十分类似，参数也尽可能相近，就是为了比较起来比较公平。具体来说，实验中采用了两种网络，basic以及large，结构相同，但是参数数量不同：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/bl.png" alt="bl"></p><p>Basic网络的参数与DQN比较接近，以便比较。两个网络在所有的非终止层后都加入了一个非线性层，采用的激活函数为Leaky ReLU，具体函数为：<br>$$<br>\mathbf{LReLU}(x) = \max(x, 0.2x)<br>$$<br>参数初始化方法采用了He Initialization，代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line">W = np.random.randn(node_in, node_out) / np.sqrt(node_in / <span class="number">2</span>)</div></pre></td></tr></table></figure><p>Agent以episode为单位进行训练和测试。每一个episode拥有525个时间步（大约一分钟），如果agent死亡那么episode也会终止。同时将时间偏置$\tau_1, \cdots, \tau_n$设置为1, 2, 4, 8, 16, 32。最后结果表明只有最新的三个时间步（8, 16, 32）对结果有贡献，贡献比例为 1:1:2。</p><p>另外，输入图像被转换成灰度图像，measurement stream并不是直接输入，而是进行了正则化 （除以标准差）。同时，我们还在训练以及测试过程中使用frame skipping技术。Agent每隔4帧采取一次action。这些被忽略的帧所采取的action与其之后的帧的action一致，相当于进行了一次简单的复制。另外，由于人类的反应速度肯定是比不上计算机的，因此fram skipping使得agent的行为更加接近人类。</p><p>对于之前提到的experience replay技术，实验中将M值设为20000， N设为64，k也设为64（$\ge32$）。同时为了能够更高效的获得训练集$\mathcal{D}$，我们同时采用8个agent并行运行。训练时采用的梯度下降算法为Adam算法，参数设置如下：$\beta_1=0.95, \;\beta_2=0.999,\;\varepsilon=10^{-4}$。Basic网络训练了800,000次mini-batch迭代，large网络训练了2,000,000次。算法实现<a href="https://github.com/IntelVCL/DirectFuturePrediction。" target="_blank" rel="external">https://github.com/IntelVCL/DirectFuturePrediction。</a></p><p>下面介绍我们的baselines。我们同三个算法进行了比较：DQN (Mnih et al., 2015), A3C (Mnih et al., 2016), 以及 DSR (Kulkarni et al., 2016b)。DQN由于其在Atari游戏上的优异效果成为了视觉控制的标准baseline。A3C更是这个领域中的最好的算法。DSR也在Virtual Doom平台上进行了实验。所以我们挑选了这三个具有代表意义的算法。</p><p>对于这三个算法我们都使用了Github上的开源实现：DQN (<a href="https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner" target="_blank" rel="external">https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner</a>) 、DSR (<a href="https://github.com/Ardavans/DSR" target="_blank" rel="external">https://github.com/Ardavans/DSR</a>), 以及 A3C (<a href="https://github.com/muupan/async-rl)。前两个都是作者提供的源码，最后的A3C是一个独立开发者的个人实现。" target="_blank" rel="external">https://github.com/muupan/async-rl)。前两个都是作者提供的源码，最后的A3C是一个独立开发者的个人实现。</a></p><p>对于DQN以及DSR我们测试了三个学习速率：默认值（0.00025），0.00005以及0.00002。其他参数直接采用默认值。对于A3C算法，为了训练更快，前两个任务我们采用了5个学习速率 ({2, 4, 8, 16, 32} · $10^{-4}$)。后两个任务我们训练了20个模型，每个模型的学习速率从一个范围从$10^{-4}$到$10^{-2}$的log-uniform分布中进行采样，$\beta$值（熵正则项）从一个范围从$10^{-4}$到$10^{-}$的lo1g-uniform分布中进行采样。结果选取最好的。</p><p>最终结果如下所示：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/t1.png" alt="t1"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/f3.png" alt="f3"></p><p>在前两个游戏场景中，模型尝试最大化血量；在后两个场景中尝试最大化血量、弹药数以及击杀数的一个线性组合，参数为0.5, 0.5, 1。因为游戏更加侧重于通过击杀数判断胜负。所有的数据都是对三次训练结果进行平均，曲线图采样点的个数为$3 \times 50,000$。可以看出，DFP模型取得了最好的结果。其中DSR算法由于训练速度过慢，所以我们只在D1场景（也进行了将近10天的训练）进行了测试。</p><p>下面进行模型泛化能力的测试，我们基于D3以及D4两个场景分别随机产生100个随机场景。其中90个用于训练，剩下10个用于测试。最后结果如下：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/f2.png" alt="f2"></p><p>其中最后一列采用了large网络。可以看出，从复杂场景训练之后，在简单场景上的泛化能力往往不错，虽然两者规则不同。但是反之则不可以。</p><p>接下来进行学习变化目标能力的测试。结果见下图：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/t3g.png" alt="t3g"></p><p>其中采用第二列的策略时，agent并不知道每一个measurement的相对重要性；最后一列，agent事先并不知道哪一个measurement是不需要考虑的。但是最后测试时，效果都很好，而且在固定目标策略没有见过的目标上的效果要更好。说明DFP模型对于变化目标的学习能力优异。</p><p>最后我们单独对measurement stream时间偏置的重要性进行测试，我们采用的是D3-tx训练集，最后结果如图：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/l2a_p2f/t4.png" alt="t4"></p><p>相比较而言，采用更多的时间偏置可以达到更好的效果。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>现在强化学习问题关注的重点还是在value function的估计上，深度强化学习模型一般采用一个深度网络直接对value function进行估计。这篇论文的创新点在于，在使用深度网络之前，对value function进行了两次额外的映射。第一次是用measurement stream来代替reward，使得reward具有更强的状态表示能力；其次，对measurement stream再次进行了一个函数映射，采用了时间偏置，借鉴了n-step Q-learning的思想。最后，再将输出作为深度网络的输入，进行value function的估计。最后的实验结果证明这种想法是有其正确性的。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;论文 &lt;a href=&quot;https://openreview.net/forum?id=rJLS7qKel&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Learning to act by predicting the future&lt;/a&gt;&lt;/e
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>Monte Carlo Methods (Reinforcement Learning)</title>
    <link href="http://yoursite.com/2017/06/02/Monte-Carlo-Methods-Reinforcement-Learning/"/>
    <id>http://yoursite.com/2017/06/02/Monte-Carlo-Methods-Reinforcement-Learning/</id>
    <published>2017-06-02T06:10:57.000Z</published>
    <updated>2017-06-02T06:11:31.491Z</updated>
    
    <content type="html"><![CDATA[<p>Here we consider our first learning methods for <strong>estimating</strong> value functions and discovering optimal policy. Unlike the previous algorithms, we do not assume complete knowledge of the environment. Monte Carlo methods require only <em>experience</em> – sample sequences of states, actions, and rewards from actual or simulated interaction with an environment. Although a model is required, the model need only generate sample transition, not the complete probability distributions of all possible transitions that is required for <a href="https://ewanlee.github.io/2017/05/31/Dynamic-Programming/" target="_blank" rel="external">dynamic programming (DP)</a>.</p><p>Monte Carlo methods are ways of solving the reinforcement learning problem based on averaging sample return. To ensure that well-defined returns are available, here we define Monte Carlo methods only for episodic tasks. Only on the completion of an episode are value estimates and policies changed.</p><p>To handle the nonstationarity, we adapt the idea of general policy iteration (GPI) developed in earlier for <a href="https://ewanlee.github.io/2017/05/31/Dynamic-Programming/" target="_blank" rel="external">DP</a>.</p><p>Suppose we wish to estimate $v_{\pi}(s)$, the value of a state $s$ under policy $\pi$, given a set of episodes obtained by following $\pi$ and passing though $s$. Each occurrence of state $s$ in an episode is called a <em>visit</em> to $s$. Let us call the first time it is visited in an episode the <em>first visit</em> to $s$. The <em>first-visit MC method</em> estimates $v_{\pi}(s)$ as the average of the returns following first visits to $s$, whereas the <em>every-visit MC method</em> averages the returns following all visits to $s$.</p><blockquote><p><strong>First-visit MC policy evaluation (returns $V \approx v_{\pi}$)</strong></p><p>Initialize:</p><p>​ $\pi \leftarrow$ policy to be evaluated</p><p>​ $V \leftarrow $ an arbitrary state-value function</p><p>​ $Return(s) \leftarrow$ an empty list, for all $s \in \mathcal{S}$</p><p>Repeat forever:</p><p>​ Generate an episode using $\pi$</p><p>​ For each state $s$ appearing in the episode:</p><p>​ $G \leftarrow$ return following the first occurrence of $s$</p><p>​ Append $G$ to $Return(s)$</p><p>​ $V(s) \leftarrow$ $\text{average}(Return(s))$</p></blockquote><p>Next, we’ll use this algorithm to solve a naive problem that defined as follows:</p><blockquote><p>The object of the popular casino card game of <em>blackjack</em> is to obtain cards the sum of whose numerical values is as great as possible without exceeding 21. All face cards count as 10, and an ace can count either as 1 or as 11. We consider the version in which each player competes independently against the dealer. The game begins with two cards dealt to both dealer and player. One of the dealer’s cards is face up and the other is face down. If the player has 21 immediately (an ace and a 10-card), it is called a <em>natural</em>. He then wins unless the dealer also has a natural, in which case the game is draw. If the player does not have a natural, then he can request additional cards, one by one (<em>hits</em>), until he either stop (<em>sticks</em>) or excepted 21 (<em>goes bust</em>). If he goes bust, he loses; if he sticks, then it becomes the dealer’s turn. The dealer hits or sticks according to a fixed strategy without choice: he sticks on any sum of 17 or greater, and hits otherwise. If the dealer goes bust, then the player wins; otherwise, the outcome–win, lose, draw–is determined by whose final sum is closer to 21.</p></blockquote><p>Playing blackjack is naturally formulated as an episode finite MDP. Each game of blackjack is an episode. Rewards of +1, -1, and 0 are given for winning, losing, and drawing, respectively. All rewards within a game are zero, and we do not discount ($\gamma=1$); therefore these terminal rewards are also returns. The player’s actions are to hit or to stick. We assume that cards are dealt from an infinite deck (i.e., with replacement). If the player holds an ace that he could count as 11 without going bust, then the ace is said to be <em>usable</em>. Consider the policy that sticks if the player’s sum is 20 or 21, and otherwise hits. Thus, the player makes decisions on the basis of three variables: his current sum (12-21), the dealer’s one showing card (ace-10), and whether or not he holds a usable ace. This makes for a total of 200 states.</p><p>Note that, although we have complete knowledge of the environment in this task, it would not be easy to apply DP methods to compute the value function. DP methods require the distribution of next events–in particular, they require the quantities $p(s^{\prime}, r|s, a)$–and it is not easy to determine these for blackjack. For example, suppose the play’s sum is 14 and he chooses to sticks. What is his excepted reward as a function of the dealer’s showing card? All of these rewards and transition probabilities must be computed <em>before</em> DP can be applied, and such computations are often complex and error-prone.</p><p>The conceptual diagram of the experimental results is as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/blackjack_c.png" alt="blackjack_c"></p><p><em>Figure 1</em></p><p>The first we define some auxiliary variables and methods:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># actions: hit or stand (stick)</span></div><div class="line">ACTION_HIT = <span class="number">0</span></div><div class="line">ACTION_STAND = <span class="number">1</span></div><div class="line">actions = [ACTION_HIT, ACTION_STAND]</div><div class="line"></div><div class="line"><span class="comment"># policy for player</span></div><div class="line">policyPlayer = np.zeros(<span class="number">22</span>)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">12</span>, <span class="number">20</span>):</div><div class="line">    policyPlayer[i] = ACTION_HIT</div><div class="line">policyPlayer[<span class="number">20</span>] = ACTION_STAND</div><div class="line">policyPlayer[<span class="number">21</span>] = ACTION_STAND</div><div class="line"></div><div class="line"><span class="comment"># function form of target policy of player</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">targetPolicyPlayer</span><span class="params">(usableAcePlayer, playerSum, dealerCard)</span>:</span></div><div class="line">    <span class="keyword">return</span> policyPlayer[playerSum]</div><div class="line"></div><div class="line"><span class="comment"># function form of behavior policy of player</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">behaviorPolicyPlayer</span><span class="params">(usableAcePlayer, playerSum, dealerCard)</span>:</span></div><div class="line">    <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, <span class="number">0.5</span>) == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> ACTION_STAND</div><div class="line">    <span class="keyword">return</span> ACTION_HIT</div><div class="line"></div><div class="line"><span class="comment"># policy for dealer</span></div><div class="line">policyDealer = np.zeros(<span class="number">22</span>)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">12</span>, <span class="number">17</span>):</div><div class="line">    policyDealer[i] = ACTION_HIT</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">17</span>, <span class="number">22</span>):</div><div class="line">    policyDealer[i] = ACTION_STAND</div><div class="line"></div><div class="line"><span class="comment"># get a new card</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCard</span><span class="params">()</span>:</span></div><div class="line">    card = np.random.randint(<span class="number">1</span>, <span class="number">14</span>)</div><div class="line">    card = min(card, <span class="number">10</span>)</div><div class="line">    <span class="keyword">return</span> card</div></pre></td></tr></table></figure><p>Furthermore, we also have a print method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># print the state value</span></div><div class="line">figureIndex = <span class="number">0</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">prettyPrint</span><span class="params">(data, tile, zlabel=<span class="string">'reward'</span>)</span>:</span></div><div class="line">    <span class="keyword">global</span> figureIndex</div><div class="line">    fig = plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    fig.suptitle(tile)</div><div class="line">    ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)</div><div class="line">    axisX = []</div><div class="line">    axisY = []</div><div class="line">    axisZ = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">12</span>, <span class="number">22</span>):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">11</span>):</div><div class="line">            axisX.append(i)</div><div class="line">            axisY.append(j)</div><div class="line">            axisZ.append(data[i - <span class="number">12</span>, j - <span class="number">1</span>])</div><div class="line">    ax.scatter(axisX, axisY, axisZ)</div><div class="line">    ax.set_xlabel(<span class="string">'player sum'</span>)</div><div class="line">    ax.set_ylabel(<span class="string">'dealer showing'</span>)</div><div class="line">    ax.set_zlabel(zlabel)</div></pre></td></tr></table></figure><p>In order to get the figure above, we wrote the following code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">onPolicy</span><span class="params">()</span>:</span></div><div class="line">    statesUsableAce1, statesNoUsableAce1 = monteCarloOnPolicy(<span class="number">10000</span>)</div><div class="line">    statesUsableAce2, statesNoUsableAce2 = monteCarloOnPolicy(<span class="number">500000</span>)</div><div class="line">    prettyPrint(statesUsableAce1, <span class="string">'Usable Ace, 10000 Episodes'</span>)</div><div class="line">    prettyPrint(statesNoUsableAce1, <span class="string">'No Usable Ace, 10000 Episodes'</span>)</div><div class="line">    prettyPrint(statesUsableAce2, <span class="string">'Usable Ace, 500000 Episodes'</span>)</div><div class="line">    prettyPrint(statesNoUsableAce2, <span class="string">'No Usable Ace, 500000 Episodes'</span>)</div><div class="line">    plt.show()</div></pre></td></tr></table></figure><p>There is a term named <em>on policy</em>, we’ll explain this term later. Now let us jump into the <strong>monteCarloOnPolicy</strong> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Monte Carlo Sample with On-Policy</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">monteCarloOnPolicy</span><span class="params">(nEpisodes)</span>:</span></div><div class="line">    statesUsableAce = np.zeros((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    <span class="comment"># initialze counts to 1 to avoid 0 being divided</span></div><div class="line">    statesUsableAceCount = np.ones((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    statesNoUsableAce = np.zeros((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    <span class="comment"># initialze counts to 1 to avoid 0 being divided</span></div><div class="line">    statesNoUsableAceCount = np.ones((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nEpisodes):</div><div class="line">        state, reward, _ = play(targetPolicyPlayer)</div><div class="line">        state[<span class="number">1</span>] -= <span class="number">12</span></div><div class="line">        state[<span class="number">2</span>] -= <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> state[<span class="number">0</span>]:</div><div class="line">            statesUsableAceCount[state[<span class="number">1</span>], state[<span class="number">2</span>]] += <span class="number">1</span></div><div class="line">            statesUsableAce[state[<span class="number">1</span>], state[<span class="number">2</span>]] += reward</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            statesNoUsableAceCount[state[<span class="number">1</span>], state[<span class="number">2</span>]] += <span class="number">1</span></div><div class="line">            statesNoUsableAce[state[<span class="number">1</span>], state[<span class="number">2</span>]] += reward</div><div class="line">    <span class="keyword">return</span> statesUsableAce / statesUsableAceCount, statesNoUsableAce / statesNoUsableAceCount</div></pre></td></tr></table></figure><p>We ignore he first four variables now and explain them later. <strong>nEpisodes</strong> represents the number of the episodes and the <strong>play</strong> method simulates the process of the blackjack cards game. So what is it like? This method is too long (more than 100 rows) so we partially explain it. In the first place, this method define some auxiliary variables:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># play a game</span></div><div class="line"><span class="comment"># @policyPlayerFn: specify policy for player</span></div><div class="line"><span class="comment"># @initialState: [whether player has a usable Ace, sum of player's cards, one card of dealer]</span></div><div class="line"><span class="comment"># @initialAction: the initial action</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">play</span><span class="params">(policyPlayerFn, initialState=None, initialAction=None)</span>:</span></div><div class="line">    <span class="comment"># player status</span></div><div class="line">	<span class="comment"># sum of player</span></div><div class="line">    playerSum = <span class="number">0</span></div><div class="line">    <span class="comment"># trajectory of player</span></div><div class="line">    playerTrajectory = []</div><div class="line">    <span class="comment"># whether player uses Ace as 11</span></div><div class="line">    usableAcePlayer = <span class="keyword">False</span></div><div class="line">    <span class="comment"># dealer status</span></div><div class="line">    dealerCard1 = <span class="number">0</span></div><div class="line">    dealerCard2 = <span class="number">0</span></div><div class="line">    usableAceDealer = <span class="keyword">False</span></div></pre></td></tr></table></figure><p>Then, we generate a random initial state if the initial state is null. If not, we load the initial state from initialState variable:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> initialState <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">    <span class="comment"># generate a random initial state</span></div><div class="line">    numOfAce = <span class="number">0</span></div><div class="line">    <span class="comment"># initialize cards of player</span></div><div class="line">    <span class="keyword">while</span> playerSum &lt; <span class="number">12</span>:</div><div class="line">        <span class="comment"># if sum of player is less than 12, always hit</span></div><div class="line">        card = getCard()</div><div class="line">        <span class="comment"># if get an Ace, use it as 11</span></div><div class="line">        <span class="keyword">if</span> card == <span class="number">1</span>:</div><div class="line">            numOfAce += <span class="number">1</span></div><div class="line">            card = <span class="number">11</span></div><div class="line">            usableAcePlayer = <span class="keyword">True</span></div><div class="line">        playerSum += card</div><div class="line">    <span class="comment"># if player's sum is larger than 21, he must hold at least one Ace, two Aces are possible</span></div><div class="line">    <span class="keyword">if</span> playerSum &gt; <span class="number">21</span>:</div><div class="line">        <span class="comment"># use the Ace as 1 rather than 11</span></div><div class="line">        playerSum -= <span class="number">10</span></div><div class="line">        <span class="comment"># if the player only has one Ace, then he doesn't have usable Ace any more</span></div><div class="line">        <span class="keyword">if</span> numOfAce == <span class="number">1</span>:</div><div class="line">            usableAcePlayer = <span class="keyword">False</span></div><div class="line">    <span class="comment"># initialize cards of dealer, suppose dealer will show the first card he gets</span></div><div class="line">    dealerCard1 = getCard()</div><div class="line">    dealerCard2 = getCard()</div><div class="line">	<span class="keyword">else</span>:</div><div class="line">    	<span class="comment"># use specified initial state</span></div><div class="line">    	usableAcePlayer = initialState[<span class="number">0</span>]</div><div class="line">    	playerSum = initialState[<span class="number">1</span>]</div><div class="line">    	dealerCard1 = initialState[<span class="number">2</span>]</div><div class="line">    	dealerCard2 = getCard()</div><div class="line"></div><div class="line">	<span class="comment"># initial state of the game</span></div><div class="line">	state = [usableAcePlayer, playerSum, dealerCard1]</div><div class="line"></div><div class="line">	<span class="comment"># initialize dealer's sum</span></div><div class="line">    dealerSum = <span class="number">0</span></div><div class="line">    <span class="keyword">if</span> dealerCard1 == <span class="number">1</span> <span class="keyword">and</span> dealerCard2 != <span class="number">1</span>:</div><div class="line">        dealerSum += <span class="number">11</span> + dealerCard2</div><div class="line">        usableAceDealer = <span class="keyword">True</span></div><div class="line">    <span class="keyword">elif</span> dealerCard1 != <span class="number">1</span> <span class="keyword">and</span> dealerCard2 == <span class="number">1</span>:</div><div class="line">        dealerSum += dealerCard1 + <span class="number">11</span></div><div class="line">        usableAceDealer = <span class="keyword">True</span></div><div class="line">    <span class="keyword">elif</span> dealerCard1 == <span class="number">1</span> <span class="keyword">and</span> dealerCard2 == <span class="number">1</span>:</div><div class="line">        dealerSum += <span class="number">1</span> + <span class="number">11</span></div><div class="line">        usableAceDealer = <span class="keyword">True</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        dealerSum += dealerCard1 + dealerCard2</div></pre></td></tr></table></figure><p>Game start! Above all is player’s turn:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># player's turn</span></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="keyword">if</span> initialAction <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        action = initialAction</div><div class="line">        initialAction = <span class="keyword">None</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="comment"># get action based on current sum</span></div><div class="line">        action = policyPlayerFn(usableAcePlayer, playerSum, dealerCard1)</div><div class="line"></div><div class="line">    <span class="comment"># track player's trajectory for importance sampling</span></div><div class="line">    playerTrajectory.append([action, (usableAcePlayer, playerSum, dealerCard1)])</div><div class="line"></div><div class="line">    <span class="keyword">if</span> action == ACTION_STAND:</div><div class="line">        <span class="keyword">break</span></div><div class="line">    <span class="comment"># if hit, get new card</span></div><div class="line">    playerSum += getCard()</div><div class="line"></div><div class="line">    <span class="comment"># player busts</span></div><div class="line">    <span class="keyword">if</span> playerSum &gt; <span class="number">21</span>:</div><div class="line">        <span class="comment"># if player has a usable Ace, use it as 1 to avoid busting and continue</span></div><div class="line">        <span class="keyword">if</span> usableAcePlayer == <span class="keyword">True</span>:</div><div class="line">            playerSum -= <span class="number">10</span></div><div class="line">            usableAcePlayer = <span class="keyword">False</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="comment"># otherwise player loses</span></div><div class="line">            <span class="keyword">return</span> state, <span class="number">-1</span>, playerTrajectory</div></pre></td></tr></table></figure><p>Then is the dealer’s turn if the player’s turn is end:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="comment"># get action based on current sum</span></div><div class="line">    action = policyDealer[dealerSum]</div><div class="line">    <span class="keyword">if</span> action == ACTION_STAND:</div><div class="line">        <span class="keyword">break</span></div><div class="line">    <span class="comment"># if hit, get a new card</span></div><div class="line">    dealerSum += getCard()</div><div class="line">    <span class="comment"># dealer busts</span></div><div class="line">    <span class="keyword">if</span> dealerSum &gt; <span class="number">21</span>:</div><div class="line">        <span class="keyword">if</span> usableAceDealer == <span class="keyword">True</span>:</div><div class="line">        <span class="comment"># if dealer has a usable Ace, use it as 1 to avoid busting and continue</span></div><div class="line">            dealerSum -= <span class="number">10</span></div><div class="line">            usableAceDealer = <span class="keyword">False</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">        <span class="comment"># otherwise dealer loses</span></div><div class="line">            <span class="keyword">return</span> state, <span class="number">1</span>, playerTrajectory</div></pre></td></tr></table></figure><p>If the both sides have finished the game:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># compare the sum between player and dealer</span></div><div class="line"><span class="keyword">if</span> playerSum &gt; dealerSum:</div><div class="line">    <span class="keyword">return</span> state, <span class="number">1</span>, playerTrajectory</div><div class="line"><span class="keyword">elif</span> playerSum == dealerSum:</div><div class="line">    <span class="keyword">return</span> state, <span class="number">0</span>, playerTrajectory</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    <span class="keyword">return</span> state, <span class="number">-1</span>, playerTrajectory</div></pre></td></tr></table></figure><p>Now, let us come back the <strong>mentoCarloOnPolicy</strong> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">monteCarloOnPolicy</span><span class="params">(nEpisodes)</span>:</span></div><div class="line">    statesUsableAce = np.zeros((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    <span class="comment"># initialze counts to 1 to avoid 0 being divided</span></div><div class="line">    statesUsableAceCount = np.ones((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    statesNoUsableAce = np.zeros((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    <span class="comment"># initialze counts to 1 to avoid 0 being divided</span></div><div class="line">    statesNoUsableAceCount = np.ones((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nEpisodes):</div><div class="line">        state, reward, _ = play(targetPolicyPlayer)</div><div class="line">        state[<span class="number">1</span>] -= <span class="number">12</span></div><div class="line">        state[<span class="number">2</span>] -= <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> state[<span class="number">0</span>]:</div><div class="line">            statesUsableAceCount[state[<span class="number">1</span>], state[<span class="number">2</span>]] += <span class="number">1</span></div><div class="line">            statesUsableAce[state[<span class="number">1</span>], state[<span class="number">2</span>]] += reward</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            statesNoUsableAceCount[state[<span class="number">1</span>], state[<span class="number">2</span>]] += <span class="number">1</span></div><div class="line">            statesNoUsableAce[state[<span class="number">1</span>], state[<span class="number">2</span>]] += reward</div><div class="line">    <span class="keyword">return</span> statesUsableAce / statesUsableeCount, statesNoUsableAce / statesNoUsableAceCount</div></pre></td></tr></table></figure><p>In this method we ignore the player’s trajectory (represent by the <strong>playerTrajectory</strong> variable). If you remember a sentence in the game definition (as follows) it will easy to understand.</p><blockquote><p>Thus, the player makes decisions on the basis of three variables: his current sum (12-21), the dealer’s one showing card (ace-10), and whether or not he holds a usable ace. This makes for a total of 200 states.</p></blockquote><p>This row (as follows) is to calculate the average returns of each state:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">return</span> statesUsableAce / statesUsableeCount, statesNoUsableAce / statesNoUsableAceCount</div></pre></td></tr></table></figure><p>Recall the beginning of the code and let’s see what results are like:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/usable_ace_10000.png" alt="usable_ace_10000"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/no_usable_ace_10000.png" alt="no_usable_ace_10000"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/usable_ace_500000.png" alt="usable_ace_500000"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/no_usable_ace_500000.png" alt="no_usable_ace_500000"></p><p><em>Figure 2 (from up to down). (1) Usable Ace, 10000 Episodes. (2) No Usable Ace, 10000 Episodes. (3) Usable Ace, 500000 Episodes. (4) No Usable Ace, 500000 Episodes.</em></p><p>If a model is not available, then it is particularly useful to estimate <em>action values</em> (the value of state-value pairs) rather than <em>state values</em>. With a model, state values alone are sufficient to determine a policy; one simply look ahead one step and chooses whichever action leads to the best combination of reward and next state, as we did in the earlier on <a href="https://ewanlee.github.io/2017/05/31/Dynamic-Programming/" target="_blank" rel="external">DP</a>. Without a model, however, state values alone are not sufficient. One must explicitly estimate the value of each action in order for the values to be useful in suggesting a policy. Thus, one of out primary goals for Monte Carlo methods is to estimate $q_{\star}$. To achieve this, we first consider the policy evaluation problem for action values.</p><p>The policy evaluation problem for action values is estimate $q_{\pi}(s, a)$. The Monte Carlo methods for this are essentially the same as just presented for state values, except now we talk about visits to a state-action pair rather than to a state. The only complication is that many state-value pairs may never be visited. This is the general problem of <em>maintaining exploration</em>, as discussed in the context of the k-armed bandit problem in <a href="https://ewanlee.github.io/2017/05/27/k-Armed-Bandit-Problem/" target="_blank" rel="external">here</a>. One way to do this is by specifying that the episodes <em>start in a state-action pair</em>, and that every pair has a nonzero probability of being selected as the start. We call this the assumption of <em>exploring starts</em>.</p><p>We are now ready to consider how Monte Carlo estimation can be used in control, that is, to approximate optimal policies. To begin, let us consider a Monte Carlo version of classical policy iteration. In this method, we perform alternating complete steps of policy evaluation and policy improvement, beginning with a arbitrary policy $\pi_{0}$ and ending with the optimal policy and optimal action-value function:<br>$$<br>\pi_{0} \stackrel{E}\longrightarrow q_{\pi{0}} \stackrel{I}\longrightarrow \pi_{1} \stackrel{E}\longrightarrow q_{\pi_{1}} \stackrel{I}\longrightarrow \pi_{2} \stackrel{E}\longrightarrow \cdots \stackrel{I}\longrightarrow \pi_{\star} \stackrel{E}\longrightarrow q_{\star},<br>$$<br>We made two unlikely assumptions above in order to easily obtain this guarantee of convergence for Monte Carlo method. One was that the episodes have exploring starts, and the other was that policy evaluation could be done with an infinite number of episodes. We postpone consideration of the first assumption until later.</p><p>The primary approach to avoiding the infinite number of episodes nominally required for policy evaluation is to forgo to complete policy evaluation before returning to policy improvement. For Monte Carlo policy evaluation it it natural to alternate between evaluation and improvement on an episode-by-episode basis. After each episode, the observed returns are used for policy evaluation,and then the policy is improved at all the states visited in the episode.</p><blockquote><p><strong>Monte Carlo ES (Exploring Starts)</strong></p><p>Initialize, for all $s \in \mathcal{S},\; a \in \mathcal{A(s)}$:</p><p>​ $Q(s,a) \leftarrow \text{arbitrary}$</p><p>​ $\pi(s) \leftarrow \text{arbitrary}$</p><p>​ $Returns(s,a) \leftarrow \text{empty list}$</p><p>Repeat forever:</p><p>​ Choose $S_{0} \in \mathcal{S}$ and $A_{0} \in \mathcal{A(S_{0})}$ s.t. all pairs have probability &gt; 0</p><p>​ Generate an episode starting from $S_0, A_0$, following $\pi$</p><p>​ For each pair $s, a$ appearing in the episode:</p><p>​ $G \leftarrow \text{return following the first occurrence of} \; s, a$</p><p>​ Append $G$ to $Returns(s,a)$</p><p>​ $Q(s,a) \leftarrow \text{average}(Returns(s,a))$</p><p>​ For each $s$ in the episode:</p><p>​ $\pi(s) \leftarrow \arg\max_{a} Q(s,a)$</p></blockquote><p>Recall the blackjack card game. It is straightforward to apply Monte Carlo ES to blackjack.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">figure5_3</span><span class="params">()</span>:</span></div><div class="line">    stateActionValues = monteCarloES(<span class="number">500000</span>)</div><div class="line">    stateValueUsableAce = np.zeros((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    stateValueNoUsableAce = np.zeros((<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    <span class="comment"># get the optimal policy</span></div><div class="line">    actionUsableAce = np.zeros((<span class="number">10</span>, <span class="number">10</span>), dtype=<span class="string">'int'</span>)</div><div class="line">    actionNoUsableAce = np.zeros((<span class="number">10</span>, <span class="number">10</span>), dtype=<span class="string">'int'</span>)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">            stateValueNoUsableAce[i, j] = np.max(stateActionValues[i, j, <span class="number">0</span>, :])</div><div class="line">            stateValueUsableAce[i, j] = np.max(stateActionValues[i, j, <span class="number">1</span>, :])</div><div class="line">            actionNoUsableAce[i, j] = argmax(stateActionValues[i, j, <span class="number">0</span>, :])</div><div class="line">            actionUsableAce[i, j] = argmax(stateActionValues[i, j, <span class="number">1</span>, :])</div><div class="line">    prettyPrint(stateValueUsableAce, <span class="string">'Optimal state value with usable Ace'</span>)</div><div class="line">    prettyPrint(stateValueNoUsableAce, <span class="string">'Optimal state value with no usable Ace'</span>)</div><div class="line">    prettyPrint(actionUsableAce, <span class="string">'Optimal policy with usable Ace'</span>, <span class="string">'Action (0 Hit, 1 Stick)'</span>)</div><div class="line">    prettyPrint(actionNoUsableAce, <span class="string">'Optimal policy with no usable Ace'</span>, <span class="string">'Action (0 Hit, 1 Stick)'</span>)</div><div class="line">    plt.show()</div></pre></td></tr></table></figure><p>Run the code we’ll get the conceptual diagram like follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/mces.png" alt="mces"></p><p>Let us to see the implementation (<strong>monteCarloES</strong> method) of this algorithm. Note that, some auxiliary variables are defined earlier.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Monte Carlo with Exploring Starts</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">monteCarloES</span><span class="params">(nEpisodes)</span>:</span></div><div class="line">    <span class="comment"># (playerSum, dealerCard, usableAce, action)</span></div><div class="line">    stateActionValues = np.zeros((<span class="number">10</span>, <span class="number">10</span>, <span class="number">2</span>, <span class="number">2</span>))</div><div class="line">    <span class="comment"># set default to 1 to avoid being divided by 0</span></div><div class="line">    stateActionPairCount = np.ones((<span class="number">10</span>, <span class="number">10</span>, <span class="number">2</span>, <span class="number">2</span>))</div><div class="line">    <span class="comment"># behavior policy is greedy</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">behaviorPolicy</span><span class="params">(usableAce, playerSum, dealerCard)</span>:</span></div><div class="line">        usableAce = int(usableAce)</div><div class="line">        playerSum -= <span class="number">12</span></div><div class="line">        dealerCard -= <span class="number">1</span></div><div class="line">        <span class="keyword">return</span> argmax(stateActionValues[playerSum, dealerCard, usableAce, :])</div><div class="line"></div><div class="line">    <span class="comment"># play for several episodes</span></div><div class="line">    <span class="keyword">for</span> episode <span class="keyword">in</span> range(nEpisodes):</div><div class="line">        print(<span class="string">'episode:'</span>, episode)</div><div class="line">        <span class="comment"># for each episode, use a randomly initialized state and action</span></div><div class="line">        initialState = [bool(np.random.choice([<span class="number">0</span>, <span class="number">1</span>])),</div><div class="line">                       np.random.choice(range(<span class="number">12</span>, <span class="number">22</span>)),</div><div class="line">                       np.random.choice(range(<span class="number">1</span>, <span class="number">11</span>))]</div><div class="line">        initialAction = np.random.choice(actions)</div><div class="line">        _, reward, trajectory = play(behaviorPolicy, initialState, initialAction)</div><div class="line">        <span class="keyword">for</span> action, (usableAce, playerSum, dealerCard) <span class="keyword">in</span> trajectory:</div><div class="line">            usableAce = int(usableAce)</div><div class="line">            playerSum -= <span class="number">12</span></div><div class="line">            dealerCard -= <span class="number">1</span></div><div class="line">            <span class="comment"># update values of state-action pairs</span></div><div class="line">            stateActionValues[playerSum, dealerCard, usableAce, action] += reward</div><div class="line">            stateActionPairCount[playerSum, dealerCard, usableAce, action] += <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> stateActionValues / stateActionPairCount</div></pre></td></tr></table></figure><p>You can see we use the <strong>trajectory</strong> variable now. The difference between Monte Carlo On Policy and Monte Carlo ES is prior calculates the average return of each state and later calculates the average return of each state-action pair.</p><p>The results are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/mces_usable_ace_optimal_policy.png" alt="mcse_usbale_ace_optimal_policy"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/mces_no_usable_ace_optimal_policy.png" alt="mcse_usbale_ace_optimal_policy"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/mces_usable_ace_optimal_state_value.png" alt="mcse_usable_ace_optimal_state_value"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/mces_no_usable_ace_optimal_state_value.png" alt="mcse_no_usable_ace_optimal_state_value"></p><p>How can we avoid the unlikely assumption of exploring starts? The only general way to ensure that all actions are selected infinitely often is for the agent to continue to select them. There are two approaches to ensuring this, resulting in what we call <em>on-policy</em> (Do you remember this term?) methods and <em>off-policy</em> methods. On-policy methods attempt to evaluate or improve the policy that is used to make decisions, whereas off-policy methods evaluate or improve a policy different from that used to generate the data.. The First-visit Monte Carlo method and the Monte Carlo ES method are an example of an on-policy method. Here we show how an on-policy Monte Carlo control method can be designed that does not use the unrealistic assumption of exploring starts. Off-policy methods are considered later.</p><p>The on-policy method we presented in here uses $\epsilon \text{-} greedy$ policies. The complete algorithm is given below.</p><blockquote><p><strong>On-policy first-visit MC control (for $\epsilon \text{-soft}$ policies)</strong></p><p>Initialize, for all $s \in \mathcal{S}, \; a \in \mathcal{A(s)}$:</p><p>​ $Q(s,a ) \leftarrow \text{arbitrary}$</p><p>​ $Returns(s,a) \leftarrow \text{empty list}$</p><p>​ $\pi(a|s) \leftarrow \text{an arbitrary} \; \epsilon \text{-soft policy}$</p><p>Repeat forever:</p><p>​ (a) Generate an episode using $\pi$</p><p>​ (b) For each pair $s, a$ appearing in the episode:</p><p>​ $G \leftarrow $ return following the first occurrence of $s, a$</p><p>​ Append $G$ to $Returns(s,a)$</p><p>​ $Q(s, a) \leftarrow \text{average}(Returns(s,a))$</p><p>​ (c) For each s in the episode:</p><p>​ $A^{\star} \leftarrow \arg\max_{a} Q(s,a)$</p><p>​ For all $a \in \mathcal{A(s)}$:</p><p>​ $\pi(a|s) \leftarrow \left\{ \begin{array}{c} 1 - \epsilon + \epsilon/|\mathcal{A(s)}|\;\;\;\text{if} \;a=A^{\star} \\ \epsilon/|\mathcal{A(s)}|\;\;\;\;\;\;\;\;\;\;\;\;\;\;\text{if} \;a\neq A^{\star} \end{array} \right.$</p></blockquote><p>All learning control methods face a dilemma: They seek to learn action values conditional on subsequent <em>optimal</em> behavior, but they need to behave non-optimally in order to explore all actions (to find the optimal actions). How can they learn about the optimal policy while behaving according to an exploratory policy? The on-policy approach in the preceding section is actually a compromise–it learns action values not for the optimal policy, but for a near-optimal policy that still explores. A more straightforward approach is to user two policies, one that is learned about and that becomes the optimal policy, and one that is more exploratory and is used to generate behavior. The policy being learned about is called the <em>target policy</em>, and the policy used to generate behavior is called the <em>behavior policy</em>. In this case we say that learning is from data “off” the target policy, and the overall process is termed <em>off-policy learning</em>.</p><p>We begin the study of off-policy methods by considering the <em>prediction</em> problem, in which both target and behavior policies are fixed. That is, suppose we wish to estimate $v_{\pi}$ or $q_{\pi}$, but all we have are episodes following another policy $\mu$, where $\mu \neq \pi$. In this case, $\pi$ is the target policy, $\mu$ is the behavior policy, and both policies are considered fixed and given.</p><p>In order to use episodes from $\mu$ to estimate values for $\pi$, we require that every action taken under $\pi$ is also taken, at least occasionally, under $\mu$. That is, we require that $\pi(a|s) &gt; 0$ implies $\mu(a|s) &gt; 0$. This is called the assumption of <em>converge</em>. It follows from converge that $\mu$ must be stochastic in states where it is not identical to $\pi$. The target policy $\pi$, on the other hand, may be deterministic. In here, we consider the prediction problem, in which $\pi$ is unchanging and given.</p><p>Almost all off-policy methods utilize <em>importance sampling</em>ddd, a general technique for estimating excepted values under one distribution given samples from another. We apply importance sampling to off-policy learning by weighting returns according to the relative probability of their trajectory occurring under the target and behavior policies, called the <em>importance-sampling ratio</em>. Given a starting state $S_{t}$, the probability of the subsequent state-action trajectory , $A_{t}, S_{t+1}, A_{t+1, \cdots, S_{T}}$, occurring under any policy $\pi$ is<br>$$<br>\prod_{k=t}^{T-1} \pi(A_k | S_k)p(S_{k+1} | S_k, A_k),<br>$$<br>where $p$ here is the state-transition probability function. Thus, the relative probability of the trajectory under the target and behavior policies (the important-sampling ratio) is<br>$$<br>\rho_{t}^{T} \doteq \frac{\prod_{k=t}^{T-1} \pi(A_k|S_k)p(S_{k+1}|S_k, A_k)}{\prod_{k=t}^{T-1} \mu(A_k|S_k)p(S_{k+1}|S_k, A_k)} = \prod_{k=t}^{T-1} \frac{\pi (A_k | S_k)}{\mu (A_k | S_k)}<br>$$<br>Now we are ready to give a Monte Carlo algorithm that uses a batch of observed episodes following policy $\mu$ to estimate $v_{\pi}(s)$. It is convenient here to number time steps in a way that increases across episode boundaries. That is, if the first episode of the batch ends in a terminal state at time 100, then the next episode begins at time $t=101$. This enables us to use time-step numbers to refer to particular steps in particular episodes. In particular, we can define the set of all time steps in which state $s$ is visited, denote $\tau(s)$. This is for an every-visit method; for a first-visit method, $\tau(s)$ would only include time steps that were first visits to $s$ within their episodes. Also, let $T(t)$ denote the first time of termination following time $t$, and $G_t$ denote the return after $t$ up though $T(t)$. Then $\{G_t\}_{t \in \tau(s)}$ are returns that pertain to state $s$, and $\{\rho_{t}^{T(t)}\}_{t \in \tau(s)}$ are the corresponding importance-sampling ratios. To estimate $v_{\pi}(s)$, we simply scale the returns by the ratios and average the results:<br>$$<br>V(s) \doteq \frac{\sum_{t \in \tau(s)} \rho_{t}^{T(t)} G_t}{|\tau(s)|}.<br>$$<br>When importance sampling is done as a simple average in this way it is called <em>ordinary importance sampling</em>.</p><p>An important alternative is <em>weighted importance sampling</em>, which uses a weighted average, defined as<br>$$<br>V(s) \doteq \frac{\sum_{t \in \tau(s)} \rho_{t}^{T(t)} G_t}{\sum_{t \in \tau(s)} \rho_{t}^{T(t)}},<br>$$<br>or zero if the denominator is zero.</p><p>We applied both ordinary and weighted importance-sampling methods to estimate the value of as single blackjack state from off-policy data. Recall that one of the advantages of Monte Carlo methods is that they can be used to evaluate a single state without forming estimated for any other states. In this example, we evaluated the state in which the dealer is showing a deuce, the sum of the player’s cards is 13, and the player has a usable ace (that is, the player holds an ace and a deuce, or equivalently three aces). The data was generate by starting in this state then choosing to hit or stick at random with equal probability (the behavior policy). The target policy was to stick only on a sum of 20 or 21. The value of this state under the target policy is approximately -0.27726 (this was determined by separately generating one-hundred million episodes using the target policy and averaging their returns). Both off-policy methods closely approximated this value after 1000 off-policy episodes using the random policy. To make sure they did this reliably, we performed 100 independent runs, each starting from estimates of zero and learning for 10,000 episodes. The implementation details are as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Monte Carlo Sample with Off-Policy</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">monteCarloOffPolicy</span><span class="params">(nEpisodes)</span>:</span></div><div class="line">    initialState = [<span class="keyword">True</span>, <span class="number">13</span>, <span class="number">2</span>]</div><div class="line">    sumOfImportanceRatio = [<span class="number">0</span>]</div><div class="line">    sumOfRewards = [<span class="number">0</span>]</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nEpisodes):</div><div class="line">        _, reward, playerTrajectory = play(behaviorPolicyPlayer, initialState=initialState)</div><div class="line"></div><div class="line">        <span class="comment"># get the importance ratio</span></div><div class="line">        importanceRatioAbove = <span class="number">1.0</span></div><div class="line">        importanceRatioBelow = <span class="number">1.0</span></div><div class="line">        <span class="keyword">for</span> action, (usableAce, playerSum, dealerCard) <span class="keyword">in</span> playerTrajectory:</div><div class="line">            <span class="keyword">if</span> action == targetPolicyPlayer(usableAce, playerSum, dealerCard):</div><div class="line">                importanceRatioBelow *= <span class="number">0.5</span></div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                importanceRatioAbove = <span class="number">0.0</span></div><div class="line">                <span class="keyword">break</span></div><div class="line">        importanceRatio = importanceRatioAbove / importanceRatioBelow</div><div class="line">        sumOfImportanceRatio.append(sumOfImportanceRatio[<span class="number">-1</span>] + importanceRatio)</div><div class="line">        sumOfRewards.append(sumOfRewards[<span class="number">-1</span>] + reward * importanceRatio)</div><div class="line">    <span class="keyword">del</span> sumOfImportanceRatio[<span class="number">0</span>]</div><div class="line">    <span class="keyword">del</span> sumOfRewards[<span class="number">0</span>]</div><div class="line"></div><div class="line">    sumOfRewards= np.asarray(sumOfRewards)</div><div class="line">    sumOfImportanceRatio= np.asarray(sumOfImportanceRatio)</div><div class="line">    ordinarySampling = sumOfRewards / np.arange(<span class="number">1</span>, nEpisodes + <span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="keyword">with</span> np.errstate(divide=<span class="string">'ignore'</span>,invalid=<span class="string">'ignore'</span>):</div><div class="line">        weightedSampling = np.where(sumOfImportanceRatio != <span class="number">0</span>, sumOfRewards / sumOfImportanceRatio, <span class="number">0</span>)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> ordinarySampling, weightedSampling</div></pre></td></tr></table></figure><p>Note that the <strong>behaviorPolicyPlayer</strong> that is a function that define the behavior policy:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># function form of behavior policy of player</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">behaviorPolicyPlayer</span><span class="params">(usableAcePlayer, playerSum, dealerCard)</span>:</span></div><div class="line">    <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, <span class="number">0.5</span>) == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> ACTION_STAND</div><div class="line">    <span class="keyword">return</span> ACTION_HIT</div></pre></td></tr></table></figure><p>And the calculation of the numerator and denominator of the importance-sampling are the summation operation. As the number of iterations increases, we need to accumulate the result from each episode. So we need to store the previous results. The <strong>sumOfRewards</strong> and <strong>sumOfImportanceRatio</strong> are used for this purpose.</p><p>Then we need to show the result (mean square error):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Figure 5.4</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">offPolicy</span><span class="params">()</span>:</span></div><div class="line">    trueValue = <span class="number">-0.27726</span></div><div class="line">    nEpisodes = <span class="number">10000</span></div><div class="line">    nRuns = <span class="number">100</span></div><div class="line">    ordinarySampling = np.zeros(nEpisodes)</div><div class="line">    weightedSampling = np.zeros(nEpisodes)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nRuns):</div><div class="line">        ordinarySampling_, weightedSampling_ = monteCarloOffPolicy(nEpisodes)</div><div class="line">        <span class="comment"># get the squared error</span></div><div class="line">        ordinarySampling += np.power(ordinarySampling_ - trueValue, <span class="number">2</span>)</div><div class="line">        weightedSampling += np.power(weightedSampling_ - trueValue, <span class="number">2</span>)</div><div class="line">    ordinarySampling /= nRuns</div><div class="line">    weightedSampling /= nRuns</div><div class="line">    axisX = np.log10(np.arange(<span class="number">1</span>, nEpisodes + <span class="number">1</span>))</div><div class="line">    plt.plot(axisX, ordinarySampling, label=<span class="string">'Ordinary Importance Sampling'</span>)</div><div class="line">    plt.plot(axisX, weightedSampling, label=<span class="string">'Weighted Importance Sampling'</span>)</div><div class="line">    plt.xlabel(<span class="string">'Episodes (10^x)'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Mean square error'</span>)</div><div class="line">    plt.legend()</div><div class="line">    plt.show()</div></pre></td></tr></table></figure><p>Result is as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/off_policy.png" alt="off_policy"></p><p>Formally, the difference between the two kinds of importance sampling is expressed in their biases and variances. The ordinary importance-sampling estimator is unbiased whereas the weighted importance-sampling estimator is biased (the bias converges asymptotically to zero). On the other hand, the variance of the ordinary importance-sampling estimator is in general unbounded because the variance of the ratios can be unbounded, whereas in the weighted estimator the largest weight on any single return is one. Nevertheless, we will not totally abandon ordinary importance sampling as it is easier to extend to the approximate methods using function approximate that we explore later.</p><p>The estimates of ordinary importance sampling will typical have infinite variance, and this can easily happen in off-policy learning when trajectories contains loops. A simple example is shown below:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/infinite_variance_example.png" alt="infinite_variance_example"></p><p>There is only one nonterminal state $s$ and two action, <strong>end</strong> and <strong>back</strong>. The <strong>end</strong> action causes a deterministic transition to termination, whereas the <strong>back</strong> action transitions, with probability 0.9, back to $s$ or, with probability 0.1, on to termination. The rewards are +1 on latter transition and otherwise zero. Consider the target policy that always selects back. All episodes under this policy consist of some number (possibly zero) of transitions back to $s$ followed by termination with a reward and return of +1. Thus the value of $s$ under the target policy is 1. Suppose we are estimating this value from off-policy data using the behavior policy that selects <strong>end</strong> and <strong>back</strong> with equal probability.</p><p>The implementation details are as follows. We first define the two policies:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">ACTION_BACK = <span class="number">0</span></div><div class="line">ACTION_END = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># behavior policy</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">behaviorPolicy</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span> np.random.binomial(<span class="number">1</span>, <span class="number">0.5</span>)</div><div class="line"></div><div class="line"><span class="comment"># target policy</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">targetPolicy</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span> ACTION_BACK</div></pre></td></tr></table></figure><p>Then we define how an episode runs:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># one turn</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">play</span><span class="params">()</span>:</span></div><div class="line">    <span class="comment"># track the action for importance ratio</span></div><div class="line">    trajectory = []</div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        action = behaviorPolicy()</div><div class="line">        trajectory.append(action)</div><div class="line">        <span class="keyword">if</span> action == ACTION_END:</div><div class="line">            <span class="keyword">return</span> <span class="number">0</span>, trajectory</div><div class="line">        <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, <span class="number">0.9</span>) == <span class="number">0</span>:</div><div class="line">            <span class="keyword">return</span> <span class="number">1</span>, trajectory</div></pre></td></tr></table></figure><p>Now we start our off-policy (first-visit MC) learning process:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Figure 5.5</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">monteCarloSample</span><span class="params">()</span>:</span></div><div class="line">    runs = <span class="number">10</span></div><div class="line">    episodes = <span class="number">100000</span></div><div class="line">    axisX = np.log10(np.arange(<span class="number">1</span>, episodes + <span class="number">1</span>))</div><div class="line">    <span class="keyword">for</span> run <span class="keyword">in</span> range(<span class="number">0</span>, runs):</div><div class="line">        sumOfRewards = [<span class="number">0</span>]</div><div class="line">        <span class="keyword">for</span> episode <span class="keyword">in</span> range(<span class="number">0</span>, episodes):</div><div class="line">            reward, trajectory = play()</div><div class="line">            <span class="keyword">if</span> trajectory[<span class="number">-1</span>] == ACTION_END:</div><div class="line">                importanceRatio = <span class="number">0</span> <span class="comment"># Because it is impossible on the target policy</span></div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                importanceRatio = <span class="number">1.0</span> / pow(<span class="number">0.5</span>, len(trajectory))</div><div class="line">            sumOfRewards.append(sumOfRewards[<span class="number">-1</span>] + importanceRatio * reward)</div><div class="line">        <span class="keyword">del</span> sumOfRewards[<span class="number">0</span>]</div><div class="line">        estimations = np.asarray(sumOfRewards) / np.arange(<span class="number">1</span>, episodes + <span class="number">1</span>)</div><div class="line">        plt.plot(axisX, estimations)</div><div class="line">    plt.xlabel(<span class="string">'Episodes (10^x)'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Ordinary Importance Sampling'</span>)</div><div class="line">    plt.show()</div><div class="line">    <span class="keyword">return</span></div></pre></td></tr></table></figure><p>Result is as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/mc/infinite_variance.png" alt="inifinite_variance"></p><p>The correct estimate here is 1, and, even though this is the expected value of a sample return (after importance sampling), the variance of the samples is infinite, and the estimates do not convergence to this value.</p><p>At last, we proposed two fancy algorithms, that is, the <strong>Incremental off-policy every-visit MC policy evaluation</strong> and the <strong>Off-policy every-visit MC control</strong>.</p><blockquote><p><strong>Incremental off-policy every-visit MC policy evaluation</strong></p><p>Initialize, for all $s \in \mathcal{S}, \; a \in \mathcal{A(s)}$:</p><p>​ $Q(s,a) \leftarrow$ arbitrary</p><p>​ $C(s,a) \leftarrow$ 0</p><p>​ $\mu(a|s) \leftarrow$ an arbitrary soft behavior policy</p><p>​ $\pi(a|s) \leftarrow$ an arbitrary target policy</p><p>Repeat forever:</p><p>​ Generate an episode using $\mu$:</p><p>​ $S_0, A_0, R_1, \cdots, S_{T-1}, A_{T-1}, R_{T}, S_{T}$</p><p>​ $G \leftarrow 0$</p><p>​ $W \leftarrow 1$</p><p>​ For $t=T-1, T-2, \cdots \;\text{downto} \; 0$:</p><p>​ $G \leftarrow \gamma G + R_{t+1}$</p><p>​ $C(S_t, A_t) \leftarrow C(S_t, A_t) + W$</p><p>​ $Q(S_t, A_t) \leftarrow Q(S_t, A_t) + \frac{W}{C(S_t, A_t)}[G - Q(S_t, A_t)]$</p><p>​ $W \leftarrow W\frac{\pi(A_t | S_t)}{\mu(A_t | S_t)}$</p><p>​ If $W = 0$ then ExitForLoop</p><p><strong>Off-policy every-visit MC control (returns $\pi \approx \pi_{\star}$)</strong></p><p>Initialize, for all $s \in \mathcal{S}, \; a \in \mathcal{A(s)}$:</p><p>​ $Q(s,a) \leftarrow$ arbitrary</p><p>​ $C(s,a) \leftarrow$ 0</p><p>​ $\mu(a|s) \leftarrow$ an arbitrary soft behavior policy</p><p>​ $\pi(s) \leftarrow$ an deterministic policy that is greedy with respect $Q$</p><p>Repeat forever:</p><p>​ Generate an episode using $\mu$:</p><p>​ $S_0, A_0, R_1, \cdots, S_{T-1}, A_{T-1}, R_{T}, S_{T}$</p><p>​ $G \leftarrow 0$</p><p>​ $W \leftarrow 1$</p><p>​ For $t=T-1, T-2, \cdots \;\text{downto} \; 0$:</p><p>​ $G \leftarrow \gamma G + R_{t+1}$</p><p>​ $C(S_t, A_t) \leftarrow C(S_t, A_t) + W$</p><p>​ $Q(S_t, A_t) \leftarrow Q(S_t, A_t) + \frac{W}{C(S_t, A_t)}[G - Q(S_t, A_t)]$</p><p>​ $\pi(S_t) \leftarrow \arg \max_{a}Q(S_t, a)$ (with ties broken consistently)</p><p>​ If $A_t \neq \pi(S_t)$ then ExitForLoop</p><p>​ $W \leftarrow W\frac{1}{\mu(A_t | S_t)}$</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Here we consider our first learning methods for &lt;strong&gt;estimating&lt;/strong&gt; value functions and discovering optimal policy. Unlike the pr
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Dynamic Programming</title>
    <link href="http://yoursite.com/2017/05/31/Dynamic-Programming/"/>
    <id>http://yoursite.com/2017/05/31/Dynamic-Programming/</id>
    <published>2017-05-31T02:19:52.000Z</published>
    <updated>2017-05-31T03:31:21.833Z</updated>
    
    <content type="html"><![CDATA[<p>The term dynamic programming (DP) refers to a collection of algorithms that can be used to compute optimal policies given a perfect model of environment as a Markov decision process (MDP). Classical DP algorithms are of limited utility in reinforcement learning both because of their assumption of a perfect model and because of their great computational expense, but they are provides an essential foundation for the understanding of the methods presented later. In fact, all of these methods can be viewed as attempts to achieve much the same effect as DP, only with less computation and without assuming a perfect model of the environment.</p><p>The key idea of DP, and of reinforcement learning generally, is the use of value functions to organize and structure the search for good policies. In here we show how DP can be used to compute the value functions defined in earlier. As discussed there, we can easily obtain optimal policies once we have found the optimal value functions $v_{\star}$ or $q_{\star}$ which satisfy the Bellman optimality equations:<br>$$<br>\begin{align}<br>v_{\star}(s) &amp;= \max_{a} \mathbb{E} [R_{t+1} + \gamma v_{\star}(S_{t+1}) \ | \ S_{t}=s, A_{t}=a] \\<br>&amp;= \max_{a} \sum_{s^{\prime}, r} p(s^{\prime}, r | s, a) \left[r + \gamma v_{\star}(s^{\prime})\right]<br>\end{align}<br>$$<br>or<br>$$<br>\begin{align}<br>q_{\star}(s, a) &amp;= \mathbb{E} [R_{t+1} + \gamma \max_{a^{\prime}} q_{\star}(S_{t+1}, a^{\prime}) \ | \ S_{t}=s, A_{t}=a] \\<br>&amp;= \sum_{s^{\prime}, r} p(s^{\prime}, r | s, a) [r + \gamma \max_{a^{\prime}} q_{\star}(s^{\prime}, a^{\prime})]<br>\end{align}<br>$$<br>for all $s \in \mathcal{S}, \; a \in \mathcal{A(s)}, \; \text{and} \; s^{\prime} \in \mathcal{S^{+}}$. As we shall see, DP algorithms are obtained by turning Bellman equations such as these into assignments, that is, into update rules for improving approximations of the desired value functions.</p><p>First we consider how to compute the state-value function $v_{\pi}$ for an arbitrary policy $\pi$. This is called <em>policy evaluation</em> in the DP literature. We also refer to it as the <em>prediction problem</em>. Recall that for all $s \in \mathcal{S}$,<br>$$<br>\begin{align}<br>v_{\pi}(s) &amp;\doteq \mathbb{E}_{\pi} [R_{t+1} + \gamma R_{t+2} + \gamma^{2}R_{t+3} + \cdots \ | \ S_{t}=s] \\<br>&amp;= \mathbb{E}_{\pi} [R_{t+1} + \gamma v_{\pi}(S_{t+1}) \ | \ S_{t}=s] \\<br>&amp;= \sum_{a} \pi(a|s) \sum_{s^{\prime}, r} p(s^{\prime}, r | s, a) [r + \gamma v_{\pi}(s^{\prime})]<br>\end{align}<br>$$<br>If the environment’s dynamics are complete known, then (7) is a system of $|\mathcal{S}|$ simultaneous linear equations in $|\mathcal{S}|$ unknowns (the $v_{\pi}(s), s \in \mathcal{S}$). In principle, its solution is a straightforward, if tedious, computation. For our purpose, iterative solution methods are most suitable. The initial approximation, $v_0$, is chosen arbitrarily (except that the terminal state, if any, must be given value 0), and each successive approximation is obtained by using the Bellman equation for $v_{\pi}$ as an update rule:<br>$$<br>\begin{align}<br>v_{k+1}(s) &amp;\doteq \mathbb{E}_{\pi}[R_{t+1} + \gamma v_{k}(S_{t+1}) \ | \ S_{t}=s] \\<br>&amp;= \sum_{a} \pi(a|s) \sum_{s^{\prime}, r} p(s^{\prime}, r|s, a) [r + \gamma v_{k} (s^{\prime})]<br>\end{align}<br>$$<br>This algorithm is called <em>iterative policy evaluation</em>.</p><blockquote><p><strong>Iterative policy evaluation</strong></p><p>Input $\pi$, the policy to be evaluated</p><p>Initialize an array $V(s) = 0$, for all $s \in \mathcal{S^{+}}$</p><p>Repeat</p><p>​ $\Delta \leftarrow 0$</p><p>​ for each $s \in \mathcal{S}$:</p><p>​ $v \leftarrow V(s)$</p><p>​ $V(s) \leftarrow \sum_{a} \pi(a|s) \sum_{s^{\prime}, r} p(s^{\prime}, r | s, a) [r + \gamma v(s^{\prime})]$</p><p>​ $\Delta \leftarrow \max(\Delta, |v - V(s)|)$</p><p>until $\Delta &lt; \theta$ (a small positive number)</p><p>Output $V \approx v_{\pi}$</p></blockquote><p>We can see the algorithm used in the <a href="https://ewanlee.github.io/2017/05/29/The-GridWorld-problem/" target="_blank" rel="external">grid world problem</a> just is the <em>iterative policy evaluation</em>.</p><p>Our reason for computing the value function for a policy is to help find better policies. Once a policy $\pi$ has been improved using $v_{\pi}$ to yield a better policy $\pi^{\prime}$, we can then compute $v_{\pi^{\prime}}$and improve it again to yield an even better $\pi^{\prime\prime}$. We can thus obtain a sequence of monotonically improving policies and value functions:<br>$$<br>\pi_{0} \stackrel{E}\longrightarrow v_{\pi_{0}} \stackrel{I}\longrightarrow \pi_{1} \stackrel{E}\longrightarrow v_{\pi_{1}} \stackrel{I}\longrightarrow \pi_{2} \stackrel{E}\longrightarrow \cdots \stackrel{I}\longrightarrow \pi_{\star} \stackrel{E}\longrightarrow v_{\star},<br>$$<br>where $\stackrel{E}\longrightarrow$ denotes a policy <em>evaluation</em> and $\stackrel{I}\longrightarrow$ denotes a policy <em>improvement</em>. This way of finding an optimal policy is called <em>policy iteration</em>.</p><blockquote><p><strong>Policy iteration (using iterative policy evaluation)</strong></p><ol><li><p>Initialization</p><p>$V(s) \in \mathbb{R}$ and $\pi(s) \in \mathcal{A(s)}$ arbitrarily for all $s \in \mathcal{S}$</p></li><li><p>Policy Evaluation</p><p>Repeat</p><p>​ $\Delta \leftarrow 0$</p><p>​ For each $s \in \mathcal{S}$:</p><p>​ $v \leftarrow V(s)$</p><p>​ $V(s) \leftarrow \sum_{s^{\prime}, r} p(s^{\prime}, r | s, \pi(s)) [r + \gamma v(s^{\prime})]$</p><p>​ $\Delta \leftarrow \max(\Delta, |v - V(s)|)$</p><p>until $\Delta &lt; \theta$ (a small positive number)</p></li><li><p>Policy Improvement</p><p><em>policy-stable</em> $\leftarrow$ <em>true</em></p><p>For each $s \in \mathcal{S}$:</p><p>​ <em>old-action</em> $\leftarrow$ $\pi_(s)$</p><p>​ $\pi (s) \leftarrow argmax_{a} \sum_{s^{\prime}, r} p(s^{\prime}, r | s, a) [r + \gamma v(s^{\prime})]$</p><p>​ If <em>old-action</em> $\neq \pi(s)$, then <em>policy-stable</em> $\leftarrow$ <em>false</em></p><p>If <em>policy-stable</em>, then stop and return $V \approx v_{\star} \; \text{and} \; \pi \approx \pi_{\star}$; else go to 2.</p></li></ol></blockquote><p>Let us solve a problem used by <strong>policy iteration</strong>. The problem defined as follows:</p><blockquote><p>Jack manages two locations for a nationwide car rental company. Each day, some number of customers arrive at each location to rent cars. If Jack has a car available, he rents it out and it credited \$10 by the national company. If he out of cats at that location, then the business is lost. Cars become available for renting the day after they are returned. To ensure that cars are available where they are needed, Jack ca move them between the two locations overnight, at a cost of \$2 per car moved. We assume that the number of cars requested and returned at each location are Poisson random variables, meaning that the probability that the number is $n$ is $\frac{\lambda^{n}}{n!}e^{-\lambda}$, where $\lambda$ is the excepted number. Suppose $\lambda$ is 3 and 4 for rental requests at the first and second locations and 3 and 2 for returns. To simplify the problem slightly, we assume that there can be no more than 20 cars at each location (any additional cars are returned to the nationwide company, and thus disappear from the problem) and a maximum of five cars can be moved from one location to the other in one night. We take the discount rate to be $\lambda=0.9$ and formulate this as a continuing finite MDP, where the time steps are days, the state is the number of cars at each location at the end of the day, and the actions are the net numbers of cats moved between the two locations overnight.</p></blockquote><p>The excepted result is as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/dp/car_rental.png" alt="car_rental"></p><p><em>Figure 1</em></p><p>The first, we define some facts of this problem:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># maximum # of cars in each location</span></div><div class="line">MAX_CARS = <span class="number">20</span></div><div class="line"><span class="comment"># maximum # of cars to move during night</span></div><div class="line">MAX_MOVE_OF_CARS = <span class="number">5</span></div><div class="line"><span class="comment"># expectation for rental requests in first location</span></div><div class="line">RENTAL_REQUEST_FIRST_LOC = <span class="number">3</span></div><div class="line"><span class="comment"># expectation for rental requests in second location</span></div><div class="line">RENTAL_REQUEST_SECOND_LOC = <span class="number">4</span></div><div class="line"><span class="comment"># expectation for # of cars returned in first location</span></div><div class="line">RETURNS_FIRST_LOC = <span class="number">3</span></div><div class="line"><span class="comment"># expectation for # of cars returned in second location</span></div><div class="line">RETURNS_SECOND_LOC = <span class="number">2</span></div><div class="line">DISCOUNT = <span class="number">0.9</span></div><div class="line"><span class="comment"># credit earned by a car</span></div><div class="line">RENTAL_CREDIT = <span class="number">10</span></div><div class="line"><span class="comment"># cost of moving a car</span></div><div class="line">MOVE_CAR_COST = <span class="number">2</span></div></pre></td></tr></table></figure><p>From the problem definition, we know that in this MDP the states is the number of cars at each location at the end of the day, and the actions are the net numbers of cats moved between the two locations overnight. Each action is a integer that positive number represents the number of cars moving from the first location to second location and vice verse.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># current policy</span></div><div class="line">policy = np.zeros((MAX_CARS + <span class="number">1</span>, MAX_CARS + <span class="number">1</span>))</div><div class="line"><span class="comment"># current state value</span></div><div class="line">stateValue = np.zeros((MAX_CARS + <span class="number">1</span>, MAX_CARS + <span class="number">1</span>))</div><div class="line"><span class="comment"># all possible states</span></div><div class="line">states = []</div><div class="line"><span class="comment"># all possible actions</span></div><div class="line">actions = np.arange(-MAX_MOVE_OF_CARS, MAX_MOVE_OF_CARS + <span class="number">1</span>)</div></pre></td></tr></table></figure><p>For visualization (Figure 1) convenient, we define a method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># axes for printing use</span></div><div class="line">AxisXPrint = []</div><div class="line">AxisYPrint = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, MAX_CARS + <span class="number">1</span>):</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, MAX_CARS + <span class="number">1</span>):</div><div class="line">        AxisXPrint.append(i)</div><div class="line">        AxisYPrint.append(j)</div><div class="line">        states.append([i, j])</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># plot a policy/state value matrix</span></div><div class="line">figureIndex = <span class="number">0</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">prettyPrint</span><span class="params">(data, labels)</span>:</span></div><div class="line">    <span class="keyword">global</span> figureIndex</div><div class="line">    fig = plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)</div><div class="line">    AxisZ = []</div><div class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> states:</div><div class="line">        AxisZ.append(data[i, j])</div><div class="line">    ax.scatter(AxisXPrint, AxisYPrint, AxisZ)</div><div class="line">    ax.set_xlabel(labels[<span class="number">0</span>])</div><div class="line">    ax.set_ylabel(labels[<span class="number">1</span>])</div><div class="line">    ax.set_zlabel(labels[<span class="number">2</span>])</div></pre></td></tr></table></figure><p>Next, we define a Poisson function that return the probability:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># An up bound for poisson distribution</span></div><div class="line"><span class="comment"># If n is greater than this value, then the probability of getting n is truncated to 0</span></div><div class="line">POISSON_UP_BOUND = <span class="number">11</span></div><div class="line"></div><div class="line"><span class="comment"># Probability for poisson distribution</span></div><div class="line"><span class="comment"># @lam: lambda should be less than 10 for this function</span></div><div class="line">poissonBackup = dict()</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">poisson</span><span class="params">(n, lam)</span>:</span></div><div class="line">    <span class="keyword">global</span> poissonBackup</div><div class="line">    key = n * <span class="number">10</span> + lam</div><div class="line">    <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> poissonBackup.keys():</div><div class="line">        poissonBackup[key] = exp(-lam) * pow(lam, n) / factorial(n)</div><div class="line">    <span class="keyword">return</span> poissonBackup[key]</div></pre></td></tr></table></figure><p>Now, the preparation is done. We’ll implement the policy iteration algorithm as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">newStateValue = np.zeros((MAX_CARS + <span class="number">1</span>, MAX_CARS + <span class="number">1</span>))</div><div class="line">improvePolicy = <span class="keyword">False</span></div><div class="line">policyImprovementInd = <span class="number">0</span></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="keyword">if</span> improvePolicy == <span class="keyword">True</span>:</div><div class="line">        <span class="comment"># start policy improvement</span></div><div class="line">        print(<span class="string">'Policy improvement'</span>, policyImprovementInd)</div><div class="line">        policyImprovementInd += <span class="number">1</span></div><div class="line">        newPolicy = np.zeros((MAX_CARS + <span class="number">1</span>, MAX_CARS + <span class="number">1</span>))</div><div class="line">        <span class="keyword">for</span> i, j <span class="keyword">in</span> states:</div><div class="line">            actionReturns = []</div><div class="line">            <span class="comment"># go through all actions and select the best one</span></div><div class="line">            <span class="keyword">for</span> action <span class="keyword">in</span> actions:</div><div class="line">                <span class="keyword">if</span> (action &gt;= <span class="number">0</span> <span class="keyword">and</span> i &gt;= action) <span class="keyword">or</span> (action &lt; <span class="number">0</span> <span class="keyword">and</span> j &gt;= abs(action)):</div><div class="line">                    actionReturns.append(expectedReturn([i, j], action, stateValue))</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    actionReturns.append(-float(<span class="string">'inf'</span>))</div><div class="line">            bestAction = argmax(actionReturns)</div><div class="line">            newPolicy[i, j] = actions[bestAction]</div><div class="line"></div><div class="line">        <span class="comment"># if policy is stable</span></div><div class="line">        policyChanges = np.sum(newPolicy != policy)</div><div class="line">        print(<span class="string">'Policy for'</span>, policyChanges, <span class="string">'states changed'</span>)</div><div class="line">        <span class="keyword">if</span> policyChanges == <span class="number">0</span>:</div><div class="line">            policy = newPolicy</div><div class="line">            <span class="keyword">break</span></div><div class="line">        policy = newPolicy</div><div class="line">        improvePolicy = <span class="keyword">False</span></div><div class="line"></div><div class="line">    <span class="comment"># start policy evaluation</span></div><div class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> states:</div><div class="line">        newStateValue[i, j] = expectedReturn([i, j], policy[i, j], stateValue)</div><div class="line">    <span class="keyword">if</span> np.sum(np.abs(newStateValue - stateValue)) &lt; <span class="number">1e-4</span>:</div><div class="line">        stateValue[:] = newStateValue</div><div class="line">        improvePolicy = <span class="keyword">True</span></div><div class="line">        <span class="keyword">continue</span></div><div class="line">    stateValue[:] = newStateValue</div></pre></td></tr></table></figure><p>We can see the logistic is the same as the pseudocode of the policy iteration algorithm. There is a core method in the code, that is, <strong>exceptedReturn()</strong> is used to calculate the reward of cars rental.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># @state: [# of cars in first location, # of cars in second location]</span></div><div class="line"><span class="comment"># @action: positive if moving cars from first location to second location,</span></div><div class="line"><span class="comment">#          negative if moving cars from second location to first location</span></div><div class="line"><span class="comment"># @stateValue: state value matrix</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">expectedReturn</span><span class="params">(state, action, stateValue)</span>:</span></div><div class="line">    <span class="comment"># initailize total return</span></div><div class="line">    returns = <span class="number">0.0</span></div><div class="line"></div><div class="line">    <span class="comment"># cost for moving cars</span></div><div class="line">    returns -= MOVE_CAR_COST * abs(action)</div><div class="line"></div><div class="line">    <span class="comment"># go through all possible rental requests</span></div><div class="line">    <span class="keyword">for</span> rentalRequestFirstLoc <span class="keyword">in</span> range(<span class="number">0</span>, POISSON_UP_BOUND):</div><div class="line">        <span class="keyword">for</span> rentalRequestSecondLoc <span class="keyword">in</span> range(<span class="number">0</span>, POISSON_UP_BOUND):</div><div class="line">            <span class="comment"># moving cars</span></div><div class="line">            numOfCarsFirstLoc = int(min(state[<span class="number">0</span>] - action, MAX_CARS))</div><div class="line">            numOfCarsSecondLoc = int(min(state[<span class="number">1</span>] + action, MAX_CARS))</div><div class="line"></div><div class="line">            <span class="comment"># valid rental requests should be less than actual # of cars</span></div><div class="line">            realRentalFirstLoc = min(numOfCarsFirstLoc, rentalRequestFirstLoc)</div><div class="line">            realRentalSecondLoc = min(numOfCarsSecondLoc, rentalRequestSecondLoc)</div><div class="line"></div><div class="line">            <span class="comment"># get credits for renting</span></div><div class="line">            reward = (realRentalFirstLoc + realRentalSecondLoc) * RENTAL_CREDIT</div><div class="line">            numOfCarsFirstLoc -= realRentalFirstLoc</div><div class="line">            numOfCarsSecondLoc -= realRentalSecondLoc</div><div class="line"></div><div class="line">            <span class="comment"># probability for current combination of rental requests</span></div><div class="line">            prob = poisson(rentalRequestFirstLoc, RENTAL_REQUEST_FIRST_LOC) * \</div><div class="line">                         poisson(rentalRequestSecondLoc, RENTAL_REQUEST_SECOND_LOC)</div><div class="line"></div><div class="line">            <span class="comment"># if set True, model is simplified such that the # of cars returned in daytime becomes constant</span></div><div class="line">            <span class="comment"># rather than a random value from poisson distribution, which will reduce calculation time</span></div><div class="line">            <span class="comment"># and leave the optimal policy/value state matrix almost the same</span></div><div class="line">            constantReturnedCars = <span class="keyword">True</span></div><div class="line">            <span class="keyword">if</span> constantReturnedCars:</div><div class="line">                <span class="comment"># get returned cars, those cars can be used for renting tomorrow</span></div><div class="line">                returnedCarsFirstLoc = RETURNS_FIRST_LOC</div><div class="line">                returnedCarsSecondLoc = RETURNS_SECOND_LOC</div><div class="line">                numOfCarsFirstLoc = min(numOfCarsFirstLoc + returnedCarsFirstLoc, MAX_CARS)</div><div class="line">                numOfCarsSecondLoc = min(numOfCarsSecondLoc + returnedCarsSecondLoc, MAX_CARS)</div><div class="line">                returns += prob * (reward + DISCOUNT * stateValue[numOfCarsFirstLoc, numOfCarsSecondLoc])</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                numOfCarsFirstLoc_ = numOfCarsFirstLoc</div><div class="line">                numOfCarsSecondLoc_ = numOfCarsSecondLoc</div><div class="line">                prob_ = prob</div><div class="line">                <span class="keyword">for</span> returnedCarsFirstLoc <span class="keyword">in</span> range(<span class="number">0</span>, POISSON_UP_BOUND):</div><div class="line">                    <span class="keyword">for</span> returnedCarsSecondLoc <span class="keyword">in</span> range(<span class="number">0</span>, POISSON_UP_BOUND):</div><div class="line">                        numOfCarsFirstLoc = numOfCarsFirstLoc_</div><div class="line">                        numOfCarsSecondLoc = numOfCarsSecondLoc_</div><div class="line">                        prob = prob_</div><div class="line">                        numOfCarsFirstLoc = min(numOfCarsFirstLoc + returnedCarsFirstLoc, MAX_CARS)</div><div class="line">                        numOfCarsSecondLoc = min(numOfCarsSecondLoc + returnedCarsSecondLoc, MAX_CARS)</div><div class="line">                        prob = poisson(returnedCarsFirstLoc, RETURNS_FIRST_LOC) * \</div><div class="line">                               poisson(returnedCarsSecondLoc, RETURNS_SECOND_LOC) * prob</div><div class="line">                        returns += prob * (reward + DISCOUNT * stateValue[numOfCarsFirstLoc, numOfCarsSecondLoc])</div><div class="line">    <span class="keyword">return</span> returns</div></pre></td></tr></table></figure><p>The comments are very clear, and we’re going to do a lot of this. Finally, let us print the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">prettyPrint(policy, [<span class="string">'# of cars in first location'</span>, <span class="string">'# of cars in second location'</span>, <span class="string">'# of cars to move during night'</span>])</div><div class="line">prettyPrint(stateValue, [<span class="string">'# of cars in first location'</span>, <span class="string">'# of cars in second location'</span>, <span class="string">'expected returns'</span>])</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>The results are as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Policy improvement <span class="number">0</span></div><div class="line">Policy <span class="keyword">for</span> <span class="number">332</span> states changed</div><div class="line">Policy improvement <span class="number">1</span></div><div class="line">Policy <span class="keyword">for</span> <span class="number">286</span> states changed</div><div class="line">Policy improvement <span class="number">2</span></div><div class="line">Policy <span class="keyword">for</span> <span class="number">83</span> states changed</div><div class="line">Policy improvement <span class="number">3</span></div><div class="line">Policy <span class="keyword">for</span> <span class="number">19</span> states changed</div><div class="line">Policy improvement <span class="number">4</span></div><div class="line">Policy <span class="keyword">for</span> <span class="number">0</span> states changed</div></pre></td></tr></table></figure><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/dp/car_rental_policy.png" alt="car_rental_policy"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/dp/car_rental_return.png" alt="car_rental_return"></p><p>One drawback to policy iteration is that each of its iterations involves policy evaluation, which may itself be a protracted iterative computation requiring multiple sweeps through the state set. If policy evaluation is done iteratively, then convergence exactly to $v_{\pi}$ occurs only in the limit. In fact, the policy evaluation step of policy iteration can be truncated in several ways without losing convergence guarantees of policy iteration. One important special case is when policy evaluation is stopped after just one sweep (one backup of each state). This algorithm is called <em>value iteration</em>. It can be written as a particular simple backup operation that combines the policy improvement and truncated policy evaluation steps:<br>$$<br>\begin{align}<br>v_{k+1} &amp;\doteq \max_{a} \mathbb{E}[R_{t+1} + \gamma v_{k}(S_{t+1}) \ | \ S_{t}=s, A_{t}=a] \\<br>&amp;= \max_{a}\sum_{s^{\prime}, r} p(s^{\prime}, r | s, a) [r + \gamma v_{k}(s^{\prime})],<br>\end{align}<br>$$<br>for all $s \in \mathcal{S}$.</p><blockquote><p><strong>Value iteration</strong></p><p>Initialize array $V$ arbitrarily (e.g. $V(s) = 0$ for all $s \in \mathcal{S^{+}}$)</p><p>Repeat</p><p>​ $\Delta \leftarrow 0$</p><p>​ For each $s \in \mathcal{S}$:</p><p>​ $v \leftarrow V(s)$</p><p>​ $V(s) \leftarrow \max_{a}\sum_{s^{\prime}, r} p(s^{\prime}, r | s, a) [r + \gamma V(s^{\prime})]$</p><p>​ $\Delta \leftarrow \max(\Delta, |v - V(s)|)$</p><p>until $\Delta &lt; \theta$ (a small positive number)</p><p>Output a deterministic policy, $\pi \approx \pi_{\star}$, such that</p><p>​ $\pi(s) = \arg\max_{a}\sum_{s^{\prime}, r} p(s^{\prime}, r | s, a) [r + \gamma V(s^{\prime})]$</p></blockquote><p>Let us use the value iteration algorithm to solve a Gambler’s Problem. The problem defined as follows:</p><blockquote><p>A gambler has the opportunity to make bets on the outcomes of a sequence of coin flips. If the coin comes up heads, he wins as many dollars as he staked on the flip; if it is tails, he loses his stake. The game ends when the gambler wins by reaching his goal of \$100, or loses by running out of money. On each flip, the gambler must decide what portion of his capital to stake, in integer number of dollars. This problem can be formulated as an undiscounted, episodic, finite MDP. The state is the gambler’s capital, $s \in \{1, 2, \cdots, 99\}$ and the actions are stakes, $a \in \{0, 1, \cdots, \min(s, 100-s)\}$. The reward is zero on all transitions excepted those on which the gambler reaches his goal, when it is +1. The state-value function then gives the probability of winning from each state. A policy is mapping from levels of capital to stakes. The optimal policy maximizes the probability of reaching the goal. Let $p_h$ denote the probability of the coin coming up heads. If $p_h$ is known, then the entire problem is known and it can be solved, for instance, by value iteration.</p></blockquote><p>OK, now let us to solve this problem by use the value iteration algorithm.</p><p>The first we defined some facts and some auxiliary data structure:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># goal</span></div><div class="line">GOAL = <span class="number">100</span></div><div class="line"><span class="comment"># all states, including state 0 and state 100</span></div><div class="line">states = np.arange(GOAL + <span class="number">1</span>)</div><div class="line"><span class="comment"># probability of head</span></div><div class="line">headProb = <span class="number">0.4</span></div><div class="line"><span class="comment"># optimal policy</span></div><div class="line">policy = np.zeros(GOAL + <span class="number">1</span>)</div><div class="line"><span class="comment"># state value</span></div><div class="line">stateValue = np.zeros(GOAL + <span class="number">1</span>)</div><div class="line">stateValue[GOAL] = <span class="number">1.0</span></div></pre></td></tr></table></figure><p>The step of value iteration:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># value iteration</span></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    delta = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> state <span class="keyword">in</span> states[<span class="number">1</span>:GOAL]:</div><div class="line">        <span class="comment"># get possilbe actions for current state</span></div><div class="line">        actions = np.arange(min(state, GOAL - state) + <span class="number">1</span>)</div><div class="line">        actionReturns = []</div><div class="line">        <span class="keyword">for</span> action <span class="keyword">in</span> actions:</div><div class="line">            actionReturns.append(headProb * stateValue[state + action] + (<span class="number">1</span> - headProb) * stateValue[state - action])</div><div class="line">        newValue = np.max(actionReturns)</div><div class="line">        delta += np.abs(stateValue[state] - newValue)</div><div class="line">        <span class="comment"># update state value</span></div><div class="line">        stateValue[state] = newValue</div><div class="line">    <span class="keyword">if</span> delta &lt; <span class="number">1e-9</span>:</div><div class="line">        <span class="keyword">break</span></div></pre></td></tr></table></figure><p>Calculate the optimal policy:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># calculate the optimal policy</span></div><div class="line"><span class="keyword">for</span> state <span class="keyword">in</span> states[<span class="number">1</span>:GOAL]:</div><div class="line">    actions = np.arange(min(state, GOAL - state) + <span class="number">1</span>)</div><div class="line">    actionReturns = []</div><div class="line">    <span class="keyword">for</span> action <span class="keyword">in</span> actions:</div><div class="line">        actionReturns.append(headProb * stateValue[state + action] + (<span class="number">1</span> - headProb) * stateValue[state - action])</div><div class="line">    <span class="comment"># due to tie and precision, can't reproduce the optimal policy in book</span></div><div class="line">    policy[state] = actions[argmax(actionReturns)]</div></pre></td></tr></table></figure><p>Print the results:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">plt.figure(<span class="number">1</span>)</div><div class="line">plt.xlabel(<span class="string">'Capital'</span>)</div><div class="line">plt.ylabel(<span class="string">'Value estimates'</span>)</div><div class="line">plt.plot(stateValue)</div><div class="line">plt.figure(<span class="number">2</span>)</div><div class="line">plt.scatter(states, policy)</div><div class="line">plt.xlabel(<span class="string">'Capital'</span>)</div><div class="line">plt.ylabel(<span class="string">'Final policy (stake)'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>The results are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/dp/gambler_policy.png" alt="gambler_policy"></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/dp/gambler_value.png" alt="gambler_value"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The term dynamic programming (DP) refers to a collection of algorithms that can be used to compute optimal policies given a perfect model
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>The GridWorld problem</title>
    <link href="http://yoursite.com/2017/05/29/The-GridWorld-problem/"/>
    <id>http://yoursite.com/2017/05/29/The-GridWorld-problem/</id>
    <published>2017-05-29T06:09:26.000Z</published>
    <updated>2017-05-29T06:14:07.620Z</updated>
    
    <content type="html"><![CDATA[<p>A reinforcement learning task that satisfied the Markov property is called <em>Markov decision process</em>, or <em>MDP</em>. If the state and action spaces are finite, then it is called a <em>finite Markov decision process</em> (<em>finite MDP</em>).</p><p>A particular finite MDP is defined by its state and action sets and by the one-step dynamics of the environment. Given any state and action <em>s</em> and <em>a</em>, the probability of each possible pair of next state and reward, <em>s’</em>, <em>r</em>, is denoted<br>$$<br>p(s^{\prime}, r | s, a) \doteq \mathrm{Pr}\{S_{t+1}=s^{\prime}, R_{t+1}=r \ | \ S_{t}=s, A_{t}=a \}<br>$$<br>Given that, one can compute anything else one might want to know about the environment, such as the excepted rewards of state-action pairs,<br>$$<br>r(s,a) \doteq \mathbb{E}[R_{t+1} \ | \ S_{t}=s, A_{t}=a] = \sum_{r \in \mathcal{R}}r\sum_{s^{\prime} \in \mathcal{S}}p(s^{\prime},r|s, a)<br>$$<br>the <em>state-transition probabilities</em>,<br>$$<br>p(s^{\prime}|s,a) \doteq \mathrm{Pr}\{S_{t+1}=s^{\prime} \ | \ S_{t}=s, A_{t}=a\} = \sum_{r \in \mathcal{R}} p(s^{\prime},r|s, a)<br>$$<br>and the excepted rewards for state-action-next-state triples,<br>$$<br>r(s, a, s^{\prime}) \doteq \mathbb{E}[R_{t+1} \ | \ S_{t}=s, A_{t}=a, S_{t+1}=s^{\prime}] = \frac{\sum_{r \in \mathcal{R}}rp(s^{\prime},r|s,a)}{p(s^{\prime}|s,a)}<br>$$<br>Almost all reinforcement learning algorithms involve estimating <em>value functions</em>–functions of states (or of state-action pairs) that estimate <em>how good</em> it is for the agent to be in a given state (or how good it is to perform a given action in a given state).</p><p>Recall that a policy, $\pi$, is a mapping from a each state, $s \in \mathcal{S}$, and action, $a \in \mathcal{A}(s)$, to the probability $\pi(a|s)$ of taking action <em>a</em> when in state <em>s</em>. Informally, the <em>value</em> of a state <em>s</em> under a policy $\pi$, denoted $v_{\pi}(s)$, is the excepted return when starting in <em>s</em> and following $\pi$ thereafter. For MDPs, we can define $v_{\pi}(s)$ formally as<br>$$<br>v_{\pi}(s) \doteq \mathbb{E_{\pi}}[G_{t} \ | \ S_{t}=s] = \mathbb{E_{\pi}}\left[\sum_{k=0}^{\infty} \gamma^{k} R_{t+k+1} \ | \ S_{t}=s \right]<br>$$<br>Note that the value of the terminal state, if any, is always zero. We call the function $v_{\pi}$ the <em>state-value function for policy $\pi$.</em></p><p>Similarly, we define the value of taking action <em>a</em> in state <em>s</em> under a policy $\pi$, denoted $q_{\pi}(s,a)$, as the expected return starting from $s$, taking the action $a$, and thereafter following policy $\pi$:<br>$$<br>q_{\pi}(s,a) \doteq \mathbb{E_{\pi}}[G_{t} \ | \ S_{t}=s, A_{t}=a] = \mathbb{E_{\pi}}\left[\sum_{k=0}^{\infty} \gamma^{k} R_{t+k+1} \ | \ S_{t}=s, A_{t}=a\right]<br>$$<br>We call $q_{\pi}$ the <em>action-value function for policy $\pi$</em>.</p><p>A fundamental property of the value functions used in reinforcement learning and dynamic programming is that they satisfy particular recursive relationships. For any policy $\pi$ and any state $s$, the following consistency condition holds between the value of $s$ and the value of its possible successor states:<br>$$<br>\begin{align}<br>v_{\pi}(s) &amp;\doteq \mathbb{E_{\pi}[G_{t} \ | \ S_{t}=s]} \\<br>&amp;= \mathbb{E_{\pi}}\left[\sum_{k=0}^{\infty} \gamma^{k} R_{t+k+1} \ | \ S_{t}=s \right] \\<br>&amp;= \mathbb{E_{\pi}}\left[R_{t+1} + \gamma \sum_{k=0}^{\infty} \gamma^{k} R_{t+k+2} \ | \ S_{t}=s \right] \\<br>&amp;= \sum_{a} \pi(a|s) \sum_{s^{\prime}}\sum_{r}p(s^{\prime},r|s,a) \left[ r + \gamma \mathbb{E_{\pi}} \left[ \sum_{k=0}^{\infty} \gamma^{k} R_{t+k+2} | S_{t+1}=s^{\prime} \right] \right] \\<br>&amp;= \sum_{a} \pi(a|s) \sum_{s^{\prime}, r}p(s^{\prime},r|s,a) \left[ r + \gamma v_{\pi}(s^{\prime}) \right], \;\;\; \forall s \in \mathcal{S},<br>\end{align}<br>$$<br>Equation (11) is the <em>Bellman equation for $v_{\pi}$</em>.</p><p>Figure 1 (left) shows a rectangular grid world representation of a simple finite MDP. The cells of the grid correspond to the states of the environment. At each cell, four actions are possible: <strong>north</strong>, <strong>south</strong>, <strong>east</strong>, and <strong>west</strong>, which deterministically cause the agent to move one cell in the respective direction on the grid. Action would take the agent off the grid leave its location unchanged, but also result in a reward of -1. Other actions result in a reward of 0, excepted those that move the agent out of the special states A and B. From state A, all four actions yield a reward of +10 and take the agent to $\mathrm{A^{\prime}}$. From state B, all actions yield a reward +5 and take the agent to $\mathrm{B^{\prime}}$.</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/grid_world/grid_world.png" alt="grid_world"></p><p><em>Figure 1</em></p><p>Suppose the agent selects all four actions with equal probability in all states. Figure 1 (right) shows the value function, $v_{\pi}$, for this policy, for the discounted reward case with $\gamma = 0.9$. This value function was computed by solving the system of linear equations (11).</p><p>OK, now let us solve this problem. The first, we need to define the grid world by code.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">WORLD_SIZE = <span class="number">5</span></div><div class="line">A_POS = [<span class="number">0</span>, <span class="number">1</span>]</div><div class="line">A_PRIME_POS = [<span class="number">4</span>, <span class="number">1</span>]</div><div class="line">B_POS = [<span class="number">0</span>, <span class="number">3</span>]</div><div class="line">B_PRIME_POS = [<span class="number">2</span>, <span class="number">3</span>]</div><div class="line">discount = <span class="number">0.9</span></div><div class="line"></div><div class="line">world = np.zeros((WORLD_SIZE, WORLD_SIZE))</div></pre></td></tr></table></figure><p>This world has 5 by 5 cells, and there are four special cells: A, A’, B, B’. Discount represents the $\gamma $ in equation (11). We know that the agent in the world selects all four actions with equal probability in all states (cells). So we have:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># left, up, right, down</span></div><div class="line">actions = [<span class="string">'L'</span>, <span class="string">'U'</span>, <span class="string">'R'</span>, <span class="string">'D'</span>]</div><div class="line"></div><div class="line">actionProb = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_SIZE):</div><div class="line">    actionProb.append([])</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_SIZE):</div><div class="line">        actionProb[i].append(dict(&#123;<span class="string">'L'</span>:<span class="number">0.25</span>, <span class="string">'U'</span>:<span class="number">0.25</span>, <span class="string">'R'</span>:<span class="number">0.25</span>, <span class="string">'D'</span>:<span class="number">0.25</span>&#125;))</div></pre></td></tr></table></figure><p>The <strong>actionProb</strong> is a list that has five items. Each item represents a row in the grid and it also is a list that has five items that represents a column in corresponding row, that is, each item in a row represents a cell in the grid. In all cells (states), there are four direction could be selected with equal probability 0.25. Then, we’ll define a undirected graph with weights. The node represented the cell in grid. If between two node has a edge then the agent could move between this two nodes (cells). The weight on the edges represents the reward do this move.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">nextState = []</div><div class="line">actionReward = []</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_SIZE):</div><div class="line">    nextState.append([])</div><div class="line">    actionReward.append([])</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_SIZE):</div><div class="line">        next = dict()</div><div class="line">        reward = dict()</div><div class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</div><div class="line">            next[<span class="string">'U'</span>] = [i, j]</div><div class="line">            reward[<span class="string">'U'</span>] = <span class="number">-1.0</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            next[<span class="string">'U'</span>] = [i - <span class="number">1</span>, j]</div><div class="line">            reward[<span class="string">'U'</span>] = <span class="number">0.0</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> i == WORLD_SIZE - <span class="number">1</span>:</div><div class="line">            next[<span class="string">'D'</span>] = [i, j]</div><div class="line">            reward[<span class="string">'D'</span>] = <span class="number">-1.0</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            next[<span class="string">'D'</span>] = [i + <span class="number">1</span>, j]</div><div class="line">            reward[<span class="string">'D'</span>] = <span class="number">0.0</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> j == <span class="number">0</span>:</div><div class="line">            next[<span class="string">'L'</span>] = [i, j]</div><div class="line">            reward[<span class="string">'L'</span>] = <span class="number">-1.0</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            next[<span class="string">'L'</span>] = [i, j - <span class="number">1</span>]</div><div class="line">            reward[<span class="string">'L'</span>] = <span class="number">0.0</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> j == WORLD_SIZE - <span class="number">1</span>:</div><div class="line">            next[<span class="string">'R'</span>] = [i, j]</div><div class="line">            reward[<span class="string">'R'</span>] = <span class="number">-1.0</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            next[<span class="string">'R'</span>] = [i, j + <span class="number">1</span>]</div><div class="line">            reward[<span class="string">'R'</span>] = <span class="number">0.0</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> [i, j] == A_POS:</div><div class="line">            next[<span class="string">'L'</span>] = next[<span class="string">'R'</span>] = next[<span class="string">'D'</span>] = next[<span class="string">'U'</span>] = A_PRIME_POS</div><div class="line">            reward[<span class="string">'L'</span>] = reward[<span class="string">'R'</span>] = reward[<span class="string">'D'</span>] = reward[<span class="string">'U'</span>] = <span class="number">10.0</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> [i, j] == B_POS:</div><div class="line">            next[<span class="string">'L'</span>] = next[<span class="string">'R'</span>] = next[<span class="string">'D'</span>] = next[<span class="string">'U'</span>] = B_PRIME_POS</div><div class="line">            reward[<span class="string">'L'</span>] = reward[<span class="string">'R'</span>] = reward[<span class="string">'D'</span>] = reward[<span class="string">'U'</span>] = <span class="number">5.0</span></div><div class="line"></div><div class="line">        nextState[i].append(next)</div><div class="line">        actionReward[i].append(reward)</div></pre></td></tr></table></figure><p>The <strong>nextState</strong> and <strong>actionReward</strong> are the same as <strong>actionProb</strong> that we explained earlier.</p><p>Now, we could solve this problem by use the equation (11):<br>$$<br>\begin{align}<br>v_{\pi}(s) &amp;\doteq \sum_{a} \pi(a|s) \sum_{s^{\prime}, r}p(s^{\prime},r|s,a) \left[ r + \gamma v_{\pi}(s^{\prime}) \right], \;\;\; \forall s \in \mathcal{S},<br>\end{align}<br>$$<br>Let us jump into the implementation detail.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="comment"># keep iteration until convergence</span></div><div class="line">    newWorld = np.zeros((WORLD_SIZE, WORLD_SIZE))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_SIZE):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_SIZE):</div><div class="line">            <span class="keyword">for</span> action <span class="keyword">in</span> actions:</div><div class="line">                newPosition = nextState[i][j][action]</div><div class="line">                <span class="comment"># bellman equation</span></div><div class="line">                newWorld[i, j] += actionProb[i][j][action] * (actionReward[i][j][action] + discount * world[newPosition[<span class="number">0</span>], newPosition[<span class="number">1</span>]])</div><div class="line">    <span class="keyword">if</span> np.sum(np.abs(world - newWorld)) &lt; <span class="number">1e-4</span>:</div><div class="line">        print(<span class="string">'Random Policy'</span>)</div><div class="line">        print(newWorld)</div><div class="line">        <span class="keyword">break</span></div><div class="line">    world = newWorld</div></pre></td></tr></table></figure><p>The core code is:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">newWorld[i, j] += actionProb[i][j][action] * (actionReward[i][j][action] + 		 discount * world[newPosition[<span class="number">0</span>], newPosition[<span class="number">1</span>]])</div></pre></td></tr></table></figure><p>The <code>+=</code> represents the first sum notation in the equation (11). If we ensure the current state (cell) and action will take in this world, then the next state and reward also will be ensured. So $\sum_{s^{\prime},r} p(s^{\prime}, r | s, a)$ is equal to 1.</p><p>The result as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Random Policy</div><div class="line">[[ <span class="number">3.30902999</span>  <span class="number">8.78932551</span>  <span class="number">4.42765281</span>  <span class="number">5.3224012</span>   <span class="number">1.49221235</span>]</div><div class="line"> [ <span class="number">1.52162172</span>  <span class="number">2.9923515</span>   <span class="number">2.25017358</span>  <span class="number">1.90760531</span>  <span class="number">0.5474363</span> ]</div><div class="line"> [ <span class="number">0.05085614</span>  <span class="number">0.73820423</span>  <span class="number">0.67314689</span>  <span class="number">0.35821982</span> <span class="number">-0.40310755</span>]</div><div class="line"> [<span class="number">-0.97355865</span> <span class="number">-0.43546179</span> <span class="number">-0.35484864</span> <span class="number">-0.58557148</span> <span class="number">-1.18304148</span>]</div><div class="line"> [<span class="number">-1.8576669</span>  <span class="number">-1.34519762</span> <span class="number">-1.22923364</span> <span class="number">-1.42288454</span> <span class="number">-1.97514545</span>]]</div></pre></td></tr></table></figure><p>We can see the value of all states is the same as the Figure 1.</p><p>Solving a reinforcement learning task means, roughly, finding a policy that achieves a lot of reward over the long run. For finite MDPs, we can precisely define an optimal policy in the following way. Value functions define a partial ordering over policies. A policy $\pi$ is defined to be better than or equal to a policy $\pi^{\prime}$ if its excepted return is greater than or equal to that of $\pi^{\prime}$ for all states. In other words, $\pi \ge \pi^{\prime}$ if and only if $v_{\pi}(s) \ge v_{\pi^{\prime}}(s)$ for all $s \in \mathcal{S}$. There is always at least one policy that is better than or equal to all other policies. This is an <em>optimal policy</em>. Although there may be more than one, we denote all the optimal policies by $\pi_{\star}$. They share the same state-value function, called the <em>optimal state-value function</em>, denote $v_{\star}$, and defined as<br>$$<br>v_{\star}(s) \doteq \max_{\pi} v_{\pi}(s),<br>$$<br>for all $s \in \mathcal{S}$.</p><p>Optimal policies also share the same <em>optimal action-value function</em>, denoted $q_{\star}$, and defined as<br>$$<br>q_{\star}(s, a) \doteq \max_{\pi} q_{\pi}(s, a)<br>$$<br>for all $s \in \mathcal{S}$ and $a \in \mathcal{A(s)}$. For the state-action pair <em>(s, a)</em>, this function gives the excepted return for taking action <em>a</em> in state <em>s</em> and thereafter following an optimal policy. Thus, we can write $q_{\star}$ in terms of $v_{\star}$ as follows:<br>$$<br>q_{\star}(s, a) = \mathbb{E}[R_{t+1} + \gamma v_{\star} \ | \ S_{t}=s, A_{t}=a]<br>$$<br>Suppose we solve the Bellman equation for $v_{\star}$ for the simple grid task introduced in earlier and shown again in Figure 2 (left). Recall that state A is followed by a reward of +10 and transition to state A’. while state B is followed by a reward of +5 and transition to state B’. Figure 2 (middle) shows the optimal value function, and Figure 2 (right) shows the corresponding optimal policies. Where there are multiple arrows in a cell, any of the corresponding actions are optimal.</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/grid_world/optimal_value.png" alt="optimal_value"></p><p><em>Figure 2</em></p><p>Now, let us solve this problem:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">world = np.zeros((WORLD_SIZE, WORLD_SIZE))</div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="comment"># keep iteration until convergence</span></div><div class="line">    newWorld = np.zeros((WORLD_SIZE, WORLD_SIZE))</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_SIZE):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, WORLD_SIZE):</div><div class="line">            values = []</div><div class="line">            <span class="keyword">for</span> action <span class="keyword">in</span> actions:</div><div class="line">                newPosition = nextState[i][j][action]</div><div class="line">                <span class="comment"># value iteration</span></div><div class="line">                values.append(actionReward[i][j][action] + discount * world[newPosition[<span class="number">0</span>], newPosition[<span class="number">1</span>]])</div><div class="line">            newWorld[i][j] = np.max(values)</div><div class="line">    <span class="keyword">if</span> np.sum(np.abs(world - newWorld)) &lt; <span class="number">1e-4</span>:</div><div class="line">        print(<span class="string">'Optimal Policy'</span>)</div><div class="line">        print(newWorld)</div><div class="line">        <span class="keyword">break</span></div><div class="line">    world = newWorld</div></pre></td></tr></table></figure><p>We can see the core code is as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">newWorld[i][j] = np.max(values)</div></pre></td></tr></table></figure><p>The only difference between this code and the earlier code is the prior only uses the maximum value and the latter uses the weighted average.</p><p>The result is below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Optimal Policy</div><div class="line">[[ <span class="number">21.97744338</span>  <span class="number">24.41938153</span>  <span class="number">21.97744338</span>  <span class="number">19.41938153</span>  <span class="number">17.47744338</span>]</div><div class="line"> [ <span class="number">19.77969904</span>  <span class="number">21.97744338</span>  <span class="number">19.77969904</span>  <span class="number">17.80172914</span>  <span class="number">16.02153504</span>]</div><div class="line"> [ <span class="number">17.80172914</span>  <span class="number">19.77969904</span>  <span class="number">17.80172914</span>  <span class="number">16.02153504</span>  <span class="number">14.41938153</span>]</div><div class="line"> [ <span class="number">16.02153504</span>  <span class="number">17.80172914</span>  <span class="number">16.02153504</span>  <span class="number">14.41938153</span>  <span class="number">12.97744338</span>]</div><div class="line"> [ <span class="number">14.41938153</span>  <span class="number">16.02153504</span>  <span class="number">14.41938153</span>  <span class="number">12.97744338</span>  <span class="number">11.67969904</span>]]</div></pre></td></tr></table></figure><p>It is not doubt that the result is the same as the Figure 2 (middle).</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;A reinforcement learning task that satisfied the Markov property is called &lt;em&gt;Markov decision process&lt;/em&gt;, or &lt;em&gt;MDP&lt;/em&gt;. If the stat
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>k-Armed Bandit Problem</title>
    <link href="http://yoursite.com/2017/05/27/k-Armed-Bandit-Problem/"/>
    <id>http://yoursite.com/2017/05/27/k-Armed-Bandit-Problem/</id>
    <published>2017-05-27T04:27:49.000Z</published>
    <updated>2017-06-13T06:00:32.852Z</updated>
    
    <content type="html"><![CDATA[<p>Consider the following learning problem. You are faced repeatedly with a choice among $k$ different options, or actions. After each choice you receive a numerical reward chosen from a stationary probability distribution that depends on the action you selected. Your objective is to maximize the expected total reward over some time period, for example, over 1000 action selections, or <em>time steps</em>.</p><p>This is the original form of the <em>k-armed bandit problem</em>. Each of the <em>k</em> actions has an excepted or mean reward given that action is selected; let us call this <em>value</em> of that action. We denote the action selected on time step <em>t</em> as $A_{t}$, and the corresponding reward as $R_{t}$. The value then of an arbitrary action <em>a</em>, denoted $q_{\star}(a)$, is the excepted reward given that <em>a</em> is selected:<br>$$<br>q_{\star}(a) = \mathbb{E}[R_t|A_t=a]<br>$$<br>If you knew the value of each action, then it would be trivial to solve the <em>k</em>-armed bandit problem: you would always select the action with highest value. We assume that you do not know the action values with certainty, although you may have estimates. We denote the estimated value of action <em>a</em> at time <em>t</em> as $Q_{t}(a) \approx q_{\star}(a)$.</p><p>We begin by looking more closely at some simple methods for estimating the values of actions and for using the estimates to make action selection decisions. Recall that the true value of an action is the mean reward when action is selected. One natural way to estimate this is by averaging the rewards actually received:</p><p>$$Q_t(a) \doteq \frac{\text{sum of rewards when a taken prior to t}}{\text{number of times a taken prior to t}} = \frac{\sum_{i=1}^{t-1}R_i \cdot \mathbf{1}_{A_i=a}}{\sum_{i=1}^{t-1}\mathbf{1}_{A_i=a}}$$</p><p>where $\mathbf{1}_{\text{predicate}}$ denotes the random variable that is 1 if <em>predicate</em> is true and 0 if it is not. If the denominator is zero, then we instead define $Q_t(a)$ as some default value, such as $Q_1(a) = 0$. As the denominator goes to infinity, by the law of large numbers, $Q_t(a)$ converges to $q_{\star} (a)$. We call this the <strong><em>sample-average</em></strong> method for estimating action values because each estimate is an average of the sample of relevant rewards.</p><p>The simplest action selection rule is to select the action (or one of the actions) with highest estimated action value, that is, to select at step <em>t</em> one of the greedy actions, $A_t^\star$ for which $Q_t(A_t^\star) = \max_a Q_t(a)$. This <em>greedy</em> action selection method can be written as<br>$$<br>A_t \doteq argmax_a Q_t(a)<br>$$<br>Naturally, we could use the <em>$\epsilon$-greedy</em> method rather the <em>greedy</em> method. We’ll show their difference on the performance. Now, let’s jump into the implementation details. In order to be able to see the results quickly, we set to <em>k</em> to be <em>10</em>. The first, we generate 10 stationary probability distributions that we’ll sample from to generate action values. The generate method is below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data=np.random.randn(<span class="number">200</span>,<span class="number">10</span>) + np.random.randn(<span class="number">10</span>)</div></pre></td></tr></table></figure><p>We first generate randomly 10 true excepted values by <code>np.random.randn(10)</code>, then I’m going to change the variance to 1. So we get 10 stationary probability distributions. The visualizations are as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/k-armed-bandit/action_value_distributions.png" alt="action_value_distributions"></p><p>We’re going to compare how different $\epsilon$ values affect the end result.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">epsilonGreedy</span><span class="params">(nBandits, time)</span>:</span></div><div class="line">    epsilons = [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.01</span>]</div><div class="line">    bandits = []</div><div class="line">    <span class="keyword">for</span> epsInd, eps <span class="keyword">in</span> enumerate(epsilons):</div><div class="line">        bandits.append([Bandit(epsilon=eps, sampleAverages=<span class="keyword">True</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, nBandits)])</div><div class="line">    bestActionCounts, averageRewards = banditSimulation(nBandits, time, bandits)</div><div class="line">    <span class="keyword">global</span> figureIndex</div><div class="line">    plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    <span class="keyword">for</span> eps, counts <span class="keyword">in</span> zip(epsilons, bestActionCounts):</div><div class="line">        plt.plot(counts, label=<span class="string">'epsilon = '</span>+str(eps))</div><div class="line">    plt.xlabel(<span class="string">'Steps'</span>)</div><div class="line">    plt.ylabel(<span class="string">'% optimal action'</span>)</div><div class="line">    plt.legend()</div><div class="line">    plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    <span class="keyword">for</span> eps, rewards <span class="keyword">in</span> zip(epsilons, averageRewards):</div><div class="line">        plt.plot(rewards, label=<span class="string">'epsilon = '</span>+str(eps))</div><div class="line">    plt.xlabel(<span class="string">'Steps'</span>)</div><div class="line">    plt.ylabel(<span class="string">'average reward'</span>)</div><div class="line">    plt.legend()</div></pre></td></tr></table></figure><p>Before we go into the details, we introduce the <strong>Bandit</strong> object first.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bandit</span>:</span></div><div class="line">    <span class="comment"># @kArm: # of arms</span></div><div class="line">    <span class="comment"># @epsilon: probability for exploration in epsilon-greedy algorithm</span></div><div class="line">    <span class="comment"># @initial: initial estimation for each action</span></div><div class="line">    <span class="comment"># @stepSize: constant step size for updating estimations</span></div><div class="line">    <span class="comment"># @sampleAverages: if True, use sample averages to update estimations instead of constant step size</span></div><div class="line">    <span class="comment"># @UCB: if not None, use UCB algorithm to select action</span></div><div class="line">    <span class="comment"># @gradient: if True, use gradient based bandit algorithm</span></div><div class="line">    <span class="comment"># @gradientBaseline: if True, use average reward as baseline for gradient based bandit algorithm</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kArm=<span class="number">10</span>, epsilon=<span class="number">0.</span>, initial=<span class="number">0.</span>, stepSize=<span class="number">0.1</span>, sampleAverages=False, UCBParam=None, gradient=False, gradientBaseline=False, trueReward=<span class="number">0.</span>)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getAction</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">takeAction</span><span class="params">(self, action)</span>:</span></div></pre></td></tr></table></figure><p>For now we just introduce <em>sample-average</em> method, so skip other methods parameters. Let us see the initialization method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kArm=<span class="number">10</span>, epsilon=<span class="number">0.</span>, initial=<span class="number">0.</span>, stepSize=<span class="number">0.1</span>, sampleAverages=False, UCBParam=None,</span></span></div><div class="line">             gradient=False, gradientBaseline=False, trueReward=<span class="number">0.</span>):</div><div class="line">    self.k = kArm</div><div class="line">    self.stepSize = stepSize</div><div class="line">    self.sampleAverages = sampleAverages</div><div class="line">    self.indices = np.arange(self.k)</div><div class="line">    self.time = <span class="number">0</span></div><div class="line">    self.UCBParam = UCBParam</div><div class="line">    self.gradient = gradient</div><div class="line">    self.gradientBaseline = gradientBaseline</div><div class="line">    self.averageReward = <span class="number">0</span></div><div class="line">    self.trueReward = trueReward</div><div class="line"></div><div class="line">    <span class="comment"># real reward for each action</span></div><div class="line">    self.qTrue = []</div><div class="line"></div><div class="line">    <span class="comment"># estimation for each action</span></div><div class="line">    self.qEst = np.zeros(self.k)</div><div class="line"></div><div class="line">    <span class="comment"># # of chosen times for each action</span></div><div class="line">    self.actionCount = []</div><div class="line"></div><div class="line">    self.epsilon = epsilon</div><div class="line"></div><div class="line">    <span class="comment"># initialize real rewards with N(0,1) distribution and estimations with desired initial value</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, self.k):</div><div class="line">        self.qTrue.append(np.random.randn() + trueReward)</div><div class="line">        self.qEst[i] = initial</div><div class="line">        self.actionCount.append(<span class="number">0</span>)</div><div class="line"></div><div class="line">    self.bestAction = np.argmax(self.qTrue)</div></pre></td></tr></table></figure><p>There are some important attributes. <strong>time</strong> is a number that represents the time steps now. <strong>actionCount</strong> is the times that correspond actions have been taken prior to current time steps. <strong>qTrue</strong> is a list. And each item is the true excepted value corresponding to each action. <strong>qEst</strong> is the estimate value of each action. It’s initialized to zero. <strong>epsilon</strong> is the $\epsilon$. Next, in the for loop, we initialize real rewards with N(0, 1) distribution and estimations with desired initial value. At last, the <strong>bestAction</strong> store the current best action will be take.</p><p>The next method tell us how to get the next action should be take:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAction</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="comment"># explore</span></div><div class="line">    <span class="keyword">if</span> self.epsilon &gt; <span class="number">0</span>:</div><div class="line">        <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, self.epsilon) == <span class="number">1</span>:</div><div class="line">            np.random.shuffle(self.indices)</div><div class="line">            <span class="keyword">return</span> self.indices[<span class="number">0</span>]</div><div class="line"></div><div class="line">    <span class="comment"># exploit</span></div><div class="line">    <span class="keyword">if</span> self.UCBParam <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        UCBEst = self.qEst + \</div><div class="line">                 self.UCBParam * np.sqrt(np.log(self.time + <span class="number">1</span>) / (np.asarray(self.actionCount) + <span class="number">1</span>))</div><div class="line">        <span class="keyword">return</span> np.argmax(UCBEst)</div><div class="line">    <span class="keyword">if</span> self.gradient:</div><div class="line">        expEst = np.exp(self.qEst)</div><div class="line">        self.actionProb = expEst / np.sum(expEst)</div><div class="line">        <span class="keyword">return</span> np.random.choice(self.indices, p=self.actionProb)</div><div class="line">    <span class="keyword">return</span> np.argmax(self.qEst)</div></pre></td></tr></table></figure><p>We can skip the second and the third if statements (we’ll introduce this two methods later). If we use <em>greedy</em> method, we just return the action that has highest value. Otherwise, we’re choosing randomly at $\epsilon$ probability.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeAction</span><span class="params">(self, action)</span>:</span></div><div class="line">    <span class="comment"># generate the reward under N(real reward, 1)</span></div><div class="line">    reward = np.random.randn() + self.qTrue[action]</div><div class="line">    self.time += <span class="number">1</span></div><div class="line">    self.averageReward = (self.time - <span class="number">1.0</span>) / self.time * self.averageReward + reward / self.time</div><div class="line">    self.actionCount[action] += <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> self.sampleAverages:</div><div class="line">        <span class="comment"># update estimation using sample averages</span></div><div class="line">        self.qEst[action] += <span class="number">1.0</span> / self.actionCount[action] * (reward - self.qEst[action])</div><div class="line">    <span class="keyword">elif</span> self.gradient:</div><div class="line">        oneHot = np.zeros(self.k)</div><div class="line">        oneHot[action] = <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> self.gradientBaseline:</div><div class="line">            baseline = self.averageReward</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            baseline = <span class="number">0</span></div><div class="line">        self.qEst = self.qEst + self.stepSize * (reward - baseline) * (oneHot - self.actionProb)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="comment"># update estimation with constant step size</span></div><div class="line">        self.qEst[action] += self.stepSize * (reward - self.qEst[action])</div><div class="line">    <span class="keyword">return</span> reward</div></pre></td></tr></table></figure><p>Similarly, we just skip other if statements and focus on this row:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">self.qEst[action] += <span class="number">1.0</span> / self.actionCount[action] * (reward - self.qEst[action])</div></pre></td></tr></table></figure><p>This formula seems different with the earlier one. The action-value methods we have discussed so far all estimate action values as sample averages of observed rewards. We now turn to the question of how these averages can be computed in a computationally efficient manner, in particular, with constant memory and per-time-step computation.</p><p>To simplify notation we concentrate on a single action. Let $R_i$ now denote the reward received after <em>i</em>th selection of <em>this action</em>, and let $Q_n$ denote the estimate of its action value after it has been select $n-1$ times, which we can now write simply as<br>$$<br>Q_n \doteq \frac{R_1 + R_2 + \cdots + R_{n-1}}{n-1}<br>$$<br>The obvious implementation would be to maintain a record of all the rewards and then perform this computation whenever the estimated value was needed. However, in this case the memory and computational requirements would grow over time as more rewards are seen.</p><p>It is easy to devise incremental formulas for updating averages with small, constant computation required to process each new reward. Given $Q_n$ and the <em>n</em>th reward, $R_n$, the new average of all <em>n</em> rewards can be computed by<br>$$<br>\begin{align}<br>Q_{n+1} &amp;\doteq \frac{1}{n}\sum_{i=1}^{n} R_i \\<br>&amp;= \frac{1}{n}(R_n + \sum_{i=1}^{n-1} R_i) \\<br>&amp;= \frac{1}{n}(R_n + (n-1) \frac{1}{n-1}\sum_{i=1}^{n-1} R_i) \\<br>&amp;= \frac{1}{n}(R_n + (n-1) Q_n) \\<br>&amp;= \frac{1}{n}(R_n + n Q_n - Q_n) \\<br>&amp;= Q_n + \frac{1}{n}[R_n - Q_n]<br>\end{align}<br>$$<br>So this is why the code is look like this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">self.qEst[action] += <span class="number">1.0</span> / self.actionCount[action] * (reward - self.qEst[action])</div></pre></td></tr></table></figure><p>Back to <strong>epsilonGreedy()</strong> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">epsilonGreedy</span><span class="params">(nBandits, time)</span>:</span></div><div class="line">    epsilons = [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.01</span>]</div><div class="line">    bandits = []</div><div class="line">    <span class="keyword">for</span> epsInd, eps <span class="keyword">in</span> enumerate(epsilons):</div><div class="line">        bandits.append([Bandit(epsilon=eps, sampleAverages=<span class="keyword">True</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, nBandits)])</div><div class="line">    bestActionCounts, averageRewards = banditSimulation(nBandits, time, bandits)</div><div class="line">    <span class="keyword">global</span> figureIndex</div><div class="line">    plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    <span class="keyword">for</span> eps, counts <span class="keyword">in</span> zip(epsilons, bestActionCounts):</div><div class="line">        plt.plot(counts, label=<span class="string">'epsilon = '</span>+str(eps))</div><div class="line">    plt.xlabel(<span class="string">'Steps'</span>)</div><div class="line">    plt.ylabel(<span class="string">'% optimal action'</span>)</div><div class="line">    plt.legend()</div><div class="line">    plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    <span class="keyword">for</span> eps, rewards <span class="keyword">in</span> zip(epsilons, averageRewards):</div><div class="line">        plt.plot(rewards, label=<span class="string">'epsilon = '</span>+str(eps))</div><div class="line">    plt.xlabel(<span class="string">'Steps'</span>)</div><div class="line">    plt.ylabel(<span class="string">'average reward'</span>)</div><div class="line">    plt.legend()</div></pre></td></tr></table></figure><p>Now, we get <strong>nBandits</strong> bandits and each bandit has 10 arm. Then we use a bandit simulation to simulate this process.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">banditSimulation</span><span class="params">(nBandits, time, bandits)</span>:</span></div><div class="line">    bestActionCounts = [np.zeros(time, dtype=<span class="string">'float'</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, len(bandits))]</div><div class="line">    averageRewards = [np.zeros(time, dtype=<span class="string">'float'</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, len(bandits))]</div><div class="line">    <span class="keyword">for</span> banditInd, bandit <span class="keyword">in</span> enumerate(bandits):</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nBandits):</div><div class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">0</span>, time):</div><div class="line">                action = bandit[i].getAction()</div><div class="line">                reward = bandit[i].takeAction(action)</div><div class="line">                averageRewards[banditInd][t] += reward</div><div class="line">                <span class="keyword">if</span> action == bandit[i].bestAction:</div><div class="line">                    bestActionCounts[banditInd][t] += <span class="number">1</span></div><div class="line">        bestActionCounts[banditInd] /= nBandits</div><div class="line">        averageRewards[banditInd] /= nBandits</div><div class="line">    <span class="keyword">return</span> bestActionCounts, averageRewards</div></pre></td></tr></table></figure><p>The <strong>bandits</strong> is a list that has three item. Each item is a list that contains <strong>nBandits</strong> bandits that has a corresponding epsilon value. We calculate the average total reward of 2000 bandits is to eliminate the effect of noise. Ok, let us see the final result.</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/k-armed-bandit/epsilon_greedy_optimal_action.png" alt="epsilon_greedy_optimal_action"><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/k-armed-bandit/epsilon_greedy_average_reward.png" alt="epsilon_greedy_average_reward"></p><p>We can see the algorithm reaches the best performance when epsilon is set to 0.1.</p><p>The averaging methods discussed so far are appropriate in a stationary environment, but not if the bandit is changing over time. As noted earlier, we often encounter reinforcement learning problems that are effectively nonstationary. In such cases it makes sense to weight recent rewards more heavily than long-past ones. One of the most popular ways of doing this is to use a constant step-size parameter. For example, the incremental update rule for updating an average $Q_n$ of the $n-1$ past rewards is modified to be<br>$$<br>Q_{n+1} \doteq Q_n + \alpha [R_n - Q_n]<br>$$<br>where the step-size parameter $\alpha \in (0, 1]$ is constant. This results in $Q_{n+1}$ being a weighted average of past rewards and the initial estimate $Q_1$:<br>$$<br>\begin{align}<br>Q_{n+1} &amp;\doteq Q_n + \alpha [R_n - Q_n] \\<br>&amp;= \alpha R_n + (1 - \alpha) Q_n \\<br>&amp;= \alpha R_n + (1 - \alpha) [\alpha R_{n-1} + (1 - \alpha) Q_{n-1}] \\<br>&amp;= \alpha R_n + (1 - \alpha) \alpha R_{n-1} + (1 - \alpha) ^2 Q_{n-1} \\<br>&amp;= \alpha R_n + (1 - \alpha) \alpha R_{n-1} + (1 - \alpha) ^2 R_{n-1} + \cdots + (1 - \alpha) ^ {n-1} \alpha R_1 + (1 - \alpha) ^ n Q_1 \\<br>&amp;= (1 - \alpha) ^ n Q_1 + \sum_{i=1}^{n} \alpha (1 - \alpha) ^ {n-i} R_i<br>\end{align}<br>$$<br>We call this a <em>weighted average</em> because the sum of the weights is 1. In fact, the weight decays exponentially according to the exponent on $1-\alpha$. According, this is sometimes called an <em>exponential, recency-weighted average</em>.</p><p>Sometimes it is convenient to vary the step-size parameter from step to step. Let $\alpha_n(a)$ denote the step-size parameter used to process the reward received after <em>n</em>th selection of action <em>a</em>. As we noted, the choice $\alpha_n(a)=\frac{1}{n}$ results in the sample-average method, which is guaranteed to converge to the true action values by the law of the large numbers. A well-known result in stochastic approximation theory gives us the conditions required to assure convergence with probability 1:<br>$$<br>\sum_{n=1}^{\infty}\alpha_{n}(a) = \infty \; \text{and} \; \sum_{n=1}^{\infty}\alpha_{n}^{2}(a) &lt; \infty<br>$$<br>All the methods we have discussed so far are dependent to some extent on the initial action-value estimates, $Q_1(a)$. <strong>In the language of statistics, these methods are <em>biased</em> by their initial estimates. For the sample-average methods, the bias disappears once all actions have been selected at least once, but for methods with constant $\alpha$ (weighted avetrage), the bias is permanent, though decreasing over time. In practice, this kind of bias is usually not a problem and can sometimes be very helpful.</strong> The downside is that the initial estimates become, in effect, a set of parameters that must be picked by the user, if only to set them all to zero. The upside is that they provide an easy way to supply some prior knowledge about what level of rewards can be excepted. So, let us do a experiment. The first we set them all to zero and the we set them all to a constant, 5.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimisticInitialValues</span><span class="params">(nBandits, time)</span>:</span></div><div class="line">    bandits = [[], []]</div><div class="line">    bandits[<span class="number">0</span>] = [Bandit(epsilon=<span class="number">0</span>, initial=<span class="number">5</span>, stepSize=<span class="number">0.1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, nBandits)]</div><div class="line">    bandits[<span class="number">1</span>] = [Bandit(epsilon=<span class="number">0.1</span>, initial=<span class="number">0</span>, stepSize=<span class="number">0.1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, nBandits)]</div><div class="line">    bestActionCounts, averageRewards = banditSimulation(nBandits, time, bandits)</div><div class="line">    <span class="keyword">global</span> figureIndex</div><div class="line">    plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    plt.plot(bestActionCounts[<span class="number">0</span>], label=<span class="string">'epsilon = 0, q = 5'</span>)</div><div class="line">    plt.plot(bestActionCounts[<span class="number">1</span>], label=<span class="string">'epsilon = 0.1, q = 0'</span>)</div><div class="line">    plt.xlabel(<span class="string">'Steps'</span>)</div><div class="line">    plt.ylabel(<span class="string">'% optimal action'</span>)</div><div class="line">    plt.legend()</div><div class="line">    plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    plt.plot(averageRewards[<span class="number">0</span>], label=<span class="string">'epsilon=0, initial=5, stepSize=0.1'</span>)</div><div class="line">    plt.plot(averageRewards[<span class="number">1</span>], label=<span class="string">'epsilon=0.1, initial=0, stepSize=0.1'</span>)</div><div class="line">    plt.xlabel(<span class="string">'Steps'</span>)</div><div class="line">    plt.ylabel(<span class="string">'average reward'</span>)</div><div class="line">    plt.legend()</div></pre></td></tr></table></figure><p>The <strong>Bandit</strong> object’s <strong>takeAction()</strong> has a little difference:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">self.qEst[action] += self.stepSize * (reward - self.qEst[action])</div></pre></td></tr></table></figure><p>The result is as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/k-armed-bandit/optimistic_initial_values.png" alt="optimistic_initial_value_optimal_action"><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/k-armed-bandit/optimistic_initial_values_average_reward.png" alt="optimistic_initial_value_optimal_action"></p><p>We can see it reaches the better performance than the $\epsilon$-greedy method, when they are all used the weighted average method. Notice that the $\epsilon$-greedy with weighted-average method is worsen than the $\epsilon$-greedy with sample-average method.</p><p>We regard it as a simple trick that can be quite effective on stationary problems, but it is far from being a generally useful approach to encouraging exploration. For example, it is not well suited to nonstationary problems because its drive for exploration is inherently temporary. If the task changes, creating a renewed need for exploration, this method cannot help. Indeed, any method that focuses on the initial state in any special way is unlikely to help with the general nonstationary case.</p><p>Exploration is needed because the estimates of the action values are uncertain. The greedy actions are those that look best at present, but some of the other actions may actually be better. $\epsilon$-greedy action selection forces the non-greedy actions to be tried, but indiscriminately, with no preference for those that are nearly greedy or particularly uncertain. It would be better to select among the non-greedy actions according to their potential for actually being optimal, taking into account both how close their estimates are to being maximal and the uncertainties in those estimates. One effective way of doing this is to select actions as<br>$$<br>A_t \doteq argmax_a \left [Q_t(a) + c\sqrt{\frac{\ln{t}}{N_t(a)}}\ \right]<br>$$<br>where $N_t(a)$ denotes the number of times that action <em>a</em> has been selected prior to time <em>t</em>, and the number $c&gt;0$ controls the degree of exploration. If $N_t(a)=0$, then <em>a</em> is considered to be a maximizing action. The idea of this is called <em>upper confidence bound</em> (UCB). Let us implement it.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ucb</span><span class="params">(nBandits, time)</span>:</span></div><div class="line">    bandits = [[], []]</div><div class="line">    bandits[<span class="number">0</span>] = [Bandit(epsilon=<span class="number">0</span>, stepSize=<span class="number">0.1</span>, UCBParam=<span class="number">2</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, nBandits)]</div><div class="line">    bandits[<span class="number">1</span>] = [Bandit(epsilon=<span class="number">0.1</span>, stepSize=<span class="number">0.1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, nBandits)]</div><div class="line">    _, averageRewards = banditSimulation(nBandits, time, bandits)</div><div class="line">    <span class="keyword">global</span> figureIndex</div><div class="line">    plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    plt.plot(averageRewards[<span class="number">0</span>], label=<span class="string">'UCB c = 2'</span>)</div><div class="line">    plt.plot(averageRewards[<span class="number">1</span>], label=<span class="string">'epsilon greedy epsilon = 0.1'</span>)</div><div class="line">    plt.xlabel(<span class="string">'Steps'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Average reward'</span>)</div><div class="line">    plt.legend()</div></pre></td></tr></table></figure><p>We note that the <strong>UCBParam=2</strong>. The Bandit object explains this. The <strong>getAction()</strong> method and <strong>takeAction()</strong> method are as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAction</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="comment"># explore</span></div><div class="line">    <span class="keyword">if</span> self.epsilon &gt; <span class="number">0</span>:</div><div class="line">        <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, self.epsilon) == <span class="number">1</span>:</div><div class="line">            np.random.shuffle(self.indices)</div><div class="line">            <span class="keyword">return</span> self.indices[<span class="number">0</span>]</div><div class="line"></div><div class="line">    <span class="comment"># exploit</span></div><div class="line">    <span class="keyword">if</span> self.UCBParam <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        UCBEst = self.qEst + \</div><div class="line">                 self.UCBParam * np.sqrt(np.log(self.time + <span class="number">1</span>) / (np.asarray(self.actionCount) + <span class="number">1</span>))</div><div class="line">        <span class="keyword">return</span> np.argmax(UCBEst)</div><div class="line">    <span class="keyword">if</span> self.gradient:</div><div class="line">        expEst = np.exp(self.qEst)</div><div class="line">        self.actionProb = expEst / np.sum(expEst)</div><div class="line">        <span class="keyword">return</span> np.random.choice(self.indices, p=self.actionProb)</div><div class="line">    <span class="keyword">return</span> np.argmax(self.qEst)</div><div class="line"></div><div class="line"><span class="comment"># take an action, update estimation for this action</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeAction</span><span class="params">(self, action)</span>:</span></div><div class="line">    <span class="comment"># generate the reward under N(real reward, 1)</span></div><div class="line">    reward = np.random.randn() + self.qTrue[action]</div><div class="line">    self.time += <span class="number">1</span></div><div class="line">    self.averageReward = (self.time - <span class="number">1.0</span>) / self.time * self.averageReward + reward / self.time</div><div class="line">    self.actionCount[action] += <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> self.sampleAverages:</div><div class="line">        <span class="comment"># update estimation using sample averages</span></div><div class="line">        self.qEst[action] += <span class="number">1.0</span> / self.actionCount[action] * (reward - self.qEst[action])</div><div class="line">    <span class="keyword">elif</span> self.gradient:</div><div class="line">        oneHot = np.zeros(self.k)</div><div class="line">        oneHot[action] = <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> self.gradientBaseline:</div><div class="line">            baseline = self.averageReward</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            baseline = <span class="number">0</span></div><div class="line">        self.qEst = self.qEst + self.stepSize * (reward - baseline) * (oneHot - self.actionProb)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="comment"># update estimation with constant step size</span></div><div class="line">        self.qEst[action] += self.stepSize * (reward - self.qEst[action])</div><div class="line">    <span class="keyword">return</span> reward</div></pre></td></tr></table></figure><p>We can see the policy get next action has changed but the update policy has not changed. The result is here:<img src="http://o7ie0tcjk.bkt.clouddn.com/rl/k-armed-bandit/ucb_average_reward.png" alt="ucb_average_reward"></p><p>We omit the figure about the optimal action because the trend of this two figures are the same. UCB will often perform well, but is more difficult than $\epsilon$-greedy to extend beyond bandits to the more general reinforcement learning setting considered in the more advanced problems. In these more advanced settings there is currently no known practical way of utilizing the idea of UCB action selection.</p><p>So far we have considered methods that estimate action values and use those estimates to select actions. This is often a good approach, but it is not the only one possible. Now, we consider learning a numerical <em>preference</em> $H_t(a)$ for each action <em>a</em>. The larger the preference, the more often that action is taken, but the preference has no interpretation in terms of reward. Only the relative preference of one action over another is important; if we add 1000 to all the preferences there is no effect on the action probabilities, which are determined according to a softmax distribution as follows:<br>$$<br>Pr\{A_t=a\} \doteq \frac{e^{H_t(a)}}{\sum_{b=1}^{k}e^{H_t(b)}} \doteq \pi_t(a)<br>$$<br>where here we have also introduced a useful new notation $\pi_t(a)$ for the probability of taking action <em>a</em> at time <em>t</em>. Initially all preferences are the same (e.g., $H_1(a)=0, \forall a$) so that all actions have an equal probability of being selected.</p><p>There is a natural learning algorithm for this setting based on the idea of stochastic gradient ascent. On each step, after selection the action $A_t$ and receiving the reward $R_t$, the preferences are updated by:<br>$$<br>\begin{align}<br>H_{t+1}(A_t) \doteq H_t(A_t) + \alpha (R_t - \overline{R_t}) (1 - \pi_t(A_t)), \; \text{and} \\<br>H_{t+1}(a) \doteq H_t(a) - \alpha (R_t - \overline{R_t}) \pi_t(a), \;\;\;\;\;\; \forall{a \neq A_t}<br>\end{align}<br>$$<br>where $\alpha&gt;0$ is a ste-size parameter, and $\overline{R_t} \in \mathbb{R}$ is the average of all the rewards up through and including time <em>t</em>, which can be computed incrementally. The $\overline{R_t}$ term serves as a <strong><em>baseline</em></strong> with which the reward is compared. Let us see the implement details (takeAction() method and getAction() method).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> self.gradient:</div><div class="line">	expEst = np.exp(self.qEst)</div><div class="line">	self.actionProb = expEst / np.sum(expEst)</div><div class="line">	<span class="keyword">return</span> np.random.choice(self.indices, p=self.actionProb)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">elif</span> self.gradient:</div><div class="line">	oneHot = np.zeros(self.k)</div><div class="line">	oneHot[action] = <span class="number">1</span></div><div class="line">	<span class="keyword">if</span> self.gradientBaseline:</div><div class="line">		baseline = self.averageReward</div><div class="line">	<span class="keyword">else</span>:</div><div class="line">		baseline = <span class="number">0</span></div><div class="line">	self.qEst = self.qEst + self.stepSize * (reward - baseline) * (oneHot self.actionProb)</div></pre></td></tr></table></figure><p>The below figure shows results with the gradient bandit algorithm on a variant of the 10-armed testbed in which the true excepted rewards were selected according to a normal distribution with a mean of +4 instead of zero (and with unit variance as before).</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/k-armed-bandit/gradient_bandit_optimal_action.png" alt="gradient_bandit_optimal_action"></p><p>Despite their simplicity, in our opinion the methods presented in here can fairly be considered the state of the art. Finally, we do a parameter study of the various bandit algorithms presented in here.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">figure2_6</span><span class="params">(nBandits, time)</span>:</span></div><div class="line">    labels = [<span class="string">'epsilon-greedy'</span>, <span class="string">'gradient bandit'</span>,</div><div class="line">              <span class="string">'UCB'</span>, <span class="string">'optimistic initialization'</span>]</div><div class="line">    generators = [<span class="keyword">lambda</span> epsilon: Bandit(epsilon=epsilon, sampleAverages=<span class="keyword">True</span>),</div><div class="line">                  <span class="keyword">lambda</span> alpha: Bandit(gradient=<span class="keyword">True</span>, stepSize=alpha, gradientBaseline=<span class="keyword">True</span>),</div><div class="line">                  <span class="keyword">lambda</span> coef: Bandit(epsilon=<span class="number">0</span>, stepSize=<span class="number">0.1</span>, UCBParam=coef),</div><div class="line">                  <span class="keyword">lambda</span> initial: Bandit(epsilon=<span class="number">0</span>, initial=initial, stepSize=<span class="number">0.1</span>)]</div><div class="line">    parameters = [np.arange(<span class="number">-7</span>, <span class="number">-1</span>),</div><div class="line">                  np.arange(<span class="number">-5</span>, <span class="number">2</span>),</div><div class="line">                  np.arange(<span class="number">-4</span>, <span class="number">3</span>),</div><div class="line">                  np.arange(<span class="number">-2</span>, <span class="number">3</span>)]</div><div class="line"></div><div class="line">    bandits = [[generator(math.pow(<span class="number">2</span>, param)) <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, nBandits)] <span class="keyword">for</span> generator, parameter <span class="keyword">in</span> zip(generators, parameters) <span class="keyword">for</span> param <span class="keyword">in</span> parameter]</div><div class="line">    _, averageRewards = banditSimulation(nBandits, time, bandits)</div><div class="line">    rewards = np.sum(averageRewards, axis=<span class="number">1</span>)/time</div><div class="line"></div><div class="line">    <span class="keyword">global</span> figureIndex</div><div class="line">    plt.figure(figureIndex)</div><div class="line">    figureIndex += <span class="number">1</span></div><div class="line">    i = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> label, parameter <span class="keyword">in</span> zip(labels, parameters):</div><div class="line">        l = len(parameter)</div><div class="line">        plt.plot(parameter, rewards[i:i+l], label=label)</div><div class="line">        i += l</div><div class="line">    plt.xlabel(<span class="string">'Parameter(2^x)'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Average reward'</span>)</div><div class="line">    plt.legend()</div></pre></td></tr></table></figure><p>The results as follows:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/rl/k-armed-bandit/bandit_algorithms_parameter_study.png" alt="parameters_study"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Consider the following learning problem. You are faced repeatedly with a choice among $k$ different options, or actions. After each choic
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Tic-Tac-Toe Game</title>
    <link href="http://yoursite.com/2017/05/26/Tic-tac-toe/"/>
    <id>http://yoursite.com/2017/05/26/Tic-tac-toe/</id>
    <published>2017-05-26T04:16:54.000Z</published>
    <updated>2017-06-30T06:59:01.026Z</updated>
    
    <content type="html"><![CDATA[<p>What is the Tic-Tac-Toe game? Two players take turns playing on a three-by-three board. One player plays Xs and the other Os until one player wins by placing three marks in a row, horizontally, vertically, or diagonally, as the X player has in the game shown to the blew. If the board fills up with neither player getting three in a row, the game is a draw.</p><p>There have three steps. Train, compete and play.</p><p>The first, let’s to see the train period. Follow is the train() method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(epochs=<span class="number">20000</span>)</span>:</span></div><div class="line">    player1 = Player()</div><div class="line">    player2 = Player()</div><div class="line">    judger = Judger(player1, player2)</div><div class="line">    player1Win = <span class="number">0.0</span></div><div class="line">    player2Win = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, epochs):</div><div class="line">        print(<span class="string">"Epoch"</span>, i)</div><div class="line">        winner = judger.play()</div><div class="line">        <span class="keyword">if</span> winner == <span class="number">1</span>:</div><div class="line">            player1Win += <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> winner == <span class="number">-1</span>:</div><div class="line">            player2Win += <span class="number">1</span></div><div class="line">        judger.reset()</div><div class="line">    print(player1Win / epochs)</div><div class="line">    print(player2Win / epochs)</div><div class="line">    player1.savePolicy()</div><div class="line">    player2.savePolicy()</div></pre></td></tr></table></figure><p>Train() method create two Player objects first, and then let them to play the tic-tac-toe through a Judger object. It’s a very simple process.</p><p>Next. let to get into the Player object.</p><p>Follow is the code of the Player object. For understand easily, I omitted the implementation details of each method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Player</span>:</span></div><div class="line">    <span class="comment"># @stepSize: step size to update estimations</span></div><div class="line">    <span class="comment"># @exploreRate: possibility to explore</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stepSize=<span class="number">0.1</span>, exploreRate=<span class="number">0.1</span>)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setSymbol</span><span class="params">(self, symbol)</span>:</span></div><div class="line">    <span class="comment"># accept a state</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedState</span><span class="params">(self, state)</span>:</span></div><div class="line">    <span class="comment"># update estimation according to reward</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedReward</span><span class="params">(self, reward)</span>:</span></div><div class="line">    <span class="comment"># determine next action</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">takeAction</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">savePolicy</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loadPolicy</span><span class="params">(self)</span>:</span></div></pre></td></tr></table></figure><p>As a Player, the important thing during the train process is to learn a policy. The policy is a selection when the player faces a state. So there are two method savePolicy() and loadPolicy(). When the train process end, the player save its learned policy and load the same policy when the player compete with someone else later.</p><p>Follow is the implementation details:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">savePolicy</span><span class="params">(self)</span>:</span></div><div class="line">    fw = open(<span class="string">'optimal_policy_'</span> + str(self.symbol), <span class="string">'wb'</span>)</div><div class="line">    pickle.dump(self.estimations, fw)</div><div class="line">    fw.close()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadPolicy</span><span class="params">(self)</span>:</span></div><div class="line">    fr = open(<span class="string">'optimal_policy_'</span> + str(self.symbol), <span class="string">'rb'</span>)</div><div class="line">    self.estimations = pickle.load(fr)</div><div class="line">    fr.close()</div></pre></td></tr></table></figure><p>And, let’s to jump into the initialization method, the below is its source code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stepSize=<span class="number">0.1</span>, exploreRate=<span class="number">0.1</span>)</span>:</span></div><div class="line">        self.allStates = allStates</div><div class="line">        self.estimations = dict()</div><div class="line">        self.stepSize = stepSize</div><div class="line">        self.exploreRate = exploreRate</div><div class="line">        self.states = []</div></pre></td></tr></table></figure><p>Every player hold a dictionary. For each item in the dictionary, the key is the state, and the value is the estimation of the probability to win from this state. We use the TD(0) method to solve the problem. That is, we need to update .the state-value function step by step. The update rule is below:</p><p>$$ V(s) = V(s) + \alpha [V(s’) - V(s)] ​$$</p><p>The $\alpha$ is the step size, and the $s’$ is the next state, $s$ is the current state. $V(\star)$ is the estimation of the probability to win from $*$ state.</p><p>So, what is the explore rate. We need to know how to choose the next action at current state if we want to understand the explore rate. For every state, first we find the every state it can transfer to. Then we look up the dictionary to find the state that has the highest estimation value. This state is our action will take. The method called <strong>greedy policy</strong>. But, the value of each state is our estimation, so we can’t say it’s the true probability. So the greedy policy has some error. There is a method to solve this problem. At every state, we not only select the next state that has the highest probability but also choose the next state randomly by <strong>explore rate</strong> probability. Formerly, if we use the symbol $\epsilon$ represents the explore rate, then the method is called <strong>$\epsilon$-greedy</strong> method.</p><p>Next, let’s see what is the <strong>allStates</strong> variable.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">self.allStates = allStates</div></pre></td></tr></table></figure><p>we can see</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># all possible board configurations</span></div><div class="line">allStates = getAllStates()</div></pre></td></tr></table></figure><p>So what is the <strong>getAllStates()</strong> look like?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAllStates</span><span class="params">()</span>:</span></div><div class="line">    currentSymbol = <span class="number">1</span></div><div class="line">    currentState = State()</div><div class="line">    allStates = dict()</div><div class="line">    allStates[currentState.getHash()] = (currentState, currentState.isEnd())</div><div class="line">    getAllStatesImpl(currentState, currentSymbol, allStates)</div><div class="line">    <span class="keyword">return</span> allStates</div></pre></td></tr></table></figure><p>Until now you may ask what is the STATE? Below is the definition:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">State</span>:</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getHash</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isEnd</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nextState</span><span class="params">(self, i, j, symbol)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show</span><span class="params">(self)</span>:</span></div></pre></td></tr></table></figure><p>One state is one arrangement of pieces on the board. So one state has some extra attributions. Such as who is the winner at current state, if the state is the terminal state or not and so on. Specially, each state has a hash value for representation convenient. The board is represented by a n by n array, that is, one state is a n by n array.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="comment"># the board is represented by a n * n array,</span></div><div class="line">    <span class="comment"># 1 represents chessman of the player who moves first,</span></div><div class="line">    <span class="comment"># -1 represents chessman of another player</span></div><div class="line">    <span class="comment"># 0 represents empty position</span></div><div class="line">    self.data = np.zeros((BOARD_ROWS, BOARD_COLS))</div><div class="line">    self.winner = <span class="keyword">None</span></div><div class="line">    self.hashVal = <span class="keyword">None</span></div><div class="line">    self.end = <span class="keyword">None</span></div></pre></td></tr></table></figure><p>Below is how to calculate the hash value of a state:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># calculate the hash value for one state, it's unique</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHash</span><span class="params">(self)</span>:</span></div><div class="line">	<span class="keyword">if</span> self.hashVal <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">		self.hashVal = <span class="number">0</span></div><div class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> self.data.reshape(BOARD_ROWS * BOARD_COLS):</div><div class="line">			<span class="keyword">if</span> i == <span class="number">-1</span>:</div><div class="line">				i = <span class="number">2</span></div><div class="line">            self.hashVal = self.hashVal * <span class="number">3</span> + i</div><div class="line">    <span class="keyword">return</span> int(self.hashVal)</div></pre></td></tr></table></figure><p>Below is how to judge if a state is end or not:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># determine whether a player has won the game, or it's a tie</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">isEnd</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">if</span> self.end <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        <span class="keyword">return</span> self.end</div><div class="line">    results = []</div><div class="line">    <span class="comment"># check row</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, BOARD_ROWS):</div><div class="line">        results.append(np.sum(self.data[i, :]))</div><div class="line">    <span class="comment"># check columns</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, BOARD_COLS):</div><div class="line">        results.append(np.sum(self.data[:, i]))</div><div class="line"></div><div class="line">    <span class="comment"># check diagonals</span></div><div class="line">    results.append(<span class="number">0</span>)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, BOARD_ROWS):</div><div class="line">        results[<span class="number">-1</span>] += self.data[i, i]</div><div class="line">    results.append(<span class="number">0</span>)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, BOARD_ROWS):</div><div class="line">        results[<span class="number">-1</span>] += self.data[i, BOARD_ROWS - <span class="number">1</span> - i]</div><div class="line"></div><div class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</div><div class="line">        <span class="keyword">if</span> result == <span class="number">3</span>:</div><div class="line">            self.winner = <span class="number">1</span></div><div class="line">            self.end = <span class="keyword">True</span></div><div class="line">            <span class="keyword">return</span> self.end</div><div class="line">        <span class="keyword">if</span> result == <span class="number">-3</span>:</div><div class="line">            self.winner = <span class="number">-1</span></div><div class="line">            self.end = <span class="keyword">True</span></div><div class="line">            <span class="keyword">return</span> self.end</div><div class="line"></div><div class="line">    <span class="comment"># whether it's a tie</span></div><div class="line">    sum = np.sum(np.abs(self.data))</div><div class="line">    <span class="keyword">if</span> sum == BOARD_ROWS * BOARD_COLS:</div><div class="line">        self.winner = <span class="number">0</span></div><div class="line">        self.end = <span class="keyword">True</span></div><div class="line">        <span class="keyword">return</span> self.end</div><div class="line"></div><div class="line">    <span class="comment"># game is still going on</span></div><div class="line">    self.end = <span class="keyword">False</span></div><div class="line">    <span class="keyword">return</span> self.end</div></pre></td></tr></table></figure><p>There are two scenarios for the end of the game: Someone wins or ties. Because player A’s chessman is represents by 1 and play B is -1. So if A wins, then one row ‘s sum is n or one column’s sum is n or one diagnose’s sum is n. Otherwise is -n. And the state’s winner attribute is 1 or -1, that is, player A or player B. if the sum of the absolute value of the all chessman in the board is n by n, then the game is tie, winner is 0 (that is no one wins).</p><p>When someone put a chessman in the board, then the state is change and transfer to another state. How to get the state?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">nextState</span><span class="params">(self, i, j, symbol)</span>:</span></div><div class="line">    newState = State()</div><div class="line">    newState.data = np.copy(self.data)</div><div class="line">    newState.data[i, j] = symbol</div><div class="line">    <span class="keyword">return</span> newState</div></pre></td></tr></table></figure><p>And the last, we are play a game so we need a GUI. This is what the <strong>show()</strong> to do.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># print the board</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, BOARD_ROWS):</div><div class="line">        print(<span class="string">'-------------'</span>)</div><div class="line">        out = <span class="string">'| '</span></div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, BOARD_COLS):</div><div class="line">            <span class="keyword">if</span> self.data[i, j] == <span class="number">1</span>:</div><div class="line">                token = <span class="string">'*'</span></div><div class="line">            <span class="keyword">if</span> self.data[i, j] == <span class="number">0</span>:</div><div class="line">                token = <span class="string">'0'</span></div><div class="line">            <span class="keyword">if</span> self.data[i, j] == <span class="number">-1</span>:</div><div class="line">                token = <span class="string">'x'</span></div><div class="line">            out += token + <span class="string">' | '</span></div><div class="line">        print(out)</div><div class="line">    print(<span class="string">'-------------'</span>)</div></pre></td></tr></table></figure><p>Let’s come back to the <strong>getAllStates()</strong> method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAllStates</span><span class="params">()</span>:</span></div><div class="line">    currentSymbol = <span class="number">1</span></div><div class="line">    currentState = State()</div><div class="line">    allStates = dict()</div><div class="line">    allStates[currentState.getHash()] = (currentState, currentState.isEnd())</div><div class="line">    getAllStatesImpl(currentState, currentSymbol, allStates)</div><div class="line">    <span class="keyword">return</span> allStates</div></pre></td></tr></table></figure><p>Now we know what is a state and the next we need to generate all possible state. The first, we need build a data structure to store the all states. So we define a dictionary <strong>allStates</strong>. It’s key is the hash value of the state, and it’s value is a tuple. The first item of the tuple is the state (a n by n array) and the second item is a flag that represent the state whether is a terminal state or not. For generate the all states, we jump into the <strong>getAllStatesImpl()</strong> method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAllStatesImpl</span><span class="params">(currentState, currentSymbol, allStates)</span>:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, BOARD_ROWS):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, BOARD_COLS):</div><div class="line">            <span class="keyword">if</span> currentState.data[i][j] == <span class="number">0</span>:</div><div class="line">                newState = currentState.nextState(i, j, currentSymbol)</div><div class="line">                newHash = newState.getHash()</div><div class="line">                <span class="keyword">if</span> newHash <span class="keyword">not</span> <span class="keyword">in</span> allStates.keys():</div><div class="line">                    isEnd = newState.isEnd()</div><div class="line">                    allStates[newHash] = (newState, isEnd)</div><div class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> isEnd:</div><div class="line">                        getAllStatesImpl(newState, -currentSymbol, allStates)</div></pre></td></tr></table></figure><p>The <strong>getAllStatesImpl()</strong> method start with a empty board (currentState), and generate the states step by step (because it recursive calls itself). Because the game is very simple, so we could generate all possible states. But for the larger game, this is impossible.</p><p>Tada~Let’s come back to the Player object. We put the code here again for convenience.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Player</span>:</span></div><div class="line">    <span class="comment"># @stepSize: step size to update estimations</span></div><div class="line">    <span class="comment"># @exploreRate: possibility to explore</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stepSize=<span class="number">0.1</span>, exploreRate=<span class="number">0.1</span>)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setSymbol</span><span class="params">(self, symbol)</span>:</span></div><div class="line">    <span class="comment"># accept a state</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedState</span><span class="params">(self, state)</span>:</span></div><div class="line">    <span class="comment"># update estimation according to reward</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedReward</span><span class="params">(self, reward)</span>:</span></div><div class="line">    <span class="comment"># determine next action</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">takeAction</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">savePolicy</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loadPolicy</span><span class="params">(self)</span>:</span></div></pre></td></tr></table></figure><p>We has explained the initialization method. It’s worth to notice that the Player object has a attribute <strong>states</strong>. We’ll explain it later.</p><p>Below is the <strong>reset()</strong> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></div><div class="line">    self.states = []</div></pre></td></tr></table></figure><p>and below is the <strong>setSymbol()</strong> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">setSymbol</span><span class="params">(self, symbol)</span>:</span></div><div class="line">    self.symbol = symbol</div><div class="line">    <span class="keyword">for</span> hash <span class="keyword">in</span> self.allStates.keys():</div><div class="line">        (state, isEnd) = self.allStates[hash]</div><div class="line">        <span class="keyword">if</span> isEnd:</div><div class="line">            <span class="keyword">if</span> state.winner == self.symbol:</div><div class="line">                self.estimations[hash] = <span class="number">1.0</span></div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                self.estimations[hash] = <span class="number">0</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            self.estimations[hash] = <span class="number">0.5</span></div></pre></td></tr></table></figure><p>We know that every player’s chessman in the board has a symbol (1 or -1). This method is set a symbol to the player. Furthermore, this method initialize the estimate state-value dictionary (we mentioned it earlier).</p><p>And the <strong>feedState()</strong> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feedState</span><span class="params">(self, state)</span>:</span></div><div class="line">        self.states.append(state)</div></pre></td></tr></table></figure><p>The same as the <strong>states</strong> variable, we’ll explain it later.</p><p>Go on, below is the <strong>feedForward()</strong> method.This method not only the core of the Player object, but also it’s the core of the method that solve this game. That is, it’s the core of the TD(0) method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feedReward</span><span class="params">(self, reward)</span>:</span></div><div class="line">    <span class="keyword">if</span> len(self.states) == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span></div><div class="line">    self.states = [state.getHash() <span class="keyword">for</span> state <span class="keyword">in</span> self.states]</div><div class="line">    target = reward</div><div class="line">    <span class="keyword">for</span> latestState <span class="keyword">in</span> reversed(self.states):</div><div class="line">        value = self.estimations[</div><div class="line">            latestState] + self.stepSize * (target - self.estimations[latestState])</div><div class="line">        self.estimations[latestState] = value</div><div class="line">        target = value</div><div class="line">    self.states = []</div></pre></td></tr></table></figure><p>We mentioned the update rule earlier. Below is it’s implementation:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">value = self.estimations[</div><div class="line">            latestState] + self.stepSize * (target - self.estimations[latestState])</div></pre></td></tr></table></figure><p>Notice that we can see there are two row in the code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">self.estimations[latestState] = value</div><div class="line">target = value</div></pre></td></tr></table></figure><p>So the update rule is a chain-like update rule. Specially, the <strong>states</strong> variable is set to empty (In the same way, we’ll explain it later).</p><p>The next method (implement the <strong>$\epsilon$-greedy</strong> policy) also is very important, because it tells the player how to take the next action:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeAction</span><span class="params">(self)</span>:</span></div><div class="line">    state = self.states[<span class="number">-1</span>]</div><div class="line">    nextStates = []</div><div class="line">    nextPositions = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(BOARD_ROWS):</div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(BOARD_COLS):</div><div class="line">            <span class="keyword">if</span> state.data[i, j] == <span class="number">0</span>:</div><div class="line">                nextPositions.append([i, j])</div><div class="line">                nextStates.append(state.nextState(</div><div class="line">                    i, j, self.symbol).getHash())</div><div class="line">    <span class="keyword">if</span> np.random.binomial(<span class="number">1</span>, self.exploreRate):</div><div class="line">        np.random.shuffle(nextPositions)</div><div class="line">        <span class="comment"># Not sure if truncating is the best way to deal with exploratory step</span></div><div class="line">        <span class="comment"># Maybe it's better to only skip this step rather than forget all</span></div><div class="line">        <span class="comment"># the history</span></div><div class="line">        self.states = []</div><div class="line">        action = nextPositions[<span class="number">0</span>]</div><div class="line">        action.append(self.symbol)</div><div class="line">        <span class="keyword">return</span> action</div><div class="line"></div><div class="line">    values = []</div><div class="line">    <span class="keyword">for</span> hash, pos <span class="keyword">in</span> zip(nextStates, nextPositions):</div><div class="line">        values.append((self.estimations[hash], pos))</div><div class="line">    np.random.shuffle(values)</div><div class="line">    values.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>], reverse=<span class="keyword">True</span>)</div><div class="line">    action = values[<span class="number">0</span>][<span class="number">1</span>]</div><div class="line">    action.append(self.symbol)</div><div class="line">    <span class="keyword">return</span> action</div></pre></td></tr></table></figure><p>We’ll see that the return action is a list that the first item is a list contains the next position and the second item is the symbol that represents the player.</p><p>Ok, the travel about the Player object is over. Then, we’ll look into the Judger object. Before that, let’s recall the <strong>train()</strong> process.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(epochs=<span class="number">20000</span>)</span>:</span></div><div class="line">    player1 = Player()</div><div class="line">    player2 = Player()</div><div class="line">    judger = Judger(player1, player2)</div><div class="line">    player1Win = <span class="number">0.0</span></div><div class="line">    player2Win = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, epochs):</div><div class="line">        print(<span class="string">"Epoch"</span>, i)</div><div class="line">        winner = judger.play()</div><div class="line">        <span class="keyword">if</span> winner == <span class="number">1</span>:</div><div class="line">            player1Win += <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> winner == <span class="number">-1</span>:</div><div class="line">            player2Win += <span class="number">1</span></div><div class="line">        judger.reset()</div><div class="line">    print(player1Win / epochs)</div><div class="line">    print(player2Win / epochs)</div><div class="line">    player1.savePolicy()</div><div class="line">    player2.savePolicy()</div></pre></td></tr></table></figure><p>We can see that the Judger object accept two parameters, that is, two player object. The definition of Judger is below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Judger</span>:</span></div><div class="line">    <span class="comment"># @player1: player who will move first, its chessman will be 1</span></div><div class="line">    <span class="comment"># @player2: another player with chessman -1</span></div><div class="line">    <span class="comment"># @feedback: if True, both players will receive rewards when game is end</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, player1, player2, feedback=True)</span>:</span></div><div class="line">    <span class="comment"># give reward to two players</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">giveReward</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedCurrentState</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="comment"># @show: if True, print each board during the game</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">play</span><span class="params">(self, show=False)</span>:</span></div></pre></td></tr></table></figure><p>Notice that the rewards only receive at the end of the game. The first, let’s see the initialization method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, player1, player2, feedback=True)</span>:</span></div><div class="line">    self.p1 = player1</div><div class="line">    self.p2 = player2</div><div class="line">    self.feedback = feedback</div><div class="line">    self.currentPlayer = <span class="keyword">None</span></div><div class="line">    self.p1Symbol = <span class="number">1</span></div><div class="line">    self.p2Symbol = <span class="number">-1</span></div><div class="line">    self.p1.setSymbol(self.p1Symbol)</div><div class="line">    self.p2.setSymbol(self.p2Symbol)</div><div class="line">    self.currentState = State()</div><div class="line">    self.allStates = allStates</div></pre></td></tr></table></figure><p>p1 and p2 is the two player that play the game. The feedback represents if the reward propagation back or not. On the train process the feedback is true and on the compete process and play process the feedback is false. currentPlayer represents who should move next. and next the judger set symbol for each player. The currentState is the start state (the board is empty).</p><p>Go on. Below is the <strong>giveReward()</strong> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">giveReward</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">if</span> self.currentState.winner == self.p1Symbol:</div><div class="line">        self.p1.feedReward(<span class="number">1</span>)</div><div class="line">        self.p2.feedReward(<span class="number">0</span>)</div><div class="line">    <span class="keyword">elif</span> self.currentState.winner == self.p2Symbol:</div><div class="line">        self.p1.feedReward(<span class="number">0</span>)</div><div class="line">        self.p2.feedReward(<span class="number">1</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        self.p1.feedReward(<span class="number">0</span>)</div><div class="line">        self.p2.feedReward(<span class="number">0</span>)</div></pre></td></tr></table></figure><p>Just like we say earlier, the rewards only receive at the end of the game. So if player A wins, then we give him a reward 1 and otherwise we give him a reward 0. If ties, then all reward is 0. We explain the <strong>feedCurrentState()</strong> later. Now we explain <strong>reset()</strong> method first.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></div><div class="line">    self.p1.reset()</div><div class="line">    self.p2.reset()</div><div class="line">    self.currentState = State()</div><div class="line">    self.currentPlayer = <span class="keyword">None</span></div></pre></td></tr></table></figure><p>It’s simple right? Let’s skip it and go to the core method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">play</span><span class="params">(self, show=False)</span>:</span></div><div class="line">    self.reset()</div><div class="line">    self.feedCurrentState()</div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        <span class="comment"># set current player</span></div><div class="line">        <span class="keyword">if</span> self.currentPlayer == self.p1:</div><div class="line">            self.currentPlayer = self.p2</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            self.currentPlayer = self.p1</div><div class="line">        <span class="keyword">if</span> show:</div><div class="line">            self.currentState.show()</div><div class="line">        [i, j, symbol] = self.currentPlayer.takeAction()</div><div class="line">        self.currentState = self.currentState.nextState(i, j, symbol)</div><div class="line">        hashValue = self.currentState.getHash()</div><div class="line">        self.currentState, isEnd = self.allStates[hashValue]</div><div class="line">        self.feedCurrentState()</div><div class="line">        <span class="keyword">if</span> isEnd:</div><div class="line">            <span class="keyword">if</span> self.feedback:</div><div class="line">                self.giveReward()</div><div class="line">            <span class="keyword">return</span> self.currentState.winner</div></pre></td></tr></table></figure><p>We can see the two player alternate to play chess. Each reached state on the game will feed to the players’ states attribute.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">self.feedCurrentState()</div></pre></td></tr></table></figure><p>So below is the method like:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feedCurrentState</span><span class="params">(self)</span>:</span></div><div class="line">    self.p1.feedState(self.currentState)</div><div class="line">    self.p2.feedState(self.currentState)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feedState</span><span class="params">(self, state)</span>:</span></div><div class="line">    self.states.append(state)</div></pre></td></tr></table></figure><p>Let’s explain the states now. Each player only update the states that the game reached in one game. Each reached state on the game will feed to the players’ states attribute. <strong>Note that, the player just update part of the states of the all states. Only after a lot of games, the all states could be updated. So all TD methods need a lot of epochs.</strong></p><p>Ouch! Finally three core objects are explained. Now we’ll clear about the three process: train, compete and play.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(epochs=<span class="number">20000</span>)</span>:</span></div><div class="line">    player1 = Player()</div><div class="line">    player2 = Player()</div><div class="line">    judger = Judger(player1, player2)</div><div class="line">    player1Win = <span class="number">0.0</span></div><div class="line">    player2Win = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, epochs):</div><div class="line">        print(<span class="string">"Epoch"</span>, i)</div><div class="line">        winner = judger.play()</div><div class="line">        <span class="keyword">if</span> winner == <span class="number">1</span>:</div><div class="line">            player1Win += <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> winner == <span class="number">-1</span>:</div><div class="line">            player2Win += <span class="number">1</span></div><div class="line">        judger.reset()</div><div class="line">    print(player1Win / epochs)</div><div class="line">    print(player2Win / epochs)</div><div class="line">    player1.savePolicy()</div><div class="line">    player2.savePolicy()</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compete</span><span class="params">(turns=<span class="number">500</span>)</span>:</span></div><div class="line">    player1 = Player(exploreRate=<span class="number">0</span>)</div><div class="line">    player2 = Player(exploreRate=<span class="number">0</span>)</div><div class="line">    judger = Judger(player1, player2, <span class="keyword">False</span>)</div><div class="line">    player1.loadPolicy()</div><div class="line">    player2.loadPolicy()</div><div class="line">    player1Win = <span class="number">0.0</span></div><div class="line">    player2Win = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, turns):</div><div class="line">        print(<span class="string">"Epoch"</span>, i)</div><div class="line">        winner = judger.play()</div><div class="line">        <span class="keyword">if</span> winner == <span class="number">1</span>:</div><div class="line">            player1Win += <span class="number">1</span></div><div class="line">        <span class="keyword">if</span> winner == <span class="number">-1</span>:</div><div class="line">            player2Win += <span class="number">1</span></div><div class="line">        judger.reset()</div><div class="line">    print(player1Win / turns)</div><div class="line">    print(player2Win / turns)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">play</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        player1 = Player(exploreRate=<span class="number">0</span>)</div><div class="line">        player2 = HumanPlayer()</div><div class="line">        judger = Judger(player1, player2, <span class="keyword">False</span>)</div><div class="line">        player1.loadPolicy()</div><div class="line">        winner = judger.play(<span class="keyword">True</span>)</div><div class="line">        <span class="keyword">if</span> winner == player2.symbol:</div><div class="line">            print(<span class="string">"Win!"</span>)</div><div class="line">        <span class="keyword">elif</span> winner == player1.symbol:</div><div class="line">            print(<span class="string">"Lose!"</span>)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            print(<span class="string">"Tie!"</span>)</div></pre></td></tr></table></figure><p>It’s worth noting that there is a <strong>HumanPlayer</strong> object.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HumanPlayer</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stepSize=<span class="number">0.1</span>, exploreRate=<span class="number">0.1</span>)</span>:</span></div><div class="line">        self.symbol = <span class="keyword">None</span></div><div class="line">        self.currentState = <span class="keyword">None</span></div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setSymbol</span><span class="params">(self, symbol)</span>:</span></div><div class="line">        self.symbol = symbol</div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedState</span><span class="params">(self, state)</span>:</span></div><div class="line">        self.currentState = state</div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedReward</span><span class="params">(self, reward)</span>:</span></div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">takeAction</span><span class="params">(self)</span>:</span></div><div class="line">        data = int(input(<span class="string">"Input your position:"</span>))</div><div class="line">        data -= <span class="number">1</span></div><div class="line">        i = data // int(BOARD_COLS)</div><div class="line">        j = data % BOARD_COLS</div><div class="line">        <span class="keyword">if</span> self.currentState.data[i, j] != <span class="number">0</span>:</div><div class="line">            <span class="keyword">return</span> self.takeAction()</div><div class="line">        <span class="keyword">return</span> (i, j, self.symbol)</div></pre></td></tr></table></figure><p>We’ll see that this object do nothing. It just put a chess to on the board.</p><p>OK, you’re done! Finally, we put the complete code <a href="https://github.com/ewanlee/reinforcement-learning-an-introduction/blob/master/chapter01/TicTacToe.py" target="_blank" rel="external">here</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;What is the Tic-Tac-Toe game? Two players take turns playing on a three-by-three board. One player plays Xs and the other Os until one pl
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="TD" scheme="http://yoursite.com/tags/TD/"/>
    
  </entry>
  
  <entry>
    <title>How to generate a unique ID in a distribute system</title>
    <link href="http://yoursite.com/2017/05/25/How-to-generate-a-unique-ID-in-a-distribute-system/"/>
    <id>http://yoursite.com/2017/05/25/How-to-generate-a-unique-ID-in-a-distribute-system/</id>
    <published>2017-05-25T05:03:40.000Z</published>
    <updated>2017-05-25T07:22:01.461Z</updated>
    
    <content type="html"><![CDATA[<p>现今所有的企业级应用都需要处理海量的数据对象，这些对象都需要一个唯一的ID与其他的对象区分开来。在关系型数据库中，我们一般是创建主键来达到这个目的。一些数据库支持内建的列类型（AUTO_INCREMENT/AUTO_NUMBER）来产生一个单调递增的64位长的数。有些人喜欢在他们的应用层中生成id，以便获得对这代人的更多控制，然后使用数据层保存记录。但是，第二种方法通过缓存最新生成的数字，并且通过某种持久性技术保存已经生成的id的轨迹来避免主键冲突。</p><p>上述两种方法本身都有各自的优点和缺点，但它们都有一个共同的缺点，即在分布式架构的情况下，这些都不具有弹性。那么需要考虑数据分片在多个数据库节点之间时，第一个技术如何确保不同节点中的表不会产生相同的auto_increment数或想象一个拓扑，在多个节点上运行应用程序，那么第二种技术如何满足所有节点的需求。</p><p>没有一种方法可以满足所有的需求，下面是在许多大型应用程序中使用的最流行的方法。</p><h2 id="1-数据库自增长序列或字段"><a href="#1-数据库自增长序列或字段" class="headerlink" title="1. 数据库自增长序列或字段"></a><strong>1. 数据库自增长序列或字段</strong></h2><p>最常见的方式。利用数据库，全数据库唯一。</p><p>优点：</p><p>1）简单，代码方便，性能可以接受。</p><p>2）数字ID天然排序，对分页或者需要排序的结果很有帮助。</p><p>缺点：</p><p>1）不同数据库语法和实现不同，数据库迁移的时候或多数据库版本支持的时候需要处理。</p><p>2）在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障的风险。</p><p>3）在性能达不到要求的情况下，比较难于扩展。</p><p>4）如果遇见多个系统需要合并或者涉及到数据迁移会相当痛苦。</p><p>5）分表分库的时候会有麻烦。</p><p>优化方案：</p><p>1）针对主库单点，如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个数。比如：Master1 生成的是 1，4，7，10，Master2生成的是2,5,8,11 Master3生成的是 3,6,9,12。这样就可以有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载。</p><h2 id="2-UUID"><a href="#2-UUID" class="headerlink" title="2. UUID"></a><strong>2. UUID</strong></h2><p>常见的方式。可以利用数据库也可以利用程序生成，一般来说全球唯一。</p><p>优点：</p><p>1）简单，代码方便。</p><p>2）生成ID性能非常好，基本不会有性能问题。</p><p>3）全球唯一，在遇见数据迁移，系统数据合并，或者数据库变更等情况下，可以从容应对。</p><p>缺点：</p><p>1）没有排序，无法保证趋势递增。</p><p>2）UUID往往是使用字符串存储，查询的效率比较低。</p><p>3）存储空间比较大，如果是海量数据库，就需要考虑存储量的问题。</p><p>4）传输数据量大</p><p>5）不可读。</p><h2 id="3-UUID的变种"><a href="#3-UUID的变种" class="headerlink" title="3. UUID的变种"></a><strong>3. UUID的变种</strong></h2><p>1）为了解决UUID不可读，可以使用UUID to Int64的方法。及</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/// &lt;summary&gt;</span></div><div class="line"><span class="comment">/// 根据GUID获取唯一数字序列</span></div><div class="line"><span class="comment">/// &lt;/summary&gt;</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">GuidToInt64</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">byte</span>[] bytes = Guid.NewGuid().ToByteArray();</div><div class="line">    <span class="keyword">return</span> BitConverter.ToInt64(bytes, <span class="number">0</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>2）为了解决UUID无序的问题，NHibernate在其主键生成方式中提供了Comb算法（combined guid/timestamp）。保留GUID的10个字节，用另6个字节表示GUID生成的时间（DateTime）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/// &lt;summary&gt; </span></div><div class="line"><span class="comment">/// Generate a new &lt;see cref="Guid"/&gt; using the comb algorithm. </span></div><div class="line"><span class="comment">/// &lt;/summary&gt; </span></div><div class="line"><span class="function"><span class="keyword">private</span> Guid <span class="title">GenerateComb</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">byte</span>[] guidArray = Guid.NewGuid().ToByteArray();</div><div class="line"> </div><div class="line">    DateTime baseDate = <span class="keyword">new</span> DateTime(<span class="number">1900</span>, <span class="number">1</span>, <span class="number">1</span>);</div><div class="line">    DateTime now = DateTime.Now;</div><div class="line"> </div><div class="line">    <span class="comment">// Get the days and milliseconds which will be used to build    </span></div><div class="line">    <span class="comment">//the byte string    </span></div><div class="line">    TimeSpan days = <span class="keyword">new</span> TimeSpan(now.Ticks - baseDate.Ticks);</div><div class="line">    TimeSpan msecs = now.TimeOfDay;</div><div class="line"> </div><div class="line">    <span class="comment">// Convert to a byte array        </span></div><div class="line">    <span class="comment">// Note that SQL Server is accurate to 1/300th of a    </span></div><div class="line">    <span class="comment">// millisecond so we divide by 3.333333    </span></div><div class="line">    <span class="keyword">byte</span>[] daysArray = BitConverter.GetBytes(days.Days);</div><div class="line">    <span class="keyword">byte</span>[] msecsArray = BitConverter.GetBytes((<span class="keyword">long</span>)</div><div class="line">      (msecs.TotalMilliseconds / <span class="number">3.333333</span>));</div><div class="line"> </div><div class="line">    <span class="comment">// Reverse the bytes to match SQL Servers ordering    </span></div><div class="line">    Array.Reverse(daysArray);</div><div class="line">    Array.Reverse(msecsArray);</div><div class="line"> </div><div class="line">    <span class="comment">// Copy the bytes into the guid    </span></div><div class="line">    Array.Copy(daysArray, daysArray.Length - <span class="number">2</span>, guidArray,</div><div class="line">      guidArray.Length - <span class="number">6</span>, <span class="number">2</span>);</div><div class="line">    Array.Copy(msecsArray, msecsArray.Length - <span class="number">4</span>, guidArray,</div><div class="line">      guidArray.Length - <span class="number">4</span>, <span class="number">4</span>);</div><div class="line"> </div><div class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Guid(guidArray);</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>用上面的算法测试一下，得到如下的结果：作为比较，前面3个是使用COMB算法得出的结果，最后12个字符串是时间序（统一毫秒生成的3个UUID），过段时间如果再次生成，则12个字符串会比图示的要大。后面3个是直接生成的GUID。</p><p><a href="http://images2015.cnblogs.com/blog/15700/201602/15700-20160227213048174-1443183768.png" target="_blank" rel="external"><img src="http://images2015.cnblogs.com/blog/15700/201602/15700-20160227213048721-177386520.png" alt="ODX}_`4N5X$F93OAS~`8Z)C"></a></p><p>如果想把时间序放在前面，可以生成后改变12个字符串的位置，也可以修改算法类的最后两个Array.Copy。</p><h2 id="4-Redis生成ID"><a href="#4-Redis生成ID" class="headerlink" title="4. Redis生成ID"></a><strong>4. Redis生成ID</strong></h2><p>当使用数据库来生成ID性能不够要求的时候，我们可以尝试使用Redis来生成ID。这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现。</p><p>可以使用Redis集群来获取更高的吞吐量。假如一个集群中有5台Redis。可以初始化每台Redis的值分别是1,2,3,4,5，然后步长都是5。各个Redis生成的ID为：</p><p>A：1,6,11,16,21</p><p>B：2,7,12,17,22</p><p>C：3,8,13,18,23</p><p>D：4,9,14,19,24</p><p>E：5,10,15,20,25</p><p>这个，随便负载到哪个机确定好，未来很难做修改。但是3-5台服务器基本能够满足器上，都可以获得不同的ID。但是步长和初始值一定需要事先需要了。使用Redis集群也可以方式单点故障的问题。</p><p>另外，比较适合使用Redis来生成每天从0开始的流水号。比如订单号=日期+当日自增长号。可以每天在Redis中生成一个Key，使用INCR进行累加。</p><p>优点：</p><p>1）不依赖于数据库，灵活方便，且性能优于数据库。</p><p>2）数字ID天然排序，对分页或者需要排序的结果很有帮助。</p><p>缺点：</p><p>1）如果系统中没有Redis，还需要引入新的组件，增加系统复杂度。</p><p>2）需要编码和配置的工作量比较大。</p><h2 id="5-Twitter的snowflake算法"><a href="#5-Twitter的snowflake算法" class="headerlink" title="5. Twitter的snowflake算法"></a><strong>5. Twitter的snowflake算法</strong></h2><p>snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。</p><p>C#代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/// &lt;summary&gt;</span></div><div class="line">    <span class="comment">/// From: https://github.com/twitter/snowflake</span></div><div class="line">    <span class="comment">/// An object that generates IDs.</span></div><div class="line">    <span class="comment">/// This is broken into a separate class in case</span></div><div class="line">    <span class="comment">/// we ever want to support multiple worker threads</span></div><div class="line">    <span class="comment">/// per process</span></div><div class="line">    <span class="comment">/// &lt;/summary&gt;</span></div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IdWorker</span></span></div><div class="line">    &#123;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">long</span> workerId;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">long</span> datacenterId;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">long</span> sequence = <span class="number">0L</span>;</div><div class="line"></div><div class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> twepoch = <span class="number">1288834974657L</span>;</div><div class="line"></div><div class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> workerIdBits = <span class="number">5L</span>;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> datacenterIdBits = <span class="number">5L</span>;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> maxWorkerId = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; (<span class="keyword">int</span>)workerIdBits);</div><div class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> maxDatacenterId = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; (<span class="keyword">int</span>)datacenterIdBits);</div><div class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">long</span> sequenceBits = <span class="number">12L</span>;</div><div class="line"></div><div class="line">        <span class="keyword">private</span> <span class="keyword">long</span> workerIdShift = sequenceBits;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">long</span> datacenterIdShift = sequenceBits + workerIdBits;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">long</span> timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">long</span> sequenceMask = -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; (<span class="keyword">int</span>)sequenceBits);</div><div class="line"></div><div class="line">        <span class="keyword">private</span> <span class="keyword">long</span> lastTimestamp = -<span class="number">1L</span>;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">static</span> object syncRoot = <span class="keyword">new</span> object();</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">IdWorker</span><span class="params">(<span class="keyword">long</span> workerId, <span class="keyword">long</span> datacenterId)</span></span></div><div class="line">        &#123;</div><div class="line"></div><div class="line">            <span class="comment">// sanity check for workerId</span></div><div class="line">            <span class="keyword">if</span> (workerId &gt; maxWorkerId || workerId &lt; <span class="number">0</span>)</div><div class="line">            &#123;</div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> ArgumentException(string.Format(<span class="string">"worker Id can't be greater than %d or less than 0"</span>, maxWorkerId));</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span> (datacenterId &gt; maxDatacenterId || datacenterId &lt; <span class="number">0</span>)</div><div class="line">            &#123;</div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> ArgumentException(string.Format(<span class="string">"datacenter Id can't be greater than %d or less than 0"</span>, maxDatacenterId));</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">this</span>.workerId = workerId;</div><div class="line">            <span class="keyword">this</span>.datacenterId = datacenterId;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">nextId</span><span class="params">()</span></span></div><div class="line">        &#123;</div><div class="line">            lock (syncRoot)</div><div class="line">            &#123;</div><div class="line">                <span class="keyword">long</span> timestamp = timeGen();</div><div class="line"></div><div class="line">                <span class="keyword">if</span> (timestamp &lt; lastTimestamp)</div><div class="line">                &#123;</div><div class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> ApplicationException(string.Format(<span class="string">"Clock moved backwards.  Refusing to generate id for %d milliseconds"</span>, lastTimestamp - timestamp));</div><div class="line">                &#125;</div><div class="line"></div><div class="line">                <span class="keyword">if</span> (lastTimestamp == timestamp)</div><div class="line">                &#123;</div><div class="line">                    sequence = (sequence + <span class="number">1</span>) &amp; sequenceMask;</div><div class="line">                    <span class="keyword">if</span> (sequence == <span class="number">0</span>)</div><div class="line">                    &#123;</div><div class="line">                        timestamp = tilNextMillis(lastTimestamp);</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">else</span></div><div class="line">                &#123;</div><div class="line">                    sequence = <span class="number">0L</span>;</div><div class="line">                &#125;</div><div class="line"></div><div class="line">                lastTimestamp = timestamp;</div><div class="line"></div><div class="line">                <span class="keyword">return</span> ((timestamp - twepoch) &lt;&lt; (<span class="keyword">int</span>)timestampLeftShift) | (datacenterId &lt;&lt; (<span class="keyword">int</span>)datacenterIdShift) | (workerId &lt;&lt; (<span class="keyword">int</span>)workerIdShift) | sequence;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">tilNextMillis</span><span class="params">(<span class="keyword">long</span> lastTimestamp)</span></span></div><div class="line">        &#123;</div><div class="line">            <span class="keyword">long</span> timestamp = timeGen();</div><div class="line">            <span class="keyword">while</span> (timestamp &lt;= lastTimestamp)</div><div class="line">            &#123;</div><div class="line">                timestamp = timeGen();</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">return</span> timestamp;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">timeGen</span><span class="params">()</span></span></div><div class="line">        &#123;</div><div class="line">            <span class="keyword">return</span> (<span class="keyword">long</span>)(DateTime.UtcNow - <span class="keyword">new</span> DateTime(<span class="number">1970</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, DateTimeKind.Utc)).TotalMilliseconds;</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure><p>测试代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">TestIdWorker</span><span class="params">()</span></span></div><div class="line">        &#123;</div><div class="line">            HashSet&lt;<span class="keyword">long</span>&gt; set = <span class="keyword">new</span> HashSet&lt;<span class="keyword">long</span>&gt;();</div><div class="line">            IdWorker idWorker1 = <span class="keyword">new</span> IdWorker(<span class="number">0</span>, <span class="number">0</span>);</div><div class="line">            IdWorker idWorker2 = <span class="keyword">new</span> IdWorker(<span class="number">1</span>, <span class="number">0</span>);</div><div class="line">            Thread t1 = <span class="keyword">new</span> Thread(() =&gt; DoTestIdWoker(idWorker1, set));</div><div class="line">            Thread t2 = <span class="keyword">new</span> Thread(() =&gt; DoTestIdWoker(idWorker2, set));</div><div class="line">            t1.IsBackground = <span class="keyword">true</span>;</div><div class="line">            t2.IsBackground = <span class="keyword">true</span>;</div><div class="line"></div><div class="line">            t1.Start();</div><div class="line">            t2.Start();</div><div class="line">            <span class="keyword">try</span></div><div class="line">            &#123;</div><div class="line">                Thread.Sleep(<span class="number">30000</span>);</div><div class="line">                t1.Abort();</div><div class="line">                t2.Abort();</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">catch</span> (Exception e)</div><div class="line">            &#123;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            Console.WriteLine(<span class="string">"done"</span>);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">DoTestIdWoker</span><span class="params">(IdWorker idWorker, HashSet&lt;<span class="keyword">long</span>&gt; set)</span></span></div><div class="line">        &#123;</div><div class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>)</div><div class="line">            &#123;</div><div class="line">                <span class="keyword">long</span> id = idWorker.nextId();</div><div class="line">                <span class="keyword">if</span> (!set.Add(id))</div><div class="line">                &#123;</div><div class="line">                    Console.WriteLine(<span class="string">"duplicate:"</span> + id);</div><div class="line">                &#125;</div><div class="line"></div><div class="line">                Thread.Sleep(<span class="number">1</span>);</div><div class="line">            &#125;</div><div class="line">        &#125;</div></pre></td></tr></table></figure><p>snowflake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数，每个数据中心的机器数以及统一毫秒可以能的并发数来调整在算法中所需要的bit数。</p><p>优点：</p><p>1）不依赖于数据库，灵活方便，且性能优于数据库。</p><p>2）ID按照时间在单机上是递增的。</p><p>缺点：</p><p>1）在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步，也许有时候也会出现不是全局递增的情况。</p><p>Snowflake 的其他变种</p><p>Snowflake 有一些变种, 各个应用结合自己的实际场景对 Snowflake 做了一些改动. 这里主要介绍 3 种.</p><h3 id="5-1-Boundary-flake"><a href="#5-1-Boundary-flake" class="headerlink" title="5.1 Boundary flake"></a><strong>5.1 Boundary flake</strong></h3><p>变化:</p><ul><li>ID 长度扩展到 128 bits:</li><li>最高 64 bits 时间戳;</li><li>然后是 48 bits 的 Worker 号 (和 Mac 地址一样长);</li><li>最后是 16 bits 的 Seq Number</li><li>由于它用 48 bits 作为 Worker ID, 和 Mac 地址的长度一样, 这样启动时不需要和 Zookeeper 通讯获取 Worker ID. 做到了完全的去中心化</li><li>基于 Erlang</li></ul><p>它这样做的目的是用更多的 bits 实现更小的冲突概率, 这样就支持更多的 Worker 同时工作. 同时, 每毫秒能分配出更多的 ID</p><h3 id="5-2-Simpleflake"><a href="#5-2-Simpleflake" class="headerlink" title="5.2 Simpleflake"></a><strong>5.2 Simpleflake</strong></h3><p>Simpleflake 的思路是取消 Worker 号, 保留 41 bits 的 Timestamp, 同时把 sequence number 扩展到 22 bits;</p><p>Simpleflake 的特点:</p><ul><li>sequence number 完全靠随机产生 (这样也导致了生成的 ID 可能出现重复)</li><li>没有 Worker 号, 也就不需要和 Zookeeper 通讯, 实现了完全去中心化</li><li>Timestamp 保持和 Snowflake 一致, 今后可以无缝升级到 Snowflake</li></ul><p>Simpleflake 的问题就是 sequence number 完全随机生成, 会导致生成的 ID 重复的可能. 这个生成 ID 重复的概率随着每秒生成的 ID 数的增长而增长.</p><p>所以, Simpleflake 的限制就是每秒生成的 ID 不能太多 (最好小于 100次/秒, 如果大于 100次/秒的场景, Simpleflake 就不适用了, 建议切换回 Snowflake).</p><h3 id="5-3-instagram-的做法"><a href="#5-3-instagram-的做法" class="headerlink" title="5.3  instagram 的做法"></a><strong>5.3 instagram 的做法</strong></h3><p>先简单介绍一下 instagram 的分布式存储方案:</p><ul><li>先把每个 Table 划分为多个逻辑分片 (logic Shard), 逻辑分片的数量可以很大, 例如 2000 个逻辑分片</li><li>然后制定一个规则, 规定每个逻辑分片被存储到哪个数据库实例上面; 数据库实例不需要很多. 例如, 对有 2 个 PostgreSQL 实例的系统 (instagram 使用 PostgreSQL); 可以使用奇数逻辑分片存放到第一个数据库实例, 偶数逻辑分片存放到第二个数据库实例的规则</li><li>每个 Table 指定一个字段作为分片字段 (例如, 对用户表, 可以指定 uid 作为分片字段)</li><li>插入一个新的数据时, 先根据分片字段的值, 决定数据被分配到哪个逻辑分片 (logic Shard)</li><li>然后再根据 logic Shard 和 PostgreSQL 实例的对应关系, 确定这条数据应该被存放到哪台 PostgreSQL 实例上</li></ul><p>instagram unique ID 的组成:</p><ul><li>41 bits: Timestamp (毫秒)</li><li>13 bits: 每个 logic Shard 的代号 (最大支持 8 x 1024 个 logic Shards)</li><li>10 bits: sequence number; 每个 Shard 每毫秒最多可以生成 1024 个 ID</li></ul><p>生成 unique ID 时, 41 bits 的 Timestamp 和 Snowflake 类似, 这里就不细说了.</p><p>主要介绍一下 13 bits 的 logic Shard 代号 和 10 bits 的 sequence number 怎么生成.</p><p>logic Shard 代号:</p><ul><li>假设插入一条新的用户记录, 插入时, 根据 uid 来判断这条记录应该被插入到哪个 logic Shard 中.</li><li>假设当前要插入的记录会被插入到第 1341 号 logic Shard 中 (假设当前的这个 Table 一共有 2000 个 logic Shard)</li><li>新生成 ID 的 13 bits 段要填的就是 1341 这个数字</li></ul><p>sequence number 利用 PostgreSQL 每个 Table 上的 auto-increment sequence 来生成:</p><ul><li>如果当前表上已经有 5000 条记录, 那么这个表的下一个 auto-increment sequence 就是 5001 (直接调用 PL/PGSQL 提供的方法可以获取到)</li><li>然后把 这个 5001 对 1024 取模就得到了 10 bits 的 sequence number</li></ul><p>instagram 这个方案的优势在于:</p><ul><li>利用 logic Shard 号来替换 Snowflake 使用的 Worker 号, 就不需要到中心节点获取 Worker 号了. 做到了完全去中心化</li><li>另外一个附带的好处就是, 可以通过 ID 直接知道这条记录被存放在哪个 logic Shard 上</li></ul><p>同时, 今后做数据迁移的时候, 也是按 logic Shard 为单位做数据迁移的, 所以这种做法也不会影响到今后的数据迁移</p><h2 id="6-利用zookeeper生成唯一ID"><a href="#6-利用zookeeper生成唯一ID" class="headerlink" title="6. 利用zookeeper生成唯一ID"></a><strong>6. 利用zookeeper生成唯一ID</strong></h2><p>zookeeper主要通过其znode数据版本来生成序列号，可以生成32位和64位的数据版本号，客户端可以使用这个版本号来作为唯一的序列号。很少会使用zookeeper来生成唯一ID。主要是由于需要依赖zookeeper，并且是多步调用API，如果在竞争较大的情况下，需要考虑使用分布式锁。因此，性能在高并发的分布式环境下，也不甚理想。</p><h2 id="7-MongoDB的ObjectId"><a href="#7-MongoDB的ObjectId" class="headerlink" title="7. MongoDB的ObjectId"></a><strong>7. MongoDB的ObjectId</strong></h2><p>MongoDB的ObjectId和snowflake算法类似。它设计成轻量型的，不同的机器都能用全局唯一的同种方法方便地生成它。MongoDB 从一开始就设计用来作为分布式数据库，处理多个节点是一个核心要求。使其在分片环境中要容易生成得多。</p><p>其格式如下：</p><p><img src="http://images.blogjava.net/blogjava_net/dongbule/46046/o_111.PNG?_=5208136" alt="mogonDB"></p><p>前4 个字节是从标准纪元开始的时间戳，单位为秒。时间戳，与随后的5 个字节组合起来，提供了秒级别的唯一性。由于时间戳在前，这意味着ObjectId 大致会按照插入的顺序排列。这对于某些方面很有用，如将其作为索引提高效率。这4 个字节也隐含了文档创建的时间。绝大多数客户端类库都会公开一个方法从ObjectId 获取这个信息。<br>接下来的3 字节是所在主机的唯一标识符。通常是机器主机名的散列值。这样就可以确保不同主机生成不同的ObjectId，不产生冲突。<br>为了确保在同一台机器上并发的多个进程产生的ObjectId 是唯一的，接下来的两字节来自产生ObjectId 的进程标识符（PID）。<br>前9 字节保证了同一秒钟不同机器不同进程产生的ObjectId 是唯一的。后3 字节就是一个自动增加的计数器，确保相同进程同一秒产生的ObjectId 也是不一样的。同一秒钟最多允许每个进程拥有2563（16 777 216）个不同的ObjectId。</p><h2 id="8-Flickr-的全局主键生成方案"><a href="#8-Flickr-的全局主键生成方案" class="headerlink" title="8. Flickr 的全局主键生成方案"></a><strong>8. Flickr 的全局主键生成方案</strong></h2><p><a href="http://code.flickr.net/2010/02/08/ticket-servers-distributed-unique-primary-keys-on-the-cheap/" target="_blank" rel="external">flickr</a>巧妙地使用了MySQL的自增ID，及replace into语法，十分简洁地实现了分片ID生成功能。</p><p>比如创建64位的自增id：<br>首先，创建一个表：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`uid_sequence`</span> (</div><div class="line">  <span class="string">`id`</span> <span class="built_in">bigint</span>(<span class="number">20</span>) <span class="keyword">unsigned</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> auto_increment,</div><div class="line">  <span class="string">`stub`</span> <span class="built_in">char</span>(<span class="number">1</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">default</span> <span class="string">''</span>,</div><div class="line">  PRIMARY <span class="keyword">KEY</span>  (<span class="string">`id`</span>),</div><div class="line">  <span class="keyword">UNIQUE</span> <span class="keyword">KEY</span> <span class="string">`stub`</span> (<span class="string">`stub`</span>)</div><div class="line">) <span class="keyword">ENGINE</span>=MyISAM;123456123456</div></pre></td></tr></table></figure><p>SELECT * from uid_sequence 输出：<br>+——————-+——+<br>| id | stub |<br>+——————-+——+<br>| 72157623227190423 | a |</p><p>如果我需要一个全局的唯一的64位uid，则执行：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">REPLACE</span> <span class="keyword">INTO</span> uid_sequence (stub) <span class="keyword">VALUES</span> (<span class="string">'a'</span>);</div><div class="line"><span class="keyword">SELECT</span> <span class="keyword">LAST_INSERT_ID</span>();1212</div></pre></td></tr></table></figure><p>说明：</p><ul><li>用 REPLACE INTO 代替 INSERT INTO 的好处是避免表行数太大，还要另外定期清理。</li><li>stub 字段要设为唯一索引，这个 sequence 表只有一条纪录，但也可以同时为多张表生成全局主键，例如user_order_id。除非你需要表的主键是连续的，那么就另建一个 user_order_id_sequence 表。</li><li>经过实际对比测试，使用 MyISAM 比 Innodb 有更高的性能。</li></ul><p>这里flickr使用两台数据库（也可以更多）作为自增序列生成，通过这两台机器做主备和负载均衡。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">TicketServer1:</div><div class="line">auto-increment-increment = 2</div><div class="line">auto-increment-offset = 1</div><div class="line"></div><div class="line">TicketServer2:</div><div class="line">auto-increment-increment = 2</div><div class="line">auto-increment-offset = 212345671234567</div></pre></td></tr></table></figure><p>优点：</p><ul><li>简单可靠。</li></ul><p>缺点：</p><ul><li>id只是一个ID，没有带入时间，shardingId等信息。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;现今所有的企业级应用都需要处理海量的数据对象，这些对象都需要一个唯一的ID与其他的对象区分开来。在关系型数据库中，我们一般是创建主键来达到这个目的。一些数据库支持内建的列类型（AUTO_INCREMENT/AUTO_NUMBER）来产生一个单调递增的64位长的数。有些人喜欢
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reproduce DQN result</title>
    <link href="http://yoursite.com/2017/05/24/Reproduce-DQN-result/"/>
    <id>http://yoursite.com/2017/05/24/Reproduce-DQN-result/</id>
    <published>2017-05-24T04:56:51.000Z</published>
    <updated>2017-05-24T05:25:38.411Z</updated>
    
    <content type="html"><![CDATA[<p>论文链接：<a href="https://www.nature.com/nature/journal/v518/n7540/full/nature14236.html" target="_blank" rel="external">https://www.nature.com/nature/journal/v518/n7540/full/nature14236.html</a></p><p>源代码地址：<a href="https://sites.google.com/a/deepmind.com/dqn/" target="_blank" rel="external">https://sites.google.com/a/deepmind.com/dqn/</a></p><p>由于源代码中只有训练阶段，没有测试阶段，因此我才用了这个<a href="https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner" target="_blank" rel="external">项目</a>的测试脚本，并且生成游戏动图。</p><p>实验复现的步骤如下（这里引用作者原文）：</p><h2 id="DQN-3-0"><a href="#DQN-3-0" class="headerlink" title="DQN 3.0"></a>DQN 3.0</h2><p>This project contains the source code of DQN 3.0, a Lua-based deep reinforcement learning architecture, necessary to reproduce the experiments described in the paper “Human-level control through deep reinforcement learning”, Nature 518, 529–533 (26 February 2015) doi:10.1038/nature14236.</p><p>To replicate the experiment results, a number of dependencies need to be installed, namely:</p><ul><li>LuaJIT and Torch 7.0</li><li>nngraph</li><li>Xitari (fork of the Arcade Learning Environment (Bellemare et al., 2013))</li><li>AleWrap (a lua interface to Xitari) An install script for these dependencies is provided.</li></ul><p>Two run scripts are provided: run_cpu and run_gpu. As the names imply, the former trains the DQN network using regular CPUs, while the latter uses GPUs (CUDA), which typically results in a significant speed-up.</p><h2 id="Installation-instructions"><a href="#Installation-instructions" class="headerlink" title="Installation instructions"></a>Installation instructions</h2><p>The installation requires Linux with apt-get.</p><p>Note: In order to run the GPU version of DQN, you should additionally have the NVIDIA® CUDA® (version 5.5 or later) toolkit installed prior to the Torch installation below. This can be downloaded from <a href="https://developer.nvidia.com/cuda-toolkit" target="_blank" rel="external">https://developer.nvidia.com/cuda-toolkit</a> and installation instructions can be found in <a href="http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux" target="_blank" rel="external">http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux</a></p><p>To train DQN on Atari games, the following components must be installed:</p><ul><li>LuaJIT and Torch 7.0</li><li>nngraph</li><li>Xitari</li><li>AleWrap</li></ul><p>To install all of the above in a subdirectory called ‘torch’, it should be enough to run</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./install_dependencies.sh</div></pre></td></tr></table></figure><p>from the base directory of the package.</p><p>Note: The above install script will install the following packages via apt-get: build-essential, gcc, g++, cmake, curl, libreadline-dev, git-core, libjpeg-dev, libpng-dev, ncurses-dev, imagemagick, unzip</p><h2 id="Training-DQN-on-Atari-games"><a href="#Training-DQN-on-Atari-games" class="headerlink" title="Training DQN on Atari games"></a>Training DQN on Atari games</h2><p>Prior to running DQN on a game, you should copy its ROM in the ‘roms’ subdirectory. It should then be sufficient to run the script</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./run_cpu &lt;game name&gt;</div></pre></td></tr></table></figure><p>Or, if GPU support is enabled,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./run_gpu &lt;game name&gt;</div></pre></td></tr></table></figure><p>Note: On a system with more than one GPU, DQN training can be launched on a specified GPU by setting the environment variable GPU_ID, e.g. by</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">GPU_ID=2 ./run_gpu &lt;game name&gt;</div></pre></td></tr></table></figure><p>If GPU_ID is not specified, the first available GPU (ID 0) will be used by default.</p><p>这之后是我采用另一个项目的测试步骤：</p><h2 id="Storing-a-gif-for-a-trained-network"><a href="#Storing-a-gif-for-a-trained-network" class="headerlink" title="Storing a .gif for a trained network"></a>Storing a .gif for a trained network</h2><p>Once you have a snapshot of a network you can run</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./test_gpu &lt;game name&gt; &lt;snapshopt filename&gt;</div></pre></td></tr></table></figure><p>to make it play one game and store the .gif under <code>gifs</code>. For example</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./test_gpu breakout DQN3_0_1_breakout_FULL_Y.t7</div></pre></td></tr></table></figure><h2 id="Options"><a href="#Options" class="headerlink" title="Options"></a>Options</h2><p>Options to DQN are set within run_cpu (respectively, run_gpu). You may, for example, want to change the frequency at which information is output to stdout by setting ‘prog_freq’ to a different value.</p><p>我在实验过程中碰到了一系列的问题，实验环境为Windows 10 Vmware Workstation中运行的Ubuntu 16.04 LTS虚拟机。需要声明的是，我才用原始代码并没有运行成功，经分析应该是虚拟机的问题，但以下碰到的问题应当是具有一般性地，下一步准备采用测试项目代码运行。</p><h2 id="Some-Problem"><a href="#Some-Problem" class="headerlink" title="Some Problem"></a>Some Problem</h2><h3 id="run-cpu之后出现Segmentation-fault错误"><a href="#run-cpu之后出现Segmentation-fault错误" class="headerlink" title="./run_cpu之后出现Segmentation fault错误"></a>./run_cpu之后出现Segmentation fault错误</h3><ol><li>可能是因为其后参数名中出现大写字母</li><li>可能是因为内存不足，可以尝试换一个游戏运行</li></ol><h3 id="test-cpu之后提示找不到gd"><a href="#test-cpu之后提示找不到gd" class="headerlink" title="./test_cpu之后提示找不到gd"></a>./test_cpu之后提示找不到gd</h3><p>这个时候需要手动安装gd，具体安装方法如下：</p><p>下载地址：<a href="https://ittner.github.io/lua-gd/manual.html#download" target="_blank" rel="external">https://ittner.github.io/lua-gd/manual.html#download</a></p><p>我下载的是这个版本<a href="http://files.luaforge.net/releases/lua-gd/lua-gd/lua-gd-2.0.33r2forLua5.1/lua-gd-2.0.33r2.tar.gz" target="_blank" rel="external">http://files.luaforge.net/releases/lua-gd/lua-gd/lua-gd-2.0.33r2forLua5.1/lua-gd-2.0.33r2.tar.gz</a></p><p>下载解压后，进到对应的目录，</p><p>执行命令：</p><p><code>make</code></p><p>make成功后，执行：</p><p><code>sudo make install</code></p><p>如果中间出现错误的话，请把下面的几个包都安装上：</p><p><code>sudo apt-get install lua5.1</code><br><code>sudo apt-get install lua5.1-0-dev</code><br><code>sudo apt-get install liblua5.1-0-dev</code><br><code>sudo apt-get install libgd2-dev</code></p><p>安装成功之后会有如下提示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">gcc -o gd.so `gdlib-config --features |sed -e &quot;s/GD_/-DGD_/g&quot;`</div><div class="line">`gdlib-config --cflags` `pkg-config lua5.1 --cflags` -O3 -Wall -shared</div><div class="line">`gdlib-config --ldflags` `gdlib-config --libs` `pkg-config lua5.1 --libs`</div><div class="line">-lgd luagd.c</div><div class="line">lua test_features.lua</div><div class="line">Lua-GD version: lua-gd 2.0.33r2</div><div class="line">Lua-GD features:</div><div class="line">    PNG support ..................... Enabled</div><div class="line">    GIF support ..................... Enabled</div><div class="line">    JPEG support .................... Enabled</div><div class="line">    XPM/XBM support ................. Enabled</div><div class="line">    FreeType support ................ Enabled</div><div class="line">    Fontconfig support .............. Enabled</div></pre></td></tr></table></figure><h3 id="安装gd时进行make的时候出现gd-h-No-such-file-or-directory"><a href="#安装gd时进行make的时候出现gd-h-No-such-file-or-directory" class="headerlink" title="安装gd时进行make的时候出现gd.h: No such file or directory"></a>安装gd时进行make的时候出现gd.h: No such file or directory</h3><p>Try to install this package if you are in debian : libgd2-noxpm-dev</p><h3 id="安装gd时进行make的时候出现srlua-makefile-error-lua-h-No-such-file-or-directory"><a href="#安装gd时进行make的时候出现srlua-makefile-error-lua-h-No-such-file-or-directory" class="headerlink" title="安装gd时进行make的时候出现srlua makefile error lua.h No such file or directory"></a>安装gd时进行make的时候出现srlua makefile error lua.h No such file or directory</h3><p><code>sudo apt-get install liblua5.1-0-dev</code></p><h3 id="在解决以上问题后依然通不过编译"><a href="#在解决以上问题后依然通不过编译" class="headerlink" title="在解决以上问题后依然通不过编译"></a>在解决以上问题后依然通不过编译</h3><p>这里引用了<a href="https://groups.google.com/forum/#!topic/bamboo-cn/myYzVk5XLgc" target="_blank" rel="external">https://groups.google.com/forum/#!topic/bamboo-cn/myYzVk5XLgc</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;论文链接：&lt;a href=&quot;https://www.nature.com/nature/journal/v518/n7540/full/nature14236.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.nature.c
    
    </summary>
    
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>Question Answering: A Very Brief Introduction</title>
    <link href="http://yoursite.com/2017/05/13/Question-Answering-A-Very-Brief-Introduction/"/>
    <id>http://yoursite.com/2017/05/13/Question-Answering-A-Very-Brief-Introduction/</id>
    <published>2017-05-13T05:07:06.000Z</published>
    <updated>2017-05-13T07:18:22.688Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>Find answers to (natual language) questions by machine</p></li><li><p>Types of questions</p><ul><li>Factoid</li><li>Definition</li><li>Yes-No</li><li>Opinion</li><li>Comparison</li></ul></li><li><p>Multiple Intelligences in Modern in QA Systems</p><ul><li><p>Knowledge-QA</p><p>结构化的，基于知识库，其实就是一个图，结点是实体，边是语义关系。关键是能够提取中问题中的实体以及实体之间的语义关系</p></li><li><p>Document-QA</p><p>非结构化的</p></li><li><p>Social-QA</p><p>类似Quora, Zhihu, Stackoverflow等</p></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;&lt;li&gt;&lt;p&gt;Find answers to (natual language) questions by machine&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Types of questions&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Factoid&lt;/li&gt;&lt;li&gt;Definition&lt;/l
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="QA" scheme="http://yoursite.com/tags/QA/"/>
    
  </entry>
  
  <entry>
    <title>Bot Sample: MultiDialog</title>
    <link href="http://yoursite.com/2017/05/12/Bot-Sample-MultiDialog/"/>
    <id>http://yoursite.com/2017/05/12/Bot-Sample-MultiDialog/</id>
    <published>2017-05-12T02:32:20.000Z</published>
    <updated>2017-05-12T14:12:56.112Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://o7ie0tcjk.bkt.clouddn.com/bot/multi_dialog/BotMultiDialogFlow.png" alt="flow"></p><h2 id="MessageController-cs"><a href="#MessageController-cs" class="headerlink" title="MessageController.cs"></a>MessageController.cs</h2><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">namespace</span> <span class="title">MultiDialogsBot</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">using</span> System.Net;</div><div class="line">    <span class="keyword">using</span> System.Net.Http;</div><div class="line">    <span class="keyword">using</span> System.Threading.Tasks;</div><div class="line">    <span class="keyword">using</span> System.Web.Http;</div><div class="line">    <span class="keyword">using</span> Dialogs;</div><div class="line">    <span class="keyword">using</span> Microsoft.Bot.Builder.Dialogs;</div><div class="line">    <span class="keyword">using</span> Microsoft.Bot.Connector;</div><div class="line"></div><div class="line">    [BotAuthentication]</div><div class="line">    <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">MessagesController</span> : <span class="title">ApiController</span></div><div class="line">    &#123;</div><div class="line">        <span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;summary&gt;</span></span></div><div class="line">        <span class="comment"><span class="doctag">///</span> POST: api/Messages</span></div><div class="line">        <span class="comment"><span class="doctag">///</span> Receive a message from a user and reply to it</span></div><div class="line">        <span class="comment"><span class="doctag">///</span> <span class="doctag">&lt;/summary&gt;</span></span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">async</span> Task&lt;HttpResponseMessage&gt; <span class="title">Post</span>(<span class="params">[FromBody]Activity activity</span>)</span></div><div class="line">        &#123;</div><div class="line">            <span class="keyword">if</span> (activity.Type == ActivityTypes.Message)</div><div class="line">            &#123;</div><div class="line">                <span class="keyword">await</span> Conversation.SendAsync(activity, () =&gt; <span class="keyword">new</span> RootDialog());</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span></div><div class="line">            &#123;</div><div class="line">                <span class="keyword">this</span>.HandleSystemMessage(activity);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">var</span> response = Request.CreateResponse(HttpStatusCode.OK);</div><div class="line">            <span class="keyword">return</span> response;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">private</span> Activity <span class="title">HandleSystemMessage</span>(<span class="params">Activity message</span>)</span></div><div class="line">        &#123;</div><div class="line">            <span class="keyword">if</span> (message.Type == ActivityTypes.DeleteUserData)</div><div class="line">            &#123;</div><div class="line">                <span class="comment">// Implement user deletion here</span></div><div class="line">                <span class="comment">// If we handle user deletion, return a real message</span></div><div class="line">            &#125;</div><div class="line">            <span class="function"><span class="keyword">else</span> <span class="title">if</span> (<span class="params">message.Type == ActivityTypes.ConversationUpdate</span>)</span></div><div class="line">            &#123;</div><div class="line">                <span class="comment">// Handle conversation state changes, like members being added and removed</span></div><div class="line">                <span class="comment">// Use Activity.MembersAdded and Activity.MembersRemoved and Activity.Action for info</span></div><div class="line">                <span class="comment">// Not available in all channels</span></div><div class="line">            &#125;</div><div class="line">            <span class="function"><span class="keyword">else</span> <span class="title">if</span> (<span class="params">message.Type == ActivityTypes.ContactRelationUpdate</span>)</span></div><div class="line">            &#123;</div><div class="line">                <span class="comment">// Handle add/remove from contact lists</span></div><div class="line">                <span class="comment">// Activity.From + Activity.Action represent what happened</span></div><div class="line">            &#125;</div><div class="line">            <span class="function"><span class="keyword">else</span> <span class="title">if</span> (<span class="params">message.Type == ActivityTypes.Typing</span>)</span></div><div class="line">            &#123;</div><div class="line">                <span class="comment">// Handle knowing tha the user is typing</span></div><div class="line">            &#125;</div><div class="line">            <span class="function"><span class="keyword">else</span> <span class="title">if</span> (<span class="params">message.Type == ActivityTypes.Ping</span>)</span></div><div class="line">            &#123;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="RootDialog-cs"><a href="#RootDialog-cs" class="headerlink" title="RootDialog.cs"></a>RootDialog.cs</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line">namespace MultiDialogsBot.Dialogs</div><div class="line">&#123;</div><div class="line">    using System;</div><div class="line">    using System.Collections.Generic;</div><div class="line">    using System.Threading;</div><div class="line">    using System.Threading.Tasks;</div><div class="line">    using Microsoft.Bot.Builder.Dialogs;</div><div class="line">    using Microsoft.Bot.Connector;</div><div class="line"></div><div class="line">    [Serializable]</div><div class="line">    public class RootDialog : IDialog&lt;object&gt;</div><div class="line">    &#123;</div><div class="line">        private const string FlightsOption = "Flights";</div><div class="line"></div><div class="line">        private const string HotelsOption = "Hotels";</div><div class="line"></div><div class="line">        public async Task StartAsync(IDialogContext context)</div><div class="line">        &#123;</div><div class="line">            context.Wait(this.MessageReceivedAsync);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        public virtual async Task MessageReceivedAsync(IDialogContext context, IAwaitable&lt;IMessageActivity&gt; result)</div><div class="line">        &#123;</div><div class="line">            var message = await result;</div><div class="line"></div><div class="line">            if (message.Text.ToLower().Contains("help") || message.Text.ToLower().Contains("support") || message.Text.ToLower().Contains("problem"))</div><div class="line">            &#123;</div><div class="line">                await context.Forward(new SupportDialog(), this.ResumeAfterSupportDialog, message, CancellationToken.None);</div><div class="line">            &#125;</div><div class="line">            else</div><div class="line">            &#123;</div><div class="line">                this.ShowOptions(context);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        private void ShowOptions(IDialogContext context)</div><div class="line">        &#123;</div><div class="line">            PromptDialog.Choice(context, this.OnOptionSelected, new List&lt;string&gt;() &#123; FlightsOption, HotelsOption &#125;, "Are you looking for a flight or a hotel?", "Not a valid option", 3);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        private async Task OnOptionSelected(IDialogContext context, IAwaitable&lt;string&gt; result)</div><div class="line">        &#123;</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                string optionSelected = await result;</div><div class="line"></div><div class="line">                switch (optionSelected)</div><div class="line">                &#123;</div><div class="line">                    case FlightsOption:</div><div class="line">                        context.Call(new FlightsDialog(), this.ResumeAfterOptionDialog);</div><div class="line">                        break;</div><div class="line"></div><div class="line">                    case HotelsOption:</div><div class="line">                        context.Call(new HotelsDialog(), this.ResumeAfterOptionDialog);</div><div class="line">                        break;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            catch (TooManyAttemptsException ex)</div><div class="line">            &#123;</div><div class="line">                await context.PostAsync($"Ooops! Too many attemps :(. But don't worry, I'm handling that exception and you can try again!");</div><div class="line"></div><div class="line">                context.Wait(this.MessageReceivedAsync);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        private async Task ResumeAfterSupportDialog(IDialogContext context, IAwaitable&lt;int&gt; result)</div><div class="line">        &#123;</div><div class="line">            var ticketNumber = await result;</div><div class="line"></div><div class="line">            await context.PostAsync($"Thanks for contacting our support team. Your ticket number is &#123;ticketNumber&#125;.");</div><div class="line">            context.Wait(this.MessageReceivedAsync);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        private async Task ResumeAfterOptionDialog(IDialogContext context, IAwaitable&lt;object&gt; result)</div><div class="line">        &#123;</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                var message = await result;</div><div class="line">            &#125;</div><div class="line">            catch (Exception ex)</div><div class="line">            &#123;</div><div class="line">                await context.PostAsync($"Failed with message: &#123;ex.Message&#125;");</div><div class="line">            &#125;</div><div class="line">            finally</div><div class="line">            &#123;</div><div class="line">                context.Wait(this.MessageReceivedAsync);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="SupportDialog-cs"><a href="#SupportDialog-cs" class="headerlink" title="SupportDialog.cs"></a>SupportDialog.cs</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">namespace MultiDialogsBot.Dialogs</div><div class="line">&#123;</div><div class="line">    using System;</div><div class="line">    using System.Threading.Tasks;</div><div class="line">    using Microsoft.Bot.Builder.Dialogs;</div><div class="line">    using Microsoft.Bot.Connector;</div><div class="line"></div><div class="line">    [Serializable]</div><div class="line">    public class SupportDialog : IDialog&lt;int&gt;</div><div class="line">    &#123;</div><div class="line">        public async Task StartAsync(IDialogContext context)</div><div class="line">        &#123;</div><div class="line">            context.Wait(this.MessageReceivedAsync);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        public virtual async Task MessageReceivedAsync(IDialogContext context, IAwaitable&lt;IMessageActivity&gt; result)</div><div class="line">        &#123;</div><div class="line">            var message = await result;</div><div class="line"></div><div class="line">            var ticketNumber = new Random().Next(0, 20000);</div><div class="line"></div><div class="line">            await context.PostAsync($"Your message '&#123;message.Text&#125;' was registered. Once we resolve it; we will get back to you.");</div><div class="line"></div><div class="line">            context.Done(ticketNumber);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="FlightsDialog-cs"><a href="#FlightsDialog-cs" class="headerlink" title="FlightsDialog.cs"></a>FlightsDialog.cs</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">namespace MultiDialogsBot.Dialogs</div><div class="line">&#123;</div><div class="line">    using System;</div><div class="line">    using System.Threading.Tasks;</div><div class="line">    using Microsoft.Bot.Builder.Dialogs;</div><div class="line">    using Microsoft.Bot.Connector;</div><div class="line"></div><div class="line">    [Serializable]</div><div class="line">    public class FlightsDialog : IDialog&lt;object&gt;</div><div class="line">    &#123;</div><div class="line">        public async Task StartAsync(IDialogContext context)</div><div class="line">        &#123;</div><div class="line">            context.Fail(new NotImplementedException("Flights Dialog is not implemented and is instead being used to show context.Fail"));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="HotelsDialog-cs"><a href="#HotelsDialog-cs" class="headerlink" title="HotelsDialog.cs"></a>HotelsDialog.cs</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div></pre></td><td class="code"><pre><div class="line">namespace MultiDialogsBot.Dialogs</div><div class="line">&#123;</div><div class="line">    using System;</div><div class="line">    using System.Collections.Generic;</div><div class="line">    using System.Linq;</div><div class="line">    using System.Threading.Tasks;</div><div class="line">    using System.Web;</div><div class="line">    using Microsoft.Bot.Builder.Dialogs;</div><div class="line">    using Microsoft.Bot.Builder.FormFlow;</div><div class="line">    using Microsoft.Bot.Connector;</div><div class="line"></div><div class="line">    [Serializable]</div><div class="line">    public class HotelsDialog : IDialog&lt;object&gt;</div><div class="line">    &#123;</div><div class="line">        public async Task StartAsync(IDialogContext context)</div><div class="line">        &#123;</div><div class="line">            await context.PostAsync("Welcome to the Hotels finder!");</div><div class="line"></div><div class="line">            var hotelsFormDialog = FormDialog.FromForm(this.BuildHotelsForm, FormOptions.PromptInStart);</div><div class="line"></div><div class="line">            context.Call(hotelsFormDialog, this.ResumeAfterHotelsFormDialog);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        private IForm&lt;HotelsQuery&gt; BuildHotelsForm()</div><div class="line">        &#123;</div><div class="line">            OnCompletionAsyncDelegate&lt;HotelsQuery&gt; processHotelsSearch = async (context, state) =&gt;</div><div class="line">            &#123;</div><div class="line">                await context.PostAsync($"Ok. Searching for Hotels in &#123;state.Destination&#125; from &#123;state.CheckIn.ToString("MM/dd")&#125; to &#123;state.CheckIn.AddDays(state.Nights).ToString("MM/dd")&#125;...");</div><div class="line">            &#125;;</div><div class="line"></div><div class="line">            return new FormBuilder&lt;HotelsQuery&gt;()</div><div class="line">                .Field(nameof(HotelsQuery.Destination))</div><div class="line">                .Message("Looking for hotels in &#123;Destination&#125;...")</div><div class="line">                .AddRemainingFields()</div><div class="line">                .OnCompletion(processHotelsSearch)</div><div class="line">                .Build();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        private async Task ResumeAfterHotelsFormDialog(IDialogContext context, IAwaitable&lt;HotelsQuery&gt; result)</div><div class="line">        &#123;</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                var searchQuery = await result;</div><div class="line"></div><div class="line">                var hotels = await this.GetHotelsAsync(searchQuery);</div><div class="line"></div><div class="line">                await context.PostAsync($"I found in total &#123;hotels.Count()&#125; hotels for your dates:");</div><div class="line"></div><div class="line">                var resultMessage = context.MakeMessage();</div><div class="line">                resultMessage.AttachmentLayout = AttachmentLayoutTypes.Carousel;</div><div class="line">                resultMessage.Attachments = new List&lt;Attachment&gt;();</div><div class="line"></div><div class="line">                foreach (var hotel in hotels)</div><div class="line">                &#123;</div><div class="line">                    HeroCard heroCard = new HeroCard()</div><div class="line">                    &#123;</div><div class="line">                        Title = hotel.Name,</div><div class="line">                        Subtitle = $"&#123;hotel.Rating&#125; starts. &#123;hotel.NumberOfReviews&#125; reviews. From $&#123;hotel.PriceStarting&#125; per night.",</div><div class="line">                        Images = new List&lt;CardImage&gt;()</div><div class="line">                        &#123;</div><div class="line">                            new CardImage() &#123; Url = hotel.Image &#125;</div><div class="line">                        &#125;,</div><div class="line">                        Buttons = new List&lt;CardAction&gt;()</div><div class="line">                        &#123;</div><div class="line">                            new CardAction()</div><div class="line">                            &#123;</div><div class="line">                                Title = "More details",</div><div class="line">                                Type = ActionTypes.OpenUrl,</div><div class="line">                                Value = $"https://www.bing.com/search?q=hotels+in+" + HttpUtility.UrlEncode(hotel.Location)</div><div class="line">                            &#125;</div><div class="line">                        &#125;</div><div class="line">                    &#125;;</div><div class="line"></div><div class="line">                    resultMessage.Attachments.Add(heroCard.ToAttachment());</div><div class="line">                &#125;</div><div class="line"></div><div class="line">                await context.PostAsync(resultMessage);</div><div class="line">            &#125;</div><div class="line">            catch (FormCanceledException ex)</div><div class="line">            &#123;</div><div class="line">                string reply;</div><div class="line"></div><div class="line">                if (ex.InnerException == null)</div><div class="line">                &#123;</div><div class="line">                    reply = "You have canceled the operation. Quitting from the HotelsDialog";</div><div class="line">                &#125;</div><div class="line">                else</div><div class="line">                &#123;</div><div class="line">                    reply = $"Oops! Something went wrong :( Technical Details: &#123;ex.InnerException.Message&#125;";</div><div class="line">                &#125;</div><div class="line"></div><div class="line">                await context.PostAsync(reply);</div><div class="line">            &#125;</div><div class="line">            finally</div><div class="line">            &#123;</div><div class="line">                context.Done&lt;object&gt;(null);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        private async Task&lt;IEnumerable&lt;Hotel&gt;&gt; GetHotelsAsync(HotelsQuery searchQuery)</div><div class="line">        &#123;</div><div class="line">            var hotels = new List&lt;Hotel&gt;();</div><div class="line"></div><div class="line">            // Filling the hotels results manually just for demo purposes</div><div class="line">            for (int i = 1; i &lt;= 5; i++)</div><div class="line">            &#123;</div><div class="line">                var random = new Random(i);</div><div class="line">                Hotel hotel = new Hotel()</div><div class="line">                &#123;</div><div class="line">                    Name = $"&#123;searchQuery.Destination&#125; Hotel &#123;i&#125;",</div><div class="line">                    Location = searchQuery.Destination,</div><div class="line">                    Rating = random.Next(1, 5),</div><div class="line">                    NumberOfReviews = random.Next(0, 5000),</div><div class="line">                    PriceStarting = random.Next(80, 450),</div><div class="line">                    Image = $"https://placeholdit.imgix.net/~text?txtsize=35&amp;txt=Hotel+&#123;i&#125;&amp;w=500&amp;h=260"</div><div class="line">                &#125;;</div><div class="line"></div><div class="line">                hotels.Add(hotel);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            hotels.Sort((h1, h2) =&gt; h1.PriceStarting.CompareTo(h2.PriceStarting));</div><div class="line"></div><div class="line">            return hotels;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="Hotel-cs"><a href="#Hotel-cs" class="headerlink" title="Hotel.cs"></a>Hotel.cs</h2><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">namespace</span> <span class="title">MultiDialogsBot</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">using</span> System;</div><div class="line"></div><div class="line">    [Serializable]</div><div class="line">    <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">Hotel</span></div><div class="line">    &#123;</div><div class="line">        <span class="keyword">public</span> <span class="keyword">string</span> Name &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</div><div class="line"></div><div class="line">        <span class="keyword">public</span> <span class="keyword">int</span> Rating &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</div><div class="line"></div><div class="line">        <span class="keyword">public</span> <span class="keyword">int</span> NumberOfReviews &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</div><div class="line"></div><div class="line">        <span class="keyword">public</span> <span class="keyword">int</span> PriceStarting &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</div><div class="line"></div><div class="line">        <span class="keyword">public</span> <span class="keyword">string</span> Image &#123; <span class="keyword">get</span>;  <span class="keyword">set</span>; &#125;</div><div class="line"></div><div class="line">        <span class="keyword">public</span> <span class="keyword">string</span> Location &#123; <span class="keyword">get</span>;  <span class="keyword">set</span>; &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="HotelsQuery-cs"><a href="#HotelsQuery-cs" class="headerlink" title="HotelsQuery.cs"></a>HotelsQuery.cs</h2><figure class="highlight csharp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">namespace</span> <span class="title">MultiDialogsBot</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">using</span> System;</div><div class="line">    <span class="keyword">using</span> Microsoft.Bot.Builder.FormFlow;</div><div class="line"></div><div class="line">    [Serializable]</div><div class="line">    <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">HotelsQuery</span></div><div class="line">    &#123;</div><div class="line">        [Prompt(<span class="string">"Please enter your &#123;&amp;&#125;"</span>)]</div><div class="line">        <span class="keyword">public</span> <span class="keyword">string</span> Destination &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</div><div class="line">        </div><div class="line">        [Prompt(<span class="string">"When do you want to &#123;&amp;&#125;?"</span>)]</div><div class="line">        <span class="keyword">public</span> DateTime CheckIn &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</div><div class="line"></div><div class="line">        [Numeric(<span class="number">1</span>, <span class="keyword">int</span>.MaxValue)]</div><div class="line">        [Prompt(<span class="string">"How many &#123;&amp;&#125; do you want to stay?"</span>)]</div><div class="line">        <span class="keyword">public</span> <span class="keyword">int</span> Nights &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://o7ie0tcjk.bkt.clouddn.com/bot/multi_dialog/BotMultiDialogFlow.png&quot; alt=&quot;flow&quot;&gt;&lt;/p&gt;&lt;h2 id=&quot;MessageController-cs&quot;&gt;&lt;a href=
    
    </summary>
    
    
      <category term="Bot" scheme="http://yoursite.com/tags/Bot/"/>
    
  </entry>
  
  <entry>
    <title>The First Course of C#</title>
    <link href="http://yoursite.com/2017/05/10/The-First-Course-of-C/"/>
    <id>http://yoursite.com/2017/05/10/The-First-Course-of-C/</id>
    <published>2017-05-10T11:08:14.000Z</published>
    <updated>2017-05-11T04:48:53.022Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><h3 id="一个例子"><a href="#一个例子" class="headerlink" title="一个例子:"></a><strong>一个例子:</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace HelloWorldApplication</div><div class="line">&#123;</div><div class="line">    /* 类名为 HelloWorld */</div><div class="line">    class HelloWorld</div><div class="line">    &#123;</div><div class="line">        /* main函数 */</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            /* 我的第一个 C# 程序 */</div><div class="line">            Console.WriteLine(&quot;Hello World!&quot;);</div><div class="line">            Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="对象类型"><a href="#对象类型" class="headerlink" title="对象类型"></a><strong>对象类型</strong></h3><p>是 C# 通用类型系统（Common Type System - CTS）中所有数据类型的终极基类。Object 是 System.Object 类的别名。所以对象（Object）类型可以被分配任何其他类型（值类型、引用类型、预定义类型或用户自定义类型）的值。但是，在分配值之前，需要先进行类型转换。</p><p>当一个值类型转换为对象类型时，则被称为 <strong>装箱</strong>；另一方面，当一个对象类型转换为值类型时，则被称为 <strong>拆箱</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">object obj;</div><div class="line">obj = 100; // 这是装箱</div></pre></td></tr></table></figure><h3 id="动态类型"><a href="#动态类型" class="headerlink" title="动态类型"></a><strong>动态类型</strong></h3><p>您可以存储任何类型的值在动态数据类型变量中。这些变量的类型检查是在运行时发生的。</p><p>声明动态类型的语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dynamic &lt;variable_name&gt; = value;</div></pre></td></tr></table></figure><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dynamic d = 20;</div></pre></td></tr></table></figure><p>动态类型与对象类型相似，但是对象类型变量的类型检查是在编译时发生的，而动态类型变量的类型检查是在运行时发生的。</p><h3 id="字符串的特殊定义方式"><a href="#字符串的特殊定义方式" class="headerlink" title="字符串的特殊定义方式"></a><strong>字符串的特殊定义方式</strong></h3><p>字符串（String）类型允许您给变量分配任何字符串值。字符串（String）类型是 System.String 类的别名。它是从对象（Object）类型派生的。字符串（String）类型的值可以通过两种形式进行分配：引号和 @引号。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">String str = &quot;runoob.com&quot;;</div></pre></td></tr></table></figure><p>一个 @引号字符串：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">@&quot;runoob.com&quot;;</div></pre></td></tr></table></figure><p>C# string 字符串的前面可以加 @（称作”逐字字符串”）将转义字符（\）当作普通字符对待，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">string str = @&quot;C:\Windows&quot;;</div></pre></td></tr></table></figure><p>等价于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">string str = &quot;C:\\Windows&quot;;</div></pre></td></tr></table></figure><p>@ 字符串中可以任意换行，换行符及缩进空格都计算在字符串长度之内。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">string str = @&quot;&lt;script type=&quot;&quot;text/javascript&quot;&quot;&gt;</div><div class="line">    &lt;!--</div><div class="line">    --&gt;</div><div class="line">&lt;/script&gt;&quot;;</div></pre></td></tr></table></figure><h3 id="显式类型转换方式"><a href="#显式类型转换方式" class="headerlink" title="显式类型转换方式"></a><strong>显式类型转换方式</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">namespace TypeConversionApplication</div><div class="line">&#123;</div><div class="line">    class StringConversion</div><div class="line">    &#123;</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            int i = 75;</div><div class="line">            float f = 53.005f;</div><div class="line">            double d = 2345.7652;</div><div class="line">            bool b = true;</div><div class="line"></div><div class="line">            Console.WriteLine(i.ToString());</div><div class="line">            Console.WriteLine(f.ToString());</div><div class="line">            Console.WriteLine(d.ToString());</div><div class="line">            Console.WriteLine(b.ToString());</div><div class="line">            Console.ReadKey();</div><div class="line">            </div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="命令行输入"><a href="#命令行输入" class="headerlink" title="命令行输入"></a><strong>命令行输入</strong></h3><p><code>System</code>命名空间中的<code>Console</code>类提供了一个函数 <code>ReadLine()</code>，用于接收来自用户的输入，并把它存储到一个变量中。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">int num;</div><div class="line">num = Convert.ToInt32(Console.ReadLine());</div></pre></td></tr></table></figure><p>函数 <code>Convert.ToInt32()</code>把用户输入的数据转换为<code>int</code> 数据类型，因为 <code>Console.ReadLine()</code>只接受字符串格式的数据。</p><h3 id="特殊运算符"><a href="#特殊运算符" class="headerlink" title="特殊运算符"></a><strong>特殊运算符</strong></h3><table><thead><tr><th>运算符</th><th>描述</th><th>实例</th></tr></thead><tbody><tr><td>sizeof()</td><td>返回数据类型的大小。</td><td>sizeof(int)，将返回 4.</td></tr><tr><td>typeof()</td><td>返回 class 的类型。</td><td>typeof(StreamReader);</td></tr><tr><td>&amp;</td><td>返回变量的地址。</td><td>&a; 将得到变量的实际地址。</td></tr><tr><td>*</td><td>变量的指针。</td><td>*a; 将指向一个变量。</td></tr><tr><td>? :</td><td>条件表达式</td><td>如果条件为真 ? 则为 X : 否则为 Y</td></tr><tr><td>is</td><td>判断对象是否为某一类型。</td><td>If( Ford is Car) // 检查 Ford 是否是 Car 类的一个对象。</td></tr><tr><td>as</td><td>强制转换，即使转换失败也不会抛出异常。</td><td>Object obj = new StringReader(“Hello”);StringReader r = obj as StringReader;</td></tr></tbody></table><h3 id="特殊访问修饰符"><a href="#特殊访问修饰符" class="headerlink" title="特殊访问修饰符"></a><strong>特殊访问修饰符</strong></h3><h4 id="Internal-访问修饰符"><a href="#Internal-访问修饰符" class="headerlink" title="Internal 访问修饰符"></a><em>Internal 访问修饰符</em></h4><p>Internal 访问说明符允许一个类将其成员变量和成员函数暴露给当前程序中的其他函数和对象。换句话说，带有 internal 访问修饰符的任何成员可以被定义在该成员所定义的应用程序内的任何类或方法访问。</p><p>类的默认访问标识符是 <strong>internal</strong>，成员的默认访问标识符是 <strong>private</strong>。</p><p>下面的实例说明了这点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">namespace RectangleApplication</div><div class="line">&#123;</div><div class="line">    class Rectangle</div><div class="line">    &#123;</div><div class="line">        //成员变量</div><div class="line">        internal double length;</div><div class="line">        internal double width;</div><div class="line">        </div><div class="line">        double GetArea()</div><div class="line">        &#123;</div><div class="line">            return length * width;</div><div class="line">        &#125;</div><div class="line">       public void Display()</div><div class="line">        &#123;</div><div class="line">            Console.WriteLine(&quot;长度： &#123;0&#125;&quot;, length);</div><div class="line">            Console.WriteLine(&quot;宽度： &#123;0&#125;&quot;, width);</div><div class="line">            Console.WriteLine(&quot;面积： &#123;0&#125;&quot;, GetArea());</div><div class="line">        &#125;</div><div class="line">    &#125;//end class Rectangle    </div><div class="line">    class ExecuteRectangle</div><div class="line">    &#123;</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            Rectangle r = new Rectangle();</div><div class="line">            r.length = 4.5;</div><div class="line">            r.width = 3.5;</div><div class="line">            r.Display();</div><div class="line">            Console.ReadLine();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">长度： 4.5</div><div class="line">宽度： 3.5</div><div class="line">面积： 15.75</div></pre></td></tr></table></figure><p>在上面的实例中，请注意成员函数 <em>GetArea()</em> 声明的时候不带有任何访问修饰符。如果没有指定访问修饰符，则使用类成员的默认访问修饰符，即为 <strong>private</strong>。</p><h4 id="Protected-Internal-访问修饰符"><a href="#Protected-Internal-访问修饰符" class="headerlink" title="Protected Internal 访问修饰符"></a><em>Protected Internal 访问修饰符</em></h4><p>Protected Internal 访问修饰符允许在本类,派生类或者包含该类的程序集中访问。这也被用于实现继承。</p><h3 id="按引用传递参数"><a href="#按引用传递参数" class="headerlink" title="按引用传递参数"></a><strong>按引用传递参数</strong></h3><p>引用参数是一个对变量的内存位置的引用。当按引用传递参数时，与值参数不同的是，它不会为这些参数创建一个新的存储位置。引用参数表示与提供给方法的实际参数具有相同的内存位置。</p><p>在 <code>C#</code> 中，使用 <code>ref</code> 关键字声明引用参数。下面的实例演示了这点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace CalculatorApplication</div><div class="line">&#123;</div><div class="line">   class NumberManipulator</div><div class="line">   &#123;</div><div class="line">      public void swap(ref int x, ref int y)</div><div class="line">      &#123;</div><div class="line">         int temp;</div><div class="line"></div><div class="line">         temp = x; /* 保存 x 的值 */</div><div class="line">         x = y;    /* 把 y 赋值给 x */</div><div class="line">         y = temp; /* 把 temp 赋值给 y */</div><div class="line">       &#125;</div><div class="line">   </div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         NumberManipulator n = new NumberManipulator();</div><div class="line">         /* 局部变量定义 */</div><div class="line">         int a = 100;</div><div class="line">         int b = 200;</div><div class="line"></div><div class="line">         Console.WriteLine(&quot;在交换之前，a 的值： &#123;0&#125;&quot;, a);</div><div class="line">         Console.WriteLine(&quot;在交换之前，b 的值： &#123;0&#125;&quot;, b);</div><div class="line"></div><div class="line">         /* 调用函数来交换值 */</div><div class="line">         n.swap(ref a, ref b);</div><div class="line"></div><div class="line">         Console.WriteLine(&quot;在交换之后，a 的值： &#123;0&#125;&quot;, a);</div><div class="line">         Console.WriteLine(&quot;在交换之后，b 的值： &#123;0&#125;&quot;, b);</div><div class="line"> </div><div class="line">         Console.ReadLine();</div><div class="line"></div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">在交换之前，a 的值：100</div><div class="line">在交换之前，b 的值：200</div><div class="line">在交换之后，a 的值：200</div><div class="line">在交换之后，b 的值：100</div></pre></td></tr></table></figure><p>结果表明，<em><code>swap</code></em> 函数内的值改变了，且这个改变可以在 <em><code>Main</code></em> 函数中反映出来。</p><a id="more"></a><h3 id="按输出传递参数"><a href="#按输出传递参数" class="headerlink" title="按输出传递参数"></a><strong>按输出传递参数</strong></h3><p><code>return</code> 语句可用于只从函数中返回一个值。但是，可以使用 输出参数 来从函数中返回两个值。输出参数会把方法输出的数据赋给自己，其他方面与引用参数相似。</p><p>下面的实例演示了这点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">namespace CalculatorApplication</div><div class="line">&#123;</div><div class="line">   class NumberManipulator</div><div class="line">   &#123;</div><div class="line">      public void getValue(out int x )</div><div class="line">      &#123;</div><div class="line">         int temp = 5;</div><div class="line">         x = temp;</div><div class="line">      &#125;</div><div class="line">   </div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         NumberManipulator n = new NumberManipulator();</div><div class="line">         /* 局部变量定义 */</div><div class="line">         int a = 100;</div><div class="line">         </div><div class="line">         Console.WriteLine(&quot;在方法调用之前，a 的值： &#123;0&#125;&quot;, a);</div><div class="line">         </div><div class="line">         /* 调用函数来获取值 */</div><div class="line">         n.getValue(out a);</div><div class="line"></div><div class="line">         Console.WriteLine(&quot;在方法调用之后，a 的值： &#123;0&#125;&quot;, a);</div><div class="line">         Console.ReadLine();</div><div class="line"></div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">在方法调用之前，a 的值： 100</div><div class="line">在方法调用之后，a 的值： 5</div></pre></td></tr></table></figure><p>提供给输出参数的变量不需要赋值。当需要从一个参数没有指定初始值的方法中返回值时，输出参数特别有用。请看下面的实例，来理解这一点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">namespace CalculatorApplication</div><div class="line">&#123;</div><div class="line">   class NumberManipulator</div><div class="line">   &#123;</div><div class="line">      public void getValues(out int x, out int y )</div><div class="line">      &#123;</div><div class="line">          Console.WriteLine(&quot;请输入第一个值： &quot;);</div><div class="line">          x = Convert.ToInt32(Console.ReadLine());</div><div class="line">          Console.WriteLine(&quot;请输入第二个值： &quot;);</div><div class="line">          y = Convert.ToInt32(Console.ReadLine());</div><div class="line">      &#125;</div><div class="line">   </div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         NumberManipulator n = new NumberManipulator();</div><div class="line">         /* 局部变量定义 */</div><div class="line">         int a , b;</div><div class="line">         </div><div class="line">         /* 调用函数来获取值 */</div><div class="line">         n.getValues(out a, out b);</div><div class="line"></div><div class="line">         Console.WriteLine(&quot;在方法调用之后，a 的值： &#123;0&#125;&quot;, a);</div><div class="line">         Console.WriteLine(&quot;在方法调用之后，b 的值： &#123;0&#125;&quot;, b);</div><div class="line">         Console.ReadLine();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果（取决于用户输入）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">请输入第一个值：</div><div class="line">7</div><div class="line">请输入第二个值：</div><div class="line">8</div><div class="line">在方法调用之后，a 的值： 7</div><div class="line">在方法调用之后，b 的值： 8</div></pre></td></tr></table></figure><h3 id="可空类型"><a href="#可空类型" class="headerlink" title="可空类型"></a><strong>可空类型</strong></h3><p><code>C#</code> 提供了一个特殊的数据类型，<code>nullable</code> 类型（可空类型），可空类型可以表示其基础值类型正常范围内的值，再加上一个 <code>null</code> 值。</p><p>例如，<code>Nullable&lt; Int32 &gt;</code>，读作”<code>可空的 Int32</code>“，可以被赋值为 <code>-2,147,483,648</code> 到 <code>2,147,483,647</code> 之间的任意值，也可以被赋值为 <code>null</code> 值。类似的，<code>Nullable&lt; bool &gt;</code> 变量可以被赋值为 <code>true</code> 或 <code>false</code> 或 <code>null</code>。</p><p>在处理数据库和其他包含可能未赋值的元素的数据类型时，将 <code>null</code> 赋值给数值类型或布尔型的功能特别有用。例如，数据库中的布尔型字段可以存储值 <code>true</code> 或 <code>false</code>，或者，该字段也可以未定义。</p><p>声明一个 <code>nullable</code>类型（可空类型）的语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt; data_type&gt; ? &lt;variable_name&gt; = null;</div></pre></td></tr></table></figure><p>下面的实例演示了可空数据类型的用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace CalculatorApplication</div><div class="line">&#123;</div><div class="line">   class NullablesAtShow</div><div class="line">   &#123;</div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         int? num1 = null;</div><div class="line">         int? num2 = 45;</div><div class="line">         double? num3 = new double?();</div><div class="line">         double? num4 = 3.14157;</div><div class="line">         </div><div class="line">         bool? boolval = new bool?();</div><div class="line"></div><div class="line">         // 显示值</div><div class="line">         </div><div class="line">         Console.WriteLine(&quot;显示可空类型的值： &#123;0&#125;, &#123;1&#125;, &#123;2&#125;, &#123;3&#125;&quot;, </div><div class="line">                            num1, num2, num3, num4);</div><div class="line">         Console.WriteLine(&quot;一个可空的布尔值： &#123;0&#125;&quot;, boolval);</div><div class="line">         Console.ReadLine();</div><div class="line"></div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">显示可空类型的值： , 45,  , 3.14157</div><div class="line">一个可空的布尔值：</div></pre></td></tr></table></figure><h3 id="Null合并运算符"><a href="#Null合并运算符" class="headerlink" title="Null合并运算符"></a><strong>Null合并运算符</strong></h3><p><code>Null</code> 合并运算符用于定义可空类型和引用类型的默认值。<code>Null</code> 合并运算符为类型转换定义了一个预设值，以防可空类型的值为 <code>Null</code>。<code>Null</code> 合并运算符把操作数类型隐式转换为另一个可空（或不可空）的值类型的操作数的类型。</p><p>如果第一个操作数的值为 <code>null</code>，则运算符返回第二个操作数的值，否则返回第一个操作数的值。下面的实例演示了这点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace CalculatorApplication</div><div class="line">&#123;</div><div class="line">   class NullablesAtShow</div><div class="line">   &#123;</div><div class="line">         </div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         </div><div class="line">         double? num1 = null;</div><div class="line">         double? num2 = 3.14157;</div><div class="line">         double num3;</div><div class="line">         num3 = num1 ?? 5.34;      </div><div class="line">         Console.WriteLine(&quot;num3 的值： &#123;0&#125;&quot;, num3);</div><div class="line">         num3 = num2 ?? 5.34;</div><div class="line">         Console.WriteLine(&quot;num3 的值： &#123;0&#125;&quot;, num3);</div><div class="line">         Console.ReadLine();</div><div class="line"></div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">num3 的值： 5.34</div><div class="line">num3 的值： 3.14157</div></pre></td></tr></table></figure><h3 id="foreach"><a href="#foreach" class="headerlink" title="foreach"></a><strong>foreach</strong></h3><p>在前面的实例中，我们使用一个 for 循环来访问每个数组元素。您也可以使用一个 <code>foreach</code> 语句来遍历数组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">namespace ArrayApplication</div><div class="line">&#123;</div><div class="line">   class MyArray</div><div class="line">   &#123;</div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         int []  n = new int[10]; /* n 是一个带有 10 个整数的数组, 赋值时初始化需要用大括号*/</div><div class="line"></div><div class="line"></div><div class="line">         /* 初始化数组 n 中的元素 */         </div><div class="line">         for ( int i = 0; i &lt; 10; i++ )</div><div class="line">         &#123;</div><div class="line">            n[i] = i + 100;</div><div class="line">         &#125;</div><div class="line"></div><div class="line">         /* 输出每个数组元素的值 */</div><div class="line">         foreach (int j in n )</div><div class="line">         &#123;</div><div class="line">            int i = j-100;</div><div class="line">            Console.WriteLine(&quot;Element[&#123;0&#125;] = &#123;1&#125;&quot;, i, j);</div><div class="line">         &#125;</div><div class="line">         Console.ReadKey();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Element[0] = 100</div><div class="line">Element[1] = 101</div><div class="line">Element[2] = 102</div><div class="line">Element[3] = 103</div><div class="line">Element[4] = 104</div><div class="line">Element[5] = 105</div><div class="line">Element[6] = 106</div><div class="line">Element[7] = 107</div><div class="line">Element[8] = 108</div><div class="line">Element[9] = 109</div></pre></td></tr></table></figure><h3 id="多维数组"><a href="#多维数组" class="headerlink" title="多维数组"></a><strong>多维数组</strong></h3><p>您可以声明一个 string 变量的二维数组，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">string [,] names;</div></pre></td></tr></table></figure><p>或者，您可以声明一个 int 变量的三维数组，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int [ , , ] m;</div></pre></td></tr></table></figure><p>多维数组可以通过在括号内为每行指定值来进行初始化。下面是一个带有 3 行 4 列的数组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">int [,] a = new int [3,4] &#123;</div><div class="line"> &#123;0, 1, 2, 3&#125; ,   /*  初始化索引号为 0 的行 */</div><div class="line"> &#123;4, 5, 6, 7&#125; ,   /*  初始化索引号为 1 的行 */</div><div class="line"> &#123;8, 9, 10, 11&#125;   /*  初始化索引号为 2 的行 */</div><div class="line">&#125;;</div></pre></td></tr></table></figure><p>二维数组中的元素是通过使用下标（即数组的行索引和列索引）来访问的。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int val = a[2,3];</div></pre></td></tr></table></figure><h3 id="交错数组"><a href="#交错数组" class="headerlink" title="交错数组"></a><strong>交错数组</strong></h3><p>交错数组是数组的数组。您可以声明一个带有 <code>int</code> 值的交错数组 <code>scores</code>，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int [][] scores;</div></pre></td></tr></table></figure><p>声明一个数组不会在内存中创建数组。创建上面的数组：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">int[][] scores = new int[5][];</div><div class="line">for (int i = 0; i &lt; scores.Length; i++) </div><div class="line">&#123;</div><div class="line">   scores[i] = new int[4];</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>您可以初始化一个交错数组，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int[][] scores = new int[2][]&#123;new int[]&#123;92,93,94&#125;,new int[]&#123;85,66,87,88&#125;&#125;;</div></pre></td></tr></table></figure><p>其中，scores 是一个由两个整型数组组成的数组 – scores[0] 是一个带有 3 个整数的数组，scores[1] 是一个带有 4 个整数的数组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">下面的实例演示了如何使用交错数组：</div><div class="line">using System;</div><div class="line"></div><div class="line">namespace ArrayApplication</div><div class="line">&#123;</div><div class="line">    class MyArray</div><div class="line">    &#123;</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            /* 一个由 5 个整型数组组成的交错数组 */</div><div class="line">            int[][] a = new int[][]&#123;new int[]&#123;0,0&#125;,new int[]&#123;1,2&#125;, </div><div class="line">            new int[]&#123;2,4&#125;,new int[]&#123; 3, 6 &#125;, new int[]&#123; 4, 8 &#125; &#125;; </div><div class="line"></div><div class="line">            int i, j;</div><div class="line"></div><div class="line">            /* 输出数组中每个元素的值 */</div><div class="line">            for (i = 0; i &lt; 5; i++)</div><div class="line">            &#123;</div><div class="line">                for (j = 0; j &lt; 2; j++)</div><div class="line">                &#123;</div><div class="line">                    Console.WriteLine(&quot;a[&#123;0&#125;][&#123;1&#125;] = &#123;2&#125;&quot;, i, j, a[i][j]);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">           Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="参数数组"><a href="#参数数组" class="headerlink" title="参数数组"></a><strong>参数数组</strong></h3><p>有时，当声明一个方法时，您不能确定要传递给函数作为参数的参数数目。C# 参数数组解决了这个问题，参数数组通常用于传递未知数量的参数给函数。</p><h4 id="params-关键字"><a href="#params-关键字" class="headerlink" title="params 关键字"></a><em>params 关键字</em></h4><p>在使用数组作为形参时，C# 提供了 params 关键字，使调用数组为形参的方法时，既可以传递数组实参，也可以只传递一组数组。params 的使用格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">public 返回类型 方法名称( params 类型名称[] 数组名称 )</div></pre></td></tr></table></figure><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a><em>实例</em></h4><p>下面的实例演示了如何使用参数数组：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">namespace ArrayApplication</div><div class="line">&#123;</div><div class="line">   class ParamArray</div><div class="line">   &#123;</div><div class="line">      public int AddElements(params int[] arr)</div><div class="line">      &#123;</div><div class="line">         int sum = 0;</div><div class="line">         foreach (int i in arr)</div><div class="line">         &#123;</div><div class="line">            sum += i;</div><div class="line">         &#125;</div><div class="line">         return sum;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">      </div><div class="line">   class TestClass</div><div class="line">   &#123;</div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         ParamArray app = new ParamArray();</div><div class="line">         int sum = app.AddElements(512, 720, 250, 567, 889);</div><div class="line">         Console.WriteLine(&quot;总和是： &#123;0&#125;&quot;, sum);</div><div class="line">         Console.ReadKey();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">总和是： 2938</div></pre></td></tr></table></figure><h3 id="Array类"><a href="#Array类" class="headerlink" title="Array类"></a><strong>Array类</strong></h3><p>Array 类是 C# 中所有数组的基类，它是在 System 命名空间中定义。Array 类提供了各种用于数组的属性和方法。</p><p>下面的程序演示了 Array 类的一些方法的用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace ArrayApplication</div><div class="line">&#123;</div><div class="line">    class MyArray</div><div class="line">    &#123;</div><div class="line">        </div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            int[] list = &#123; 34, 72, 13, 44, 25, 30, 10 &#125;;</div><div class="line">            int[] temp = list;</div><div class="line"></div><div class="line">            Console.Write(&quot;原始数组： &quot;);</div><div class="line">            foreach (int i in list)</div><div class="line">            &#123;</div><div class="line">                Console.Write(i + &quot; &quot;);</div><div class="line">            &#125;</div><div class="line">            Console.WriteLine();</div><div class="line">           </div><div class="line">            // 逆转数组</div><div class="line">            Array.Reverse(temp);</div><div class="line">            Console.Write(&quot;逆转数组： &quot;);</div><div class="line">            foreach (int i in temp)</div><div class="line">            &#123;</div><div class="line">                Console.Write(i + &quot; &quot;);</div><div class="line">            &#125;</div><div class="line">            Console.WriteLine();</div><div class="line">            </div><div class="line">            // 排序数组</div><div class="line">            Array.Sort(list);</div><div class="line">            Console.Write(&quot;排序数组： &quot;);</div><div class="line">            foreach (int i in list)</div><div class="line">            &#123;</div><div class="line">                Console.Write(i + &quot; &quot;);</div><div class="line">            &#125;</div><div class="line">            Console.WriteLine();</div><div class="line"></div><div class="line">           Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">原始数组： 34 72 13 44 25 30 10</div><div class="line">逆转数组： 10 30 25 44 13 72 34</div><div class="line">排序数组： 10 13 25 30 34 44 72</div></pre></td></tr></table></figure><h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a><strong>结构体</strong></h3><p>在 C# 中，结构是值类型数据结构。它使得一个单一变量可以存储各种数据类型的相关数据。<code>struct</code> 关键字用于创建结构。</p><p>结构是用来代表一个记录。假设您想跟踪图书馆中书的动态。您可能想跟踪每本书的以下属性：</p><ul><li>Title</li><li>Author</li><li>Subject</li><li>Book ID</li></ul><p><em>定义结构</em></p><p>为了定义一个结构，您必须使用 struct 语句。struct 语句为程序定义了一个带有多个成员的新的数据类型。</p><p>例如，您可以按照如下的方式声明 Book 结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">struct Books</div><div class="line">&#123;</div><div class="line">   public string title;</div><div class="line">   public string author;</div><div class="line">   public string subject;</div><div class="line">   public int book_id;</div><div class="line">&#125;;</div></pre></td></tr></table></figure><p>下面的程序演示了结构的用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">     </div><div class="line">struct Books</div><div class="line">&#123;</div><div class="line">   public string title;</div><div class="line">   public string author;</div><div class="line">   public string subject;</div><div class="line">   public int book_id;</div><div class="line">&#125;;  </div><div class="line"></div><div class="line">public class testStructure</div><div class="line">&#123;</div><div class="line">   public static void Main(string[] args)</div><div class="line">   &#123;</div><div class="line"></div><div class="line">      Books Book1;        /* 声明 Book1，类型为 Book */</div><div class="line">      Books Book2;        /* 声明 Book2，类型为 Book */</div><div class="line"></div><div class="line">      /* book 1 详述 */</div><div class="line">      Book1.title = &quot;C Programming&quot;;</div><div class="line">      Book1.author = &quot;Nuha Ali&quot;; </div><div class="line">      Book1.subject = &quot;C Programming Tutorial&quot;;</div><div class="line">      Book1.book_id = 6495407;</div><div class="line"></div><div class="line">      /* book 2 详述 */</div><div class="line">      Book2.title = &quot;Telecom Billing&quot;;</div><div class="line">      Book2.author = &quot;Zara Ali&quot;;</div><div class="line">      Book2.subject =  &quot;Telecom Billing Tutorial&quot;;</div><div class="line">      Book2.book_id = 6495700;</div><div class="line"></div><div class="line">      /* 打印 Book1 信息 */</div><div class="line">      Console.WriteLine( &quot;Book 1 title : &#123;0&#125;&quot;, Book1.title);</div><div class="line">      Console.WriteLine(&quot;Book 1 author : &#123;0&#125;&quot;, Book1.author);</div><div class="line">      Console.WriteLine(&quot;Book 1 subject : &#123;0&#125;&quot;, Book1.subject);</div><div class="line">      Console.WriteLine(&quot;Book 1 book_id :&#123;0&#125;&quot;, Book1.book_id);</div><div class="line"></div><div class="line">      /* 打印 Book2 信息 */</div><div class="line">      Console.WriteLine(&quot;Book 2 title : &#123;0&#125;&quot;, Book2.title);</div><div class="line">      Console.WriteLine(&quot;Book 2 author : &#123;0&#125;&quot;, Book2.author);</div><div class="line">      Console.WriteLine(&quot;Book 2 subject : &#123;0&#125;&quot;, Book2.subject);</div><div class="line">      Console.WriteLine(&quot;Book 2 book_id : &#123;0&#125;&quot;, Book2.book_id);       </div><div class="line"></div><div class="line">      Console.ReadKey();</div><div class="line"></div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Book 1 title : C Programming</div><div class="line">Book 1 author : Nuha Ali</div><div class="line">Book 1 subject : C Programming Tutorial</div><div class="line">Book 1 book_id : 6495407</div><div class="line">Book 2 title : Telecom Billing</div><div class="line">Book 2 author : Zara Ali</div><div class="line">Book 2 subject : Telecom Billing Tutorial</div><div class="line">Book 2 book_id : 6495700</div></pre></td></tr></table></figure><h4 id="C-结构的特点"><a href="#C-结构的特点" class="headerlink" title="C# 结构的特点"></a><em>C# 结构的特点</em></h4><p>您已经用了一个简单的名为 Books 的结构。在 C# 中的结构与传统的 C 或 C++ 中的结构不同。C# 中的结构有以下特点：</p><ul><li>结构可带有方法、字段、索引、属性、运算符方法和事件。</li><li>结构可定义构造函数，但不能定义析构函数。但是，您不能为结构定义默认的构造函数。默认的构造函数是自动定义的，且不能被改变。</li><li>与类不同，结构不能继承其他的结构或类。</li><li>结构不能作为其他结构或类的基础结构。</li><li>结构可实现一个或多个接口。</li><li>结构成员不能指定为 abstract、virtual 或 protected。</li><li>当您使用 <strong>New</strong> 操作符创建一个结构对象时，会调用适当的构造函数来创建结构。与类不同，结构可以不使用 New 操作符即可被实例化。</li><li>如果不使用 New 操作符，只有在所有的字段都被初始化之后，字段才被赋值，对象才被使用。</li></ul><h4 id="类-vs-结构"><a href="#类-vs-结构" class="headerlink" title="类 vs 结构"></a><em>类 vs 结构</em></h4><p>类和结构有以下几个基本的不同点：</p><ul><li>类是引用类型，结构是值类型。</li><li>结构不支持继承。</li><li>结构不能声明默认的构造函数。</li></ul><p>针对上述讨论，让我们重写前面的实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">     </div><div class="line">struct Books</div><div class="line">&#123;</div><div class="line">   private string title;</div><div class="line">   private string author;</div><div class="line">   private string subject;</div><div class="line">   private int book_id;</div><div class="line">   public void getValues(string t, string a, string s, int id)</div><div class="line">   &#123;</div><div class="line">      title = t;</div><div class="line">      author = a;</div><div class="line">      subject = s;</div><div class="line">      book_id = id;</div><div class="line">   &#125;</div><div class="line">   public void display()</div><div class="line">   &#123;</div><div class="line">      Console.WriteLine(&quot;Title : &#123;0&#125;&quot;, title);</div><div class="line">      Console.WriteLine(&quot;Author : &#123;0&#125;&quot;, author);</div><div class="line">      Console.WriteLine(&quot;Subject : &#123;0&#125;&quot;, subject);</div><div class="line">      Console.WriteLine(&quot;Book_id :&#123;0&#125;&quot;, book_id);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">&#125;;  </div><div class="line"></div><div class="line">public class testStructure</div><div class="line">&#123;</div><div class="line">   public static void Main(string[] args)</div><div class="line">   &#123;</div><div class="line"></div><div class="line">      Books Book1 = new Books(); /* 声明 Book1，类型为 Book */</div><div class="line">      Books Book2 = new Books(); /* 声明 Book2，类型为 Book */</div><div class="line"></div><div class="line">      /* book 1 详述 */</div><div class="line">      Book1.getValues(&quot;C Programming&quot;,</div><div class="line">      &quot;Nuha Ali&quot;, &quot;C Programming Tutorial&quot;,6495407);</div><div class="line"></div><div class="line">      /* book 2 详述 */</div><div class="line">      Book2.getValues(&quot;Telecom Billing&quot;,</div><div class="line">      &quot;Zara Ali&quot;, &quot;Telecom Billing Tutorial&quot;, 6495700);</div><div class="line"></div><div class="line">      /* 打印 Book1 信息 */</div><div class="line">      Book1.display();</div><div class="line"></div><div class="line">      /* 打印 Book2 信息 */</div><div class="line">      Book2.display(); </div><div class="line"></div><div class="line">      Console.ReadKey();</div><div class="line"></div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Title : C Programming</div><div class="line">Author : Nuha Ali</div><div class="line">Subject : C Programming Tutorial</div><div class="line">Book_id : 6495407</div><div class="line">Title : Telecom Billing</div><div class="line">Author : Zara Ali</div><div class="line">Subject : Telecom Billing Tutorial</div><div class="line">Book_id : 6495700</div></pre></td></tr></table></figure><h3 id="多态性"><a href="#多态性" class="headerlink" title="多态性"></a>多态性</h3><p><strong>多态：</strong>一个接口多个功能。</p><p><strong>静态多态性：</strong>编译时发生函数响应（调用）；</p><p><strong>动态多态性：</strong>运行时发生函数响应。</p><p><strong>静态绑定（早期绑定）：</strong>编译时函数和对象的连接机制。</p><p>两种技术实现静态多态性：函数重载/运算符重载。</p><p><strong>函数重载：</strong>在同一范围内对相同函数名有多个定义，可以是参数类型或参数个数的不同，但不许只有返回值类型不同。</p><p><strong>运算符重载：</strong></p><p>关键字 <code>abstract</code> 声明抽象类：用于接口部分类的实现（派生类继承抽象类时，实现完成）。抽象类包含抽象方法，抽象方法可被派生类实现。</p><p>抽象类规则：</p><ul><li>1.不能创建抽象类的实例</li><li>2.不能在抽象类外定义抽象方法</li><li>3.不能把抽象类声明为<code>sealed</code>（类前带关键字<code>sealed</code>代表该类是密封类，不能被继承）</li></ul><p>关键字<code>virtual</code>声明虚方法:用于方法在继承类中的实现（在不同的继承类中有不同的实现）。</p><p>抽象类和虚方法共同实现动态多态性。</p><p>注：继承类中的重写虚函数需要声明关键字 <code>override</code>，在方法参数传入中写（类名 形参名）例如 <code>public void CallArea(Shape sh)</code>，意思是传入一个 <code>shape</code> 类型的类。</p><h3 id="运算符重载"><a href="#运算符重载" class="headerlink" title="运算符重载"></a><strong>运算符重载</strong></h3><p>您可以重定义或重载 C# 中内置的运算符。因此，程序员也可以使用用户自定义类型的运算符。重载运算符是具有特殊名称的函数，是通过关键字 <strong>operator</strong> 后跟运算符的符号来定义的。与其他函数一样，重载运算符有返回类型和参数列表。</p><p>例如，请看下面的函数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">public static Box operator+ (Box b, Box c)</div><div class="line">&#123;</div><div class="line">   Box box = new Box();</div><div class="line">   box.length = b.length + c.length;</div><div class="line">   box.breadth = b.breadth + c.breadth;</div><div class="line">   box.height = b.height + c.height;</div><div class="line">   return box;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>上面的函数为用户自定义的类 Box 实现了加法运算符（+）。它把两个 Box 对象的属性相加，并返回相加后的 Box 对象。</p><h4 id="运算符重载的实现"><a href="#运算符重载的实现" class="headerlink" title="运算符重载的实现"></a>运算符重载的实现</h4><p>下面的程序演示了完整的实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">namespace OperatorOvlApplication</div><div class="line">&#123;</div><div class="line">   class Box</div><div class="line">   &#123;</div><div class="line">      private double length;      // 长度</div><div class="line">      private double breadth;     // 宽度</div><div class="line">      private double height;      // 高度</div><div class="line"></div><div class="line">      public double getVolume()</div><div class="line">      &#123;</div><div class="line">         return length * breadth * height;</div><div class="line">      &#125;</div><div class="line">      public void setLength( double len )</div><div class="line">      &#123;</div><div class="line">         length = len;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public void setBreadth( double bre )</div><div class="line">      &#123;</div><div class="line">         breadth = bre;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public void setHeight( double hei )</div><div class="line">      &#123;</div><div class="line">         height = hei;</div><div class="line">      &#125;</div><div class="line">      // 重载 + 运算符来把两个 Box 对象相加</div><div class="line">      public static Box operator+ (Box b, Box c)</div><div class="line">      &#123;</div><div class="line">         Box box = new Box();</div><div class="line">         box.length = b.length + c.length;</div><div class="line">         box.breadth = b.breadth + c.breadth;</div><div class="line">         box.height = b.height + c.height;</div><div class="line">         return box;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">   &#125;</div><div class="line"></div><div class="line">   class Tester</div><div class="line">   &#123;</div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         Box Box1 = new Box();         // 声明 Box1，类型为 Box</div><div class="line">         Box Box2 = new Box();         // 声明 Box2，类型为 Box</div><div class="line">         Box Box3 = new Box();         // 声明 Box3，类型为 Box</div><div class="line">         double volume = 0.0;          // 体积</div><div class="line"></div><div class="line">         // Box1 详述</div><div class="line">         Box1.setLength(6.0);</div><div class="line">         Box1.setBreadth(7.0);</div><div class="line">         Box1.setHeight(5.0);</div><div class="line"></div><div class="line">         // Box2 详述</div><div class="line">         Box2.setLength(12.0);</div><div class="line">         Box2.setBreadth(13.0);</div><div class="line">         Box2.setHeight(10.0);</div><div class="line"></div><div class="line">         // Box1 的体积</div><div class="line">         volume = Box1.getVolume();</div><div class="line">         Console.WriteLine(&quot;Box1 的体积： &#123;0&#125;&quot;, volume);</div><div class="line"></div><div class="line">         // Box2 的体积</div><div class="line">         volume = Box2.getVolume();</div><div class="line">         Console.WriteLine(&quot;Box2 的体积： &#123;0&#125;&quot;, volume);</div><div class="line"></div><div class="line">         // 把两个对象相加</div><div class="line">         Box3 = Box1 + Box2;</div><div class="line"></div><div class="line">         // Box3 的体积</div><div class="line">         volume = Box3.getVolume();</div><div class="line">         Console.WriteLine(&quot;Box3 的体积： &#123;0&#125;&quot;, volume);</div><div class="line">         Console.ReadKey();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Box1 的体积： 210</div><div class="line">Box2 的体积： 1560</div><div class="line">Box3 的体积： 5400</div></pre></td></tr></table></figure><h4 id="可重载和不可重载运算符"><a href="#可重载和不可重载运算符" class="headerlink" title="可重载和不可重载运算符"></a>可重载和不可重载运算符</h4><p>下表描述了 C# 中运算符重载的能力：</p><table><thead><tr><th>运算符</th><th>描述</th></tr></thead><tbody><tr><td>+, -, !, ~, ++, –</td><td>这些一元运算符只有一个操作数，且可以被重载。</td></tr><tr><td>+, -, *, /, %</td><td>这些二元运算符带有两个操作数，且可以被重载。</td></tr><tr><td>==, !=, &lt;, &gt;, &lt;=, &gt;=</td><td>这些比较运算符可以被重载。</td></tr><tr><td>&amp;&amp;, \</td><td>\</td><td></td><td>这些条件逻辑运算符不能被直接重载。</td></tr><tr><td>+=, -=, *=, /=, %=</td><td>这些赋值运算符不能被重载。</td></tr><tr><td>=, ., ?:, -&gt;, new, is, sizeof, typeof</td><td>这些运算符不能被重载。</td></tr></tbody></table><h4 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h4><p>针对上述讨论，让我们扩展上面的实例，重载更多的运算符：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">namespace OperatorOvlApplication</div><div class="line">&#123;</div><div class="line">    class Box</div><div class="line">    &#123;</div><div class="line">       private double length;      // 长度</div><div class="line">       private double breadth;     // 宽度</div><div class="line">       private double height;      // 高度</div><div class="line">      </div><div class="line">       public double getVolume()</div><div class="line">       &#123;</div><div class="line">         return length * breadth * height;</div><div class="line">       &#125;</div><div class="line">      public void setLength( double len )</div><div class="line">      &#123;</div><div class="line">          length = len;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public void setBreadth( double bre )</div><div class="line">      &#123;</div><div class="line">          breadth = bre;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public void setHeight( double hei )</div><div class="line">      &#123;</div><div class="line">          height = hei;</div><div class="line">      &#125;</div><div class="line">      // 重载 + 运算符来把两个 Box 对象相加</div><div class="line">      public static Box operator+ (Box b, Box c)</div><div class="line">      &#123;</div><div class="line">          Box box = new Box();</div><div class="line">          box.length = b.length + c.length;</div><div class="line">          box.breadth = b.breadth + c.breadth;</div><div class="line">          box.height = b.height + c.height;</div><div class="line">          return box;</div><div class="line">      &#125;</div><div class="line">      </div><div class="line">      public static bool operator == (Box lhs, Box rhs)</div><div class="line">      &#123;</div><div class="line">          bool status = false;</div><div class="line">          if (lhs.length == rhs.length &amp;&amp; lhs.height == rhs.height </div><div class="line">             &amp;&amp; lhs.breadth == rhs.breadth)</div><div class="line">          &#123;</div><div class="line">              status = true;</div><div class="line">          &#125;</div><div class="line">          return status;</div><div class="line">      &#125;</div><div class="line">      public static bool operator !=(Box lhs, Box rhs)</div><div class="line">      &#123;</div><div class="line">          bool status = false;</div><div class="line">          if (lhs.length != rhs.length || lhs.height != rhs.height </div><div class="line">              || lhs.breadth != rhs.breadth)</div><div class="line">          &#123;</div><div class="line">              status = true;</div><div class="line">          &#125;</div><div class="line">          return status;</div><div class="line">      &#125;</div><div class="line">      public static bool operator &lt;(Box lhs, Box rhs)</div><div class="line">      &#123;</div><div class="line">          bool status = false;</div><div class="line">          if (lhs.length &lt; rhs.length &amp;&amp; lhs.height </div><div class="line">              &lt; rhs.height &amp;&amp; lhs.breadth &lt; rhs.breadth)</div><div class="line">          &#123;</div><div class="line">              status = true;</div><div class="line">          &#125;</div><div class="line">          return status;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public static bool operator &gt;(Box lhs, Box rhs)</div><div class="line">      &#123;</div><div class="line">          bool status = false;</div><div class="line">          if (lhs.length &gt; rhs.length &amp;&amp; lhs.height </div><div class="line">              &gt; rhs.height &amp;&amp; lhs.breadth &gt; rhs.breadth)</div><div class="line">          &#123;</div><div class="line">              status = true;</div><div class="line">          &#125;</div><div class="line">          return status;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public static bool operator &lt;=(Box lhs, Box rhs)</div><div class="line">      &#123;</div><div class="line">          bool status = false;</div><div class="line">          if (lhs.length &lt;= rhs.length &amp;&amp; lhs.height </div><div class="line">              &lt;= rhs.height &amp;&amp; lhs.breadth &lt;= rhs.breadth)</div><div class="line">          &#123;</div><div class="line">              status = true;</div><div class="line">          &#125;</div><div class="line">          return status;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public static bool operator &gt;=(Box lhs, Box rhs)</div><div class="line">      &#123;</div><div class="line">          bool status = false;</div><div class="line">          if (lhs.length &gt;= rhs.length &amp;&amp; lhs.height </div><div class="line">             &gt;= rhs.height &amp;&amp; lhs.breadth &gt;= rhs.breadth)</div><div class="line">          &#123;</div><div class="line">              status = true;</div><div class="line">          &#125;</div><div class="line">          return status;</div><div class="line">      &#125;</div><div class="line">      public override string ToString()</div><div class="line">      &#123;</div><div class="line">          return String.Format(&quot;(&#123;0&#125;, &#123;1&#125;, &#123;2&#125;)&quot;, length, breadth, height);</div><div class="line">      &#125;</div><div class="line">   </div><div class="line">   &#125;</div><div class="line">    </div><div class="line">   class Tester</div><div class="line">   &#123;</div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">        Box Box1 = new Box();          // 声明 Box1，类型为 Box</div><div class="line">        Box Box2 = new Box();          // 声明 Box2，类型为 Box</div><div class="line">        Box Box3 = new Box();          // 声明 Box3，类型为 Box</div><div class="line">        Box Box4 = new Box();</div><div class="line">        double volume = 0.0;   // 体积</div><div class="line"></div><div class="line">        // Box1 详述</div><div class="line">        Box1.setLength(6.0);</div><div class="line">        Box1.setBreadth(7.0);</div><div class="line">        Box1.setHeight(5.0);</div><div class="line"></div><div class="line">        // Box2 详述</div><div class="line">        Box2.setLength(12.0);</div><div class="line">        Box2.setBreadth(13.0);</div><div class="line">        Box2.setHeight(10.0);</div><div class="line"></div><div class="line">       // 使用重载的 ToString() 显示两个盒子</div><div class="line">        Console.WriteLine(&quot;Box1： &#123;0&#125;&quot;, Box1.ToString());</div><div class="line">        Console.WriteLine(&quot;Box2： &#123;0&#125;&quot;, Box2.ToString());</div><div class="line">        </div><div class="line">        // Box1 的体积</div><div class="line">        volume = Box1.getVolume();</div><div class="line">        Console.WriteLine(&quot;Box1 的体积： &#123;0&#125;&quot;, volume);</div><div class="line"></div><div class="line">        // Box2 的体积</div><div class="line">        volume = Box2.getVolume();</div><div class="line">        Console.WriteLine(&quot;Box2 的体积： &#123;0&#125;&quot;, volume);</div><div class="line"></div><div class="line">        // 把两个对象相加</div><div class="line">        Box3 = Box1 + Box2;</div><div class="line">        Console.WriteLine(&quot;Box3： &#123;0&#125;&quot;, Box3.ToString());</div><div class="line">        // Box3 的体积</div><div class="line">        volume = Box3.getVolume();</div><div class="line">        Console.WriteLine(&quot;Box3 的体积： &#123;0&#125;&quot;, volume);</div><div class="line"></div><div class="line">        //comparing the boxes</div><div class="line">        if (Box1 &gt; Box2)</div><div class="line">          Console.WriteLine(&quot;Box1 大于 Box2&quot;);</div><div class="line">        else</div><div class="line">          Console.WriteLine(&quot;Box1 不大于 Box2&quot;);</div><div class="line">        if (Box1 &lt; Box2)</div><div class="line">          Console.WriteLine(&quot;Box1 小于 Box2&quot;);</div><div class="line">        else</div><div class="line">          Console.WriteLine(&quot;Box1 不小于 Box2&quot;);</div><div class="line">        if (Box1 &gt;= Box2)</div><div class="line">          Console.WriteLine(&quot;Box1 大于等于 Box2&quot;);</div><div class="line">        else</div><div class="line">          Console.WriteLine(&quot;Box1 不大于等于 Box2&quot;);</div><div class="line">        if (Box1 &lt;= Box2)</div><div class="line">          Console.WriteLine(&quot;Box1 小于等于 Box2&quot;);</div><div class="line">        else</div><div class="line">          Console.WriteLine(&quot;Box1 不小于等于 Box2&quot;);</div><div class="line">        if (Box1 != Box2)</div><div class="line">          Console.WriteLine(&quot;Box1 不等于 Box2&quot;);</div><div class="line">        else</div><div class="line">          Console.WriteLine(&quot;Box1 等于 Box2&quot;);</div><div class="line">        Box4 = Box3;</div><div class="line">        if (Box3 == Box4)</div><div class="line">          Console.WriteLine(&quot;Box3 等于 Box4&quot;);</div><div class="line">        else</div><div class="line">          Console.WriteLine(&quot;Box3 不等于 Box4&quot;);</div><div class="line"></div><div class="line">        Console.ReadKey();</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">Box1： (6, 7, 5)</div><div class="line">Box2： (12, 13, 10)</div><div class="line">Box1 的体积： 210</div><div class="line">Box2 的体积： 1560</div><div class="line">Box3： (18, 20, 15)</div><div class="line">Box3 的体积： 5400</div><div class="line">Box1 不大于 Box2</div><div class="line">Box1 小于 Box2</div><div class="line">Box1 不大于等于 Box2</div><div class="line">Box1 小于等于 Box2</div><div class="line">Box1 不等于 Box2</div><div class="line">Box3 等于 Box4</div></pre></td></tr></table></figure><h3 id="FileStream"><a href="#FileStream" class="headerlink" title="FileStream"></a>FileStream</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using System.IO;</div><div class="line"></div><div class="line">namespace FileIOApplication</div><div class="line">&#123;</div><div class="line">    class Program</div><div class="line">    &#123;</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            FileStream F = new FileStream(&quot;test.dat&quot;, </div><div class="line">            FileMode.OpenOrCreate, FileAccess.ReadWrite);</div><div class="line"></div><div class="line">            for (int i = 1; i &lt;= 20; i++)</div><div class="line">            &#123;</div><div class="line">                F.WriteByte((byte)i);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            F.Position = 0;</div><div class="line"></div><div class="line">            for (int i = 0; i &lt;= 20; i++)</div><div class="line">            &#123;</div><div class="line">                Console.Write(F.ReadByte() + &quot; &quot;);</div><div class="line">            &#125;</div><div class="line">            F.Close();</div><div class="line">            Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 -1</div></pre></td></tr></table></figure><h3 id="StreamReader-和-StreamWriter"><a href="#StreamReader-和-StreamWriter" class="headerlink" title="StreamReader 和 StreamWriter"></a><strong>StreamReader</strong> 和 <strong>StreamWriter</strong></h3><h4 id="StreamReader-类"><a href="#StreamReader-类" class="headerlink" title="StreamReader 类"></a>StreamReader 类</h4><p>下面的实例演示了读取名为 Jamaica.txt 的文件。文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">Down the way where the nights are gay</div><div class="line">And the sun shines daily on the mountain top</div><div class="line">I took a trip on a sailing ship</div><div class="line">And when I reached Jamaica</div><div class="line">I made a stop</div><div class="line">using System;</div><div class="line">using System.IO;</div><div class="line"></div><div class="line">namespace FileApplication</div><div class="line">&#123;</div><div class="line">    class Program</div><div class="line">    &#123;</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                // 创建一个 StreamReader 的实例来读取文件 </div><div class="line">                // using 语句也能关闭 StreamReader</div><div class="line">                using (StreamReader sr = new StreamReader(&quot;c:/jamaica.txt&quot;))</div><div class="line">                &#123;</div><div class="line">                    string line;</div><div class="line">                   </div><div class="line">                    // 从文件读取并显示行，直到文件的末尾 </div><div class="line">                    while ((line = sr.ReadLine()) != null)</div><div class="line">                    &#123;</div><div class="line">                        Console.WriteLine(line);</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            catch (Exception e)</div><div class="line">            &#123;</div><div class="line">                // 向用户显示出错消息</div><div class="line">                Console.WriteLine(&quot;The file could not be read:&quot;);</div><div class="line">                Console.WriteLine(e.Message);</div><div class="line">            &#125;</div><div class="line">            Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当您编译和执行上面的程序时，它会显示文件的内容。</p><h4 id="StreamWriter-类"><a href="#StreamWriter-类" class="headerlink" title="StreamWriter 类"></a>StreamWriter 类</h4><p>下面的实例演示了使用 StreamWriter 类向文件写入文本数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using System.IO;</div><div class="line"></div><div class="line">namespace FileApplication</div><div class="line">&#123;</div><div class="line">    class Program</div><div class="line">    &#123;</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line"></div><div class="line">            string[] names = new string[] &#123;&quot;Zara Ali&quot;, &quot;Nuha Ali&quot;&#125;;</div><div class="line">            using (StreamWriter sw = new StreamWriter(&quot;names.txt&quot;))</div><div class="line">            &#123;</div><div class="line">                foreach (string s in names)</div><div class="line">                &#123;</div><div class="line">                    sw.WriteLine(s);</div><div class="line"></div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            // 从文件中读取并显示每行</div><div class="line">            string line = &quot;&quot;;</div><div class="line">            using (StreamReader sr = new StreamReader(&quot;names.txt&quot;))</div><div class="line">            &#123;</div><div class="line">                while ((line = sr.ReadLine()) != null)</div><div class="line">                &#123;</div><div class="line">                    Console.WriteLine(line);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Zara Ali</div><div class="line">Nuha Ali</div></pre></td></tr></table></figure><h3 id="BinaryReader-和-BinaryWriter"><a href="#BinaryReader-和-BinaryWriter" class="headerlink" title="BinaryReader 和 BinaryWriter"></a><strong>BinaryReader</strong> 和 <strong>BinaryWriter</strong></h3><p>下面的实例演示了读取和写入二进制数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using System.IO;</div><div class="line"></div><div class="line">namespace BinaryFileApplication</div><div class="line">&#123;</div><div class="line">    class Program</div><div class="line">    &#123;</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            BinaryWriter bw;</div><div class="line">            BinaryReader br;</div><div class="line">            int i = 25;</div><div class="line">            double d = 3.14157;</div><div class="line">            bool b = true;</div><div class="line">            string s = &quot;I am happy&quot;;</div><div class="line">            // 创建文件</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                bw = new BinaryWriter(new FileStream(&quot;mydata&quot;,</div><div class="line">				FileMode.Create));</div><div class="line">            &#125;</div><div class="line">            catch (IOException e)</div><div class="line">            &#123;</div><div class="line">                Console.WriteLine(e.Message + &quot;\n Cannot create file.&quot;);</div><div class="line">                return;</div><div class="line">            &#125;</div><div class="line">            // 写入文件</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                bw.Write(i);</div><div class="line">                bw.Write(d);</div><div class="line">                bw.Write(b);</div><div class="line">                bw.Write(s);</div><div class="line">            &#125;</div><div class="line">            catch (IOException e)</div><div class="line">            &#123;</div><div class="line">                Console.WriteLine(e.Message + &quot;\n Cannot write to file.&quot;);</div><div class="line">                return;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            bw.Close();</div><div class="line">            // 读取文件</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                br = new BinaryReader(new FileStream(&quot;mydata&quot;,</div><div class="line">				FileMode.Open));</div><div class="line">            &#125;</div><div class="line">            catch (IOException e)</div><div class="line">            &#123;</div><div class="line">                Console.WriteLine(e.Message + &quot;\n Cannot open file.&quot;);</div><div class="line">                return;</div><div class="line">            &#125;</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                i = br.ReadInt32();</div><div class="line">                Console.WriteLine(&quot;Integer data: &#123;0&#125;&quot;, i);</div><div class="line">                d = br.ReadDouble();</div><div class="line">                Console.WriteLine(&quot;Double data: &#123;0&#125;&quot;, d);</div><div class="line">                b = br.ReadBoolean();</div><div class="line">                Console.WriteLine(&quot;Boolean data: &#123;0&#125;&quot;, b);</div><div class="line">                s = br.ReadString();</div><div class="line">                Console.WriteLine(&quot;String data: &#123;0&#125;&quot;, s);</div><div class="line">            &#125;</div><div class="line">            catch (IOException e)</div><div class="line">            &#123;</div><div class="line">                Console.WriteLine(e.Message + &quot;\n Cannot read from file.&quot;);</div><div class="line">                return;</div><div class="line">            &#125;</div><div class="line">            br.Close();</div><div class="line">            Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Integer data: 25</div><div class="line">Double data: 3.14157</div><div class="line">Boolean data: True</div><div class="line">String data: I am happy</div></pre></td></tr></table></figure><h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><p><strong>属性（Property）</strong> 是类（class）、结构（structure）和接口（interface）的命名（named）成员。类或结构中的成员变量或方法称为 <strong>域（Field）</strong>。属性（Property）是域（Field）的扩展，且可使用相同的语法来访问。它们使用 <strong>访问器（accessors）</strong> 让私有域的值可被读写或操作。</p><p>属性（Property）不会确定存储位置。相反，它们具有可读写或计算它们值的 <strong>访问器（accessors）</strong>。</p><p>例如，有一个名为 Student 的类，带有 age、name 和 code 的私有域。我们不能在类的范围以外直接访问这些域，但是我们可以拥有访问这些私有域的属性。</p><h4 id="访问器（Accessors）"><a href="#访问器（Accessors）" class="headerlink" title="访问器（Accessors）"></a>访问器（Accessors）</h4><p>属性（Property）的<strong>访问器（accessor）</strong>包含有助于获取（读取或计算）或设置（写入）属性的可执行语句。访问器（accessor）声明可包含一个 get 访问器、一个 set 访问器，或者同时包含二者。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">// 声明类型为 string 的 Code 属性</div><div class="line">public string Code</div><div class="line">&#123;</div><div class="line">   get</div><div class="line">   &#123;</div><div class="line">      return code;</div><div class="line">   &#125;</div><div class="line">   set</div><div class="line">   &#123;</div><div class="line">      code = value;</div><div class="line">   &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">// 声明类型为 string 的 Name 属性</div><div class="line">public string Name</div><div class="line">&#123;</div><div class="line">   get</div><div class="line">   &#123;</div><div class="line">     return name;</div><div class="line">   &#125;</div><div class="line">   set</div><div class="line">   &#123;</div><div class="line">     name = value;</div><div class="line">   &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">// 声明类型为 int 的 Age 属性</div><div class="line">public int Age</div><div class="line">&#123; </div><div class="line">   get</div><div class="line">   &#123;</div><div class="line">      return age;</div><div class="line">   &#125;</div><div class="line">   set</div><div class="line">   &#123;</div><div class="line">      age = value;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="实例-2"><a href="#实例-2" class="headerlink" title="实例"></a>实例</h4><p>下面的实例演示了属性（Property）的用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace tutorialspoint</div><div class="line">&#123;</div><div class="line">   class Student</div><div class="line">   &#123;</div><div class="line"></div><div class="line">      private string code = &quot;N.A&quot;;</div><div class="line">      private string name = &quot;not known&quot;;</div><div class="line">      private int age = 0;</div><div class="line"></div><div class="line">      // 声明类型为 string 的 Code 属性</div><div class="line">      public string Code</div><div class="line">      &#123;</div><div class="line">         get</div><div class="line">         &#123;</div><div class="line">            return code;</div><div class="line">         &#125;</div><div class="line">         set</div><div class="line">         &#123;</div><div class="line">            code = value;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   </div><div class="line">      // 声明类型为 string 的 Name 属性</div><div class="line">      public string Name</div><div class="line">      &#123;</div><div class="line">         get</div><div class="line">         &#123;</div><div class="line">            return name;</div><div class="line">         &#125;</div><div class="line">         set</div><div class="line">         &#123;</div><div class="line">            name = value;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      // 声明类型为 int 的 Age 属性</div><div class="line">      public int Age</div><div class="line">      &#123;</div><div class="line">         get</div><div class="line">         &#123;</div><div class="line">            return age;</div><div class="line">         &#125;</div><div class="line">         set</div><div class="line">         &#123;</div><div class="line">            age = value;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">      public override string ToString()</div><div class="line">      &#123;</div><div class="line">         return &quot;Code = &quot; + Code +&quot;, Name = &quot; + Name + &quot;, Age = &quot; + Age;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    class ExampleDemo</div><div class="line">    &#123;</div><div class="line">      public static void Main()</div><div class="line">      &#123;</div><div class="line">         // 创建一个新的 Student 对象</div><div class="line">         Student s = new Student();</div><div class="line">            </div><div class="line">         // 设置 student 的 code、name 和 age</div><div class="line">         s.Code = &quot;001&quot;;</div><div class="line">         s.Name = &quot;Zara&quot;;</div><div class="line">         s.Age = 9;</div><div class="line">         Console.WriteLine(&quot;Student Info: &#123;0&#125;&quot;, s);</div><div class="line">         // 增加年龄</div><div class="line">         s.Age += 1;</div><div class="line">         Console.WriteLine(&quot;Student Info: &#123;0&#125;&quot;, s);</div><div class="line">         Console.ReadKey();</div><div class="line">       &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Student Info: Code = 001, Name = Zara, Age = 9</div><div class="line">Student Info: Code = 001, Name = Zara, Age = 10</div></pre></td></tr></table></figure><h4 id="抽象属性（Abstract-Properties）"><a href="#抽象属性（Abstract-Properties）" class="headerlink" title="抽象属性（Abstract Properties）"></a>抽象属性（Abstract Properties）</h4><p>抽象类可拥有抽象属性，这些属性应在派生类中被实现。下面的程序说明了这点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace tutorialspoint</div><div class="line">&#123;</div><div class="line">   public abstract class Person</div><div class="line">   &#123;</div><div class="line">      public abstract string Name</div><div class="line">      &#123;</div><div class="line">         get;</div><div class="line">         set;</div><div class="line">      &#125;</div><div class="line">      public abstract int Age</div><div class="line">      &#123;</div><div class="line">         get;</div><div class="line">         set;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">   class Student : Person</div><div class="line">   &#123;</div><div class="line"></div><div class="line">      private string code = &quot;N.A&quot;;</div><div class="line">      private string name = &quot;N.A&quot;;</div><div class="line">      private int age = 0;</div><div class="line"></div><div class="line">      // 声明类型为 string 的 Code 属性</div><div class="line">      public string Code</div><div class="line">      &#123;</div><div class="line">         get</div><div class="line">         &#123;</div><div class="line">            return code;</div><div class="line">         &#125;</div><div class="line">         set</div><div class="line">         &#123;</div><div class="line">            code = value;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   </div><div class="line">      // 声明类型为 string 的 Name 属性</div><div class="line">      public override string Name</div><div class="line">      &#123;</div><div class="line">         get</div><div class="line">         &#123;</div><div class="line">            return name;</div><div class="line">         &#125;</div><div class="line">         set</div><div class="line">         &#123;</div><div class="line">            name = value;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      // 声明类型为 int 的 Age 属性</div><div class="line">      public override int Age</div><div class="line">      &#123;</div><div class="line">         get</div><div class="line">         &#123;</div><div class="line">            return age;</div><div class="line">         &#125;</div><div class="line">         set</div><div class="line">         &#123;</div><div class="line">            age = value;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">      public override string ToString()</div><div class="line">      &#123;</div><div class="line">         return &quot;Code = &quot; + Code +&quot;, Name = &quot; + Name + &quot;, Age = &quot; + Age;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">   class ExampleDemo</div><div class="line">   &#123;</div><div class="line">      public static void Main()</div><div class="line">      &#123;</div><div class="line">         // 创建一个新的 Student 对象</div><div class="line">         Student s = new Student();</div><div class="line">            </div><div class="line">         // 设置 student 的 code、name 和 age</div><div class="line">         s.Code = &quot;001&quot;;</div><div class="line">         s.Name = &quot;Zara&quot;;</div><div class="line">         s.Age = 9;</div><div class="line">         Console.WriteLine(&quot;Student Info:- &#123;0&#125;&quot;, s);</div><div class="line">         // 增加年龄</div><div class="line">         s.Age += 1;</div><div class="line">         Console.WriteLine(&quot;Student Info:- &#123;0&#125;&quot;, s);</div><div class="line">         Console.ReadKey();</div><div class="line">       &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Student Info: Code = 001, Name = Zara, Age = 9</div><div class="line">Student Info: Code = 001, Name = Zara, Age = 10</div></pre></td></tr></table></figure><h3 id="索引器"><a href="#索引器" class="headerlink" title="索引器"></a>索引器</h3><p><strong>索引器（Indexer）</strong> 允许一个对象可以像数组一样被索引。当您为类定义一个索引器时，该类的行为就会像一个 <strong>虚拟数组（virtual array）</strong> 一样。您可以使用数组访问运算符（[ ]）来访问该类的实例。</p><h4 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h4><p>一维索引器的语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">element-type this[int index] </div><div class="line">&#123;</div><div class="line">   // get 访问器</div><div class="line">   get </div><div class="line">   &#123;</div><div class="line">      // 返回 index 指定的值</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   // set 访问器</div><div class="line">   set </div><div class="line">   &#123;</div><div class="line">      // 设置 index 指定的值 </div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="索引器（Indexer）的用途"><a href="#索引器（Indexer）的用途" class="headerlink" title="索引器（Indexer）的用途"></a>索引器（Indexer）的用途</h4><p>索引器的行为的声明在某种程度上类似于属性（property）。就像属性（property），您可使用 <strong>get</strong> 和 <strong>set</strong> 访问器来定义索引器。但是，属性返回或设置一个特定的数据成员，而索引器返回或设置对象实例的一个特定值。换句话说，它把实例数据分为更小的部分，并索引每个部分，获取或设置每个部分。</p><p>定义一个属性（property）包括提供属性名称。索引器定义的时候不带有名称，但带有 <strong>this</strong> 关键字，它指向对象实例。下面的实例演示了这个概念：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace IndexerApplication</div><div class="line">&#123;</div><div class="line">   class IndexedNames</div><div class="line">   &#123;</div><div class="line">      private string[] namelist = new string[size];</div><div class="line">      static public int size = 10;</div><div class="line">      public IndexedNames()</div><div class="line">      &#123;</div><div class="line">         for (int i = 0; i &lt; size; i++)</div><div class="line">         namelist[i] = &quot;N. A.&quot;;</div><div class="line">      &#125;</div><div class="line">      public string this[int index]</div><div class="line">      &#123;</div><div class="line">         get</div><div class="line">         &#123;</div><div class="line">            string tmp;</div><div class="line"></div><div class="line">            if( index &gt;= 0 &amp;&amp; index &lt;= size-1 )</div><div class="line">            &#123;</div><div class="line">               tmp = namelist[index];</div><div class="line">            &#125;</div><div class="line">            else</div><div class="line">            &#123;</div><div class="line">               tmp = &quot;&quot;;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            return ( tmp );</div><div class="line">         &#125;</div><div class="line">         set</div><div class="line">         &#123;</div><div class="line">            if( index &gt;= 0 &amp;&amp; index &lt;= size-1 )</div><div class="line">            &#123;</div><div class="line">               namelist[index] = value;</div><div class="line">            &#125;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         IndexedNames names = new IndexedNames();</div><div class="line">         names[0] = &quot;Zara&quot;;</div><div class="line">         names[1] = &quot;Riz&quot;;</div><div class="line">         names[2] = &quot;Nuha&quot;;</div><div class="line">         names[3] = &quot;Asif&quot;;</div><div class="line">         names[4] = &quot;Davinder&quot;;</div><div class="line">         names[5] = &quot;Sunil&quot;;</div><div class="line">         names[6] = &quot;Rubic&quot;;</div><div class="line">         for ( int i = 0; i &lt; IndexedNames.size; i++ )</div><div class="line">         &#123;</div><div class="line">            Console.WriteLine(names[i]);</div><div class="line">         &#125;</div><div class="line">         Console.ReadKey();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Zara</div><div class="line">Riz</div><div class="line">Nuha</div><div class="line">Asif</div><div class="line">Davinder</div><div class="line">Sunil</div><div class="line">Rubic</div><div class="line">N. A.</div><div class="line">N. A.</div><div class="line">N. A.</div></pre></td></tr></table></figure><h4 id="重载索引器（Indexer）"><a href="#重载索引器（Indexer）" class="headerlink" title="重载索引器（Indexer）"></a>重载索引器（Indexer）</h4><p>索引器（Indexer）可被重载。索引器声明的时候也可带有多个参数，且每个参数可以是不同的类型。没有必要让索引器必须是整型的。C# 允许索引器可以是其他类型，例如，字符串类型。</p><p>下面的实例演示了重载索引器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace IndexerApplication</div><div class="line">&#123;</div><div class="line">   class IndexedNames</div><div class="line">   &#123;</div><div class="line">      private string[] namelist = new string[size];</div><div class="line">      static public int size = 10;</div><div class="line">      public IndexedNames()</div><div class="line">      &#123;</div><div class="line">         for (int i = 0; i &lt; size; i++)</div><div class="line">         &#123;</div><div class="line">          namelist[i] = &quot;N. A.&quot;;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">      public string this[int index]</div><div class="line">      &#123;</div><div class="line">         get</div><div class="line">         &#123;</div><div class="line">            string tmp;</div><div class="line"></div><div class="line">            if( index &gt;= 0 &amp;&amp; index &lt;= size-1 )</div><div class="line">            &#123;</div><div class="line">               tmp = namelist[index];</div><div class="line">            &#125;</div><div class="line">            else</div><div class="line">            &#123;</div><div class="line">               tmp = &quot;&quot;;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            return ( tmp );</div><div class="line">         &#125;</div><div class="line">         set</div><div class="line">         &#123;</div><div class="line">            if( index &gt;= 0 &amp;&amp; index &lt;= size-1 )</div><div class="line">            &#123;</div><div class="line">               namelist[index] = value;</div><div class="line">            &#125;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">      public int this[string name]</div><div class="line">      &#123;</div><div class="line">         get</div><div class="line">         &#123;</div><div class="line">            int index = 0;</div><div class="line">            while(index &lt; size)</div><div class="line">            &#123;</div><div class="line">               if (namelist[index] == name)</div><div class="line">               &#123;</div><div class="line">                return index;</div><div class="line">               &#125;</div><div class="line">               index++;</div><div class="line">            &#125;</div><div class="line">            return index;</div><div class="line">         &#125;</div><div class="line"></div><div class="line">      &#125;</div><div class="line"></div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         IndexedNames names = new IndexedNames();</div><div class="line">         names[0] = &quot;Zara&quot;;</div><div class="line">         names[1] = &quot;Riz&quot;;</div><div class="line">         names[2] = &quot;Nuha&quot;;</div><div class="line">         names[3] = &quot;Asif&quot;;</div><div class="line">         names[4] = &quot;Davinder&quot;;</div><div class="line">         names[5] = &quot;Sunil&quot;;</div><div class="line">         names[6] = &quot;Rubic&quot;;</div><div class="line">         // 使用带有 int 参数的第一个索引器</div><div class="line">         for (int i = 0; i &lt; IndexedNames.size; i++)</div><div class="line">         &#123;</div><div class="line">            Console.WriteLine(names[i]);</div><div class="line">         &#125;</div><div class="line">         // 使用带有 string 参数的第二个索引器</div><div class="line">         Console.WriteLine(names[&quot;Nuha&quot;]);</div><div class="line">         Console.ReadKey();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Zara</div><div class="line">Riz</div><div class="line">Nuha</div><div class="line">Asif</div><div class="line">Davinder</div><div class="line">Sunil</div><div class="line">Rubic</div><div class="line">N. A.</div><div class="line">N. A.</div><div class="line">N. A.</div><div class="line">2</div></pre></td></tr></table></figure><h3 id="委托"><a href="#委托" class="headerlink" title="委托"></a>委托</h3><p>C# 中的委托（Delegate）类似于 C 或 C++ 中函数的指针。<strong>委托（Delegate）</strong> 是存有对某个方法的引用的一种引用类型变量。引用可在运行时被改变。</p><p>委托（Delegate）特别用于实现事件和回调方法。所有的委托（Delegate）都派生自 <strong>System.Delegate</strong> 类。</p><h4 id="声明委托（Delegate）"><a href="#声明委托（Delegate）" class="headerlink" title="声明委托（Delegate）"></a>声明委托（Delegate）</h4><p>委托声明决定了可由该委托引用的方法。委托可指向一个与其具有相同标签的方法。</p><p>例如，假设有一个委托：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">public delegate int MyDelegate (string s);</div></pre></td></tr></table></figure><p>上面的委托可被用于引用任何一个带有一个单一的 <em>string</em> 参数的方法，并返回一个 <em>int</em> 类型变量。</p><p>声明委托的语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">delegate &lt;return type&gt; &lt;delegate-name&gt; &lt;parameter list&gt;</div></pre></td></tr></table></figure><h4 id="实例化委托（Delegate）"><a href="#实例化委托（Delegate）" class="headerlink" title="实例化委托（Delegate）"></a>实例化委托（Delegate）</h4><p>一旦声明了委托类型，委托对象必须使用 <strong>new</strong> 关键字来创建，且与一个特定的方法有关。当创建委托时，传递到 <strong>new</strong> 语句的参数就像方法调用一样书写，但是不带有参数。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">public delegate void printString(string s);</div><div class="line">...</div><div class="line">printString ps1 = new printString(WriteToScreen);</div><div class="line">printString ps2 = new printString(WriteToFile);</div></pre></td></tr></table></figure><p>下面的实例演示了委托的声明、实例化和使用，该委托可用于引用带有一个整型参数的方法，并返回一个整型值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">delegate int NumberChanger(int n);</div><div class="line">namespace DelegateAppl</div><div class="line">&#123;</div><div class="line">   class TestDelegate</div><div class="line">   &#123;</div><div class="line">      static int num = 10;</div><div class="line">      public static int AddNum(int p)</div><div class="line">      &#123;</div><div class="line">         num += p;</div><div class="line">         return num;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public static int MultNum(int q)</div><div class="line">      &#123;</div><div class="line">         num *= q;</div><div class="line">         return num;</div><div class="line">      &#125;</div><div class="line">      public static int getNum()</div><div class="line">      &#123;</div><div class="line">         return num;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         // 创建委托实例</div><div class="line">         NumberChanger nc1 = new NumberChanger(AddNum);</div><div class="line">         NumberChanger nc2 = new NumberChanger(MultNum);</div><div class="line">         // 使用委托对象调用方法</div><div class="line">         nc1(25);</div><div class="line">         Console.WriteLine(&quot;Value of Num: &#123;0&#125;&quot;, getNum());</div><div class="line">         nc2(5);</div><div class="line">         Console.WriteLine(&quot;Value of Num: &#123;0&#125;&quot;, getNum());</div><div class="line">         Console.ReadKey();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Value of Num: 35</div><div class="line">Value of Num: 175</div></pre></td></tr></table></figure><h4 id="委托的多播（Multicasting-of-a-Delegate）"><a href="#委托的多播（Multicasting-of-a-Delegate）" class="headerlink" title="委托的多播（Multicasting of a Delegate）"></a>委托的多播（Multicasting of a Delegate）</h4><p>委托对象可使用 “+” 运算符进行合并。一个合并委托调用它所合并的两个委托。只有相同类型的委托可被合并。”-“ 运算符可用于从合并的委托中移除组件委托。</p><p>使用委托的这个有用的特点，您可以创建一个委托被调用时要调用的方法的调用列表。这被称为委托的 <strong>多播（multicasting）</strong>，也叫组播。下面的程序演示了委托的多播：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">delegate int NumberChanger(int n);</div><div class="line">namespace DelegateAppl</div><div class="line">&#123;</div><div class="line">   class TestDelegate</div><div class="line">   &#123;</div><div class="line">      static int num = 10;</div><div class="line">      public static int AddNum(int p)</div><div class="line">      &#123;</div><div class="line">         num += p;</div><div class="line">         return num;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public static int MultNum(int q)</div><div class="line">      &#123;</div><div class="line">         num *= q;</div><div class="line">         return num;</div><div class="line">      &#125;</div><div class="line">      public static int getNum()</div><div class="line">      &#123;</div><div class="line">         return num;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         // 创建委托实例</div><div class="line">         NumberChanger nc;</div><div class="line">         NumberChanger nc1 = new NumberChanger(AddNum);</div><div class="line">         NumberChanger nc2 = new NumberChanger(MultNum);</div><div class="line">         nc = nc1;</div><div class="line">         nc += nc2;</div><div class="line">         // 调用多播</div><div class="line">         nc(5);</div><div class="line">         Console.WriteLine(&quot;Value of Num: &#123;0&#125;&quot;, getNum());</div><div class="line">         Console.ReadKey();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Value of Num: 75</div></pre></td></tr></table></figure><h4 id="委托（Delegate）的用途"><a href="#委托（Delegate）的用途" class="headerlink" title="委托（Delegate）的用途"></a>委托（Delegate）的用途</h4><p>委托多播实例：例如小明叫小张买完车票，之后接着又让他带张电影票：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">// 小张类</div><div class="line">public class MrZhang</div><div class="line">	&#123;</div><div class="line">	// 其实买车票的悲情人物是小张</div><div class="line">	public static void BuyTicket()</div><div class="line">	&#123;</div><div class="line">	    	Console.WriteLine(&quot;NND,每次都让我去买票，鸡人呀！&quot;);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public static void BuyMovieTicket()</div><div class="line">	&#123;</div><div class="line">		Console.WriteLine(&quot;我去，自己泡妞，还要让我带电影票！&quot;);</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">//小明类</div><div class="line">class MrMing</div><div class="line">&#123;</div><div class="line">    // 声明一个委托，其实就是个“命令”</div><div class="line">    public delegate void BugTicketEventHandler();</div><div class="line"></div><div class="line">    public static void Main(string[] args)</div><div class="line">    &#123;</div><div class="line">        // 这里就是具体阐述这个命令是干什么的，本例是MrZhang.BuyTicket“小张买车票”</div><div class="line">        BugTicketEventHandler myDelegate = new BugTicketEventHandler(MrZhang.BuyTicket);</div><div class="line"></div><div class="line">        myDelegate += MrZhang.BuyMovieTicket;</div><div class="line">        // 这时候委托被附上了具体的方法</div><div class="line">        myDelegate();</div><div class="line">        Console.ReadKey();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h3><p><strong>事件（Event）</strong> 基本上说是一个用户操作，如按键、点击、鼠标移动等等，或者是一些出现，如系统生成的通知。应用程序需要在事件发生时响应事件。例如，中断。事件是用于进程间通信。</p><h4 id="通过事件使用委托"><a href="#通过事件使用委托" class="headerlink" title="通过事件使用委托"></a>通过事件使用委托</h4><p>事件在类中声明且生成，且通过使用同一个类或其他类中的委托与事件处理程序关联。包含事件的类用于发布事件。这被称为 <strong>发布器（publisher）</strong> 类。其他接受该事件的类被称为 <strong>订阅器（subscriber）</strong> 类。事件使用 <strong>发布-订阅（publisher-subscriber）</strong> 模型。</p><p><strong>发布器（publisher）</strong> 是一个包含事件和委托定义的对象。事件和委托之间的联系也定义在这个对象中。发布器（publisher）类的对象调用这个事件，并通知其他的对象。</p><p><strong>订阅器（subscriber）</strong> 是一个接受事件并提供事件处理程序的对象。在发布器（publisher）类中的委托调用订阅器（subscriber）类中的方法（事件处理程序）。</p><h4 id="声明事件（Event）"><a href="#声明事件（Event）" class="headerlink" title="声明事件（Event）"></a>声明事件（Event）</h4><p>在类的内部声明事件，首先必须声明该事件的委托类型。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">public delegate void BoilerLogHandler(string status);</div></pre></td></tr></table></figure><p>然后，声明事件本身，使用 <strong>event</strong> 关键字：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">// 基于上面的委托定义事件</div><div class="line">public event BoilerLogHandler BoilerEventLog;</div></pre></td></tr></table></figure><p>上面的代码定义了一个名为 <em>BoilerLogHandler</em> 的委托和一个名为 <em>BoilerEventLog</em> 的事件，该事件在生成的时候会调用委托。</p><h4 id="实例-1"><a href="#实例-1" class="headerlink" title="实例 1"></a>实例 1</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">namespace SimpleEvent</div><div class="line">&#123;</div><div class="line">   using System;</div><div class="line"></div><div class="line">   public class EventTest</div><div class="line">   &#123;</div><div class="line">      private int value;</div><div class="line"></div><div class="line">      public delegate void NumManipulationHandler();</div><div class="line"></div><div class="line">      public event NumManipulationHandler ChangeNum;</div><div class="line"></div><div class="line">      protected virtual void OnNumChanged()</div><div class="line">      &#123;</div><div class="line">         if (ChangeNum != null)</div><div class="line">         &#123;</div><div class="line">            ChangeNum();</div><div class="line">         &#125;</div><div class="line">         else</div><div class="line">         &#123;</div><div class="line">            Console.WriteLine(&quot;Event fired!&quot;);</div><div class="line">         &#125;</div><div class="line"></div><div class="line">      &#125;</div><div class="line">      public EventTest(int n )</div><div class="line">      &#123;</div><div class="line">         SetValue(n);</div><div class="line">      &#125;</div><div class="line">      public void SetValue(int n)</div><div class="line">      &#123;</div><div class="line">         if (value != n)</div><div class="line">         &#123;</div><div class="line">            value = n;</div><div class="line">            OnNumChanged();</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">   public class MainClass</div><div class="line">   &#123;</div><div class="line">      public static void Main()</div><div class="line">      &#123;</div><div class="line">         EventTest e = new EventTest(5);</div><div class="line">         e.SetValue(7);</div><div class="line">         e.SetValue(11);</div><div class="line">         Console.ReadKey();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Event Fired!</div><div class="line">Event Fired!</div><div class="line">Event Fired!</div></pre></td></tr></table></figure><h4 id="实例-2"><a href="#实例-2" class="headerlink" title="实例 2"></a>实例 2</h4><p>本实例提供一个简单的用于热水锅炉系统故障排除的应用程序。当维修工程师检查锅炉时，锅炉的温度和压力会随着维修工程师的备注自动记录到日志文件中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using System.IO;</div><div class="line"></div><div class="line">namespace BoilerEventAppl</div><div class="line">&#123;</div><div class="line"></div><div class="line">   // boiler 类</div><div class="line">   class Boiler</div><div class="line">   &#123;</div><div class="line">      private int temp;</div><div class="line">      private int pressure;</div><div class="line">      public Boiler(int t, int p)</div><div class="line">      &#123;</div><div class="line">         temp = t;</div><div class="line">         pressure = p;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      public int getTemp()</div><div class="line">      &#123;</div><div class="line">         return temp;</div><div class="line">      &#125;</div><div class="line">      public int getPressure()</div><div class="line">      &#123;</div><div class="line">         return pressure;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">   // 事件发布器</div><div class="line">   class DelegateBoilerEvent</div><div class="line">   &#123;</div><div class="line">      public delegate void BoilerLogHandler(string status);</div><div class="line"></div><div class="line">      // 基于上面的委托定义事件</div><div class="line">      public event BoilerLogHandler BoilerEventLog;</div><div class="line"></div><div class="line">      public void LogProcess()</div><div class="line">      &#123;</div><div class="line">         string remarks = &quot;O. K&quot;;</div><div class="line">         Boiler b = new Boiler(100, 12);</div><div class="line">         int t = b.getTemp();</div><div class="line">         int p = b.getPressure();</div><div class="line">         if(t &gt; 150 || t &lt; 80 || p &lt; 12 || p &gt; 15)</div><div class="line">         &#123;</div><div class="line">            remarks = &quot;Need Maintenance&quot;;</div><div class="line">         &#125;</div><div class="line">         OnBoilerEventLog(&quot;Logging Info:\n&quot;);</div><div class="line">         OnBoilerEventLog(&quot;Temparature &quot; + t + &quot;\nPressure: &quot; + p);</div><div class="line">         OnBoilerEventLog(&quot;\nMessage: &quot; + remarks);</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      protected void OnBoilerEventLog(string message)</div><div class="line">      &#123;</div><div class="line">         if (BoilerEventLog != null)</div><div class="line">         &#123;</div><div class="line">            BoilerEventLog(message);</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">   // 该类保留写入日志文件的条款</div><div class="line">   class BoilerInfoLogger</div><div class="line">   &#123;</div><div class="line">      FileStream fs;</div><div class="line">      StreamWriter sw;</div><div class="line">      public BoilerInfoLogger(string filename)</div><div class="line">      &#123;</div><div class="line">         fs = new FileStream(filename, FileMode.Append, FileAccess.Write);</div><div class="line">         sw = new StreamWriter(fs);</div><div class="line">      &#125;</div><div class="line">      public void Logger(string info)</div><div class="line">      &#123;</div><div class="line">         sw.WriteLine(info);</div><div class="line">      &#125;</div><div class="line">      public void Close()</div><div class="line">      &#123;</div><div class="line">         sw.Close();</div><div class="line">         fs.Close();</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line">   // 事件订阅器</div><div class="line">   public class RecordBoilerInfo</div><div class="line">   &#123;</div><div class="line">      static void Logger(string info)</div><div class="line">      &#123;</div><div class="line">         Console.WriteLine(info);</div><div class="line">      &#125;//end of Logger</div><div class="line"></div><div class="line">      static void Main(string[] args)</div><div class="line">      &#123;</div><div class="line">         BoilerInfoLogger filelog = new BoilerInfoLogger(&quot;e:\\boiler.txt&quot;);</div><div class="line">         DelegateBoilerEvent boilerEvent = new DelegateBoilerEvent();</div><div class="line">         boilerEvent.BoilerEventLog += new </div><div class="line">         DelegateBoilerEvent.BoilerLogHandler(Logger);</div><div class="line">         boilerEvent.BoilerEventLog += new </div><div class="line">         DelegateBoilerEvent.BoilerLogHandler(filelog.Logger);</div><div class="line">         boilerEvent.LogProcess();</div><div class="line">         Console.ReadLine();</div><div class="line">         filelog.Close();</div><div class="line">      &#125;//end of main</div><div class="line"></div><div class="line">   &#125;//end of RecordBoilerInfo</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Logging info:</div><div class="line"></div><div class="line">Temperature 100</div><div class="line">Pressure 12</div><div class="line"></div><div class="line">Message: O. K</div></pre></td></tr></table></figure><h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><p>集合（Collection）类是专门用于数据存储和检索的类。这些类提供了对栈（stack）、队列（queue）、列表（list）和哈希表（hash table）的支持。大多数集合类实现了相同的接口。</p><p>集合（Collection）类服务于不同的目的，如为元素动态分配内存，基于索引访问列表项等等。这些类创建 Object 类的对象的集合。在 C# 中，Object 类是所有数据类型的基类。</p><h4 id="各种集合类和它们的用法"><a href="#各种集合类和它们的用法" class="headerlink" title="各种集合类和它们的用法"></a>各种集合类和它们的用法</h4><p>下面是各种常用的 <strong>System.Collection</strong> 命名空间的类。点击下面的链接查看细节。</p><table><thead><tr><th>类</th><th>描述和用法</th></tr></thead><tbody><tr><td><a href="http://www.runoob.com/csharp/csharp-arraylist.html" target="_blank" rel="external">动态数组（ArrayList）</a></td><td>它代表了可被单独<strong>索引</strong>的对象的有序集合。它基本上可以替代一个数组。但是，与数组不同的是，您可以使用<strong>索引</strong>在指定的位置添加和移除项目，动态数组会自动重新调整它的大小。它也允许在列表中进行动态内存分配、增加、搜索、排序各项。</td></tr><tr><td><a href="http://www.runoob.com/csharp/csharp-hashtable.html" target="_blank" rel="external">哈希表（Hashtable）</a></td><td>它使用<strong>键</strong>来访问集合中的元素。当您使用键访问元素时，则使用哈希表，而且您可以识别一个有用的键值。哈希表中的每一项都有一个<strong>键/值</strong>对。键用于访问集合中的项目。</td></tr><tr><td><a href="http://www.runoob.com/csharp/csharp-sortedlist.html" target="_blank" rel="external">排序列表（SortedList）</a></td><td>它可以使用<strong>键</strong>和<strong>索引</strong>来访问列表中的项。排序列表是数组和哈希表的组合。它包含一个可使用键或索引访问各项的列表。如果您使用索引访问各项，则它是一个动态数组（ArrayList），如果您使用键访问各项，则它是一个哈希表（Hashtable）。集合中的各项总是按键值排序。</td></tr><tr><td><a href="http://www.runoob.com/csharp/csharp-stack.html" target="_blank" rel="external">堆栈（Stack）</a></td><td>它代表了一个<strong>后进先出</strong>的对象集合。当您需要对各项进行后进先出的访问时，则使用堆栈。当您在列表中添加一项，称为<strong>推入</strong>元素，当您从列表中移除一项时，称为<strong>弹出</strong>元素。</td></tr><tr><td><a href="http://www.runoob.com/csharp/csharp-queue.html" target="_blank" rel="external">队列（Queue）</a></td><td>它代表了一个<strong>先进先出</strong>的对象集合。当您需要对各项进行先进先出的访问时，则使用队列。当您在列表中添加一项，称为<strong>入队</strong>，当您从列表中移除一项时，称为<strong>出队</strong>。</td></tr><tr><td><a href="http://www.runoob.com/csharp/csharp-bitarray.html" target="_blank" rel="external">点阵列（BitArray）</a></td><td>它代表了一个使用值 1 和 0 来表示的<strong>二进制</strong>数组。当您需要存储位，但是事先不知道位数时，则使用点阵列。您可以使用<strong>整型索引</strong>从点阵列集合中访问各项，索引从零开始。</td></tr></tbody></table><h3 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h3><p><strong>泛型（Generic）</strong> 允许您延迟编写类或方法中的编程元素的数据类型的规范，直到实际在程序中使用它的时候。换句话说，泛型允许您编写一个可以与任何数据类型一起工作的类或方法。</p><p>您可以通过数据类型的替代参数编写类或方法的规范。当编译器遇到类的构造函数或方法的函数调用时，它会生成代码来处理指定的数据类型。下面这个简单的实例将有助于您理解这个概念：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using System.Collections.Generic;</div><div class="line"></div><div class="line">namespace GenericApplication</div><div class="line">&#123;</div><div class="line">    public class MyGenericArray&lt;T&gt;</div><div class="line">    &#123;</div><div class="line">        private T[] array;</div><div class="line">        public MyGenericArray(int size)</div><div class="line">        &#123;</div><div class="line">            array = new T[size + 1];</div><div class="line">        &#125;</div><div class="line">        public T getItem(int index)</div><div class="line">        &#123;</div><div class="line">            return array[index];</div><div class="line">        &#125;</div><div class="line">        public void setItem(int index, T value)</div><div class="line">        &#123;</div><div class="line">            array[index] = value;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">           </div><div class="line">    class Tester</div><div class="line">    &#123;</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            // 声明一个整型数组</div><div class="line">            MyGenericArray&lt;int&gt; intArray = new MyGenericArray&lt;int&gt;(5);</div><div class="line">            // 设置值</div><div class="line">            for (int c = 0; c &lt; 5; c++)</div><div class="line">            &#123;</div><div class="line">                intArray.setItem(c, c*5);</div><div class="line">            &#125;</div><div class="line">            // 获取值</div><div class="line">            for (int c = 0; c &lt; 5; c++)</div><div class="line">            &#123;</div><div class="line">                Console.Write(intArray.getItem(c) + &quot; &quot;);</div><div class="line">            &#125;</div><div class="line">            Console.WriteLine();</div><div class="line">            // 声明一个字符数组</div><div class="line">            MyGenericArray&lt;char&gt; charArray = new MyGenericArray&lt;char&gt;(5);</div><div class="line">            // 设置值</div><div class="line">            for (int c = 0; c &lt; 5; c++)</div><div class="line">            &#123;</div><div class="line">                charArray.setItem(c, (char)(c+97));</div><div class="line">            &#125;</div><div class="line">            // 获取值</div><div class="line">            for (int c = 0; c &lt; 5; c++)</div><div class="line">            &#123;</div><div class="line">                Console.Write(charArray.getItem(c) + &quot; &quot;);</div><div class="line">            &#125;</div><div class="line">            Console.WriteLine();</div><div class="line">            Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">0 5 10 15 20</div><div class="line">a b c d e</div></pre></td></tr></table></figure><h4 id="泛型（Generic）的特性"><a href="#泛型（Generic）的特性" class="headerlink" title="泛型（Generic）的特性"></a>泛型（Generic）的特性</h4><p>使用泛型是一种增强程序功能的技术，具体表现在以下几个方面：</p><ul><li>它有助于您最大限度地重用代码、保护类型的安全以及提高性能。</li><li>您可以创建泛型集合类。.NET 框架类库在 <em>System.Collections.Generic</em> 命名空间中包含了一些新的泛型集合类。您可以使用这些泛型集合类来替代 <em>System.Collections</em> 中的集合类。</li><li>您可以创建自己的泛型接口、泛型类、泛型方法、泛型事件和泛型委托。</li><li>您可以对泛型类进行约束以访问特定数据类型的方法。</li><li>关于泛型数据类型中使用的类型的信息可在运行时通过使用反射获取。</li></ul><h4 id="泛型（Generic）方法"><a href="#泛型（Generic）方法" class="headerlink" title="泛型（Generic）方法"></a>泛型（Generic）方法</h4><p>在上面的实例中，我们已经使用了泛型类，我们可以通过类型参数声明泛型方法。下面的程序说明了这个概念：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using System.Collections.Generic;</div><div class="line"></div><div class="line">namespace GenericMethodAppl</div><div class="line">&#123;</div><div class="line">    class Program</div><div class="line">    &#123;</div><div class="line">        static void Swap&lt;T&gt;(ref T lhs, ref T rhs)</div><div class="line">        &#123;</div><div class="line">            T temp;</div><div class="line">            temp = lhs;</div><div class="line">            lhs = rhs;</div><div class="line">            rhs = temp;</div><div class="line">        &#125;</div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            int a, b;</div><div class="line">            char c, d;</div><div class="line">            a = 10;</div><div class="line">            b = 20;</div><div class="line">            c = &apos;I&apos;;</div><div class="line">            d = &apos;V&apos;;</div><div class="line"></div><div class="line">            // 在交换之前显示值</div><div class="line">            Console.WriteLine(&quot;Int values before calling swap:&quot;);</div><div class="line">            Console.WriteLine(&quot;a = &#123;0&#125;, b = &#123;1&#125;&quot;, a, b);</div><div class="line">            Console.WriteLine(&quot;Char values before calling swap:&quot;);</div><div class="line">            Console.WriteLine(&quot;c = &#123;0&#125;, d = &#123;1&#125;&quot;, c, d);</div><div class="line"></div><div class="line">            // 调用 swap</div><div class="line">            Swap&lt;int&gt;(ref a, ref b);</div><div class="line">            Swap&lt;char&gt;(ref c, ref d);</div><div class="line"></div><div class="line">            // 在交换之后显示值</div><div class="line">            Console.WriteLine(&quot;Int values after calling swap:&quot;);</div><div class="line">            Console.WriteLine(&quot;a = &#123;0&#125;, b = &#123;1&#125;&quot;, a, b);</div><div class="line">            Console.WriteLine(&quot;Char values after calling swap:&quot;);</div><div class="line">            Console.WriteLine(&quot;c = &#123;0&#125;, d = &#123;1&#125;&quot;, c, d);</div><div class="line">            Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Int values before calling swap:</div><div class="line">a = 10, b = 20</div><div class="line">Char values before calling swap:</div><div class="line">c = I, d = V</div><div class="line">Int values after calling swap:</div><div class="line">a = 20, b = 10</div><div class="line">Char values after calling swap:</div><div class="line">c = V, d = I</div></pre></td></tr></table></figure><h4 id="泛型（Generic）委托"><a href="#泛型（Generic）委托" class="headerlink" title="泛型（Generic）委托"></a>泛型（Generic）委托</h4><p>您可以通过类型参数定义泛型委托。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">delegate T NumberChanger&lt;T&gt;(T n);</div></pre></td></tr></table></figure><p>下面的实例演示了委托的使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using System.Collections.Generic;</div><div class="line"></div><div class="line">delegate T NumberChanger&lt;T&gt;(T n);</div><div class="line">namespace GenericDelegateAppl</div><div class="line">&#123;</div><div class="line">    class TestDelegate</div><div class="line">    &#123;</div><div class="line">        static int num = 10;</div><div class="line">        public static int AddNum(int p)</div><div class="line">        &#123;</div><div class="line">            num += p;</div><div class="line">            return num;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        public static int MultNum(int q)</div><div class="line">        &#123;</div><div class="line">            num *= q;</div><div class="line">            return num;</div><div class="line">        &#125;</div><div class="line">        public static int getNum()</div><div class="line">        &#123;</div><div class="line">            return num;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            // 创建委托实例</div><div class="line">            NumberChanger&lt;int&gt; nc1 = new NumberChanger&lt;int&gt;(AddNum);</div><div class="line">            NumberChanger&lt;int&gt; nc2 = new NumberChanger&lt;int&gt;(MultNum);</div><div class="line">            // 使用委托对象调用方法</div><div class="line">            nc1(25);</div><div class="line">            Console.WriteLine(&quot;Value of Num: &#123;0&#125;&quot;, getNum());</div><div class="line">            nc2(5);</div><div class="line">            Console.WriteLine(&quot;Value of Num: &#123;0&#125;&quot;, getNum());</div><div class="line">            Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Value of Num: 35</div><div class="line">Value of Num: 175</div></pre></td></tr></table></figure><h3 id="匿名方法"><a href="#匿名方法" class="headerlink" title="匿名方法"></a>匿名方法</h3><p>我们已经提到过，委托是用于引用与其具有相同标签的方法。换句话说，您可以使用委托对象调用可由委托引用的方法。</p><p><strong>匿名方法（Anonymous methods）</strong> 提供了一种传递代码块作为委托参数的技术。匿名方法是没有名称只有主体的方法。</p><p>在匿名方法中您不需要指定返回类型，它是从方法主体内的 return 语句推断的。</p><h4 id="编写匿名方法的语法"><a href="#编写匿名方法的语法" class="headerlink" title="编写匿名方法的语法"></a>编写匿名方法的语法</h4><p>匿名方法是通过使用 <strong>delegate</strong> 关键字创建委托实例来声明的。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">delegate void NumberChanger(int n);</div><div class="line">...</div><div class="line">NumberChanger nc = delegate(int x)</div><div class="line">&#123;</div><div class="line">    Console.WriteLine(&quot;Anonymous Method: &#123;0&#125;&quot;, x);</div><div class="line">&#125;;</div></pre></td></tr></table></figure><p>代码块 <code>Console.WriteLine(&quot;Anonymous Method: {0}&quot;, x);</code> 是匿名方法的主体。</p><p>委托可以通过匿名方法调用，也可以通过命名方法调用，即，通过向委托对象传递方法参数。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nc(10);</div></pre></td></tr></table></figure><h4 id="实例-3"><a href="#实例-3" class="headerlink" title="实例"></a>实例</h4><p>下面的实例演示了匿名方法的概念：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line"></div><div class="line">delegate void NumberChanger(int n);</div><div class="line">namespace DelegateAppl</div><div class="line">&#123;</div><div class="line">    class TestDelegate</div><div class="line">    &#123;</div><div class="line">        static int num = 10;</div><div class="line">        public static void AddNum(int p)</div><div class="line">        &#123;</div><div class="line">            num += p;</div><div class="line">            Console.WriteLine(&quot;Named Method: &#123;0&#125;&quot;, num);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        public static void MultNum(int q)</div><div class="line">        &#123;</div><div class="line">            num *= q;</div><div class="line">            Console.WriteLine(&quot;Named Method: &#123;0&#125;&quot;, num);</div><div class="line">        &#125;</div><div class="line">        public static int getNum()</div><div class="line">        &#123;</div><div class="line">            return num;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        static void Main(string[] args)</div><div class="line">        &#123;</div><div class="line">            // 使用匿名方法创建委托实例</div><div class="line">            NumberChanger nc = delegate(int x)</div><div class="line">            &#123;</div><div class="line">               Console.WriteLine(&quot;Anonymous Method: &#123;0&#125;&quot;, x);</div><div class="line">            &#125;;</div><div class="line">            </div><div class="line">            // 使用匿名方法调用委托</div><div class="line">            nc(10);</div><div class="line"></div><div class="line">            // 使用命名方法实例化委托</div><div class="line">            nc =  new NumberChanger(AddNum);</div><div class="line">            </div><div class="line">            // 使用命名方法调用委托</div><div class="line">            nc(5);</div><div class="line"></div><div class="line">            // 使用另一个命名方法实例化委托</div><div class="line">            nc =  new NumberChanger(MultNum);</div><div class="line">            </div><div class="line">            // 使用命名方法调用委托</div><div class="line">            nc(2);</div><div class="line">            Console.ReadKey();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>当上面的代码被编译和执行时，它会产生下列结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Anonymous Method: 10</div><div class="line">Named Method: 15</div><div class="line">Named Method: 30</div></pre></td></tr></table></figure><h3 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a><a href="http://www.runoob.com/csharp/csharp-multithreading.html" target="_blank" rel="external">多线程</a></h3>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基本语法&quot;&gt;&lt;a href=&quot;#基本语法&quot; class=&quot;headerlink&quot; title=&quot;基本语法&quot;&gt;&lt;/a&gt;基本语法&lt;/h2&gt;&lt;h3 id=&quot;一个例子&quot;&gt;&lt;a href=&quot;#一个例子&quot; class=&quot;headerlink&quot; title=&quot;一个例子:&quot;&gt;&lt;/a&gt;&lt;strong&gt;一个例子:&lt;/strong&gt;&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;using System;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;namespace HelloWorldApplication&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    /* 类名为 HelloWorld */&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    class HelloWorld&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        /* main函数 */&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        static void Main(string[] args)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            /* 我的第一个 C# 程序 */&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.WriteLine(&amp;quot;Hello World!&amp;quot;);&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.ReadKey();&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 id=&quot;对象类型&quot;&gt;&lt;a href=&quot;#对象类型&quot; class=&quot;headerlink&quot; title=&quot;对象类型&quot;&gt;&lt;/a&gt;&lt;strong&gt;对象类型&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;是 C# 通用类型系统（Common Type System - CTS）中所有数据类型的终极基类。Object 是 System.Object 类的别名。所以对象（Object）类型可以被分配任何其他类型（值类型、引用类型、预定义类型或用户自定义类型）的值。但是，在分配值之前，需要先进行类型转换。&lt;/p&gt;&lt;p&gt;当一个值类型转换为对象类型时，则被称为 &lt;strong&gt;装箱&lt;/strong&gt;；另一方面，当一个对象类型转换为值类型时，则被称为 &lt;strong&gt;拆箱&lt;/strong&gt;。&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;object obj;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;obj = 100; // 这是装箱&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 id=&quot;动态类型&quot;&gt;&lt;a href=&quot;#动态类型&quot; class=&quot;headerlink&quot; title=&quot;动态类型&quot;&gt;&lt;/a&gt;&lt;strong&gt;动态类型&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;您可以存储任何类型的值在动态数据类型变量中。这些变量的类型检查是在运行时发生的。&lt;/p&gt;&lt;p&gt;声明动态类型的语法：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;dynamic &amp;lt;variable_name&amp;gt; = value;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;例如：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;dynamic d = 20;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;动态类型与对象类型相似，但是对象类型变量的类型检查是在编译时发生的，而动态类型变量的类型检查是在运行时发生的。&lt;/p&gt;&lt;h3 id=&quot;字符串的特殊定义方式&quot;&gt;&lt;a href=&quot;#字符串的特殊定义方式&quot; class=&quot;headerlink&quot; title=&quot;字符串的特殊定义方式&quot;&gt;&lt;/a&gt;&lt;strong&gt;字符串的特殊定义方式&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;字符串（String）类型允许您给变量分配任何字符串值。字符串（String）类型是 System.String 类的别名。它是从对象（Object）类型派生的。字符串（String）类型的值可以通过两种形式进行分配：引号和 @引号。&lt;/p&gt;&lt;p&gt;例如：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;String str = &amp;quot;runoob.com&amp;quot;;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;一个 @引号字符串：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;@&amp;quot;runoob.com&amp;quot;;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;C# string 字符串的前面可以加 @（称作”逐字字符串”）将转义字符（\）当作普通字符对待，比如：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;string str = @&amp;quot;C:\Windows&amp;quot;;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;等价于：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;string str = &amp;quot;C:\\Windows&amp;quot;;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;@ 字符串中可以任意换行，换行符及缩进空格都计算在字符串长度之内。&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;string str = @&amp;quot;&amp;lt;script type=&amp;quot;&amp;quot;text/javascript&amp;quot;&amp;quot;&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;lt;!--&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    --&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/script&amp;gt;&amp;quot;;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 id=&quot;显式类型转换方式&quot;&gt;&lt;a href=&quot;#显式类型转换方式&quot; class=&quot;headerlink&quot; title=&quot;显式类型转换方式&quot;&gt;&lt;/a&gt;&lt;strong&gt;显式类型转换方式&lt;/strong&gt;&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;namespace TypeConversionApplication&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    class StringConversion&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        static void Main(string[] args)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            int i = 75;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            float f = 53.005f;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            double d = 2345.7652;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            bool b = true;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.WriteLine(i.ToString());&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.WriteLine(f.ToString());&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.WriteLine(d.ToString());&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.WriteLine(b.ToString());&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.ReadKey();&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 id=&quot;命令行输入&quot;&gt;&lt;a href=&quot;#命令行输入&quot; class=&quot;headerlink&quot; title=&quot;命令行输入&quot;&gt;&lt;/a&gt;&lt;strong&gt;命令行输入&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;code&gt;System&lt;/code&gt;命名空间中的&lt;code&gt;Console&lt;/code&gt;类提供了一个函数 &lt;code&gt;ReadLine()&lt;/code&gt;，用于接收来自用户的输入，并把它存储到一个变量中。&lt;/p&gt;&lt;p&gt;例如：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;int num;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;num = Convert.ToInt32(Console.ReadLine());&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;函数 &lt;code&gt;Convert.ToInt32()&lt;/code&gt;把用户输入的数据转换为&lt;code&gt;int&lt;/code&gt; 数据类型，因为 &lt;code&gt;Console.ReadLine()&lt;/code&gt;只接受字符串格式的数据。&lt;/p&gt;&lt;h3 id=&quot;特殊运算符&quot;&gt;&lt;a href=&quot;#特殊运算符&quot; class=&quot;headerlink&quot; title=&quot;特殊运算符&quot;&gt;&lt;/a&gt;&lt;strong&gt;特殊运算符&lt;/strong&gt;&lt;/h3&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;运算符&lt;/th&gt;&lt;th&gt;描述&lt;/th&gt;&lt;th&gt;实例&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;sizeof()&lt;/td&gt;&lt;td&gt;返回数据类型的大小。&lt;/td&gt;&lt;td&gt;sizeof(int)，将返回 4.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;typeof()&lt;/td&gt;&lt;td&gt;返回 class 的类型。&lt;/td&gt;&lt;td&gt;typeof(StreamReader);&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&amp;amp;&lt;/td&gt;&lt;td&gt;返回变量的地址。&lt;/td&gt;&lt;td&gt;&amp;a; 将得到变量的实际地址。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;*&lt;/td&gt;&lt;td&gt;变量的指针。&lt;/td&gt;&lt;td&gt;*a; 将指向一个变量。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;? :&lt;/td&gt;&lt;td&gt;条件表达式&lt;/td&gt;&lt;td&gt;如果条件为真 ? 则为 X : 否则为 Y&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;is&lt;/td&gt;&lt;td&gt;判断对象是否为某一类型。&lt;/td&gt;&lt;td&gt;If( Ford is Car) // 检查 Ford 是否是 Car 类的一个对象。&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;as&lt;/td&gt;&lt;td&gt;强制转换，即使转换失败也不会抛出异常。&lt;/td&gt;&lt;td&gt;Object obj = new StringReader(“Hello”);StringReader r = obj as StringReader;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 id=&quot;特殊访问修饰符&quot;&gt;&lt;a href=&quot;#特殊访问修饰符&quot; class=&quot;headerlink&quot; title=&quot;特殊访问修饰符&quot;&gt;&lt;/a&gt;&lt;strong&gt;特殊访问修饰符&lt;/strong&gt;&lt;/h3&gt;&lt;h4 id=&quot;Internal-访问修饰符&quot;&gt;&lt;a href=&quot;#Internal-访问修饰符&quot; class=&quot;headerlink&quot; title=&quot;Internal 访问修饰符&quot;&gt;&lt;/a&gt;&lt;em&gt;Internal 访问修饰符&lt;/em&gt;&lt;/h4&gt;&lt;p&gt;Internal 访问说明符允许一个类将其成员变量和成员函数暴露给当前程序中的其他函数和对象。换句话说，带有 internal 访问修饰符的任何成员可以被定义在该成员所定义的应用程序内的任何类或方法访问。&lt;/p&gt;&lt;p&gt;类的默认访问标识符是 &lt;strong&gt;internal&lt;/strong&gt;，成员的默认访问标识符是 &lt;strong&gt;private&lt;/strong&gt;。&lt;/p&gt;&lt;p&gt;下面的实例说明了这点：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;using System;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;namespace RectangleApplication&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    class Rectangle&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        //成员变量&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        internal double length;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        internal double width;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        double GetArea()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            return length * width;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;       public void Display()&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.WriteLine(&amp;quot;长度： &amp;#123;0&amp;#125;&amp;quot;, length);&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.WriteLine(&amp;quot;宽度： &amp;#123;0&amp;#125;&amp;quot;, width);&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.WriteLine(&amp;quot;面积： &amp;#123;0&amp;#125;&amp;quot;, GetArea());&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#125;//end class Rectangle    &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    class ExecuteRectangle&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        static void Main(string[] args)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Rectangle r = new Rectangle();&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            r.length = 4.5;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            r.width = 3.5;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            r.Display();&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;            Console.ReadLine();&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;        &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;当上面的代码被编译和执行时，它会产生下列结果：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;长度： 4.5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;宽度： 3.5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;面积： 15.75&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;在上面的实例中，请注意成员函数 &lt;em&gt;GetArea()&lt;/em&gt; 声明的时候不带有任何访问修饰符。如果没有指定访问修饰符，则使用类成员的默认访问修饰符，即为 &lt;strong&gt;private&lt;/strong&gt;。&lt;/p&gt;&lt;h4 id=&quot;Protected-Internal-访问修饰符&quot;&gt;&lt;a href=&quot;#Protected-Internal-访问修饰符&quot; class=&quot;headerlink&quot; title=&quot;Protected Internal 访问修饰符&quot;&gt;&lt;/a&gt;&lt;em&gt;Protected Internal 访问修饰符&lt;/em&gt;&lt;/h4&gt;&lt;p&gt;Protected Internal 访问修饰符允许在本类,派生类或者包含该类的程序集中访问。这也被用于实现继承。&lt;/p&gt;&lt;h3 id=&quot;按引用传递参数&quot;&gt;&lt;a href=&quot;#按引用传递参数&quot; class=&quot;headerlink&quot; title=&quot;按引用传递参数&quot;&gt;&lt;/a&gt;&lt;strong&gt;按引用传递参数&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;引用参数是一个对变量的内存位置的引用。当按引用传递参数时，与值参数不同的是，它不会为这些参数创建一个新的存储位置。引用参数表示与提供给方法的实际参数具有相同的内存位置。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;C#&lt;/code&gt; 中，使用 &lt;code&gt;ref&lt;/code&gt; 关键字声明引用参数。下面的实例演示了这点：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;17&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;18&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;19&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;20&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;21&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;22&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;23&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;24&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;25&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;26&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;27&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;28&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;29&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;30&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;31&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;32&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;33&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;34&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;35&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;using System;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;namespace CalculatorApplication&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;   class NumberManipulator&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;   &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      public void swap(ref int x, ref int y)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         int temp;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         temp = x; /* 保存 x 的值 */&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         x = y;    /* 把 y 赋值给 x */&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         y = temp; /* 把 temp 赋值给 y */&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;       &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;   &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      static void Main(string[] args)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      &amp;#123;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         NumberManipulator n = new NumberManipulator();&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         /* 局部变量定义 */&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         int a = 100;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         int b = 200;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         Console.WriteLine(&amp;quot;在交换之前，a 的值： &amp;#123;0&amp;#125;&amp;quot;, a);&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         Console.WriteLine(&amp;quot;在交换之前，b 的值： &amp;#123;0&amp;#125;&amp;quot;, b);&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         /* 调用函数来交换值 */&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         n.swap(ref a, ref b);&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         Console.WriteLine(&amp;quot;在交换之后，a 的值： &amp;#123;0&amp;#125;&amp;quot;, a);&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         Console.WriteLine(&amp;quot;在交换之后，b 的值： &amp;#123;0&amp;#125;&amp;quot;, b);&lt;/div&gt;&lt;div class=&quot;line&quot;&gt; &lt;/div&gt;&lt;div class=&quot;line&quot;&gt;         Console.ReadLine();&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;      &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;   &amp;#125;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;#125;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;当上面的代码被编译和执行时，它会产生下列结果：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;在交换之前，a 的值：100&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;在交换之前，b 的值：200&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;在交换之后，a 的值：200&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;在交换之后，b 的值：100&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;结果表明，&lt;em&gt;&lt;code&gt;swap&lt;/code&gt;&lt;/em&gt; 函数内的值改变了，且这个改变可以在 &lt;em&gt;&lt;code&gt;Main&lt;/code&gt;&lt;/em&gt; 函数中反映出来。&lt;/p&gt;
    
    </summary>
    
    
      <category term="c#" scheme="http://yoursite.com/tags/c/"/>
    
  </entry>
  
  <entry>
    <title>GRADIENTS, BATCH NORMALIZATION AND LAYER NORMALIZATION</title>
    <link href="http://yoursite.com/2017/05/09/GRADIENTS-BATCH-NORMALIZATION-AND-LAYER-NORMALIZATION/"/>
    <id>http://yoursite.com/2017/05/09/GRADIENTS-BATCH-NORMALIZATION-AND-LAYER-NORMALIZATION/</id>
    <published>2017-05-09T02:17:48.000Z</published>
    <updated>2017-05-09T02:24:45.862Z</updated>
    
    <content type="html"><![CDATA[<p>In this post, we will take a look at common pit falls with optimization and solutions to some of these issues. The main topics that will be covered are:</p><ul><li>Gradients</li><li>Exploding gradients</li><li>Vanishing gradients</li><li>LSTMs (pertaining to vanishing gradients)</li><li>Normalization</li></ul><p>And then we will see how to implement batch and layer normalization and apply them to our cells.</p><h2 id="GRADIENTS"><a href="#GRADIENTS" class="headerlink" title="GRADIENTS"></a>GRADIENTS</h2><p>First, we will take a closer look at gradients and backpropagation during optimization. Our example will be a simple MLP but we will extend to an RNN later on.</p><p>I want to go over what a gradient means. Let’s say we have a very simple MLP with 1 set of weights W_1 which is used to calcualte some y. We devise a very simple loss function J, and our gradient becomes dJ/dW_1 (d = partials). Sure we can take the derivative and apply chain rule and get a number, but what does this value even mean? The gradient can be thought of as several things. One is that the magnitude of the gradient represents the sensitivity or impact this weight has on determining y which determines our loss. This can be seen below:</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-10-26-at-6-20-24-pm.png?w=620" alt="Screen Shot 2016-10-26 at 6.20.24 PM.png"></p><p><strong>CS231n</strong></p><p>What the gradients (dfdx, dfdy, dfdz, dfdq, dfdz) tell us is the sensitivity of each variable on our result f. In an MLP, we will produce a result (logits) and compare it with our targets to determine the deviance in what we got and what we should have gotten. From this we can use backpropagation to determine how much adjusting needs to be made for each variable along the way, all the way to the beginning.</p><p>The gradient also holds another key piece of information. It repesents how much we need to change the weights in order to move towards our goal (minimizing the loss, maximizing some objective, etc.). With simple SGD, we get the gradient and we apply an update to the weights (W_i_new = W_i_old – alpha * gradient). If we follow the direction of the gradient, we will be maximizing the goal function. Our loss functions (NLL or cross entropy) are functions we wish to minimize, so we subtract the gradient. We use the learning parameter alpha to control how quickly we change. This is where all of the normalization techniques in this post will come in handy.</p><p>If we have an alpha that is 1 or larger, we will allow the gradient to directly impact our weights. In the beginning of training a neural net, our weight initializations are bound to be far off from the weights we actually need. This creates a large error and so, results in large gradients. If we choose to update our weights with these large gradients, we will be never reach the minimum point for our loss function. We will keep overshooting and bouncing back and forth. So, we use this alpha (small value) to control how much impact the gradient has. Eventually, the gradient will get smaller as well because of less error and we will reach our goal, but with such a small alpha, this can take a while. With techniques, such as batch normalization and layer normalization, we can afford to use large alpha because the gradients will be controlled due to controlled outputs from the neurons.</p><p>Now, even with a simple RNN structure, backpropagation can pose several issues. When we get our result, we need to backpropagate all the way back to the very first cell in order to complete our updates. The main principles to really understand are: if I multiply a number greater than 1 over and over, I will reach infinity (explosion) and vice versa, if I multiply a number less than 1 over and over, I will reach 0 (vanishing).</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-10-04-at-5-54-13-am.png?w=620" alt="screen-shot-2016-10-04-at-5-54-13-am"></p><h2 id="EXPLODING-GRADIENTS"><a href="#EXPLODING-GRADIENTS" class="headerlink" title="EXPLODING GRADIENTS"></a>EXPLODING GRADIENTS</h2><p>The first issue is that our gradients can be greater than 1. As we backpropagate the gradient through the network, we can end up with massive gradients. So far, the solution to exploding gradients is a very hacky but cheap solution; just clip the norm of the gradient at some threshold.</p><p><img src="https://qph.ec.quoracdn.net/main-qimg-3e453fb7dd33a6e6e4d82adf6165d39a?convert_to_webp=true" alt="img"></p><h2 id="VANISHING-GRADIENTS"><a href="#VANISHING-GRADIENTS" class="headerlink" title="VANISHING GRADIENTS"></a>VANISHING GRADIENTS</h2><p>We could also experience the other issue where the gradient is less than 1 to start with and as we backpropagate, the effect of the gradient weakens and it will eventually be negligible. A common scenario where this occurs is when we have saturation at the tails of the sigmoidal function (0 or 1). This is problematic because now the derivative will always be near 0. During backpropagation, we will be multiplying this near zero derivative with our error repeatedly.</p><p>Let’s look at the sigmoidal activation function. You can replicate this example for tanh too.</p><p><img src="https://qph.ec.quoracdn.net/main-qimg-45bad3db11225318bd4aa686a823181c?convert_to_webp=true" alt="img"><img src="https://qph.ec.quoracdn.net/main-qimg-4635c1521f87e2d6f5cf4fe8f39ca76d?convert_to_webp=true" alt="img"></p><p>To solve this issue, we can use rectified linear units (ReLU) which don’t suffer from this tail saturation as much. <img src="https://qph.ec.quoracdn.net/main-qimg-bb38bf7ef543aa6a0c24134f61d15ba7?convert_to_webp=true" alt="img"></p><p>The derivative is 1 if x &gt; 0, so now error signal won’t weaken as it backpropagates through the network. But we do have the problem in the negative region (x &lt;0) where the derivative is zero. This can nullify our error signal so it’s best to add a leaky factor (<a href="http://arxiv.org/abs/1502.01852" target="_blank" rel="external">http://arxiv.org/abs/1502.01852</a>) to the ReLU unit, where the negative region will have some small negative slope. This parameter can be fixed or be a randomized parameter and be fixed after training. There’s also maxout (<a href="http://arxiv.org/abs/1302.4389" target="_blank" rel="external">http://arxiv.org/abs/1302.4389</a>) but this will have twice the amount of weights as a regular ReLU unit.</p><h2 id="LSTMS-VANISHING-GRADIENTS"><a href="#LSTMS-VANISHING-GRADIENTS" class="headerlink" title="LSTMS (VANISHING GRADIENTS)"></a>LSTMS (VANISHING GRADIENTS)</h2><p>As for how LSTMs solve the vanishing gradient issue, they don’t have to worry about the error signal weakening as with a regular basic RNN cell. It’s a bit complicated but the basic idea is that they have a forget gate that determines how much previous memory is stored in the network. This architecture allows the error signal to be transferred effectively to the previous time step. This is usually referred to as the constant error carousel (CEC).</p><h2 id="NORMALIZATION"><a href="#NORMALIZATION" class="headerlink" title="NORMALIZATION"></a>NORMALIZATION</h2><p>There are several types of normalization techniques but the idea behind all of them is the same, which is shifting our inputs to a zero mean and unit variance.</p><p>Techniques like batch norm (<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="external">https://arxiv.org/abs/1502.03167</a>) may help with the gradient issues as a side effect but the main object is to improve overall optimization. When we first initialize our weights, we are bound to have very large deviances from the true weights. These outliers need to be compensated for by the gradients and this further delays convergence during training. Batchnorm helps us here by normalizing the gradients (reducing influence from weight deviances) on a batched implementation and allows us to train faster (can even safely use larger learning rates now).</p><p>With batch norm, the main idea is to normalize at each layer for every minibatch. We initially may normalize our inputs, but as they travel through the layers, the inputs are operated on by weights and neurons and effectively change. As this progresses, the deviances get larger and larger and our backpropagation will need to account for these large deviances. This restricts us to using a small learning rate to prevent gradient explosion/vanishing. With <strong>batch norm</strong>, we will normalize the inputs (<strong>activations</strong> coming from the previous layer) going into each layer using the mean and variance of the activations for the <strong>entire</strong> <strong>minibatch</strong>. The normalization is a bit different during training and inference but it is beyond the scope of this post. (details in paper).</p><p>Batch normalization is very nice but it is based on minibatch size and so it’s a bit difficult to use with recurrent architectures. With <strong>layer normalization</strong>, we instead compute the mean and variance using ALL of the summed inputs to the neurons in a layer for EVERY <strong>single</strong> <strong>training**</strong>case<strong>. This removes the dependency on a minibatch size. Unlike batch normalization, the normalization operation for layer norm is same for training and inference. More details can be found on Hinton’s paper </strong>here**.</p><p>######</p><h2 id="IMPLEMENTING-BATCH-NORMALIZATION"><a href="#IMPLEMENTING-BATCH-NORMALIZATION" class="headerlink" title="IMPLEMENTING BATCH NORMALIZATION"></a>IMPLEMENTING BATCH NORMALIZATION</h2><p>As stated above, the main goal of batch normalization is optimization. By normalizing the inputs to a layer to zero mean and unit variance, we can help our net learn faster by minimizing the effects from large errors (especially during initial training).</p><p>Batch norm is given by the operation below, where \epsilon is a small random noise (for stability). When we apply batch norm on a layer, we are restricting the inputs to follow a normal distribution, which ultimately will restrict the nets ability to learn. In order to fix this, we multiply by a scale parameter (\alpha) and add a shift parameter (\beta). Both of these parameters are trainable.</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-11-08-at-8-09-28-pm.png?w=620" alt="Screen Shot 2016-11-08 at 8.09.28 PM.png"></p><p>Note that both alpha and beta are applied element wise, so there will be a scale and shift for each neuron in the subsequent layer. With batchnorm, we compute mean and variance across an entire batch and we have a value for each neuron we are feeding our normalized inputs into.</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-11-14-at-9-00-40-pm.png?w=620" alt="Screen Shot 2016-11-14 at 9.00.40 PM.png"></p><p>So for a given layer, the mean during BN will be 1X. Each training data gets this mean subtracted from it and divided by sqrt(var + epsilon) and then shifted and scaled. To find the mean and var, we use all the examples in the training batch.</p><p>In order to accurately evaluate the effectiveness of batchnorm, we will use a simple MLP to classify MNIST digits. We will run a normal MLP and an MLP with batchnorm, both initialized with the same starting weights. Let’s take a look at both the naive and TF implementations.</p><p>First, the naive version:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Naive BN layer</span></div><div class="line">scale1 = tf.Variable(tf.ones([<span class="number">100</span>]))</div><div class="line">shift1 = tf.Variable(tf.zeros([<span class="number">100</span>]))</div><div class="line">W1_BN = tf.Variable(W1_init)</div><div class="line">b1_BN = tf.Variable(tf.zeros([<span class="number">100</span>]))</div><div class="line">z1_BN = tf.matmul(X,W1_BN)+b1_BN</div><div class="line">mean1, var1 = tf.nn.moments(z1_BN, [<span class="number">0</span>])</div><div class="line">BN1 = (z1_BN - mean1) / tf.sqrt(var1 + FLAGS.epsilon)</div><div class="line">BN1 = scale1*BN1 + shift1</div><div class="line">fc1_BN = tf.nn.relu(BN1)</div></pre></td></tr></table></figure><p>TF implementation:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># TF BN layer</span></div><div class="line">scale2 = tf.Variable(tf.ones([<span class="number">100</span>]))</div><div class="line">shift2 = tf.Variable(tf.zeros([<span class="number">100</span>]))</div><div class="line">W2_BN = tf.Variable(W2_init)</div><div class="line">b2_BN = tf.Variable(tf.zeros([<span class="number">100</span>]))</div><div class="line">z2_BN = tf.matmul(fc1_BN,W2_BN)+b2_BN</div><div class="line">mean2, var2 = tf.nn.moments(z2_BN, [<span class="number">0</span>])</div><div class="line">BN2 = tf.nn.batch_normalization(z2_BN,mean2,var2,shift2,scale2,FLAGS.epsilon)</div><div class="line">fc2_BN = tf.nn.relu(BN2)</div></pre></td></tr></table></figure><p>We first need to compute the mean and variance of the inputs coming into the layer. Then normalize them and scale/shift and then apply the activation function and pass to the next layer.</p><p>Let’s compare the performance of the normal MLP and the MLP with batchnorm. We will focus of the massive impact on our cost with and without BN. Other interesting features to look at would be gradient norm, neuron inputs, etc.</p><h3 id="CROSS-ENTROPY-LOSS"><a href="#CROSS-ENTROPY-LOSS" class="headerlink" title="CROSS ENTROPY LOSS"></a>CROSS ENTROPY LOSS</h3><p>###</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-11-10-at-8-58-44-pm.png?w=620" alt="Screen Shot 2016-11-10 at 8.58.44 PM.png"></p><h2 id="NUANCE"><a href="#NUANCE" class="headerlink" title="NUANCE:"></a>NUANCE:</h2><p>Training is all fine and well, but what about testing. When doing BN on our test set, with the implementation from above, we will be using the mean and variance from our test set. Now think about what will happen if our test set is very small or even size 1. This will homogenize all the outputs we get since all inputs will be close to mean 0 and variance 1. The solution to this is to calculate the population mean and variance during testing and then use those values during testing.</p><p>Now there are couple ways we can try to calculate the population, even simple as taking the average of the training batch and using it for testing. This isn’t the true population measure so we will calculate the unbiased mean and variance as they do in the original <strong>paper</strong>. But first, let’s see the accuracy when we feed in test samples of size 1.</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-11-10-at-9-40-52-pm.png?w=620" alt="Screen Shot 2016-11-10 at 9.40.52 PM.png"></p><p>Not exactly state of the art anymore. So let’s see how to calculate population mean and variance.<br><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-11-09-at-7-45-05-pm.png?w=620" alt="Screen Shot 2016-11-09 at 7.45.05 PM.png"></p><p>We will be updating the population mean and variance after each training batch and we will use them for inference. In fact we can simple replace the inference batchnorm process with a simple linear transformation:</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-11-09-at-7-50-58-pm.png?w=620" alt="Screen Shot 2016-11-09 at 7.50.58 PM.png"></p><p>Below is the tensorflow implementation for batchnorm with the exponential moving average to use during inference. Take a look <strong>here</strong> for more implementation specifications for batch_norm but the required parameters for us is the actual input that we wish to normalize and wether or not we are training. Note: TF batchnorm with inference is in <strong>batch_norm2.py</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> tensorflow.contrib.layers <span class="keyword">import</span> (</div><div class="line">    batch_norm</div><div class="line">)</div><div class="line">...</div><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'BN_1'</span>) <span class="keyword">as</span> BN_1:</div><div class="line">    self.BN1 = tf.cond(self.is_training_ph,</div><div class="line">        <span class="keyword">lambda</span>: batch_norm(</div><div class="line">            self.z1_BN, is_training=<span class="keyword">True</span>, center=<span class="keyword">True</span>,</div><div class="line">            scale=<span class="keyword">True</span>, activation_fn=tf.nn.relu,</div><div class="line">            updates_collections=<span class="keyword">None</span>, scope=BN_1),</div><div class="line">        <span class="keyword">lambda</span>: batch_norm(</div><div class="line">            self.z1_BN, is_training=<span class="keyword">False</span>, center=<span class="keyword">True</span>,</div><div class="line">            scale=<span class="keyword">True</span>, activation_fn=tf.nn.relu,</div><div class="line">            updates_collections=<span class="keyword">None</span>, scope=BN_1, reuse=<span class="keyword">True</span>))</div></pre></td></tr></table></figure><p>Here are the inference results with the population mean and variance:</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-11-14-at-6-45-55-pm.png?w=620" alt="Screen Shot 2016-11-14 at 6.45.55 PM.png"></p><p>######</p><h2 id="IMPLEMENTING-LAYER-NORMALIZATION"><a href="#IMPLEMENTING-LAYER-NORMALIZATION" class="headerlink" title="IMPLEMENTING LAYER NORMALIZATION"></a>IMPLEMENTING LAYER NORMALIZATION</h2><p>Layernorm is very similar to batch normalization in many ways as you can see with the equation below but it usually reserved for use with recurrent architectures.</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2017-01-19-at-6-23-36-pm.png?w=352&amp;h=105" alt="Screen Shot 2017-01-19 at 6.23.36 PM.png"></p><p>Layernorm acts on a per layer per sample basis, where the mean and variance are calculated for a specific layer for a specific training point. To understand the different between layernorm and batchnorm let’s see how these mean and variances are computed for both with figures.</p><p>With layernorm it’s a bit different from BN. We compute the mean and var for every single sample for each layer independently and then do the LN operations using those computed values.</p><p><img src="https://theneuralperspective.files.wordpress.com/2016/10/screen-shot-2016-11-14-at-8-59-44-pm.png?w=620" alt="Screen Shot 2016-11-14 at 8.59.44 PM.png"></p><p>First, we will make a function that will apply batch norm given an input tensor.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># LN funcition</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ln</span><span class="params">(inputs, epsilon = <span class="number">1e-5</span>, scope = None)</span>:</span></div><div class="line"> </div><div class="line">    <span class="string">""" Computer LN given an input tensor. We get in an input of shape</span></div><div class="line">    [N X D] and with LN we compute the mean and var for each individual</div><div class="line">    training point across all it's hidden dimensions rather than across</div><div class="line">    the training batch as we do in BN. This gives us a mean and var of shape</div><div class="line">    [N X 1].</div><div class="line">    """</div><div class="line">    mean, var = tf.nn.moments(inputs, [<span class="number">1</span>], keep_dims=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">with</span> tf.variable_scope(scope + <span class="string">'LN'</span>):</div><div class="line">        scale = tf.get_variable(<span class="string">'alpha'</span>,</div><div class="line">                                shape=[inputs.get_shape()[<span class="number">1</span>]],</div><div class="line">                                initializer=tf.constant_initializer(<span class="number">1</span>))</div><div class="line">        shift = tf.get_variable(<span class="string">'beta'</span>,</div><div class="line">                                shape=[inputs.get_shape()[<span class="number">1</span>]],</div><div class="line">                                initializer=tf.constant_initializer(<span class="number">0</span>))</div><div class="line">    LN = scale * (inputs - mean) / tf.sqrt(var + epsilon) + shift</div><div class="line"> </div><div class="line">    <span class="keyword">return</span> LN</div></pre></td></tr></table></figure><p>Now we can apply our LN function to a GRUCell class. Note that I am using tensorflow’s <strong>GRUCell class</strong> but we can apply LN to all of their other RNN variants as well (LSTM, peephole LSTM, etc.)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">GRUCell</span><span class="params">(RNNCell)</span>:</span></div><div class="line">  <span class="string">"""Gated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.1078)."""</span></div><div class="line"> </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_units, input_size=None, activation=tanh)</span>:</span></div><div class="line">    <span class="keyword">if</span> input_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">      logging.warn(<span class="string">"%s: The input_size parameter is deprecated."</span>, self)</div><div class="line">    self._num_units = num_units</div><div class="line">    self._activation = activation</div><div class="line"> </div><div class="line"><span class="meta">  @property</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">state_size</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">return</span> self._num_units</div><div class="line"> </div><div class="line"><span class="meta">  @property</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">output_size</span><span class="params">(self)</span>:</span></div><div class="line">    <span class="keyword">return</span> self._num_units</div><div class="line"> </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, inputs, state, scope=None)</span>:</span></div><div class="line">    <span class="string">"""Gated recurrent unit (GRU) with nunits cells."""</span></div><div class="line">    <span class="keyword">with</span> vs.variable_scope(scope <span class="keyword">or</span> type(self).__name__):  <span class="comment"># "GRUCell"</span></div><div class="line">      <span class="keyword">with</span> vs.variable_scope(<span class="string">"Gates"</span>):  <span class="comment"># Reset gate and update gate.</span></div><div class="line">        <span class="comment"># We start with bias of 1.0 to not reset and not update.</span></div><div class="line">        r, u = array_ops.split(<span class="number">1</span>, <span class="number">2</span>, _linear([inputs, state],</div><div class="line">                                             <span class="number">2</span> * self._num_units, <span class="keyword">True</span>, <span class="number">1.0</span>))</div><div class="line"> </div><div class="line">        <span class="comment"># Apply Layer Normalization to the two gates</span></div><div class="line">        r = ln(r, scope = <span class="string">'r/'</span>)</div><div class="line">        u = ln(r, scope = <span class="string">'u/'</span>)</div><div class="line"> </div><div class="line">        r, u = sigmoid(r), sigmoid(u)</div><div class="line">      <span class="keyword">with</span> vs.variable_scope(<span class="string">"Candidate"</span>):</div><div class="line">        c = self._activation(_linear([inputs, r * state],</div><div class="line">                                     self._num_units, <span class="keyword">True</span>))</div><div class="line">      new_h = u * state + (<span class="number">1</span> - u) * c</div><div class="line">    <span class="keyword">return</span> new_h, new_h</div></pre></td></tr></table></figure><h2 id="SHAPES"><a href="#SHAPES" class="headerlink" title="SHAPES:"></a>SHAPES:</h2><p>I received quite a few PMs about some confusing aspects of BN and LN, mostly centered around what is actually the input. Let’s look at BN first. The input to a hidden layer will be [NXH]. Applying BN involves calculating the mean value for each H across all N samples. So we will have a mean of shape [1XH]. This “batch” mean will be used for BN, basically subtracting this batch mean from each sample.</p><p>Now for LN, let’s imagine a simple RNN situation. Batch major inputs are of shape [N, M, H], where N is the batch size, M is the max number of time steps and H is the number of hidden units. Before feeing to an RNN, we can reshape to time-major which becomes [M, N, H]. Now we feed in one time step at a time into the RNN, so the shape of each time-step’s input is [N,H]. Applying LN involves calculating the mean for sample across dimension [1], which means looking at all hidden states for each sample (for this particular time step). This gives us a mean of size [NX1]. We use this “layer” mean for each sample.</p><hr><p>Source page is <a href="https://theneuralperspective.com/2016/10/27/gradient-topics/" target="_blank" rel="external">HERE</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In this post, we will take a look at common pit falls with optimization and solutions to some of these issues. The main topics that will 
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>What Is Local Response Normalization In Convolutional Neural Networks</title>
    <link href="http://yoursite.com/2017/05/04/What-Is-Local-Response-Normalization-In-Convolutional-Neural-Networks/"/>
    <id>http://yoursite.com/2017/05/04/What-Is-Local-Response-Normalization-In-Convolutional-Neural-Networks/</id>
    <published>2017-05-04T03:32:10.000Z</published>
    <updated>2017-05-04T03:37:33.386Z</updated>
    
    <content type="html"><![CDATA[<p>Convolutional Neural Networks (CNNs) have been doing wonders in the field of image recognition in recent times. CNN is a type of deep neural network in which the layers are connected using spatially organized patterns. This is in line with how the human visual cortex processes image data. Researchers have been working on coming up with better architectures over the last few years. In this blog post, we will discuss a particular type of layer that has been used consistently across many famous architectures. This layer is called Local Response Normalization layer and it plays an important role. What does it do? What’s the advantage of having this in our network?</p><h2 id="Why-do-we-need-normalization-layers-in-the-first-place"><a href="#Why-do-we-need-normalization-layers-in-the-first-place" class="headerlink" title="Why do we need normalization layers in the first place?"></a><strong>Why do we need normalization layers in the first place?</strong></h2><p>A typical CNN consists of the following layers: convolution, pooling, rectified linear unit (ReLU), fully connected, and loss. If the previous sentence didn’t make sense, you may want to go through a quick CNN tutorial before proceeding further. Anyway, the reason we may want to have normalization layers in our CNN is that we want to have some kind of inhibition scheme.</p><p>In neurobiology, there is a concept called “lateral inhibition”. Now what does that mean? This refers to the capacity of an excited neuron to subdue its neighbors. We basically want a significant peak so that we have a form of local maxima. This tends to create a contrast in that area, hence increasing the sensory perception. Increasing the sensory perception is a good thing! We want to have the same thing in our CNNs.</p><h2 id="What-exactly-is-Local-Response-Normalization"><a href="#What-exactly-is-Local-Response-Normalization" class="headerlink" title="What exactly is Local Response Normalization?"></a><strong>What exactly is Local Response Normalization?</strong></h2><p>Local Response Normalization (LRN) layer implements the lateral inhibition we were talking about in the previous section. This layer is useful when we are dealing with ReLU neurons. Why is that? Because ReLU neurons have unbounded activations and we need LRN to normalize that. We want to detect high frequency features with a large response. If we normalize around the local neighborhood of the excited neuron, it becomes even more sensitive as compared to its neighbors.</p><p>At the same time, it will dampen the responses that are uniformly large in any given local neighborhood. If all the values are large, then normalizing those values will diminish all of them. So basically we want to encourage some kind of inhibition and boost the neurons with relatively larger activations. This has been discussed nicely in Section 3.3 of the <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf" target="_blank" rel="external">original paper</a> by Krizhevsky et al.</p><h2 id="How-is-it-done-in-practice"><a href="#How-is-it-done-in-practice" class="headerlink" title="How is it done in practice?"></a><strong>How is it done in practice?</strong></h2><p>There are two types of normalizations available in Caffe. You can either normalize within the same channel or you can normalize across channels. Both these methods tend to amplify the excited neuron while dampening the surrounding neurons. When you are normalizing within the same channel, it’s just like considering a 2D neighborhood of dimension N x N, where N is the size of the normalization window. You normalize this window using the values in this neighborhood. If you are normalizing across channels, you will consider a neighborhood along the third dimension but at a single location. You need to consider an area of shape N x 1 x 1. Here 1 x 1 refers to a single value in a 2D matrix and N refers to the normalization size.</p><hr><p>Source page is <a href="https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/" target="_blank" rel="external">here</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Convolutional Neural Networks (CNNs) have been doing wonders in the field of image recognition in recent times. CNN is a type of deep neu
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>The first course of the Docker</title>
    <link href="http://yoursite.com/2017/05/01/The-first-course-of-the-Docker/"/>
    <id>http://yoursite.com/2017/05/01/The-first-course-of-the-Docker/</id>
    <published>2017-05-01T08:33:38.000Z</published>
    <updated>2017-05-01T11:19:36.300Z</updated>
    
    <content type="html"><![CDATA[<p>Docker command:</p><ul><li><p>docker images <strong>查看本机所有镜像</strong></p></li><li><p>docker pull NAME <strong>从仓库下载镜像</strong></p></li><li><p>docker run [-d -p 8080:80] or [-P] NAME <strong>启动镜像（-d 后台运行 -p 端口映射 -P 随机映射）</strong></p></li><li><p>docker exec [-i -t] NAME bash <strong>进入容器并执行bash</strong></p></li><li><p>docker ps <strong>查看后台容器</strong></p></li><li><p>docker stop ID <strong>停止docker容器</strong></p></li><li><p>docker restart ID <strong>重启容器</strong></p><p>​</p></li></ul><p>Docker netowrk type: bridge</p><p>Docker port map: host(eth0:80) &lt;–&gt; dicker0(bridge) &lt;–&gt; docker container(eth0:80)</p><p>Build Docker</p><ul><li>Dockerfile</li><li>docker build [-t] <strong>建立Docker，指定TAG</strong></li></ul><p>A Dcokerfile example (based tomcat):</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> tomcat </div><div class="line"></div><div class="line"><span class="keyword">MAINTAINER</span> ewan ewanlee@yeah.net</div><div class="line"></div><div class="line"><span class="keyword">COPY</span> jpress-web-newest.war /usr/local/tomcat/webapps</div></pre></td></tr></table></figure><h2 id="搭建第一个Web-app"><a href="#搭建第一个Web-app" class="headerlink" title="搭建第一个Web app"></a>搭建第一个Web app</h2><p>为了介绍方便，所以使用了开源的java实现的wordpress，也就是<a href="https://github.com/JpressProjects/jpress" target="_blank" rel="external">Jpress</a></p><p>[1]下载相应的<a href="https://github.com/JpressProjects/jpress/blob/master/wars/jpress-web-newest.war" target="_blank" rel="external">war包</a>，并存到工作目录下</p><p>[2]下载一个tomcat的Docker镜像<code>docker pull tomcat</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">Using default tag: latest</div><div class="line">latest: Pulling from library/tomcat</div><div class="line">cd0a524342ef: Pull complete </div><div class="line">e39c3ffe4133: Pull complete </div><div class="line">aac3320edf40: Pull complete </div><div class="line">4d9e109682f7: Pull complete </div><div class="line">0a59efcf9553: Pull complete </div><div class="line">43a404e523e0: Pull complete </div><div class="line">806f07b1dce8: Pull complete </div><div class="line">0cad96dccb4c: Pull complete </div><div class="line">04073e2a9145: Pull complete </div><div class="line">d9e4bf4be89c: Pull complete </div><div class="line">739005fdecc9: Pull complete </div><div class="line">8bd03d99f1b2: Pull complete </div><div class="line">d586afbd7622: Pull complete </div><div class="line">Digest: sha256:88483873b279aaea5ced002c98dde04555584b66de29797a4476d5e94874e6de</div><div class="line">Status: Downloaded newer image for tomcat:latest</div></pre></td></tr></table></figure><p>[3]写一个<code>Dockerfile</code>，也就是之前的example</p><p>[4]建立镜像<code>docker build -t jpress:latest .</code></p><p>结果如下：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Sending build context to Docker daemon  <span class="number">20.8</span> MB</div><div class="line">Step <span class="number">1</span> : FROM tomcat</div><div class="line"> ---&gt; d71978506e58</div><div class="line">Step <span class="number">2</span> : MAINTAINER ewan ewanlee<span class="meta">@yeah</span>.net</div><div class="line"> ---&gt; Running <span class="keyword">in</span> dfa1902d1ea4</div><div class="line"> ---&gt; <span class="number">956612</span>ba6987</div><div class="line">Removing intermediate container dfa1902d1ea4</div><div class="line">Step <span class="number">3</span> : COPY jpress-web-newest.war /usr/local/tomcat/webapps</div><div class="line"> ---&gt; dd6eecd741e7</div><div class="line">Removing intermediate container <span class="number">1</span>fe7f943071b</div><div class="line">Successfully built dd6eecd741e7</div></pre></td></tr></table></figure><p>[5]下载一个mysql的docker镜像<code>docker pull mysql</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Using default tag: latest</div><div class="line">latest: Pulling from library/mysql</div><div class="line">cd0a524342ef: Already exists </div><div class="line">d9c95f06c17e: Pull complete </div><div class="line">46b2d578f59a: Pull complete </div><div class="line">10fbc2bcc6e9: Pull complete </div><div class="line">91b1a29c3956: Pull complete </div><div class="line">5bf9316bd602: Pull complete </div><div class="line">69bd23f08b55: Pull complete </div><div class="line">4fb778132e94: Pull complete </div><div class="line">6913628d7744: Pull complete </div><div class="line">a477f36dc2e0: Pull complete </div><div class="line">c954124ae935: Pull complete </div><div class="line">Digest: sha256:e44b9a3ae88db013a3e8571a89998678ba44676ed4ae9f54714fd31e108f8b58</div><div class="line">Status: Downloaded newer image for mysql:latest</div></pre></td></tr></table></figure><p>[6]运行mysql并创建一个数据库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=000000 -e MYSQL_DATABASE=jpress mysql</div></pre></td></tr></table></figure><p>[7]运行自己建立的<code>jpress</code>镜像<code>docker run -d -p 8888:8080 jpress</code></p><p>下面进行浏览器页面的配置，在浏览器输入<code>localhost:8888</code>将出现以下界面：</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/docker-jpress/index_page.png" alt="index"></p><p>在地址栏后加入后缀<code>jpress-web-newest</code></p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/docker-jpress/jpress_install.png" alt="install"></p><p>填写配置信息，注意服务器地址是<code>docker0</code>网卡的ip</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/docker-jpress/config.png" alt="config"></p><p>结果</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/docker-jpress/home_page.png" alt="home"></p><p>安装过程中出现了一个bug，就是在进行配置后我退出了，再次进去重新配置出错，最后发现原因是表前缀需要改一下，因为之前配置成功了，数据库中已经有了一个相同的表前缀​:P</p><p>是不是很方便，完全不用手动安装任何东西~</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="http://www.imooc.com/learn/824" target="_blank" rel="external">http://www.imooc.com/learn/824</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker command:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;docker images &lt;strong&gt;查看本机所有镜像&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;docker pull NAME &lt;strong&gt;从仓库下载镜像&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;l
    
    </summary>
    
    
      <category term="docker" scheme="http://yoursite.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>HMM implemented by hmmlearn</title>
    <link href="http://yoursite.com/2017/05/01/HMM-implemented-by-hmmlearn/"/>
    <id>http://yoursite.com/2017/05/01/HMM-implemented-by-hmmlearn/</id>
    <published>2017-05-01T05:33:52.000Z</published>
    <updated>2017-05-01T05:47:05.948Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Sampling-from-HMM"><a href="#Sampling-from-HMM" class="headerlink" title="Sampling from HMM"></a>Sampling from HMM</h1><p>This script shows how to sample points from a Hidden Markov Model (HMM): we use a 4-components with specified mean and covariance.</p><p>The plot show the sequence of observations generated with the transitions between them. We can see that, as specified by our transition matrix, there are no transition between component 1 and 3.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">print(__doc__)</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="keyword">from</span> hmmlearn <span class="keyword">import</span> hmm</div></pre></td></tr></table></figure><p>Prepare parameters for a 4-components HMM Initial population probability</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">startprob = np.array([<span class="number">0.6</span>, <span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.0</span>])</div><div class="line"><span class="comment"># The transition matrix, note that there are no transitions possible</span></div><div class="line"><span class="comment"># between component 1 and 3</span></div><div class="line">transmat = np.array([[<span class="number">0.7</span>, <span class="number">0.2</span>, <span class="number">0.0</span>, <span class="number">0.1</span>],</div><div class="line">                     [<span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0.0</span>],</div><div class="line">                     [<span class="number">0.0</span>, <span class="number">0.3</span>, <span class="number">0.5</span>, <span class="number">0.2</span>],</div><div class="line">                     [<span class="number">0.2</span>, <span class="number">0.0</span>, <span class="number">0.2</span>, <span class="number">0.6</span>]])</div><div class="line"><span class="comment"># The means of each component</span></div><div class="line">means = np.array([[<span class="number">0.0</span>,  <span class="number">0.0</span>],</div><div class="line">                  [<span class="number">0.0</span>, <span class="number">11.0</span>],</div><div class="line">                  [<span class="number">9.0</span>, <span class="number">10.0</span>],</div><div class="line">                  [<span class="number">11.0</span>, <span class="number">-1.0</span>]])</div><div class="line"><span class="comment"># The covariance of each component</span></div><div class="line">covars = <span class="number">.5</span> * np.tile(np.identity(<span class="number">2</span>), (<span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>))</div><div class="line"></div><div class="line"><span class="comment"># Build an HMM instance and set parameters</span></div><div class="line">model = hmm.GaussianHMM(n_components=<span class="number">4</span>, covariance_type=<span class="string">"full"</span>)</div><div class="line"></div><div class="line"><span class="comment"># Instead of fitting it from the data, we directly set the estimated</span></div><div class="line"><span class="comment"># parameters, the means and covariance of the components</span></div><div class="line">model.startprob_ = startprob</div><div class="line">model.transmat_ = transmat</div><div class="line">model.means_ = means</div><div class="line">model.covars_ = covars</div><div class="line"></div><div class="line"><span class="comment"># Generate samples</span></div><div class="line">X, Z = model.sample(<span class="number">500</span>)</div><div class="line"></div><div class="line"><span class="comment"># Plot the sampled data</span></div><div class="line">plt.plot(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], <span class="string">".-"</span>, label=<span class="string">"observations"</span>, ms=<span class="number">6</span>,</div><div class="line">         mfc=<span class="string">"orange"</span>, alpha=<span class="number">0.7</span>)</div><div class="line"></div><div class="line"><span class="comment"># Indicate the component numbers</span></div><div class="line"><span class="keyword">for</span> i, m <span class="keyword">in</span> enumerate(means):</div><div class="line">    plt.text(m[<span class="number">0</span>], m[<span class="number">1</span>], <span class="string">'Component %i'</span> % (i + <span class="number">1</span>),</div><div class="line">             size=<span class="number">17</span>, horizontalalignment=<span class="string">'center'</span>,</div><div class="line">             bbox=dict(alpha=<span class="number">.7</span>, facecolor=<span class="string">'w'</span>))</div><div class="line">plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="http://hmmlearn.readthedocs.io/en/latest/_images/sphx_glr_plot_hmm_sampling_001.png" alt="sampling_result"></p><p><strong>Total running time of the script:</strong> ( 0 minutes 0.676 seconds)</p><h1 id="Gaussian-HMM-of-stock-data"><a href="#Gaussian-HMM-of-stock-data" class="headerlink" title="Gaussian HMM of stock data"></a>Gaussian HMM of stock data</h1><p>This script shows how to use Gaussian HMM on stock price data from Yahoo! finance. For more information on how to visualize stock prices with matplotlib, please refer to <code>date_demo1.py</code> of matplotlib.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> cm, pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> matplotlib.dates <span class="keyword">import</span> YearLocator, MonthLocator</div><div class="line"><span class="keyword">try</span>:</div><div class="line">    <span class="keyword">from</span> matplotlib.finance <span class="keyword">import</span> quotes_historical_yahoo_ochl</div><div class="line"><span class="keyword">except</span> ImportError:</div><div class="line">    <span class="comment"># For Matplotlib prior to 1.5.</span></div><div class="line">    <span class="keyword">from</span> matplotlib.finance <span class="keyword">import</span> (</div><div class="line">        quotes_historical_yahoo <span class="keyword">as</span> quotes_historical_yahoo_ochl</div><div class="line">    )</div><div class="line"></div><div class="line"><span class="keyword">from</span> hmmlearn.hmm <span class="keyword">import</span> GaussianHMM</div><div class="line"></div><div class="line"></div><div class="line">print(__doc__)</div></pre></td></tr></table></figure><p>Get quotes from Yahoo! finance</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">quotes = quotes_historical_yahoo_ochl(</div><div class="line">    <span class="string">"INTC"</span>, datetime.date(<span class="number">1995</span>, <span class="number">1</span>, <span class="number">1</span>), datetime.date(<span class="number">2012</span>, <span class="number">1</span>, <span class="number">6</span>))</div><div class="line"></div><div class="line"><span class="comment"># Unpack quotes</span></div><div class="line">dates = np.array([q[<span class="number">0</span>] <span class="keyword">for</span> q <span class="keyword">in</span> quotes], dtype=int)</div><div class="line">close_v = np.array([q[<span class="number">2</span>] <span class="keyword">for</span> q <span class="keyword">in</span> quotes])</div><div class="line">volume = np.array([q[<span class="number">5</span>] <span class="keyword">for</span> q <span class="keyword">in</span> quotes])[<span class="number">1</span>:]</div><div class="line"></div><div class="line"><span class="comment"># Take diff of close value. Note that this makes</span></div><div class="line"><span class="comment"># ``len(diff) = len(close_t) - 1``, therefore, other quantities also</span></div><div class="line"><span class="comment"># need to be shifted by 1.</span></div><div class="line">diff = np.diff(close_v)</div><div class="line">dates = dates[<span class="number">1</span>:]</div><div class="line">close_v = close_v[<span class="number">1</span>:]</div><div class="line"></div><div class="line"><span class="comment"># Pack diff and volume for training.</span></div><div class="line">X = np.column_stack([diff, volume])</div></pre></td></tr></table></figure><p>Run Gaussian HMM</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">"fitting to HMM and decoding ..."</span>, end=<span class="string">""</span>)</div><div class="line"></div><div class="line"><span class="comment"># Make an HMM instance and execute fit</span></div><div class="line">model = GaussianHMM(n_components=<span class="number">4</span>, covariance_type=<span class="string">"diag"</span>, n_iter=<span class="number">1000</span>).fit(X)</div><div class="line"></div><div class="line"><span class="comment"># Predict the optimal sequence of internal hidden state</span></div><div class="line">hidden_states = model.predict(X)</div><div class="line"></div><div class="line">print(<span class="string">"done"</span>)</div></pre></td></tr></table></figure><p>Out:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fitting to HMM and decoding ...done</div></pre></td></tr></table></figure><p>Print trained parameters and plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">"Transition matrix"</span>)</div><div class="line">print(model.transmat_)</div><div class="line">print()</div><div class="line"></div><div class="line">print(<span class="string">"Means and vars of each hidden state"</span>)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(model.n_components):</div><div class="line">    print(<span class="string">"&#123;0&#125;th hidden state"</span>.format(i))</div><div class="line">    print(<span class="string">"mean = "</span>, model.means_[i])</div><div class="line">    print(<span class="string">"var = "</span>, np.diag(model.covars_[i]))</div><div class="line">    print()</div><div class="line"></div><div class="line">fig, axs = plt.subplots(model.n_components, sharex=<span class="keyword">True</span>, sharey=<span class="keyword">True</span>)</div><div class="line">colours = cm.rainbow(np.linspace(<span class="number">0</span>, <span class="number">1</span>, model.n_components))</div><div class="line"><span class="keyword">for</span> i, (ax, colour) <span class="keyword">in</span> enumerate(zip(axs, colours)):</div><div class="line">    <span class="comment"># Use fancy indexing to plot data in each state.</span></div><div class="line">    mask = hidden_states == i</div><div class="line">    ax.plot_date(dates[mask], close_v[mask], <span class="string">".-"</span>, c=colour)</div><div class="line">    ax.set_title(<span class="string">"&#123;0&#125;th hidden state"</span>.format(i))</div><div class="line"></div><div class="line">    <span class="comment"># Format the ticks.</span></div><div class="line">    ax.xaxis.set_major_locator(YearLocator())</div><div class="line">    ax.xaxis.set_minor_locator(MonthLocator())</div><div class="line"></div><div class="line">    ax.grid(<span class="keyword">True</span>)</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p><img src="http://hmmlearn.readthedocs.io/en/latest/_images/sphx_glr_plot_hmm_stock_analysis_001.png" alt="hmm_yahoo_analysis"></p><p>Out:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">Transition matrix</div><div class="line">[[  <span class="number">9.79220773e-01</span>   <span class="number">2.57382344e-15</span>   <span class="number">2.72061945e-03</span>   <span class="number">1.80586073e-02</span>]</div><div class="line"> [  <span class="number">1.12216188e-12</span>   <span class="number">7.73561269e-01</span>   <span class="number">1.85019044e-01</span>   <span class="number">4.14196869e-02</span>]</div><div class="line"> [  <span class="number">3.25313504e-03</span>   <span class="number">1.12692615e-01</span>   <span class="number">8.83368021e-01</span>   <span class="number">6.86228435e-04</span>]</div><div class="line"> [  <span class="number">1.18741799e-01</span>   <span class="number">4.20310643e-01</span>   <span class="number">1.18670597e-18</span>   <span class="number">4.60947557e-01</span>]]</div><div class="line"></div><div class="line">Means <span class="keyword">and</span> vars of each hidden state</div><div class="line"><span class="number">0</span>th hidden state</div><div class="line">mean =  [  <span class="number">2.33331888e-02</span>   <span class="number">4.97389989e+07</span>]</div><div class="line">var =  [  <span class="number">6.97748259e-01</span>   <span class="number">2.49466578e+14</span>]</div><div class="line"></div><div class="line"><span class="number">1</span>th hidden state</div><div class="line">mean =  [  <span class="number">2.12401671e-02</span>   <span class="number">8.81882861e+07</span>]</div><div class="line">var =  [  <span class="number">1.18665023e-01</span>   <span class="number">5.64418451e+14</span>]</div><div class="line"></div><div class="line"><span class="number">2</span>th hidden state</div><div class="line">mean =  [  <span class="number">7.69658065e-03</span>   <span class="number">5.43135922e+07</span>]</div><div class="line">var =  [  <span class="number">5.02315562e-02</span>   <span class="number">1.54569357e+14</span>]</div><div class="line"></div><div class="line"><span class="number">3</span>th hidden state</div><div class="line">mean =  [ <span class="number">-3.53210673e-01</span>   <span class="number">1.53080943e+08</span>]</div><div class="line">var =  [  <span class="number">2.55544137e+00</span>   <span class="number">5.88210257e+15</span>]</div></pre></td></tr></table></figure><p><strong>Total running time of the script:</strong> ( 0 minutes 2.903 seconds)</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Sampling-from-HMM&quot;&gt;&lt;a href=&quot;#Sampling-from-HMM&quot; class=&quot;headerlink&quot; title=&quot;Sampling from HMM&quot;&gt;&lt;/a&gt;Sampling from HMM&lt;/h1&gt;&lt;p&gt;This scrip
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="HMM" scheme="http://yoursite.com/tags/HMM/"/>
    
  </entry>
  
  <entry>
    <title>The Basic of Hidden Markov Model</title>
    <link href="http://yoursite.com/2017/04/30/The-basic-of-Hidden-Markov-Model/"/>
    <id>http://yoursite.com/2017/04/30/The-basic-of-Hidden-Markov-Model/</id>
    <published>2017-04-30T15:04:54.000Z</published>
    <updated>2017-04-30T15:46:21.384Z</updated>
    
    <content type="html"><![CDATA[<div class="row"><embed src="http://o7ie0tcjk.bkt.clouddn.com/hmm-paper/tutorial%20on%20hmm%20and%20applications.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      &lt;div class=&quot;row&quot;&gt;&lt;embed src=&quot;http://o7ie0tcjk.bkt.clouddn.com/hmm-paper/tutorial%20on%20hmm%20and%20applications.pdf&quot; width=&quot;100%&quot; height=&quot;5
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="HMM" scheme="http://yoursite.com/tags/HMM/"/>
    
  </entry>
  
</feed>
