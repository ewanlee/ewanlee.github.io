<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Abracdabra</title>
  <subtitle>Do it yourself</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-04-29T10:01:59.545Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Ewan Li</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>The awesome Wasserstein GAN</title>
    <link href="http://yoursite.com/2017/04/29/The-awesome-Wasserstein-GAN/"/>
    <id>http://yoursite.com/2017/04/29/The-awesome-Wasserstein-GAN/</id>
    <published>2017-04-29T08:55:06.000Z</published>
    <updated>2017-04-29T10:01:59.545Z</updated>
    
    <content type="html"><![CDATA[<p>原帖地址：<a href="https://zhuanlan.zhihu.com/p/25071913" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/25071913</a></p><blockquote><p>本文后续：<a href="https://www.zhihu.com/question/52602529/answer/158727900" target="_blank" rel="external">Wasserstein GAN最新进展：从weight clipping到gradient penalty，更加先进的Lipschitz限制手法</a></p></blockquote><p>在GAN的相关研究如火如荼甚至可以说是泛滥的今天，一篇新鲜出炉的arXiv论文《<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1701.07875" target="_blank" rel="external">Wasserstein GAN</a>》却在Reddit的Machine Learning频道火了，连Goodfellow都<a href="http://link.zhihu.com/?target=https%3A//www.reddit.com/r/MachineLearning/comments/5qxoaz/r_170107875_wasserstein_gan/" target="_blank" rel="external">在帖子里和大家热烈讨论</a>，这篇论文究竟有什么了不得的地方呢？</p><p>要知道自从<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1406.2661" target="_blank" rel="external">2014年Ian Goodfellow提出</a>以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.06434" target="_blank" rel="external">DCGAN</a>依靠的是对判别器和生成器的架构进行实验枚举，最终找到一组比较好的网络架构设置，但是实际上是治标不治本，没有彻底解决问题。而今天的主角Wasserstein GAN（下面简称WGAN）成功地做到了以下爆炸性的几点：</p><ul><li>彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度</li><li>基本解决了collapse mode的问题，确保了生成样本的多样性</li><li>训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高（如题图所示）</li><li>以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到</li></ul><p>那以上好处来自哪里？这就是令人拍案叫绝的部分了——实际上作者整整花了两篇论文，在第一篇《<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1701.04862" target="_blank" rel="external">Towards Principled Methods for Training Generative Adversarial Networks</a>》里面推了一堆公式定理，从理论上分析了原始GAN的问题所在，从而针对性地给出了改进要点；在这第二篇《<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1701.07875" target="_blank" rel="external">Wasserstein GAN</a>》里面，又再从这个改进点出发推了一堆公式定理，最终给出了改进的算法实现流程，<strong>而改进后相比原始GAN的算法实现流程却只改了四点</strong>：</p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul><p>算法截图如下：</p><p><img src="https://pic1.zhimg.com/v2-6be6e2ef3d15c4b10c2a943e9bf4db70_b.jpg" alt="img"></p><p>改动是如此简单，效果却惊人地好，以至于Reddit上不少人在感叹：就这样？没有别的了？ 太简单了吧！这些反应让我想起了一个颇有年头的鸡汤段子，说是一个工程师在电机外壳上用粉笔划了一条线排除了故障，要价一万美元——画一条线，1美元；知道在哪画线，9999美元。上面这四点改进就是作者Martin Arjovsky划的简简单单四条线，对于工程实现便已足够，但是知道在哪划线，背后却是精巧的数学分析，而这也是本文想要整理的内容。</p><p>本文内容分为五个部分：</p><ul><li>原始GAN究竟出了什么问题？（此部分较长）</li><li>WGAN之前的一个过渡解决方案</li><li>Wasserstein距离的优越性质</li><li>从Wasserstein距离到WGAN</li><li>总结</li></ul><p><em>理解原文的很多公式定理需要对测度论、 拓扑学等数学知识有所掌握，本文会从直观的角度对每一个重要公式进行解读，有时通过一些低维的例子帮助读者理解数学背后的思想，所以不免会失于严谨，如有引喻不当之处，欢迎在评论中指出。</em></p><p><em>以下简称《Wassertein GAN》为“WGAN本作”，简称《Towards Principled Methods for Training Generative Adversarial Networks》为“WGAN前作”。</em></p><p><em>WGAN源码实现：martinarjovsky/WassersteinGAN</em></p><h2 id="第一部分：原始GAN究竟出了什么问题？"><a href="#第一部分：原始GAN究竟出了什么问题？" class="headerlink" title="第一部分：原始GAN究竟出了什么问题？"></a>第一部分：原始GAN究竟出了什么问题？</h2><p>回顾一下，原始GAN中判别器要最小化如下损失函数，尽可能把真实样本分为正例，生成样本分为负例：</p><script type="math/tex;mode=display">-\mathbb{E}_{x \sim P_r}[log D(x)] - \mathbb{E}_{x \sim P_{g}}[log(1-D(x))]</script><p>其中$P_r$是真实样本分布，$P_g$是由生成器产生的样本分布。对于生成器，Goodfellow一开始提出来一个损失函数，后来又提出了一个改进的损失函数，分别是</p><script type="math/tex;mode=display">\mathbb{E}_{x \sim P_g}[log(1-D(x))]</script><script type="math/tex;mode=display">\mathbb{E}_{x \sim P_g}[-log D(x)]</script><p>后者在WGAN两篇论文中称为“the - log D alternative”或“the - log D trick”。WGAN前作分别分析了这两种形式的原始GAN各自的问题所在，下面分别说明。</p><h2 id="第一种原始GAN形式的问题"><a href="#第一种原始GAN形式的问题" class="headerlink" title="第一种原始GAN形式的问题"></a>第一种原始GAN形式的问题</h2><p><strong>一句话概括：判别器越好，生成器梯度消失越严重。</strong>WGAN前作从两个角度进行了论证，第一个角度是从生成器的等价损失函数切入的。</p><p>首先从公式1可以得到，在生成器G固定参数时最优的判别器D应该是什么。对于一个具体的样本$x$，它可能来自真实分布也可能来自生成分布，它对公式1损失函数的贡献是</p><script type="math/tex;mode=display">- P_r(x)logD(x) - p_g(x)log[1 - D(x)]</script><p>令其关于$D(x)$的导数为0，得</p><script type="math/tex;mode=display">-\frac{P_r(x)}{D(x)} + \frac{P_g(x)}{1 - D(x)} = 0</script><p>化简得最优判别器为：</p><script type="math/tex;mode=display">D^{\star}(x) = \frac{P_r(x)}{P_r(x) + P_g(x)}</script><p>这个结果从直观上很容易理解，就是看一个样本$x$来自真实分布和生成分布的可能性的相对比例。如果$P_r(x) = 0$且$P_g(x) \neq 0$，最优判别器就应该非常自信地给出概率0；如果$P_r(x) = P_g(x)$，说明该样本是真是假的可能性刚好一半一半，此时最优判别器也应该给出概率0.5。</p><p>然而GAN训练有一个trick，就是别把判别器训练得太好，否则在实验中生成器会完全学不动（loss降不下去），为了探究背后的原因，我们就可以看看在极端情况——判别器最优时，生成器的损失函数变成什么。给公式2加上一个不依赖于生成器的项，使之变成</p><script type="math/tex;mode=display">\mathbb{E}_{x \sim P_r}[log D(x)] - \mathbb{E}_{x \sim P_{g}}[log(1-D(x))]</script><p>注意，最小化这个损失函数等价于最小化公式2，而且它刚好是判别器损失函数的反。代入最优判别器即公式4，再进行简单的变换可以得到</p><script type="math/tex;mode=display">\mathbb{E}_{x \sim P_r} \log \frac{P_r(x)}{\frac{1}{2}[P_r(x) + P_g(x)]} + \mathbb{E}_{x \sim P_g} \log \frac{P_g(x)}{\frac{1}{2}[P_r(x) + P_g(x)]} - 2\log 2</script><p>变换成这个样子是为了引入Kullback–Leibler divergence（简称KL散度）和Jensen-Shannon divergence（简称JS散度）这两个重要的相似度衡量指标，后面的主角之一Wasserstein距离，就是要来吊打它们两个的。所以接下来介绍这两个重要的配角——KL散度和JS散度：</p><script type="math/tex;mode=display">KL(P_1||P_2) = \mathbb{E}_{x \sim P_1} \log \frac{P_1}{P_2}</script><script type="math/tex;mode=display">JS(P_1 || P_2) = \frac{1}{2}KL(P_1||\frac{P_1 + P_2}{2}) + \frac{1}{2}KL(P_2||\frac{P_1 + P_2}{2})</script><p>于是公式5就可以继续写成</p><script type="math/tex;mode=display">2JS(P_r || P_g) - 2\log 2</script><p>到这里读者可以先喘一口气，看看目前得到了什么结论：<strong>根据原始GAN定义的判别器loss，我们可以得到最优判别器的形式；而在最优判别器的下，我们可以把原始GAN定义的生成器loss等价变换为最小化真实分布$P_r$与生成分布$P_g$之间的JS散度。我们越训练判别器，它就越接近最优，最小化生成器的loss也就会越近似于最小化$P_r$和$P_g$之间的JS散度。</strong></p><p>问题就出在这个JS散度上。我们会希望如果两个分布之间越接近它们的JS散度越小，我们通过优化JS散度就能将$P_g$“拉向”$P_r$，最终以假乱真。这个希望在两个分布有所重叠的时候是成立的，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略（下面解释什么叫可忽略），它们的JS散度是多少呢？</p><p>答案是$\log 2$，因为对于任意一个x只有四种可能：</p><script type="math/tex;mode=display">P_1(x) = 0$且$P_2(x) = 0</script><script type="math/tex;mode=display">P_1(x) \neq 0$且$P_2(x) \neq 0</script><script type="math/tex;mode=display">P_1(x) = 0$且$P_2(x) \neq 0</script><script type="math/tex;mode=display">P_1(x) \neq 0$且$P_2(x) = 0</script><p>第一种对计算JS散度无贡献，第二种情况由于重叠部分可忽略所以贡献也为0，第三种情况对公式7右边第一个项的贡献是$\log \frac{P_2}{\frac{1}{2}(P_2 + 0)} = \log 2$，第四种情况与之类似，所以最终$JS(P_1||P_2) = \log 2$。</p><p>换句话说，无论$P_r$跟$P_g$是远在天边，还是近在眼前，只要它们俩没有一点重叠或者重叠部分可忽略，JS散度就固定是常数$\log 2$，<strong>而这对于梯度下降方法意味着——梯度为0</strong>！此时对于最优判别器来说，生成器肯定是得不到一丁点梯度信息的；即使对于接近最优的判别器来说，生成器也有很大机会面临梯度消失的问题。</p><p>但是$P_r$与$P_g$不重叠或重叠部分可忽略的可能性有多大？不严谨的答案是：非常大。比较严谨的答案是：<strong>当$P_r$与$P_g$的支撑集（support）是高维空间中的低维流形（manifold）时，$P_r$与$P_g$重叠部分测度（measure）为0的概率为1。</strong></p><p>不用被奇怪的术语吓得关掉页面，虽然论文给出的是严格的数学表述，但是直观上其实很容易理解。首先简单介绍一下这几个概念：</p><ul><li>支撑集（support）其实就是函数的非零部分子集，比如ReLU函数的支撑集就是$(0, +\infty)$，一个概率分布的支撑集就是所有概率密度非零部分的集合。</li><li>流形（manifold）是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。</li><li>测度（measure）是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”。</li></ul><p>回过头来看第一句话，“当$P_r$与$P_g$的支撑集是高维空间中的低维流形时”，基本上是成立的。原因是GAN中的生成器一般是从某个低维（比如100维）的随机分布中采样出一个编码向量，再经过一个神经网络生成出一个高维样本（比如64x64的图片就有4096维）。当生成器的参数固定时，生成样本的概率分布虽然是定义在4096维的空间上，但它本身所有可能产生的变化已经被那个100维的随机分布限定了，其本质维度就是100，再考虑到神经网络带来的映射降维，最终可能比100还小，所以生成样本分布的支撑集就在4096维空间中构成一个最多100维的低维流形，“撑不满”整个高维空间。</p><p>“撑不满”就会导致真实分布与生成分布难以“碰到面”，这很容易在二维空间中理解：一方面，二维平面中随机取两条曲线，它们之间刚好存在重叠线段的概率为0；另一方面，虽然它们很大可能会存在交叉点，但是相比于两条曲线而言，交叉点比曲线低一个维度，长度（测度）为0，可忽略。三维空间中也是类似的，随机取两个曲面，它们之间最多就是比较有可能存在交叉线，但是交叉线比曲面低一个维度，面积（测度）是0，可忽略。从低维空间拓展到高维空间，就有了如下逻辑：因为一开始生成器随机初始化，所以$P_g$几乎不可能与$P_r$有什么关联，所以它们的支撑集之间的重叠部分要么不存在，要么就比$P_r$和$P_g$的最小维度还要低至少一个维度，故而测度为0。所谓“重叠部分测度为0”，就是上文所言“不重叠或者重叠部分可忽略”的意思。</p><p>我们就得到了WGAN前作中关于生成器梯度消失的第一个论证：<strong>在（近似）最优判别器下，最小化生成器的loss等价于最小化$P_r$与$P_g$之间的JS散度，而由于$P_r$与$P_g$几乎不可能有不可忽略的重叠，所以无论它们相距多远JS散度都是常数$\log 2$，最终导致生成器的梯度（近似）为0，梯度消失。</strong></p><p>接着作者写了很多公式定理从第二个角度进行论证，但是背后的思想也可以直观地解释：</p><ul><li>首先，$P_r$与$P_g$之间几乎不可能有不可忽略的重叠，所以无论它们之间的“缝隙”多狭小，都肯定存在一个最优分割曲面把它们隔开，最多就是在那些可忽略的重叠处隔不开而已。</li><li>由于判别器作为一个神经网络可以无限拟合这个分隔曲面，所以存在一个最优判别器，对几乎所有真实样本给出概率1，对几乎所有生成样本给出概率0，而那些隔不开的部分就是难以被最优判别器分类的样本，但是它们的测度为0，可忽略。</li><li>最优判别器在真实分布和生成分布的支撑集上给出的概率都是常数（1和0），导致生成器的loss梯度为0，梯度消失。</li></ul><p>有了这些理论分析，原始GAN不稳定的原因就彻底清楚了：判别器训练得太好，生成器梯度消失，生成器loss降不下去；判别器训练得不好，生成器梯度不准，四处乱跑。只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样，所以GAN才那么难训练。</p><p>实验辅证如下：</p><blockquote><p>WGAN前作Figure 2。先分别将DCGAN训练1，20，25个epoch，然后固定生成器不动，判别器重新随机初始化从头开始训练，对于第一种形式的生成器loss产生的梯度可以打印出其尺度的变化曲线，可以看到随着判别器的训练，生成器的梯度均迅速衰减。注意y轴是对数坐标轴。</p></blockquote><h2 id="第二种原始GAN形式的问题"><a href="#第二种原始GAN形式的问题" class="headerlink" title="第二种原始GAN形式的问题"></a>第二种原始GAN形式的问题</h2><p><strong>一句话概括：最小化第二种生成器loss函数，会等价于最小化一个不合理的距离衡量，导致两个问题，一是梯度不稳定，二是collapse mode即多样性不足。</strong>WGAN前作又是从两个角度进行了论证，下面只说第一个角度，因为对于第二个角度我难以找到一个直观的解释方式，感兴趣的读者还是去看论文吧（逃）。</p><p>如前文所说，Ian Goodfellow提出的“- log D trick”是把生成器loss改成</p><script type="math/tex;mode=display">\mathbb{E}_{x\sim P_g}[- \log D(x)]</script><p>上文推导已经得到在最优判别器$D^*$下</p><script type="math/tex;mode=display">\mathbb{E}_{x\sim P_r}[\log D^*(x)]</script><p>我们可以把KL散度（注意下面是先g后r）变换成含<img src="http://www.zhihu.com/equation?tex=D%5E%2A" alt="D^*">的形式：</p><script type="math/tex;mode=display">\begin{align}KL(P_g || P_r) &= \mathbb{E}_{x \sim P_g} [\log \frac{P_g(x)}{P_r(x)}] \\&= \mathbb{E}_{x \sim P_g} [\log \frac{P_g(x) / (P_r(x) + P_g(x))}{P_r(x) / (P_r(x) + P_g(x))}] \\&= \mathbb{E}_{x \sim P_g} [\log \frac{1 - D^*(x)}{D^*(x)}] \\&= \mathbb{E}_{x \sim P_g} \log [1 - D^*(x)] -  \mathbb{E}_{x \sim P_g} \log D^*(x)\end{align} \\</script><p>可得最小化目标的等价变形</p><script type="math/tex;mode=display">\begin{align}\mathbb{E}_{x \sim P_g} [-\log D^*(x)] &=  KL(P_g || P_r) -  \mathbb{E}_{x \sim P_g} \log [1 - D^*(x)] \\&= KL(P_g || P_r) - 2JS(P_r || P_g) + 2\log 2 + \mathbb{E}_{x\sim P_r}[\log D^*(x)]\end{align}</script><p>注意上式最后两项不依赖于生成器G，最终得到最小化公式3等价于最小化</p><script type="math/tex;mode=display">KL(P_g || P_r) - 2JS(P_r || P_g)</script><p>这个等价最小化目标存在两个严重的问题。第一是它同时要最小化生成分布与真实分布的KL散度，却又要最大化两者的JS散度，一个要拉近，一个却要推远！这在直观上非常荒谬，在数值上则会导致梯度不稳定，这是后面那个JS散度项的毛病。</p><p>第二，即便是前面那个正常的$KL$散度项也有毛病。因为$KL$散度不是一个对称的衡量，$KL(P_g || P_r)$与$KL(P_r || P_g)$是有差别的。以前者为例</p><ul><li>当$P_g(x)\rightarrow 0$而$P_r(x)\rightarrow 1$时，$P_g(x) \log \frac{P_g(x)}{P_r(x)} \rightarrow 0$，对$KL(P_g || P_r)$贡献趋近0</li><li>当$P_g(x)\rightarrow 1$而$P_r(x)\rightarrow 0$时，$P_g(x) \log \frac{P_g(x)}{P_r(x)} \rightarrow +\infty$，对$KL(P_g || P_r)$贡献趋近正无穷</li></ul><p>换言之，$KL(P_g || P_r)$对于上面两种错误的惩罚是不一样的，第一种错误对应的是“生成器没能生成真实的样本”，惩罚微小；第二种错误对应的是“生成器生成了不真实的样本” ，惩罚巨大。第一种错误对应的是缺乏多样性，第二种错误对应的是缺乏准确性。<strong>这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode。</strong></p><p><strong>第一部分小结：在原始GAN的（近似）最优判别器下，第一种生成器loss面临梯度消失问题，第二种生成器loss面临优化目标荒谬、梯度不稳定、对多样性与准确性惩罚不平衡导致mode collapse这几个问题。</strong></p><p>实验辅证如下：</p><p><img src="https://pic4.zhimg.com/v2-b85cdb4d79d7618213c320cfb3a6d4bf_b.jpg" alt="img"></p><blockquote><p>WGAN前作Figure 3。先分别将DCGAN训练1，20，25个epoch，然后固定生成器不动，判别器重新随机初始化从头开始训练，对于第二种形式的生成器loss产生的梯度可以打印出其尺度的变化曲线，可以看到随着判别器的训练，蓝色和绿色曲线中生成器的梯度迅速增长，说明梯度不稳定，红线对应的是DCGAN相对收敛的状态，梯度才比较稳定。</p></blockquote><h2 id="第二部分：WGAN之前的一个过渡解决方案"><a href="#第二部分：WGAN之前的一个过渡解决方案" class="headerlink" title="第二部分：WGAN之前的一个过渡解决方案"></a>第二部分：WGAN之前的一个过渡解决方案</h2><p>原始GAN问题的根源可以归结为两点，一是等价优化的距离衡量（KL散度、JS散度）不合理，二是生成器随机初始化后的生成分布很难与真实分布有不可忽略的重叠。</p><p>WGAN前作其实已经针对第二点提出了一个解决方案，就是对生成样本和真实样本加噪声，直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是（在第一种原始GAN形式下）梯度消失的问题就解决了。在训练过程中，我们可以对所加的噪声进行退火（annealing），慢慢减小其方差，到后面两个低维流形“本体”都已经有重叠时，就算把噪声完全拿掉，JS散度也能照样发挥作用，继续产生有意义的梯度把两个低维流形拉近，直到它们接近完全重合。以上是对原文的直观解释。</p><p>在这个解决方案下我们可以放心地把判别器训练到接近最优，不必担心梯度消失的问题。而当判别器最优时，对公式9取反可得判别器的最小loss为</p><p>其中$P<em>{r+\epsilon}$和$P</em>{g+\epsilon}$分别是加噪后的真实分布与生成分布。反过来说，从最优判别器的loss可以反推出当前两个加噪分布的JS散度。两个加噪分布的JS散度可以在某种程度上代表两个原本分布的距离，也就是说可以通过最优判别器的loss反映训练进程！……真的有这样的好事吗？</p><p>并没有，因为加噪JS散度的具体数值受到噪声的方差影响，随着噪声的退火，前后的数值就没法比较了，所以它不能成为$P_r$和$P_g$距离的本质性衡量。</p><p>因为本文的重点是WGAN本身，所以WGAN前作的加噪方案简单介绍到这里，感兴趣的读者可以阅读原文了解更多细节。<strong>加噪方案是针对原始GAN问题的第二点根源提出的，解决了训练不稳定的问题，不需要小心平衡判别器训练的火候，可以放心地把判别器训练到接近最优，但是仍然没能够提供一个衡量训练进程的数值指标。但是WGAN本作就从第一点根源出发，用Wasserstein距离代替JS散度，同时完成了稳定训练和进程指标的问题！</strong></p><p>作者未对此方案进行实验验证。</p><h2 id="第三部分：Wasserstein距离的优越性质"><a href="#第三部分：Wasserstein距离的优越性质" class="headerlink" title="第三部分：Wasserstein距离的优越性质"></a>第三部分：Wasserstein距离的优越性质</h2><p>Wasserstein距离又叫Earth-Mover（EM）距离，定义如下：</p><script type="math/tex;mode=display">W(P_r, P_g) = \inf_{\gamma \sim \Pi (P_r, P_g)} \mathbb{E}_{(x, y) \sim \gamma} [||x - y||</script><p>解释如下：$ \Pi (P<em>r, P_g)$是$P_r$和$P_g$组合起来的所有可能的联合分布的集合，反过来说，$\Pi (P_r, P_g)$中每一个分布的边缘分布都是$P_r$和$P_g$。对于每一个可能的联合分布$\gamma$而言，可以从中采样$(x, y) \sim \gamma$得到一个真实样本$x$和一个生成样本$y$，并算出这对样本的距离$||x-y||$，所以可以计算该联合分布$\gamma$下样本对距离的期望值$\mathbb{E}</em>{(x, y) \sim \gamma} [||x - y||$。在所有可能的联合分布中能够对这个期望值取到的下界$\inf<em>{\gamma \sim \Pi (P_r, P_g)} \mathbb{E}</em>{(x, y) \sim \gamma} [||x - y||$，就定义为Wasserstein距离。</p><p>直观上可以把$\mathbb{E}_{(x, y) \sim \gamma} [||x - y||]$理解为在$\gamma$这个“路径规划”下把$P_r$这堆“沙土”挪到$P_g$“位置”所需的“消耗”，而$W(P_r, P_g)$就是“最优路径规划”下的“最小消耗”，所以才叫Earth-Mover（推土机）距离。</p><p><strong>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。</strong>WGAN本作通过简单的例子展示了这一点。考虑如下二维空间中的两个分布$P_1$和$P_2$，$P_1$在线段AB上均匀分布，$P_2$在线段CD上均匀分布，通过控制参数$\theta$可以控制着两个分布的距离远近。</p><p><img src="https://pic3.zhimg.com/v2-c9cc9f8c879e7fe93d6e3bfafd41bd8a_b.jpg" alt="img"></p><p>此时容易得到（读者可自行验证）</p><script type="math/tex;mode=display">KL(P_1 || P_2) = KL(P_1 || P_2) =\begin{cases}+\infty & \text{if $\theta \neq 0$} \\0 & \text{if $\theta = 0$}\end{cases}</script><script type="math/tex;mode=display">JS(P_1||P_2)=\begin{cases}\log 2 & \text{if $\theta \neq 0$} \\0 & \text{if $\theta - 0$}\end{cases}</script><script type="math/tex;mode=display">W(P_0, P_1) = |\theta|</script><p>KL散度和JS散度是突变的，要么最大要么最小，<strong>Wasserstein距离却是平滑的</strong>，如果我们要用梯度下降法优化$\theta$这个参数，前两者根本提供不了梯度，Wasserstein距离却可以。类似地，在高维空间中如果两个分布不重叠或者重叠部分可忽略，则KL和JS既反映不了远近，也提供不了梯度，<strong>但是Wasserstein却可以提供有意义的梯度</strong>。</p><h2 id="第四部分：从Wasserstein距离到WGAN"><a href="#第四部分：从Wasserstein距离到WGAN" class="headerlink" title="第四部分：从Wasserstein距离到WGAN"></a>第四部分：从Wasserstein距离到WGAN</h2><p>既然Wasserstein距离有如此优越的性质，如果我们能够把它定义为生成器的loss，不就可以产生有意义的梯度来更新生成器，使得生成分布被拉向真实分布吗？</p><p>没那么简单，因为Wasserstein距离定义中的$\inf_{\gamma \sim \Pi (P_r, P_g)}$没法直接求解，不过没关系，作者用了一个已有的定理把它变换为如下形式</p><script type="math/tex;mode=display">W(P_r, P_g) = \frac{1}{K} \sup_{||f||_L \leq K} \mathbb{E}_{x \sim P_r} [f(x)</script><p>证明过程被作者丢到论文附录中了，我们也姑且不管，先看看上式究竟说了什么。</p><p>首先需要介绍一个概念——Lipschitz连续。它其实就是在一个连续函数$f$上面额外施加了一个限制，要求存在一个常数$K\geq 0$使得定义域内的任意两个元素$x_1$和$x_2$都满足</p><p>此时称函数$f$的Lipschitz常数为$K$。</p><p>简单理解，比如说$f$的定义域是实数集合，那上面的要求就等价于$f$的导函数绝对值不超过$K$。再比如说$\log (x)$就不是Lipschitz连续，因为它的导函数没有上界。Lipschitz连续条件限制了一个连续函数的最大局部变动幅度。</p><p>公式13的意思就是在要求函数$f$的Lipschitz常数$||f||<em>L$不超过$K$的条件下，对所有可能满足条件的$f$取到$\mathbb{E}</em>{x \sim P_r} [f(x)]$的上界，然后再除以$K$。特别地，我们可以用一组参数$w$来定义一系列可能的函数$f_w$，此时求解公式13可以近似变成求解如下形式</p><script type="math/tex;mode=display">K \cdot W(P_r, P_g) \approx \max_{w: |f_w|_L \leq K} \mathbb{E}_{x \sim P_r} [f_w(x)</script><p>再用上我们搞深度学习的人最熟悉的那一套，不就可以把$f$用一个带参数$w$的神经网络来表示嘛！由于神经网络的拟合能力足够强大，我们有理由相信，这样定义出来的一系列$f<em>w$虽然无法囊括所有可能，但是也足以高度近似公式13要求的那个$sup</em>{||f||_L \leq K} $了。</p><p>最后，还不能忘了满足公式14中$||f<em>w||_L \leq K$这个限制。我们其实不关心具体的K是多少，只要它不是正无穷就行，因为它只是会使得梯度变大K倍，并不会影响梯度的方向。所以作者采取了一个非常简单的做法，就是限制神经网络$f</em>\theta$的所有参数$w_i$的不超过某个范围$[-c, c]$，比如$w_i \in [- 0.01, 0.01$，此时关于输入样本x的导数$\frac{\partial f_w}{\partial x}$也不会超过某个范围，所以一定存在某个不知道的常数K使得$f_w$的局部变动幅度不会超过它，Lipschitz连续条件得以满足。具体在算法实现中，只需要每次更新完$w$后把它clip回这个范围就可以了。</p><p><strong>到此为止，我们可以构造一个含参数$w$、最后一层不是非线性激活层的判别器网络$f_w$，在限制$w$不超过某个范围的条件下，使得</strong></p><script type="math/tex;mode=display">L = \mathbb{E}_{x \sim P_r} [f_w(x)</script><p><strong>尽可能取到最大，此时L就会近似真实分布与生成分布之间的Wasserstein距离（忽略常数倍数K）。注意原始GAN的判别器做的是真假二分类任务，所以最后一层是sigmoid，但是现在WGAN中的判别器$f_w$做的是近似拟合Wasserstein距离，属于回归任务，所以要把最后一层的sigmoid拿掉。</strong></p><p><strong>接下来生成器要近似地最小化Wasserstein距离，可以最小化$L$，由于Wasserstein距离的优良性质，我们不需要担心生成器梯度消失的问题。再考虑到$L$的第一项与生成器无关，就得到了WGAN的两个loss。</strong></p><script type="math/tex;mode=display">\mathbb{E}_{x \sim P_g} [f_w(x)]</script><p>（WGAN生成器loss函数）</p><script type="math/tex;mode=display">\mathbb{E}_{x \sim P_g} [f_w(x)</script><p>（WGAN判别器loss函数）</p><p><strong>可以指示训练进程，其数值越小，表示真实分布与生成分布的Wasserstein距离越小，GAN训练得越好。</strong></p><p>WGAN完整的算法流程已经贴过了，为了方便读者此处再贴一遍：</p><p><img src="https://pic1.zhimg.com/v2-6be6e2ef3d15c4b10c2a943e9bf4db70_b.jpg" alt="img">上文说过，WGAN与原始</p><p>GAN第一种形式相比，只改了四点：</p><ul><li>判别器最后一层去掉sigmoid</li><li>生成器和判别器的loss不取log</li><li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li><li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li></ul><p>前三点都是从理论分析中得到的，已经介绍完毕；第四点却是作者从实验中发现的，属于trick，相对比较“玄”。作者发现如果使用Adam，判别器的loss有时候会崩掉，当它崩掉时，Adam给出的更新方向与梯度方向夹角的cos值就变成负数，更新方向与梯度方向南辕北辙，这意味着判别器的loss梯度是不稳定的，所以不适合用Adam这类基于动量的优化算法。作者改用RMSProp之后，问题就解决了，因为RMSProp适合梯度不稳定的情况。</p><p>对WGAN作者做了不少实验验证，本文只提比较重要的三点。第一，判别器所近似的Wasserstein距离与生成器的生成图片质量高度相关，如下所示（此即题图）：</p><p><img src="https://pic3.zhimg.com/v2-3cfe84e6b6b58c00e013975fe649398e_b.jpg" alt="img">第二，WGAN如果用类似</p><p>DCGAN架构，生成图片的效果与DCGAN差不多：</p><p><img src="https://pic2.zhimg.com/v2-5fdccfd580ea6f96626948cf8698a831_b.jpg" alt="img"></p><p>但是厉害的地方在于WGAN不用DCGAN各种特殊的架构设计也能做到不错的效果，比如如果大家一起拿掉Batch Normalization的话， DCGAN就崩了：</p><p><img src="https://pic1.zhimg.com/v2-8adc9f92a9c6d5a43c00da4411a67c34_b.jpg" alt="img"></p><p>如果WGAN和原始GAN都使用多层全连接网络（MLP），不用CNN，WGAN质量会变差些，但是原始GAN不仅质量变得更差，而且还出现了collapse mode，即多样性不足：</p><p><img src="https://pic3.zhimg.com/v2-972a7823c50e7c8f5edba9ee7a252152_b.jpg" alt="img"></p><p>第三，在所有WGAN的实验中未观察到collapse mode，作者也只说应该是解决了，</p><p>最后补充一点论文没提到，但是我个人觉得比较微妙的问题。判别器所近似的Wasserstein距离能够用来指示单次训练中的训练进程，这个没错；接着作者又说它可以用于比较多次训练进程，指引调参，我倒是觉得需要小心些。比如说我下次训练时改了判别器的层数、节点数等超参，判别器的拟合能力就必然有所波动，再比如说我下次训练时改了生成器两次迭代之间，判别器的迭代次数，这两种常见的变动都会使得Wasserstein距离的拟合误差就与上次不一样。<strong>那么这个拟合误差的变动究竟有多大，或者说不同的人做实验时判别器的拟合能力或迭代次数相差实在太大，那它们之间还能不能直接比较上述指标，我都是存疑的。</strong></p><p>评论区的知友<a href="http://www.zhihu.com/people/822cec1d495864da61b8e7ff62aaef23" target="_blank" rel="external">@Minjie Xu</a> 进一步指出，相比于判别器迭代次数的改变，<strong>对判别器架构超参的改变会直接影响到对应的Lipschitz常数<img src="http://www.zhihu.com/equation?tex=K" alt="K">，进而改变近似Wasserstein距离的倍数，前后两轮训练的指标就肯定不能比较了，</strong>这是需要在实际应用中注意的。对此我想到了一个工程化的解决方式，不是很优雅：取同样一对生成分布和真实分布，让前后两个不同架构的判别器各自拟合到收敛，看收敛到的指标差多少倍，可以近似认为是后面的<img src="http://www.zhihu.com/equation?tex=K_2" alt="K_2">相对前面<img src="http://www.zhihu.com/equation?tex=K_1" alt="K_1">的变化倍数，于是就可以用这个变化倍数校正前后两轮训练的指标。</p><h2 id="第五部分：总结"><a href="#第五部分：总结" class="headerlink" title="第五部分：总结"></a>第五部分：总结</h2><p>WGAN前作分析了Ian Goodfellow提出的原始GAN两种形式各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。</p><p>WGAN前作针对分布重叠问题提出了一个过渡解决方案，通过对生成样本和真实样本加噪声使得两个分布产生重叠，理论上可以解决训练不稳定的问题，可以放心训练判别器到接近最优，但是未能提供一个指示训练进程的可靠指标，也未做实验验证。</p><p>WGAN本作引入了Wasserstein距离，由于它相对KL散度与JS散度具有优越的平滑特性，理论上可以解决梯度消失问题。接着通过数学变换将Wasserstein距离写成可求解的形式，利用一个参数数值范围受限的判别器神经网络来最大化这个形式，就可以近似Wasserstein距离。在此近似最优判别器下优化生成器使得Wasserstein距离缩小，就能有效拉近生成分布与真实分布。WGAN既解决了训练不稳定的问题，也提供了一个可靠的训练进程指标，而且该指标确实与生成样本的质量高度相关。作者对WGAN进行了实验验证。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原帖地址：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/25071913&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/25071913&lt;/a&gt;&lt;/p&gt;&lt;blockqu
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="GAN" scheme="http://yoursite.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)</title>
    <link href="http://yoursite.com/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/"/>
    <id>http://yoursite.com/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/</id>
    <published>2017-04-28T11:46:55.000Z</published>
    <updated>2017-04-28T11:53:35.942Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f" target="_blank" rel="external">Source Blog</a></p><p>PyTorch Install: <a href="http://pytorch.org/" target="_blank" rel="external">http://pytorch.org/</a></p><p>The models play two distinct (literally, <em>adversarial</em>) roles. Given some real data set <strong>R</strong>, <strong>G</strong> is the <em>generator</em>, trying to create fake data that looks just like the genuine data, while <strong>D</strong> is the <em>discriminator</em>, getting data from either the real set or <strong>G </strong>and labeling the difference. Goodfellow’s metaphor (and a fine one it is) was that <strong>G</strong> was like a team of forgers trying to match real paintings with their output, while <strong>D</strong> was the team of detectives trying to tell the difference. (Except that in this case, the forgers <strong>G</strong> never get to see the original data — only the judgments of <strong>D</strong>. They’re like <em>blind</em> forgers.)</p><p><img src="https://cdn-images-1.medium.com/max/800/1*-gFsbymY9oJUQJ-A3GTfeg.png" alt="img"></p><p>In the ideal case, both <strong>D</strong> and <strong>G</strong> would get better over time until <strong>G</strong> had essentially become a “master forger” of the genuine article and <strong>D</strong> was at a loss, “unable to differentiate between the two distributions.”</p><p>In practice, what Goodfellow had shown was that <strong>G</strong> would be able to perform a form of <em>unsupervised learning</em> on the original dataset, finding some way of representing that data in a (possibly) much lower-dimensional manner. And as Yann LeCun famously stated, <a href="https://www.facebook.com/yann.lecun/posts/10153426023477143" target="_blank" rel="external">unsupervised learning is the “cake” of true AI</a>.</p><hr><p>This powerful technique seems like it must require a <strong>metric ton</strong> of code just to get started, right? Nope. Using <a href="http://pytorch.org/" target="_blank" rel="external">PyTorch</a>, we can actually create a very simple GAN in under 50 lines of code. There are really only 5 components to think about:</p><ul><li><strong>R</strong>: The original, genuine data set</li><li><strong>I</strong>: The random noise that goes into the generator as a source of entropy</li><li><strong>G</strong>: The generator which tries to copy/mimic the original data set</li><li><strong>D</strong>: The discriminator which tries to tell apart <strong>G</strong>’s output from <strong>R</strong></li><li>The actual ‘training’ loop where we teach <strong>G</strong> to trick <strong>D</strong> and <strong>D </strong>to <em>beware</em> <strong>G</strong>.</li></ul><p><strong>1.) R</strong>: In our case, we’ll start with the simplest possible <strong>R</strong> — a bell curve. This function takes a mean and a standard deviation and returns a function which provides the right shape of sample data from a Gaussian with those parameters. In our sample code, we’ll use a mean of 4.0 and a standard deviation of 1.25.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*xsuE-nhsJOzk9lfI3rayuw.png" alt="img"></p><p><strong>2.) I</strong>: The input into the generator is also random, but to make our job a little bit harder, let’s use a uniform distribution rather than a normal one. This means that our model <strong>G</strong> can’t simply shift/scale the input to copy <strong>R, </strong>but has to reshape the data in a non-linear way.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*wuhEVnK25V3zXQzuCwFDAg.png" alt="img"></p><p><strong>3.) G</strong>: The generator is a standard feedforward graph — two hidden layers, three linear maps. We’re using an <a href="http://pytorch.org/docs/nn.html#elu" target="_blank" rel="external">ELU (exponential linear unit)</a> because<a href="https://www.linkedin.com/pulse/exponential-linear-units-elu-deep-network-learning-martin-heusel" target="_blank" rel="external">they’re the new black, yo.</a> <strong>G</strong> is going to get the uniformly distributed data samples from <strong>I</strong> and somehow mimic the normally distributed samples from <strong>R</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*NM6wfbhZLSiVnCX33f7eBw.png" alt="img"></p><p><strong>4.) D</strong>: The discriminator code is very similar to <strong>G</strong>’s generator code; a feedforward graph with two hidden layers and three linear maps. It’s going to get samples from either <strong>R</strong> or <strong>G</strong> and will output a single scalar between 0 and 1, interpreted as ‘fake’ vs. ‘real’. This is about as milquetoast as a neural net can get.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*5x9hrP5oozp3e2pm-Mtqmw.png" alt="img"></p><p><strong>5.)</strong> Finally, the training loop alternates between two modes: first training <strong>D</strong> on real data vs. fake data, with <em>accurate</em> labels (think of this as <a href="https://en.wikipedia.org/wiki/Police_Academy_%28film%29" target="_blank" rel="external">Police Academy</a>); and then training <strong>G</strong> to fool <strong>D</strong>, with <em>inaccurate</em> labels (this is more like those preparation montages from <a href="https://en.wikipedia.org/wiki/Ocean%27s_Eleven" target="_blank" rel="external">Ocean’s Eleven</a>). It’s a fight between good and evil, people.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*MESLBNZIWxJp553TWKUADQ.png" alt="img"></p><p>Even if you haven’t seen PyTorch before, you can probably tell what’s going on. In the first (green) section, we push both types of data through <strong>D</strong> and apply a differentiable criterion to <strong>D</strong>’s guesses vs. the actual labels. That pushing is the ‘forward’ step; we then call ‘backward()’ explicitly in order to calculate gradients, which are then used to update <strong>D</strong>’s parameters in the d_optimizer step() call. <strong>G</strong> is used but isn’t trained here.</p><p>Then in the last (red) section, we do the same thing for <strong>G</strong> — note that we also run <strong>G</strong>’s output through <strong>D</strong> (we’re essentially giving the forger a detective to practice on) but we <em>do not optimize or change</em> <strong>D</strong> at this step. We don’t want the detective <strong>D</strong> to learn the wrong labels. Hence, we only call g_optimizer.step().</p><p>And…<em>that’s all</em>. There’s some other boilerplate code but the GAN-specific stuff is just those 5 components, nothing else.</p><hr><p>After a few thousand rounds of this forbidden dance between <strong>D</strong> and <strong>G</strong>, what do we get? The discriminator <strong>D</strong> gets good very quickly (while <strong>G</strong> slowly moves up), but once it gets to a certain level of power, <strong>G</strong> has a worthy adversary and begins to improve. <em>Really</em> improve.</p><p>Over 20,000 training rounds, the mean of <strong>G</strong>’s output overshoots 4.0 but then comes back in a fairly stable, correct range (left). Likewise, the standard deviation initially drops in the wrong direction but then rises up to the desired 1.25 range (right), matching <strong>R</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*2Qm33RqWBKVF3g1Vg2HnVg.png" alt="img"></p><p>Ok, so the basic stats match <strong>R</strong>, eventually. How about the higher moments? Does the shape of the distribution look right? After all, you could certainly have a uniform distribution with a mean of 4.0 and a standard deviation of 1.25, but that wouldn’t really match <strong>R</strong>. Let’s show the final distribution emitted by <strong>G</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*Ary_6gaLxIijk7j2trroBQ.png" alt="img"></p><p>Not bad. The left tail is a bit longer than the right, but the skew and kurtosis are, shall we say, <em>evocative</em> of the original Gaussian.</p><p><strong>G</strong> recovers the original distribution <strong>R</strong> nearly perfectly — and <strong>D</strong> is left cowering in the corner, mumbling to itself, unable to tell fact from fiction. This is <em>precisely</em> the behavior we want (see <a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank" rel="external">Figure 1 in Goodfellow</a>). <strong>From fewer than 50 lines of code</strong>.</p><p>Goodfellow would go on to publish many other papers on GANs, including a <a href="https://arxiv.org/pdf/1606.03498.pdf" target="_blank" rel="external">2016 gem describing some practical improvements</a>, including the minibatch discrimination method adapted here. And <a href="https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks" target="_blank" rel="external">here’s a 2-hour tutorial he presented at NIPS 2016</a>. For TensorFlow users, here’s a parallel <a href="http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/" target="_blank" rel="external">post from Aylien on GANs</a>.</p><p>Ok. Enough talk. <a href="https://github.com/devnag/pytorch-generative-adversarial-networks" target="_blank" rel="external"><strong>Go look at the code</strong></a>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="comment"># Generative Adversarial Networks (GAN) example in PyTorch.</span></div><div class="line"><span class="comment"># See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> torch</div><div class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div><div class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</div><div class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</div><div class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</div><div class="line"></div><div class="line"><span class="comment"># Data params</span></div><div class="line">data_mean = <span class="number">4</span></div><div class="line">data_stddev = <span class="number">1.25</span></div><div class="line"></div><div class="line"><span class="comment"># Model params</span></div><div class="line">g_input_size = <span class="number">1</span>     <span class="comment"># Random noise dimension coming into generator, per output vector</span></div><div class="line">g_hidden_size = <span class="number">50</span>   <span class="comment"># Generator complexity</span></div><div class="line">g_output_size = <span class="number">1</span>    <span class="comment"># size of generated output vector</span></div><div class="line">d_input_size = <span class="number">100</span>   <span class="comment"># Minibatch size - cardinality of distributions</span></div><div class="line">d_hidden_size = <span class="number">50</span>   <span class="comment"># Discriminator complexity</span></div><div class="line">d_output_size = <span class="number">1</span>    <span class="comment"># Single dimension for 'real' vs. 'fake'</span></div><div class="line">minibatch_size = d_input_size</div><div class="line"></div><div class="line">d_learning_rate = <span class="number">2e-4</span>  <span class="comment"># 2e-4</span></div><div class="line">g_learning_rate = <span class="number">2e-4</span></div><div class="line">optim_betas = (<span class="number">0.9</span>, <span class="number">0.999</span>)</div><div class="line">num_epochs = <span class="number">30000</span></div><div class="line">print_interval = <span class="number">200</span></div><div class="line">d_steps = <span class="number">1</span>  <span class="comment"># 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator</span></div><div class="line">g_steps = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># ### Uncomment only one of these</span></div><div class="line"><span class="comment">#(name, preprocess, d_input_func) = ("Raw data", lambda data: data, lambda x: x)</span></div><div class="line">(name, preprocess, d_input_func) = (<span class="string">"Data and variances"</span>, <span class="keyword">lambda</span> data: decorate_with_diffs(data, <span class="number">2.0</span>), <span class="keyword">lambda</span> x: x * <span class="number">2</span>)</div><div class="line"></div><div class="line">print(<span class="string">"Using data [%s]"</span> % (name))</div><div class="line"></div><div class="line"><span class="comment"># ##### DATA: Target data and generator input data</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_distribution_sampler</span><span class="params">(mu, sigma)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> n: torch.Tensor(np.random.normal(mu, sigma, (<span class="number">1</span>, n)))  <span class="comment"># Gaussian</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_generator_input_sampler</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> m, n: torch.rand(m, n)  <span class="comment"># Uniform-dist data into generator, _NOT_ Gaussian</span></div><div class="line"></div><div class="line"><span class="comment"># ##### MODELS: Generator model and discriminator model</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Generator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.sigmoid(self.map2(x))</div><div class="line">        <span class="keyword">return</span> self.map3(x)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Discriminator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.elu(self.map2(x))</div><div class="line">        <span class="keyword">return</span> F.sigmoid(self.map3(x))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract</span><span class="params">(v)</span>:</span></div><div class="line">    <span class="keyword">return</span> v.data.storage().tolist()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stats</span><span class="params">(d)</span>:</span></div><div class="line">    <span class="keyword">return</span> [np.mean(d), np.std(d)]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">decorate_with_diffs</span><span class="params">(data, exponent)</span>:</span></div><div class="line">    mean = torch.mean(data.data, <span class="number">1</span>)</div><div class="line">    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[<span class="number">0</span>][<span class="number">0</span>])</div><div class="line">    diffs = torch.pow(data - Variable(mean_broadcast), exponent)</div><div class="line">    <span class="keyword">return</span> torch.cat([data, diffs], <span class="number">1</span>)</div><div class="line"></div><div class="line">d_sampler = get_distribution_sampler(data_mean, data_stddev)</div><div class="line">gi_sampler = get_generator_input_sampler()</div><div class="line">G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)</div><div class="line">D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)</div><div class="line">criterion = nn.BCELoss()  <span class="comment"># Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss</span></div><div class="line">d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)</div><div class="line">g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)</div><div class="line"></div><div class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</div><div class="line">    <span class="keyword">for</span> d_index <span class="keyword">in</span> range(d_steps):</div><div class="line">        <span class="comment"># 1. Train D on real+fake</span></div><div class="line">        D.zero_grad()</div><div class="line"></div><div class="line">        <span class="comment">#  1A: Train D on real</span></div><div class="line">        d_real_data = Variable(d_sampler(d_input_size))</div><div class="line">        d_real_decision = D(preprocess(d_real_data))</div><div class="line">        d_real_error = criterion(d_real_decision, Variable(torch.ones(<span class="number">1</span>)))  <span class="comment"># ones = true</span></div><div class="line">        d_real_error.backward() <span class="comment"># compute/store gradients, but don't change params</span></div><div class="line"></div><div class="line">        <span class="comment">#  1B: Train D on fake</span></div><div class="line">        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        d_fake_data = G(d_gen_input).detach()  <span class="comment"># detach to avoid training G on these labels</span></div><div class="line">        d_fake_decision = D(preprocess(d_fake_data.t()))</div><div class="line">        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(<span class="number">1</span>)))  <span class="comment"># zeros = fake</span></div><div class="line">        d_fake_error.backward()</div><div class="line">        d_optimizer.step()     <span class="comment"># Only optimizes D's parameters; changes based on stored gradients from backward()</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> g_index <span class="keyword">in</span> range(g_steps):</div><div class="line">        <span class="comment"># 2. Train G on D's response (but DO NOT train D on these labels)</span></div><div class="line">        G.zero_grad()</div><div class="line"></div><div class="line">        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        g_fake_data = G(gen_input)</div><div class="line">        dg_fake_decision = D(preprocess(g_fake_data.t()))</div><div class="line">        g_error = criterion(dg_fake_decision, Variable(torch.ones(<span class="number">1</span>)))  <span class="comment"># we want to fool, so pretend it's all genuine</span></div><div class="line"></div><div class="line">        g_error.backward()</div><div class="line">        g_optimizer.step()  <span class="comment"># Only optimizes G's parameters</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> epoch % print_interval == <span class="number">0</span>:</div><div class="line">        print(<span class="string">"%s: D: %s/%s G: %s (Real: %s, Fake: %s) "</span> % (epoch,</div><div class="line">                                                            extract(d_real_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(d_fake_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(g_error)[<span class="number">0</span>],</div><div class="line">                                                            stats(extract(d_real_data)),</div><div class="line">                                                            stats(extract(d_fake_data))))</div></pre></td></tr></table></figure><p>Result：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div></pre></td><td class="code"><pre><div class="line">ewan<span class="meta">@ubuntu</span>:~<span class="regexp">/Documents/g</span>an/pytorch-generative-adversarial-networks$ python gan_pytorch.py </div><div class="line">Using data [Data and variances]</div><div class="line"><span class="number">0</span>: D: <span class="number">0.636019647121</span>/<span class="number">0.687892377377</span> G: <span class="number">0.692580163479</span> (Real: [<span class="number">4.0121619534492492</span>, <span class="number">1.3228379995364423</span>], Fake: [<span class="number">0.36497069358825684</span>, <span class="number">0.0040907625909989871</span>]) </div><div class="line"><span class="number">200</span>: D: <span class="number">2.92067015835e-05</span>/<span class="number">0.474851727486</span> G: <span class="number">1.00973010063</span> (Real: [<span class="number">4.0935744738578794</span>, <span class="number">1.3016500752040552</span>], Fake: [<span class="number">-0.5716635638475418</span>, <span class="number">0.019948046232028654</span>]) </div><div class="line"><span class="number">400</span>: D: <span class="number">0.0014917049557</span>/<span class="number">0.502498149872</span> G: <span class="number">0.943185687065</span> (Real: [<span class="number">4.198446000814438</span>, <span class="number">1.1262929992527102</span>], Fake: [<span class="number">-0.21786054879426955</span>, <span class="number">0.0067362612730766476</span>]) </div><div class="line"><span class="number">600</span>: D: <span class="number">6.4969262894e-06</span>/<span class="number">0.384293109179</span> G: <span class="number">1.15257537365</span> (Real: [<span class="number">3.8602226501703263</span>, <span class="number">1.3292726136430937</span>], Fake: [<span class="number">-0.29857088595628739</span>, <span class="number">0.03924369275813562</span>]) </div><div class="line"><span class="number">800</span>: D: <span class="number">1.84774467016e-06</span>/<span class="number">0.211148008704</span> G: <span class="number">1.67116880417</span> (Real: [<span class="number">4.0269100540876392</span>, <span class="number">1.2954351206409835</span>], Fake: [<span class="number">-0.32296697288751602</span>, <span class="number">0.14901211840131676</span>]) </div><div class="line"><span class="number">1000</span>: D: <span class="number">9.02455067262e-05</span>/<span class="number">0.0219078511</span> G: <span class="number">4.19585323334</span> (Real: [<span class="number">3.9491306754946707</span>, <span class="number">1.3613105655283608</span>], Fake: [<span class="number">0.13110455054789782</span>, <span class="number">0.5252103421913964</span>]) </div><div class="line"><span class="number">1200</span>: D: <span class="number">0.00441630883142</span>/<span class="number">0.137605398893</span> G: <span class="number">2.78980493546</span> (Real: [<span class="number">4.238747425079346</span>, <span class="number">1.1837142728845262</span>], Fake: [<span class="number">2.3851456820964811</span>, <span class="number">0.69947230698573948</span>]) </div><div class="line"><span class="number">1400</span>: D: <span class="number">0.291683584452</span>/<span class="number">0.824121117592</span> G: <span class="number">0.26126781106</span> (Real: [<span class="number">3.8486315739154815</span>, <span class="number">1.2074486225815622</span>], Fake: [<span class="number">3.4868409335613251</span>, <span class="number">1.2438192602257458</span>]) </div><div class="line"><span class="number">1600</span>: D: <span class="number">0.503275632858</span>/<span class="number">1.08712184429</span> G: <span class="number">0.628099560738</span> (Real: [<span class="number">3.7856648898124696</span>, <span class="number">1.1925325100947208</span>], Fake: [<span class="number">3.9149187129735945</span>, <span class="number">1.5374543372663099</span>]) </div><div class="line"><span class="number">1800</span>: D: <span class="number">0.992162883282</span>/<span class="number">0.955306172371</span> G: <span class="number">0.215137541294</span> (Real: [<span class="number">3.9097139459848402</span>, <span class="number">1.3729001379532129</span>], Fake: [<span class="number">4.9751595187187192</span>, <span class="number">1.2850838287273094</span>]) </div><div class="line"><span class="number">2000</span>: D: <span class="number">0.701098382473</span>/<span class="number">0.634775817394</span> G: <span class="number">0.389043629169</span> (Real: [<span class="number">3.9641699814796447</span>, <span class="number">1.1512756986625183</span>], Fake: [<span class="number">5.0374661159515384</span>, <span class="number">1.5190411587235346</span>]) </div><div class="line"><span class="number">2200</span>: D: <span class="number">0.510353624821</span>/<span class="number">0.350295126438</span> G: <span class="number">1.5988701582</span> (Real: [<span class="number">4.0406568145751951</span>, <span class="number">1.3612318676859239</span>], Fake: [<span class="number">5.4763065743446351</span>, <span class="number">1.2736378899688456</span>]) </div><div class="line"><span class="number">2400</span>: D: <span class="number">0.895085930824</span>/<span class="number">0.400622785091</span> G: <span class="number">0.922062814236</span> (Real: [<span class="number">3.8292097043991089</span>, <span class="number">1.1506111704583193</span>], Fake: [<span class="number">4.5642045128345492</span>, <span class="number">1.7082890861364539</span>]) </div><div class="line"><span class="number">2600</span>: D: <span class="number">0.802581310272</span>/<span class="number">0.717123866081</span> G: <span class="number">0.572393655777</span> (Real: [<span class="number">4.0654918360710148</span>, <span class="number">1.2552944260604222</span>], Fake: [<span class="number">5.1286249160766602</span>, <span class="number">1.0479449058428656</span>]) </div><div class="line"><span class="number">2800</span>: D: <span class="number">0.51098883152</span>/<span class="number">0.489002883434</span> G: <span class="number">0.842381119728</span> (Real: [<span class="number">4.0405197954177856</span>, <span class="number">1.136660175398452</span>], Fake: [<span class="number">3.9549839448928834</span>, <span class="number">1.1751749984899784</span>]) </div><div class="line"><span class="number">3000</span>: D: <span class="number">0.496278882027</span>/<span class="number">0.97537201643</span> G: <span class="number">0.753688693047</span> (Real: [<span class="number">4.0026307255029678</span>, <span class="number">1.2446167315972034</span>], Fake: [<span class="number">3.2340782660245897</span>, <span class="number">1.2949288892421307</span>]) </div><div class="line"><span class="number">3200</span>: D: <span class="number">0.696556508541</span>/<span class="number">0.829834342003</span> G: <span class="number">0.475445389748</span> (Real: [<span class="number">3.9983750417828561</span>, <span class="number">1.2828095340103229</span>], Fake: [<span class="number">3.5434492731094362</span>, <span class="number">0.98673911467128028</span>]) </div><div class="line"><span class="number">3400</span>: D: <span class="number">0.479906737804</span>/<span class="number">0.477254271507</span> G: <span class="number">1.2421528101</span> (Real: [<span class="number">4.1585888534784319</span>, <span class="number">1.2672863214247221</span>], Fake: [<span class="number">3.3173918831348419</span>, <span class="number">1.156708995162234</span>]) </div><div class="line"><span class="number">3600</span>: D: <span class="number">1.36562228203</span>/<span class="number">0.508370876312</span> G: <span class="number">0.550418972969</span> (Real: [<span class="number">4.0406067597866056</span>, <span class="number">1.1363201759386616</span>], Fake: [<span class="number">4.4300824308395388</span>, <span class="number">1.0639278538481793</span>]) </div><div class="line"><span class="number">3800</span>: D: <span class="number">0.538426816463</span>/<span class="number">0.622343420982</span> G: <span class="number">0.786149024963</span> (Real: [<span class="number">4.0097330248355867</span>, <span class="number">1.1609232820569348</span>], Fake: [<span class="number">4.5179304122924808</span>, <span class="number">1.2347411732817635</span>]) </div><div class="line"><span class="number">4000</span>: D: <span class="number">0.350504934788</span>/<span class="number">0.361344873905</span> G: <span class="number">0.728424191475</span> (Real: [<span class="number">3.7975878280401232</span>, <span class="number">1.2378775025626094</span>], Fake: [<span class="number">4.3484812033176423</span>, <span class="number">1.4327683271077338</span>]) </div><div class="line"><span class="number">4200</span>: D: <span class="number">0.912463009357</span>/<span class="number">0.779066801071</span> G: <span class="number">0.840294659138</span> (Real: [<span class="number">3.9861780107021332</span>, <span class="number">1.2293009498211762</span>], Fake: [<span class="number">4.0718169224262235</span>, <span class="number">1.2044778720046834</span>]) </div><div class="line"><span class="number">4400</span>: D: <span class="number">0.814347147942</span>/<span class="number">0.794115483761</span> G: <span class="number">0.889387726784</span> (Real: [<span class="number">3.9556436133384705</span>, <span class="number">1.1131208050960595</span>], Fake: [<span class="number">3.6148070895671847</span>, <span class="number">1.1790021094109027</span>]) </div><div class="line"><span class="number">4600</span>: D: <span class="number">0.637132883072</span>/<span class="number">0.639598190784</span> G: <span class="number">0.835896074772</span> (Real: [<span class="number">4.0807307386398319</span>, <span class="number">1.1590112689981971</span>], Fake: [<span class="number">3.6376679444313051</span>, <span class="number">1.2540016088688517</span>]) </div><div class="line"><span class="number">4800</span>: D: <span class="number">0.816388785839</span>/<span class="number">0.629823803902</span> G: <span class="number">0.6337043643</span> (Real: [<span class="number">4.1595975148677828</span>, <span class="number">1.2996693029809485</span>], Fake: [<span class="number">4.0303308999538423</span>, <span class="number">1.3050560562935769</span>]) </div><div class="line"><span class="number">5000</span>: D: <span class="number">1.38226401806</span>/<span class="number">0.714248239994</span> G: <span class="number">1.17240273952</span> (Real: [<span class="number">3.9217003214359285</span>, <span class="number">1.3408209709046912</span>], Fake: [<span class="number">4.4204820060729979</span>, <span class="number">1.0378887480226417</span>]) </div><div class="line"><span class="number">5200</span>: D: <span class="number">0.752707779408</span>/<span class="number">0.432243227959</span> G: <span class="number">0.735915839672</span> (Real: [<span class="number">4.033863249272108</span>, <span class="number">1.417255801501303</span>], Fake: [<span class="number">3.7434970003366472</span>, <span class="number">1.4305561672741818</span>]) </div><div class="line"><span class="number">5400</span>: D: <span class="number">0.672449588776</span>/<span class="number">0.694190680981</span> G: <span class="number">0.671269893646</span> (Real: [<span class="number">3.9849637061357499</span>, <span class="number">1.3054745436415693</span>], Fake: [<span class="number">3.7987613070011137</span>, <span class="number">1.1584021967574571</span>]) </div><div class="line"><span class="number">5600</span>: D: <span class="number">0.633513212204</span>/<span class="number">0.678804934025</span> G: <span class="number">0.736048042774</span> (Real: [<span class="number">3.8742538380622862</span>, <span class="number">1.1924929483627851</span>], Fake: [<span class="number">4.0905960440635685</span>, <span class="number">1.0496450658176097</span>]) </div><div class="line"><span class="number">5800</span>: D: <span class="number">0.954816102982</span>/<span class="number">0.619474828243</span> G: <span class="number">0.847522497177</span> (Real: [<span class="number">4.0848416697978971</span>, <span class="number">1.2377045321962332</span>], Fake: [<span class="number">4.5059887909889218</span>, <span class="number">1.0769809353783582</span>]) </div><div class="line"><span class="number">6000</span>: D: <span class="number">0.634225904942</span>/<span class="number">0.653471052647</span> G: <span class="number">0.402414888144</span> (Real: [<span class="number">3.9909452509880068</span>, <span class="number">1.2152347623325401</span>], Fake: [<span class="number">3.9412865948677065</span>, <span class="number">1.2808620107297906</span>]) </div><div class="line"><span class="number">6200</span>: D: <span class="number">0.733776032925</span>/<span class="number">0.414616316557</span> G: <span class="number">0.969770550728</span> (Real: [<span class="number">4.0096452310681343</span>, <span class="number">1.2858629342885464</span>], Fake: [<span class="number">3.4776910370588303</span>, <span class="number">1.4216167469252254</span>]) </div><div class="line"><span class="number">6400</span>: D: <span class="number">0.483776688576</span>/<span class="number">0.456314682961</span> G: <span class="number">0.42595911026</span> (Real: [<span class="number">4.16927042722702</span>, <span class="number">1.2557057135387499</span>], Fake: [<span class="number">3.905275868177414</span>, <span class="number">1.3509040440658031</span>]) </div><div class="line"><span class="number">6600</span>: D: <span class="number">1.06177055836</span>/<span class="number">0.443961560726</span> G: <span class="number">0.910483181477</span> (Real: [<span class="number">4.0327691116929056</span>, <span class="number">1.1752792712434861</span>], Fake: [<span class="number">4.1322225379943847</span>, <span class="number">1.3041032842304898</span>]) </div><div class="line"><span class="number">6800</span>: D: <span class="number">0.911615252495</span>/<span class="number">0.851063728333</span> G: <span class="number">0.822307884693</span> (Real: [<span class="number">4.0429812586307525</span>, <span class="number">1.0149434426406105</span>], Fake: [<span class="number">4.181604235172272</span>, <span class="number">1.1091966315801844</span>]) </div><div class="line"><span class="number">7000</span>: D: <span class="number">0.859644412994</span>/<span class="number">0.819373309612</span> G: <span class="number">0.683367550373</span> (Real: [<span class="number">4.0413902151584624</span>, <span class="number">1.2697299173474621</span>], Fake: [<span class="number">3.6461249232292174</span>, <span class="number">1.1392232969008105</span>]) </div><div class="line"><span class="number">7200</span>: D: <span class="number">0.697537004948</span>/<span class="number">1.29639554024</span> G: <span class="number">0.567749083042</span> (Real: [<span class="number">3.9289280462265013</span>, <span class="number">1.1476723124689931</span>], Fake: [<span class="number">4.3612218284606934</span>, <span class="number">1.1698644305174593</span>]) </div><div class="line"><span class="number">7400</span>: D: <span class="number">0.892510712147</span>/<span class="number">0.93148213625</span> G: <span class="number">1.18729686737</span> (Real: [<span class="number">3.9838603484630584</span>, <span class="number">1.10640478112829</span>], Fake: [<span class="number">4.1228645443916321</span>, <span class="number">1.2695625804586594</span>]) </div><div class="line"><span class="number">7600</span>: D: <span class="number">0.855136275291</span>/<span class="number">0.683420717716</span> G: <span class="number">0.87994658947</span> (Real: [<span class="number">4.1161885654926298</span>, <span class="number">1.1923004904972447</span>], Fake: [<span class="number">3.6958885985612868</span>, <span class="number">1.3379389180110717</span>]) </div><div class="line"><span class="number">7800</span>: D: <span class="number">0.549697399139</span>/<span class="number">1.37823116779</span> G: <span class="number">0.398991644382</span> (Real: [<span class="number">4.2173074555397037</span>, <span class="number">1.2371073094023581</span>], Fake: [<span class="number">3.8741448554396629</span>, <span class="number">1.3837623378110455</span>]) </div><div class="line"><span class="number">8000</span>: D: <span class="number">1.35398185253</span>/<span class="number">0.410179078579</span> G: <span class="number">0.527717351913</span> (Real: [<span class="number">3.9588229835033415</span>, <span class="number">1.3744496473744439</span>], Fake: [<span class="number">3.9429207968711855</span>, <span class="number">1.3684983506717674</span>]) </div><div class="line"><span class="number">8200</span>: D: <span class="number">0.700774013996</span>/<span class="number">0.295857429504</span> G: <span class="number">0.803082704544</span> (Real: [<span class="number">3.8515358114242555</span>, <span class="number">1.2566173136350174</span>], Fake: [<span class="number">3.7108538401126863</span>, <span class="number">1.3342916614304938</span>]) </div><div class="line"><span class="number">8400</span>: D: <span class="number">0.689352571964</span>/<span class="number">0.590398311615</span> G: <span class="number">0.698961615562</span> (Real: [<span class="number">3.965521250963211</span>, <span class="number">1.2231963456729893</span>], Fake: [<span class="number">4.6866454958915709</span>, <span class="number">1.1286615282559416</span>]) </div><div class="line"><span class="number">8600</span>: D: <span class="number">0.19632807374</span>/<span class="number">0.604559898376</span> G: <span class="number">0.812706291676</span> (Real: [<span class="number">3.8928249645233155</span>, <span class="number">1.3264703109197318</span>], Fake: [<span class="number">3.918080286383629</span>, <span class="number">1.2016505045193488</span>]) </div><div class="line"><span class="number">8800</span>: D: <span class="number">0.595732450485</span>/<span class="number">0.572122216225</span> G: <span class="number">0.738678693771</span> (Real: [<span class="number">3.7554583859443667</span>, <span class="number">1.2011572644775179</span>], Fake: [<span class="number">3.8252914756536485</span>, <span class="number">1.1905187885079342</span>]) </div><div class="line"><span class="number">9000</span>: D: <span class="number">0.232542961836</span>/<span class="number">1.26930451393</span> G: <span class="number">0.834500789642</span> (Real: [<span class="number">3.9203160056471824</span>, <span class="number">1.2725988502730134</span>], Fake: [<span class="number">4.1613124001026156</span>, <span class="number">1.2681795442466237</span>]) </div><div class="line"><span class="number">9200</span>: D: <span class="number">1.257376194</span>/<span class="number">0.5735257864</span> G: <span class="number">0.554405272007</span> (Real: [<span class="number">3.8860677522420883</span>, <span class="number">1.1041807259307903</span>], Fake: [<span class="number">3.9102136331796644</span>, <span class="number">1.3811967247690093</span>]) </div><div class="line"><span class="number">9400</span>: D: <span class="number">0.610212028027</span>/<span class="number">0.538761377335</span> G: <span class="number">0.558459818363</span> (Real: [<span class="number">4.0015355503559116</span>, <span class="number">0.99711450973270277</span>], Fake: [<span class="number">3.8555663478374482</span>, <span class="number">1.1037480705144518</span>]) </div><div class="line"><span class="number">9600</span>: D: <span class="number">0.702151358128</span>/<span class="number">0.81621837616</span> G: <span class="number">0.706716835499</span> (Real: [<span class="number">4.0513852632045744</span>, <span class="number">1.1984303669025829</span>], Fake: [<span class="number">4.2933621263504032</span>, <span class="number">1.1478353305254103</span>]) </div><div class="line"><span class="number">9800</span>: D: <span class="number">0.511451423168</span>/<span class="number">0.670217812061</span> G: <span class="number">0.873916983604</span> (Real: [<span class="number">3.935146123766899</span>, <span class="number">1.3218541944694313</span>], Fake: [<span class="number">4.2863738107681275</span>, <span class="number">1.1362357473661524</span>]) </div><div class="line"><span class="number">10000</span>: D: <span class="number">0.587130308151</span>/<span class="number">0.764386773109</span> G: <span class="number">0.714644312859</span> (Real: [<span class="number">4.0829932641983033</span>, <span class="number">1.1844677307174318</span>], Fake: [<span class="number">4.2149634605646131</span>, <span class="number">1.1542778585504672</span>]) </div><div class="line"><span class="number">10200</span>: D: <span class="number">0.454408079386</span>/<span class="number">0.390097141266</span> G: <span class="number">0.694087386131</span> (Real: [<span class="number">3.9480907583236693</span>, <span class="number">1.2586832917742197</span>], Fake: [<span class="number">3.9525690937042235</span>, <span class="number">1.3555640918653922</span>]) </div><div class="line"><span class="number">10400</span>: D: <span class="number">0.232991695404</span>/<span class="number">0.377689123154</span> G: <span class="number">0.839949011803</span> (Real: [<span class="number">3.9636431083083155</span>, <span class="number">1.2146210496905581</span>], Fake: [<span class="number">4.0022356742620468</span>, <span class="number">1.0348462356745984</span>]) </div><div class="line"><span class="number">10600</span>: D: <span class="number">0.887756228447</span>/<span class="number">0.452646583319</span> G: <span class="number">0.776298880577</span> (Real: [<span class="number">4.1107078218460087</span>, <span class="number">1.3061081296488184</span>], Fake: [<span class="number">4.3001403945684435</span>, <span class="number">1.3191353715419794</span>]) </div><div class="line"><span class="number">10800</span>: D: <span class="number">0.988030552864</span>/<span class="number">0.472889751196</span> G: <span class="number">2.00703763962</span> (Real: [<span class="number">4.1303015506267551</span>, <span class="number">1.2646447231333668</span>], Fake: [<span class="number">4.2425211107730867</span>, <span class="number">1.2706986066792705</span>]) </div><div class="line"><span class="number">11000</span>: D: <span class="number">0.962553679943</span>/<span class="number">1.00584948063</span> G: <span class="number">0.458068579435</span> (Real: [<span class="number">4.1017441129684444</span>, <span class="number">1.1564779436003478</span>], Fake: [<span class="number">3.861787896156311</span>, <span class="number">1.2478181443952361</span>]) </div><div class="line"><span class="number">11200</span>: D: <span class="number">0.404395908117</span>/<span class="number">0.560545325279</span> G: <span class="number">0.764987766743</span> (Real: [<span class="number">3.8819530367851258</span>, <span class="number">1.1290593525971337</span>], Fake: [<span class="number">4.0393019503355028</span>, <span class="number">1.1760851438968263</span>]) </div><div class="line"><span class="number">11400</span>: D: <span class="number">1.04482722282</span>/<span class="number">0.170368790627</span> G: <span class="number">0.979512214661</span> (Real: [<span class="number">4.0775347077846531</span>, <span class="number">1.1743573984958275</span>], Fake: [<span class="number">4.4076948529481887</span>, <span class="number">1.1430737801156545</span>]) </div><div class="line"><span class="number">11600</span>: D: <span class="number">0.767144262791</span>/<span class="number">0.419019073248</span> G: <span class="number">0.804197788239</span> (Real: [<span class="number">4.1507718646526337</span>, <span class="number">1.2935215526943189</span>], Fake: [<span class="number">4.2565110635757444</span>, <span class="number">1.1195747875890809</span>]) </div><div class="line"><span class="number">11800</span>: D: <span class="number">0.328228145838</span>/<span class="number">0.192100420594</span> G: <span class="number">0.694948136806</span> (Real: [<span class="number">4.2615561389923098</span>, <span class="number">1.3187283101366121</span>], Fake: [<span class="number">3.7841238260269163</span>, <span class="number">1.2796545407667934</span>]) </div><div class="line"><span class="number">12000</span>: D: <span class="number">0.939581632614</span>/<span class="number">0.512252509594</span> G: <span class="number">0.486280798912</span> (Real: [<span class="number">4.1770594882965089</span>, <span class="number">1.2492834466325793</span>], Fake: [<span class="number">4.0997331076860428</span>, <span class="number">1.0701209918243111</span>]) </div><div class="line"><span class="number">12200</span>: D: <span class="number">0.964525461197</span>/<span class="number">0.397465586662</span> G: <span class="number">1.45534229279</span> (Real: [<span class="number">3.9129967219382524</span>, <span class="number">1.3473476671217695</span>], Fake: [<span class="number">4.3561846733093263</span>, <span class="number">1.1667221650406194</span>]) </div><div class="line"><span class="number">12400</span>: D: <span class="number">0.516430974007</span>/<span class="number">0.255626231432</span> G: <span class="number">0.753806650639</span> (Real: [<span class="number">3.9942912605404852</span>, <span class="number">1.3623400447216258</span>], Fake: [<span class="number">4.2171517282724382</span>, <span class="number">1.2046534326031684</span>]) </div><div class="line"><span class="number">12600</span>: D: <span class="number">0.050210531801</span>/<span class="number">0.567070662975</span> G: <span class="number">0.887824892998</span> (Real: [<span class="number">3.9560802054405211</span>, <span class="number">1.3569670682588555</span>], Fake: [<span class="number">3.6434229278564452</span>, <span class="number">1.2798963544271591</span>]) </div><div class="line"><span class="number">12800</span>: D: <span class="number">0.566556215286</span>/<span class="number">1.45121753216</span> G: <span class="number">2.67591071129</span> (Real: [<span class="number">4.0868541407585148</span>, <span class="number">1.1440918337515926</span>], Fake: [<span class="number">3.7308121472597122</span>, <span class="number">1.2567484994327229</span>]) </div><div class="line"><span class="number">13000</span>: D: <span class="number">0.285438686609</span>/<span class="number">1.26493763924</span> G: <span class="number">0.714931368828</span> (Real: [<span class="number">4.0406689298152925</span>, <span class="number">1.2295255598171184</span>], Fake: [<span class="number">4.1976348906755447</span>, <span class="number">1.2778464434389283</span>]) </div><div class="line"><span class="number">13200</span>: D: <span class="number">0.420082330704</span>/<span class="number">0.20268279314</span> G: <span class="number">1.13221895695</span> (Real: [<span class="number">4.0006502330303189</span>, <span class="number">1.1790149224725006</span>], Fake: [<span class="number">4.2336275362968445</span>, <span class="number">1.2803975596845565</span>]) </div><div class="line"><span class="number">13400</span>: D: <span class="number">0.219869300723</span>/<span class="number">0.733704686165</span> G: <span class="number">1.4634616375</span> (Real: [<span class="number">3.8348834168910981</span>, <span class="number">1.240605849665303</span>], Fake: [<span class="number">3.8208065938949587</span>, <span class="number">1.3042463825727604</span>]) </div><div class="line"><span class="number">13600</span>: D: <span class="number">1.35286784172</span>/<span class="number">0.161317944527</span> G: <span class="number">2.29795908928</span> (Real: [<span class="number">4.0841373348236081</span>, <span class="number">1.2295542819596996</span>], Fake: [<span class="number">4.0513113558292391</span>, <span class="number">1.2789595441318489</span>]) </div><div class="line"><span class="number">13800</span>: D: <span class="number">0.188396275043</span>/<span class="number">0.38589566946</span> G: <span class="number">1.38826131821</span> (Real: [<span class="number">4.0228236329555509</span>, <span class="number">1.3524482715610078</span>], Fake: [<span class="number">4.2307587480545044</span>, <span class="number">1.2042737228043698</span>]) </div><div class="line"><span class="number">14000</span>: D: <span class="number">0.0101562952623</span>/<span class="number">0.363918542862</span> G: <span class="number">1.24292945862</span> (Real: [<span class="number">4.0695835274457934</span>, <span class="number">1.4484548400603423</span>], Fake: [<span class="number">4.3588982570171355</span>, <span class="number">1.2305509242343933</span>]) </div><div class="line"><span class="number">14200</span>: D: <span class="number">0.308517187834</span>/<span class="number">0.687216579914</span> G: <span class="number">0.831201374531</span> (Real: [<span class="number">4.1314239382743834</span>, <span class="number">1.2039768851618762</span>], Fake: [<span class="number">4.3469831347465515</span>, <span class="number">1.1622408025070994</span>]) </div><div class="line"><span class="number">14400</span>: D: <span class="number">1.05658388138</span>/<span class="number">0.777651846409</span> G: <span class="number">0.713593065739</span> (Real: [<span class="number">3.9307258637249469</span>, <span class="number">1.3932677098843045</span>], Fake: [<span class="number">3.8781710839271546</span>, <span class="number">1.3920662615905985</span>]) </div><div class="line"><span class="number">14600</span>: D: <span class="number">0.428974717855</span>/<span class="number">0.430344074965</span> G: <span class="number">0.865560889244</span> (Real: [<span class="number">4.2443156433105464</span>, <span class="number">1.4786604488020483</span>], Fake: [<span class="number">3.9386759352684022</span>, <span class="number">1.2173706417721266</span>]) </div><div class="line"><span class="number">14800</span>: D: <span class="number">0.358524769545</span>/<span class="number">0.631785154343</span> G: <span class="number">1.72760403156</span> (Real: [<span class="number">4.0897545439004901</span>, <span class="number">1.3611061267905207</span>], Fake: [<span class="number">4.0185626268386843</span>, <span class="number">1.2011546705663261</span>]) </div><div class="line"><span class="number">15000</span>: D: <span class="number">0.451200634241</span>/<span class="number">0.451773911715</span> G: <span class="number">1.10325527191</span> (Real: [<span class="number">3.9933083570003509</span>, <span class="number">1.0881706638388742</span>], Fake: [<span class="number">3.902902855873108</span>, <span class="number">1.1771562868487595</span>]) </div><div class="line"><span class="number">15200</span>: D: <span class="number">0.756480932236</span>/<span class="number">0.419855684042</span> G: <span class="number">0.942300021648</span> (Real: [<span class="number">4.1753564620018002</span>, <span class="number">1.3629881946025171</span>], Fake: [<span class="number">3.8721090507507325</span>, <span class="number">1.189488508024922</span>]) </div><div class="line"><span class="number">15400</span>: D: <span class="number">0.219109147787</span>/<span class="number">0.190036550164</span> G: <span class="number">2.20304942131</span> (Real: [<span class="number">3.9836783826351168</span>, <span class="number">1.4838718408508595</span>], Fake: [<span class="number">3.9491609585285188</span>, <span class="number">1.1700151592543104</span>]) </div><div class="line"><span class="number">15600</span>: D: <span class="number">1.01965582371</span>/<span class="number">0.519556045532</span> G: <span class="number">1.10594069958</span> (Real: [<span class="number">4.1213941669464109</span>, <span class="number">1.2398676800048194</span>], Fake: [<span class="number">4.1908504700660707</span>, <span class="number">1.1195751576139747</span>]) </div><div class="line"><span class="number">15800</span>: D: <span class="number">0.733263611794</span>/<span class="number">0.697221815586</span> G: <span class="number">0.84056687355</span> (Real: [<span class="number">4.0593542096018789</span>, <span class="number">1.1946663317303297</span>], Fake: [<span class="number">4.3031868946552274</span>, <span class="number">1.0306412415157991</span>]) </div><div class="line"><span class="number">16000</span>: D: <span class="number">0.400649875402</span>/<span class="number">0.377974271774</span> G: <span class="number">1.2899967432</span> (Real: [<span class="number">4.0140545344352718</span>, <span class="number">1.2630515897106358</span>], Fake: [<span class="number">4.1656066524982451</span>, <span class="number">1.1779954377184654</span>]) </div><div class="line"><span class="number">16200</span>: D: <span class="number">0.34089872241</span>/<span class="number">0.265896707773</span> G: <span class="number">1.11251270771</span> (Real: [<span class="number">4.0408088731765748</span>, <span class="number">1.3839176416694203</span>], Fake: [<span class="number">4.0593357777595518</span>, <span class="number">1.2213436233279213</span>]) </div><div class="line"><span class="number">16400</span>: D: <span class="number">0.00472234329209</span>/<span class="number">0.513436615467</span> G: <span class="number">1.63225841522</span> (Real: [<span class="number">4.1417997646331788</span>, <span class="number">1.2449733327544124</span>], Fake: [<span class="number">3.7269023895263671</span>, <span class="number">1.1296458384504016</span>]) </div><div class="line"><span class="number">16600</span>: D: <span class="number">0.756382524967</span>/<span class="number">0.66779255867</span> G: <span class="number">0.536718785763</span> (Real: [<span class="number">3.9379871004819869</span>, <span class="number">1.278594816781579</span>], Fake: [<span class="number">3.8750299978256226</span>, <span class="number">1.2829775944385431</span>]) </div><div class="line"><span class="number">16800</span>: D: <span class="number">0.879319548607</span>/<span class="number">0.169020995498</span> G: <span class="number">2.33787298203</span> (Real: [<span class="number">4.2075482982397077</span>, <span class="number">1.3725696551173026</span>], Fake: [<span class="number">3.6744112837314606</span>, <span class="number">1.3225226221432227</span>]) </div><div class="line"><span class="number">17000</span>: D: <span class="number">0.0482731573284</span>/<span class="number">1.43823099136</span> G: <span class="number">1.15067052841</span> (Real: [<span class="number">4.0404629743099214</span>, <span class="number">1.218948521692204</span>], Fake: [<span class="number">4.0387165582180025</span>, <span class="number">1.2794767516999943</span>]) </div><div class="line"><span class="number">17200</span>: D: <span class="number">2.88490628009e-05</span>/<span class="number">0.57872825861</span> G: <span class="number">0.495411038399</span> (Real: [<span class="number">3.9901529085636138</span>, <span class="number">1.4349120434336065</span>], Fake: [<span class="number">4.0573103535175328</span>, <span class="number">1.1918079188127153</span>]) </div><div class="line"><span class="number">17400</span>: D: <span class="number">0.231002807617</span>/<span class="number">1.2511702776</span> G: <span class="number">1.33606302738</span> (Real: [<span class="number">3.7472488379478452</span>, <span class="number">1.1658634335870959</span>], Fake: [<span class="number">3.9354779303073881</span>, <span class="number">1.2931455406139682</span>]) </div><div class="line"><span class="number">17600</span>: D: <span class="number">0.181431129575</span>/<span class="number">0.149175107479</span> G: <span class="number">2.51311731339</span> (Real: [<span class="number">4.1270963573455814</span>, <span class="number">1.312367798822683</span>], Fake: [<span class="number">4.3470913958549495</span>, <span class="number">1.1818067904116243</span>]) </div><div class="line"><span class="number">17800</span>: D: <span class="number">0.830040276051</span>/<span class="number">0.415931969881</span> G: <span class="number">1.57710897923</span> (Real: [<span class="number">3.99146986246109</span>, <span class="number">1.0836663745208763</span>], Fake: [<span class="number">4.3325731372833252</span>, <span class="number">1.266683405420135</span>]) </div><div class="line"><span class="number">18000</span>: D: <span class="number">0.20047518611</span>/<span class="number">0.460676729679</span> G: <span class="number">2.56421780586</span> (Real: [<span class="number">4.3388666504621503</span>, <span class="number">1.3881540592894346</span>], Fake: [<span class="number">3.9820314025878907</span>, <span class="number">1.0436684747098013</span>]) </div><div class="line"><span class="number">18200</span>: D: <span class="number">0.0659740716219</span>/<span class="number">0.428199917078</span> G: <span class="number">0.931035280228</span> (Real: [<span class="number">3.8892200005054476</span>, <span class="number">1.2217018988161374</span>], Fake: [<span class="number">3.8822696304321287</span>, <span class="number">1.304586899060783</span>]) </div><div class="line"><span class="number">18400</span>: D: <span class="number">0.791511416435</span>/<span class="number">0.56503880024</span> G: <span class="number">1.98549497128</span> (Real: [<span class="number">3.7894453473389147</span>, <span class="number">1.3567878969348022</span>], Fake: [<span class="number">4.0909739780426024</span>, <span class="number">1.2361544714927677</span>]) </div><div class="line"><span class="number">18600</span>: D: <span class="number">1.15297484398</span>/<span class="number">0.102882102132</span> G: <span class="number">1.85704553127</span> (Real: [<span class="number">4.2316720616817474</span>, <span class="number">1.2603607958456993</span>], Fake: [<span class="number">3.7415710711479186</span>, <span class="number">1.311454258421634</span>]) </div><div class="line"><span class="number">18800</span>: D: <span class="number">1.06078708172</span>/<span class="number">0.366641134024</span> G: <span class="number">0.914008259773</span> (Real: [<span class="number">3.9394708669185636</span>, <span class="number">1.2924449902046702</span>], Fake: [<span class="number">3.9466111737489702</span>, <span class="number">1.137776845711856</span>]) </div><div class="line"><span class="number">19000</span>: D: <span class="number">0.374139517546</span>/<span class="number">0.448283135891</span> G: <span class="number">0.701639294624</span> (Real: [<span class="number">3.9492650532722475</span>, <span class="number">1.2348435624999976</span>], Fake: [<span class="number">3.7365686148405075</span>, <span class="number">1.215777672310739</span>]) </div><div class="line"><span class="number">19200</span>: D: <span class="number">0.209440857172</span>/<span class="number">0.522395193577</span> G: <span class="number">0.707223057747</span> (Real: [<span class="number">3.8846979635953902</span>, <span class="number">1.2146658434075039</span>], Fake: [<span class="number">4.1696245861053463</span>, <span class="number">1.2979841463522084</span>]) </div><div class="line"><span class="number">19400</span>: D: <span class="number">0.15654887259</span>/<span class="number">0.133351936936</span> G: <span class="number">1.43907415867</span> (Real: [<span class="number">4.0292040088772776</span>, <span class="number">1.2291287794070285</span>], Fake: [<span class="number">3.8498308193683624</span>, <span class="number">1.1121767482065514</span>]) </div><div class="line"><span class="number">19600</span>: D: <span class="number">0.329566717148</span>/<span class="number">0.222448319197</span> G: <span class="number">0.429250627756</span> (Real: [<span class="number">3.7978928279876709</span>, <span class="number">1.1554982239517226</span>], Fake: [<span class="number">3.5122534275054931</span>, <span class="number">1.2462801759237472</span>]) </div><div class="line"><span class="number">19800</span>: D: <span class="number">0.0176634714007</span>/<span class="number">0.480926275253</span> G: <span class="number">0.39424943924</span> (Real: [<span class="number">4.0822606313228604</span>, <span class="number">1.2484518469881001</span>], Fake: [<span class="number">4.5482089626789097</span>, <span class="number">1.1266585202489452</span>]) </div><div class="line"><span class="number">20000</span>: D: <span class="number">0.45860773325</span>/<span class="number">0.517112135887</span> G: <span class="number">0.957448124886</span> (Real: [<span class="number">4.0875282829999922</span>, <span class="number">1.2310698313795749</span>], Fake: [<span class="number">4.2767848205566406</span>, <span class="number">1.1186856033319335</span>]) </div><div class="line"><span class="number">20200</span>: D: <span class="number">1.71172118187</span>/<span class="number">0.240745082498</span> G: <span class="number">0.314642876387</span> (Real: [<span class="number">3.8525538909435273</span>, <span class="number">1.2094100771830765</span>], Fake: [<span class="number">3.6543397814035417</span>, <span class="number">1.2917598911679764</span>]) </div><div class="line"><span class="number">20400</span>: D: <span class="number">0.583434104919</span>/<span class="number">0.703361749649</span> G: <span class="number">1.45571947098</span> (Real: [<span class="number">4.0388400733470915</span>, <span class="number">1.2267253073862441</span>], Fake: [<span class="number">3.9019298100471498</span>, <span class="number">1.0292402192122965</span>]) </div><div class="line"><span class="number">20600</span>: D: <span class="number">0.176266431808</span>/<span class="number">0.55411952734</span> G: <span class="number">0.962469100952</span> (Real: [<span class="number">4.0694609802961352</span>, <span class="number">1.2276659305759301</span>], Fake: [<span class="number">3.9728190612792971</span>, <span class="number">1.1212652107309595</span>]) </div><div class="line"><span class="number">20800</span>: D: <span class="number">1.17427504063</span>/<span class="number">0.212535098195</span> G: <span class="number">0.505771696568</span> (Real: [<span class="number">3.7983859290182589</span>, <span class="number">1.3565768879920506</span>], Fake: [<span class="number">4.0766829651594163</span>, <span class="number">1.1742807548541911</span>]) </div><div class="line"><span class="number">21000</span>: D: <span class="number">0.247546881437</span>/<span class="number">0.242251947522</span> G: <span class="number">2.533826828</span> (Real: [<span class="number">4.048124186992645</span>, <span class="number">1.2074367711533176</span>], Fake: [<span class="number">3.8443934541940687</span>, <span class="number">1.0964556009967605</span>]) </div><div class="line"><span class="number">21200</span>: D: <span class="number">0.000996549613774</span>/<span class="number">1.77280521393</span> G: <span class="number">0.741032421589</span> (Real: [<span class="number">3.8826335191726686</span>, <span class="number">1.3432952882949609</span>], Fake: [<span class="number">4.0052364200353621</span>, <span class="number">1.0658632049377181</span>]) </div><div class="line"><span class="number">21400</span>: D: <span class="number">0.0162861924618</span>/<span class="number">0.202122434974</span> G: <span class="number">0.640827775002</span> (Real: [<span class="number">3.949158318042755</span>, <span class="number">1.2312223613675215</span>], Fake: [<span class="number">3.9677765011787414</span>, <span class="number">1.1984950273079937</span>]) </div><div class="line"><span class="number">21600</span>: D: <span class="number">0.494586825371</span>/<span class="number">0.368914216757</span> G: <span class="number">1.73299539089</span> (Real: [<span class="number">4.2141097390651705</span>, <span class="number">1.3170628249721785</span>], Fake: [<span class="number">3.9259325069189073</span>, <span class="number">1.2402090610341174</span>]) </div><div class="line"><span class="number">21800</span>: D: <span class="number">1.72856020927</span>/<span class="number">0.280478566885</span> G: <span class="number">0.301942139864</span> (Real: [<span class="number">3.9425574642419816</span>, <span class="number">1.3421295277895979</span>], Fake: [<span class="number">4.1370714265108113</span>, <span class="number">1.3135434962232824</span>]) </div><div class="line"><span class="number">22000</span>: D: <span class="number">0.316263616085</span>/<span class="number">0.425417006016</span> G: <span class="number">4.6092467308</span> (Real: [<span class="number">3.9253722500801085</span>, <span class="number">1.1573266813219236</span>], Fake: [<span class="number">3.7590440094470976</span>, <span class="number">1.2176312271677099</span>]) </div><div class="line"><span class="number">22200</span>: D: <span class="number">1.70313096046</span>/<span class="number">0.166758075356</span> G: <span class="number">1.76803898811</span> (Real: [<span class="number">4.1788750314712528</span>, <span class="number">1.3796412025948377</span>], Fake: [<span class="number">4.4896411395072935</span>, <span class="number">0.88890948354147137</span>]) </div><div class="line"><span class="number">22400</span>: D: <span class="number">0.00245383195579</span>/<span class="number">0.618139982224</span> G: <span class="number">0.561835348606</span> (Real: [<span class="number">4.0531666296720505</span>, <span class="number">1.3030890495946361</span>], Fake: [<span class="number">3.9800510057806968</span>, <span class="number">1.2769573713555427</span>]) </div><div class="line"><span class="number">22600</span>: D: <span class="number">0.0456999950111</span>/<span class="number">0.270536243916</span> G: <span class="number">0.719259619713</span> (Real: [<span class="number">3.8036734467744826</span>, <span class="number">1.2489490089903446</span>], Fake: [<span class="number">4.2525720745325089</span>, <span class="number">1.3061806069103183</span>]) </div><div class="line"><span class="number">22800</span>: D: <span class="number">0.0318684391677</span>/<span class="number">0.34651991725</span> G: <span class="number">1.3301807642</span> (Real: [<span class="number">4.0768313544988635</span>, <span class="number">1.2930152979365797</span>], Fake: [<span class="number">4.4993063497543337</span>, <span class="number">1.2277717696258752</span>]) </div><div class="line"><span class="number">23000</span>: D: <span class="number">1.38112533092</span>/<span class="number">0.656377196312</span> G: <span class="number">0.700986683369</span> (Real: [<span class="number">4.0261077487468722</span>, <span class="number">1.1634786009859657</span>], Fake: [<span class="number">4.1274698692560197</span>, <span class="number">1.1909195549188023</span>]) </div><div class="line"><span class="number">23200</span>: D: <span class="number">0.7532761693</span>/<span class="number">0.30048418045</span> G: <span class="number">1.24321329594</span> (Real: [<span class="number">4.0255234652757643</span>, <span class="number">1.2277433432951119</span>], Fake: [<span class="number">4.0463824319839476</span>, <span class="number">1.2493841122917879</span>]) </div><div class="line"><span class="number">23400</span>: D: <span class="number">1.54497790337</span>/<span class="number">0.524266302586</span> G: <span class="number">1.88104653358</span> (Real: [<span class="number">4.1244187545776363</span>, <span class="number">1.2126284333800423</span>], Fake: [<span class="number">4.0199511092901226</span>, <span class="number">1.4125067136876193</span>]) </div><div class="line"><span class="number">23600</span>: D: <span class="number">0.838026106358</span>/<span class="number">1.1139113903</span> G: <span class="number">2.2735543251</span> (Real: [<span class="number">4.0352903008460999</span>, <span class="number">1.1687086536829701</span>], Fake: [<span class="number">4.5685070466995237</span>, <span class="number">1.4508884769834012</span>]) </div><div class="line"><span class="number">23800</span>: D: <span class="number">0.869914472103</span>/<span class="number">0.160864800215</span> G: <span class="number">1.42444908619</span> (Real: [<span class="number">4.1635012495517731</span>, <span class="number">1.1441051019240691</span>], Fake: [<span class="number">4.1520407730340958</span>, <span class="number">1.2022442680490875</span>]) </div><div class="line"><span class="number">24000</span>: D: <span class="number">0.0401677601039</span>/<span class="number">0.240127012134</span> G: <span class="number">1.21359109879</span> (Real: [<span class="number">4.0558859372138976</span>, <span class="number">1.1263029268841764</span>], Fake: [<span class="number">3.8535136532783509</span>, <span class="number">0.99055012605544335</span>]) </div><div class="line"><span class="number">24200</span>: D: <span class="number">0.444084912539</span>/<span class="number">0.761975646019</span> G: <span class="number">1.18176090717</span> (Real: [<span class="number">4.1462872040271757</span>, <span class="number">1.1670976588949802</span>], Fake: [<span class="number">4.0291124176979061</span>, <span class="number">1.4000525541431663</span>]) </div><div class="line"><span class="number">24400</span>: D: <span class="number">0.259448975325</span>/<span class="number">0.206390738487</span> G: <span class="number">0.850725114346</span> (Real: [<span class="number">4.2600694203376772</span>, <span class="number">1.3260391555100224</span>], Fake: [<span class="number">4.7161277580261229</span>, <span class="number">1.3763624799621637</span>]) </div><div class="line"><span class="number">24600</span>: D: <span class="number">0.821855664253</span>/<span class="number">0.381440609694</span> G: <span class="number">0.898442983627</span> (Real: [<span class="number">3.9929001557826997</span>, <span class="number">1.316718033939094</span>], Fake: [<span class="number">3.659836998283863</span>, <span class="number">1.033547623133473</span>]) </div><div class="line"><span class="number">24800</span>: D: <span class="number">0.869792580605</span>/<span class="number">0.143853545189</span> G: <span class="number">1.68244981766</span> (Real: [<span class="number">3.9503055346012115</span>, <span class="number">1.1980136516743376</span>], Fake: [<span class="number">4.3753550618886949</span>, <span class="number">1.4268488751378543</span>]) </div><div class="line"><span class="number">25000</span>: D: <span class="number">0.533834278584</span>/<span class="number">0.944993913174</span> G: <span class="number">1.35653877258</span> (Real: [<span class="number">3.8403973925113677</span>, <span class="number">1.1415226099240794</span>], Fake: [<span class="number">4.3022644245624546</span>, <span class="number">1.277824404897737</span>]) </div><div class="line"><span class="number">25200</span>: D: <span class="number">0.57686984539</span>/<span class="number">1.21011674404</span> G: <span class="number">0.49785476923</span> (Real: [<span class="number">4.1094828593730925</span>, <span class="number">1.0606124114518727</span>], Fake: [<span class="number">3.8350191235542299</span>, <span class="number">1.1822398134788241</span>]) </div><div class="line"><span class="number">25400</span>: D: <span class="number">1.30570268631</span>/<span class="number">0.127069279552</span> G: <span class="number">2.14658904076</span> (Real: [<span class="number">3.8440176880359651</span>, <span class="number">1.2759016439053388</span>], Fake: [<span class="number">4.2303895175457003</span>, <span class="number">1.2478330871411345</span>]) </div><div class="line"><span class="number">25600</span>: D: <span class="number">0.163877904415</span>/<span class="number">0.356351107359</span> G: <span class="number">1.50513041019</span> (Real: [<span class="number">3.9149920016527178</span>, <span class="number">1.3322359586431274</span>], Fake: [<span class="number">4.5107577931880947</span>, <span class="number">1.37733363996175</span>]) </div><div class="line"><span class="number">25800</span>: D: <span class="number">0.0257995054126</span>/<span class="number">0.501479804516</span> G: <span class="number">0.846267580986</span> (Real: [<span class="number">4.0328698861598973</span>, <span class="number">1.0891363228332751</span>], Fake: [<span class="number">4.2062628841400143</span>, <span class="number">1.2707193105443095</span>]) </div><div class="line"><span class="number">26000</span>: D: <span class="number">0.4208984375</span>/<span class="number">0.45090213418</span> G: <span class="number">1.24405300617</span> (Real: [<span class="number">4.0495267909765245</span>, <span class="number">1.3629959211491509</span>], Fake: [<span class="number">3.881335927248001</span>, <span class="number">1.1534035700479874</span>]) </div><div class="line"><span class="number">26200</span>: D: <span class="number">1.0977101326</span>/<span class="number">0.260044932365</span> G: <span class="number">0.274282753468</span> (Real: [<span class="number">4.0526520502567287</span>, <span class="number">1.1354404896569923</span>], Fake: [<span class="number">3.7989616423845289</span>, <span class="number">1.3036229409468019</span>]) </div><div class="line"><span class="number">26400</span>: D: <span class="number">0.836492598057</span>/<span class="number">0.194570705295</span> G: <span class="number">1.25769793987</span> (Real: [<span class="number">4.2580243301391603</span>, <span class="number">1.1229754918621602</span>], Fake: [<span class="number">4.9420129108428954</span>, <span class="number">1.4595622988211396</span>]) </div><div class="line"><span class="number">26600</span>: D: <span class="number">0.0381172671914</span>/<span class="number">0.229116663337</span> G: <span class="number">3.23367476463</span> (Real: [<span class="number">3.9871047949790954</span>, <span class="number">1.2891811878363044</span>], Fake: [<span class="number">5.5130027627944944</span>, <span class="number">1.3531596753079107</span>]) </div><div class="line"><span class="number">26800</span>: D: <span class="number">0.33750808239</span>/<span class="number">0.0588937625289</span> G: <span class="number">2.76632380486</span> (Real: [<span class="number">4.0901136839389798</span>, <span class="number">1.2240984948711151</span>], Fake: [<span class="number">5.9970619964599612</span>, <span class="number">1.3296608494175821</span>]) </div><div class="line"><span class="number">27000</span>: D: <span class="number">0.403919011354</span>/<span class="number">0.025144957006</span> G: <span class="number">5.00026988983</span> (Real: [<span class="number">3.9684947764873506</span>, <span class="number">1.1928812330565042</span>], Fake: [<span class="number">5.5821900677680967</span>, <span class="number">1.5869340992569609</span>]) </div><div class="line"><span class="number">27200</span>: D: <span class="number">1.26118826866</span>/<span class="number">1.14945113659</span> G: <span class="number">0.233536079526</span> (Real: [<span class="number">4.0953157800436024</span>, <span class="number">1.2000917970554563</span>], Fake: [<span class="number">3.457775202393532</span>, <span class="number">1.2362199991432059</span>]) </div><div class="line"><span class="number">27400</span>: D: <span class="number">0.842516124249</span>/<span class="number">0.577941656113</span> G: <span class="number">0.518706798553</span> (Real: [<span class="number">3.8673747038841246</span>, <span class="number">1.1826108239366226</span>], Fake: [<span class="number">3.6999527400732042</span>, <span class="number">1.2050256827670227</span>]) </div><div class="line"><span class="number">27600</span>: D: <span class="number">0.459548681974</span>/<span class="number">0.516558885574</span> G: <span class="number">1.69328427315</span> (Real: [<span class="number">4.0379843235015871</span>, <span class="number">1.267741160236167</span>], Fake: [<span class="number">4.3069088852405546</span>, <span class="number">1.2883256614455194</span>]) </div><div class="line"><span class="number">27800</span>: D: <span class="number">0.757292568684</span>/<span class="number">0.295852422714</span> G: <span class="number">0.82683211565</span> (Real: [<span class="number">3.6750951480865477</span>, <span class="number">1.1881818498282759</span>], Fake: [<span class="number">4.3079475378990173</span>, <span class="number">1.3863961893145142</span>]) </div><div class="line"><span class="number">28000</span>: D: <span class="number">1.0311729908</span>/<span class="number">0.836829304695</span> G: <span class="number">0.54562240839</span> (Real: [<span class="number">3.8109287106990815</span>, <span class="number">1.2699445078581264</span>], Fake: [<span class="number">4.0800623488426204</span>, <span class="number">1.2420579399013889</span>]) </div><div class="line"><span class="number">28200</span>: D: <span class="number">0.662180066109</span>/<span class="number">0.698618113995</span> G: <span class="number">0.430238395929</span> (Real: [<span class="number">3.8820258617401122</span>, <span class="number">1.3192879801078357</span>], Fake: [<span class="number">3.8678512275218964</span>, <span class="number">1.2100339116659864</span>]) </div><div class="line"><span class="number">28400</span>: D: <span class="number">0.857332766056</span>/<span class="number">0.637849986553</span> G: <span class="number">0.443328052759</span> (Real: [<span class="number">4.0044168281555175</span>, <span class="number">1.2977773729964786</span>], Fake: [<span class="number">3.77621297955513</span>, <span class="number">1.10884790779666</span>]) </div><div class="line"><span class="number">28600</span>: D: <span class="number">0.518617451191</span>/<span class="number">0.676390469074</span> G: <span class="number">0.824631929398</span> (Real: [<span class="number">3.9321113193035124</span>, <span class="number">1.189980080467403</span>], Fake: [<span class="number">4.1412628889083862</span>, <span class="number">1.4110153520360829</span>]) </div><div class="line"><span class="number">28800</span>: D: <span class="number">0.924657285213</span>/<span class="number">0.57682287693</span> G: <span class="number">0.867313206196</span> (Real: [<span class="number">3.8806186806410552</span>, <span class="number">1.2663798129949515</span>], Fake: [<span class="number">3.7928846073150635</span>, <span class="number">0.96599856269415929</span>]) </div><div class="line"><span class="number">29000</span>: D: <span class="number">0.681347727776</span>/<span class="number">0.833830595016</span> G: <span class="number">0.880895376205</span> (Real: [<span class="number">4.0122552135586735</span>, <span class="number">1.3382642859979685</span>], Fake: [<span class="number">3.8699622356891634</span>, <span class="number">1.5246898233773196</span>]) </div><div class="line"><span class="number">29200</span>: D: <span class="number">0.690975308418</span>/<span class="number">0.571468651295</span> G: <span class="number">0.539677977562</span> (Real: [<span class="number">3.9422134029865266</span>, <span class="number">1.2798402813873653</span>], Fake: [<span class="number">3.4796924066543578</span>, <span class="number">1.0078584415562459</span>]) </div><div class="line"><span class="number">29400</span>: D: <span class="number">0.600927650928</span>/<span class="number">0.692537486553</span> G: <span class="number">0.785535871983</span> (Real: [<span class="number">4.0494313037395475</span>, <span class="number">1.2729051468200046</span>], Fake: [<span class="number">4.0457676327228542</span>, <span class="number">1.2121629628604733</span>]) </div><div class="line"><span class="number">29600</span>: D: <span class="number">0.662378668785</span>/<span class="number">0.552553355694</span> G: <span class="number">0.665563106537</span> (Real: [<span class="number">3.8692034566402436</span>, <span class="number">1.1988600586203602</span>], Fake: [<span class="number">4.3626180648803707</span>, <span class="number">1.3098951956607312</span>]) </div><div class="line"><span class="number">29800</span>: D: <span class="number">0.844242811203</span>/<span class="number">0.719559967518</span> G: <span class="number">0.89226102829</span> (Real: [<span class="number">3.8751950478553772</span>, <span class="number">1.1053984789259368</span>], Fake: [<span class="number">3.9671442759037019</span>, <span class="number">1.1584875699071935</span>])</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f&quot; target=&quot;_blank&quot; rel=&quot;e
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="GAN" scheme="http://yoursite.com/tags/GAN/"/>
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>LSTM by Example using Tensorflow (Text Generate)</title>
    <link href="http://yoursite.com/2017/04/26/LSTM-by-Example-using-Tensorflow-Text-Generate/"/>
    <id>http://yoursite.com/2017/04/26/LSTM-by-Example-using-Tensorflow-Text-Generate/</id>
    <published>2017-04-26T13:05:01.000Z</published>
    <updated>2017-04-26T13:10:20.095Z</updated>
    
    <content type="html"><![CDATA[<p>In Deep Learning, Recurrent Neural Networks (RNN) are a family of neural networks that excels in learning from sequential data. A class of RNN that has found practical applications is Long Short-Term Memory (LSTM) because it is robust against the problems of long-term dependency.</p><p>What seems to be lacking is a good documentation and example on how to build an easy to understand Tensorflow application based on LSTM. This is the motivation behind this article.</p><p>Suppose we want to train a LSTM to predict the next word using a sample short story, <a href="http://www.taleswithmorals.com/" target="_blank" rel="external">Aesop’s Fables</a>:</p><blockquote><p>long ago , the mice had a general council to consider what measures they could take to outwit their common enemy , the cat . some said this , and some said that but at last a young mouse got up and said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger consists in the sly and treacherous manner in which the enemy approaches us . now , if we could receive some signal of her approach , we could easily escape from her . i venture , therefore , to propose that a small bell be procured , and attached by a ribbon round the neck of the cat . by this means we should always know when she was about , and could easily retire while she was in the neighbourhood . this proposal met with general applause , until an old mouse got up and said that is all very well , but who is to bell the cat ? the mice looked at one another and nobody spoke . then the old mouse said it is easy to propose impossible remedies .</p></blockquote><p>If we feed a LSTM with correct sequences from the text of 3 symbols as inputs and 1 labeled symbol, eventually the neural network will learn to predict the next symbol correctly.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*epcf2SBjRHBynBNFf-CpQA.png" alt="lstm"></p><p>Technically, LSTM inputs can only understand real numbers. A way to convert symbol to number is to assign a unique integer to each symbol based on frequency of occurrence. For example, there are 112 unique symbols in the text above. The function in Listing 2 builds a dictionary with the following entries [ “,” : 0 ][ “the” : 1 ], …, [ “council” : 37 ],…,[ “spoke” : 111 ]. The reverse dictionary is also generated since it will be used in decoding the output of LSTM.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dataset</span><span class="params">(words)</span>:</span></div><div class="line">    count = collections.Counter(words).most_common()</div><div class="line">    dictionary = dict()</div><div class="line">    <span class="keyword">for</span> word, _ <span class="keyword">in</span> count:</div><div class="line">        dictionary[word] = len(dictionary)</div><div class="line">    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))</div><div class="line">    <span class="keyword">return</span> dictionary, reverse_dictionary</div></pre></td></tr></table></figure><p>Similarly, the prediction is a unique integer identifying the index in the reverse dictionary of the predicted symbol. For example, if the prediction is 37, the predicted symbol is actually “council”.</p><p>The generation of output may sound simple but actually LSTM produces a 112-element vector of probabilities of prediction for the next symbol normalized by the softmax() function. The index of the element with the highest probability is the predicted index of the symbol in the reverse dictionary (ie a one-hot vector).</p><p><img src="https://cdn-images-1.medium.com/max/800/1*XAJdt_EbedqDlrTT9eqWvQ.png" alt="word-gen"></p><p>There is the source code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div></pre></td><td class="code"><pre><div class="line"><span class="string">'''</span></div><div class="line">A Recurrent Neural Network (LSTM) implementation example using TensorFlow..</div><div class="line">Next word prediction after n_input words learned from text file.</div><div class="line">A story is automatically generated if the predicted word is fed back as input.</div><div class="line">Author: Rowel Atienza</div><div class="line">Project: https://github.com/roatienza/Deep-Learning-Experiments</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">from</span> tensorflow.contrib <span class="keyword">import</span> rnn</div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> collections</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line">start_time = time.time()</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">elapsed</span><span class="params">(sec)</span>:</span></div><div class="line">    <span class="keyword">if</span> sec&lt;<span class="number">60</span>:</div><div class="line">        <span class="keyword">return</span> str(sec) + <span class="string">" sec"</span></div><div class="line">    <span class="keyword">elif</span> sec&lt;(<span class="number">60</span>*<span class="number">60</span>):</div><div class="line">        <span class="keyword">return</span> str(sec/<span class="number">60</span>) + <span class="string">" min"</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> str(sec/(<span class="number">60</span>*<span class="number">60</span>)) + <span class="string">" hr"</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Target log path</span></div><div class="line">logs_path = <span class="string">'/tmp/tensorflow/rnn_words'</span></div><div class="line">writer = tf.summary.FileWriter(logs_path)</div><div class="line"></div><div class="line"><span class="comment"># Text file containing words for training</span></div><div class="line">training_file = <span class="string">'belling_the_cat.txt'</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span><span class="params">(fname)</span>:</span></div><div class="line">    <span class="keyword">with</span> open(fname) <span class="keyword">as</span> f:</div><div class="line">        content = f.readlines()</div><div class="line">    content = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> content]</div><div class="line">    content = [content[i].split() <span class="keyword">for</span> i <span class="keyword">in</span> range(len(content))]</div><div class="line">    content = np.array(content)</div><div class="line">    content = np.reshape(content, [<span class="number">-1</span>, ])</div><div class="line">    <span class="keyword">return</span> content</div><div class="line"></div><div class="line">training_data = read_data(training_file)</div><div class="line">print(<span class="string">"Loaded training data..."</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dataset</span><span class="params">(words)</span>:</span></div><div class="line">    count = collections.Counter(words).most_common()</div><div class="line">    dictionary = dict()</div><div class="line">    <span class="keyword">for</span> word, _ <span class="keyword">in</span> count:</div><div class="line">        dictionary[word] = len(dictionary)</div><div class="line">    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))</div><div class="line">    <span class="keyword">return</span> dictionary, reverse_dictionary</div><div class="line"></div><div class="line">dictionary, reverse_dictionary = build_dataset(training_data)</div><div class="line">vocab_size = len(dictionary)</div><div class="line"></div><div class="line"><span class="comment"># Parameters</span></div><div class="line">learning_rate = <span class="number">0.001</span></div><div class="line">training_iters = <span class="number">50000</span></div><div class="line">display_step = <span class="number">1000</span></div><div class="line">n_input = <span class="number">3</span></div><div class="line"></div><div class="line"><span class="comment"># number of units in RNN cell</span></div><div class="line">n_hidden = <span class="number">512</span></div><div class="line"></div><div class="line"><span class="comment"># tf Graph input</span></div><div class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, n_input, <span class="number">1</span>])</div><div class="line">y = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, vocab_size])</div><div class="line"></div><div class="line"><span class="comment"># RNN output node weights and biases</span></div><div class="line">weights = &#123;</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_hidden, vocab_size]))</div><div class="line">&#125;</div><div class="line">biases = &#123;</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([vocab_size]))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">RNN</span><span class="params">(x, weights, biases)</span>:</span></div><div class="line"></div><div class="line">    <span class="comment"># reshape to [1, n_input]</span></div><div class="line">    x = tf.reshape(x, [<span class="number">-1</span>, n_input])</div><div class="line"></div><div class="line">    <span class="comment"># Generate a n_input-element sequence of inputs</span></div><div class="line">    <span class="comment"># (eg. [had] [a] [general] -&gt; [20] [6] [33])</span></div><div class="line">    x = tf.split(x,n_input,<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="comment"># 2-layer LSTM, each layer has n_hidden units.</span></div><div class="line">    <span class="comment"># Average Accuracy= 95.20% at 50k iter</span></div><div class="line">    </div><div class="line">    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])</div><div class="line"></div><div class="line">    <span class="comment"># 1-layer LSTM with n_hidden units but with lower accuracy.</span></div><div class="line">    <span class="comment"># Average Accuracy= 90.60% 50k iter</span></div><div class="line">    <span class="comment"># Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above</span></div><div class="line">    <span class="comment"># rnn_cell = rnn.BasicLSTMCell(n_hidden)</span></div><div class="line"></div><div class="line">    <span class="comment"># generate prediction</span></div><div class="line">    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)</div><div class="line"></div><div class="line">    <span class="comment"># there are n_input outputs but</span></div><div class="line">    <span class="comment"># we only want the last output</span></div><div class="line">    <span class="keyword">return</span> tf.matmul(outputs[<span class="number">-1</span>], weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</div><div class="line"></div><div class="line">pred = RNN(x, weights, biases)</div><div class="line"></div><div class="line"><span class="comment"># Loss and optimizer</span></div><div class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))</div><div class="line">optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)</div><div class="line"></div><div class="line"><span class="comment"># Model evaluation</span></div><div class="line">correct_pred = tf.equal(tf.argmax(pred,<span class="number">1</span>), tf.argmax(y,<span class="number">1</span>))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</div><div class="line"></div><div class="line"><span class="comment"># Initializing the variables</span></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line"><span class="comment"># Launch the graph</span></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</div><div class="line">    session.run(init)</div><div class="line">    step = <span class="number">0</span></div><div class="line">    offset = random.randint(<span class="number">0</span>,n_input+<span class="number">1</span>)</div><div class="line">    end_offset = n_input + <span class="number">1</span></div><div class="line">    acc_total = <span class="number">0</span></div><div class="line">    loss_total = <span class="number">0</span></div><div class="line"></div><div class="line">    writer.add_graph(session.graph)</div><div class="line"></div><div class="line">    <span class="keyword">while</span> step &lt; training_iters:</div><div class="line">        <span class="comment"># Generate a minibatch. Add some randomness on selection process.</span></div><div class="line">        <span class="keyword">if</span> offset &gt; (len(training_data)-end_offset):</div><div class="line">            offset = random.randint(<span class="number">0</span>, n_input+<span class="number">1</span>)</div><div class="line"></div><div class="line">        symbols_in_keys = [ [dictionary[ str(training_data[i])]] <span class="keyword">for</span> i <span class="keyword">in</span> range(offset, offset+n_input) ]</div><div class="line">        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [<span class="number">-1</span>, n_input, <span class="number">1</span>])</div><div class="line"></div><div class="line">        symbols_out_onehot = np.zeros([vocab_size], dtype=float)</div><div class="line">        symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = <span class="number">1.0</span></div><div class="line">        symbols_out_onehot = np.reshape(symbols_out_onehot,[<span class="number">1</span>,<span class="number">-1</span>])</div><div class="line"></div><div class="line">        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \</div><div class="line">                                                feed_dict=&#123;x: symbols_in_keys, y: symbols_out_onehot&#125;)</div><div class="line">        loss_total += loss</div><div class="line">        acc_total += acc</div><div class="line">        <span class="keyword">if</span> (step+<span class="number">1</span>) % display_step == <span class="number">0</span>:</div><div class="line">            print(<span class="string">"Iter= "</span> + str(step+<span class="number">1</span>) + <span class="string">", Average Loss= "</span> + \</div><div class="line">                  <span class="string">"&#123;:.6f&#125;"</span>.format(loss_total/display_step) + <span class="string">", Average Accuracy= "</span> + \</div><div class="line">                  <span class="string">"&#123;:.2f&#125;%"</span>.format(<span class="number">100</span>*acc_total/display_step))</div><div class="line">            acc_total = <span class="number">0</span></div><div class="line">            loss_total = <span class="number">0</span></div><div class="line">            symbols_in = [training_data[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(offset, offset + n_input)]</div><div class="line">            symbols_out = training_data[offset + n_input]</div><div class="line">            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, <span class="number">1</span>).eval())]</div><div class="line">            print(<span class="string">"%s - [%s] vs [%s]"</span> % (symbols_in,symbols_out,symbols_out_pred))</div><div class="line">        step += <span class="number">1</span></div><div class="line">        offset += (n_input+<span class="number">1</span>)</div><div class="line">    print(<span class="string">"Optimization Finished!"</span>)</div><div class="line">    print(<span class="string">"Elapsed time: "</span>, elapsed(time.time() - start_time))</div><div class="line">    print(<span class="string">"Run on command line."</span>)</div><div class="line">    print(<span class="string">"\ttensorboard --logdir=%s"</span> % (logs_path))</div><div class="line">    print(<span class="string">"Point your web browser to: http://localhost:6006/"</span>)</div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        prompt = <span class="string">"%s words: "</span> % n_input</div><div class="line">        sentence = input(prompt)</div><div class="line">        sentence = sentence.strip()</div><div class="line">        words = sentence.split(<span class="string">' '</span>)</div><div class="line">        <span class="keyword">if</span> len(words) != n_input:</div><div class="line">            <span class="keyword">continue</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            symbols_in_keys = [dictionary[str(words[i])] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(words))]</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">32</span>):</div><div class="line">                keys = np.reshape(np.array(symbols_in_keys), [<span class="number">-1</span>, n_input, <span class="number">1</span>])</div><div class="line">                onehot_pred = session.run(pred, feed_dict=&#123;x: keys&#125;)</div><div class="line">                onehot_pred_index = int(tf.argmax(onehot_pred, <span class="number">1</span>).eval())</div><div class="line">                sentence = <span class="string">"%s %s"</span> % (sentence,reverse_dictionary[onehot_pred_index])</div><div class="line">                symbols_in_keys = symbols_in_keys[<span class="number">1</span>:]</div><div class="line">                symbols_in_keys.append(onehot_pred_index)</div><div class="line">            print(sentence)</div><div class="line">        <span class="keyword">except</span>:</div><div class="line">            print(<span class="string">"Word not in dictionary"</span>)</div></pre></td></tr></table></figure><p><strong>source blog:</strong> <a href="https://medium.com/towards-data-science/lstm-by-example-using-tensorflow-feb0c1968537" target="_blank" rel="external">https://medium.com/towards-data-science/lstm-by-example-using-tensorflow-feb0c1968537</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In Deep Learning, Recurrent Neural Networks (RNN) are a family of neural networks that excels in learning from sequential data. A class o
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>Xiaomi mini wifi cannot build the connection</title>
    <link href="http://yoursite.com/2017/04/26/Xiaomi-mini-wifi-cannot-build-the-connection/"/>
    <id>http://yoursite.com/2017/04/26/Xiaomi-mini-wifi-cannot-build-the-connection/</id>
    <published>2017-04-26T09:42:41.000Z</published>
    <updated>2017-04-26T09:48:43.727Z</updated>
    
    <content type="html"><![CDATA[<h2 id="针对Win10不能正常使用的问题"><a href="#针对Win10不能正常使用的问题" class="headerlink" title="针对Win10不能正常使用的问题"></a>针对Win10不能正常使用的问题</h2><ol><li>进入安装目录</li><li>进入<code>drivers</code>文件夹</li><li>进入<code>Win81x64</code>文件夹</li><li>找到<code>netr28ux.inf</code>文件，右键安装之</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;针对Win10不能正常使用的问题&quot;&gt;&lt;a href=&quot;#针对Win10不能正常使用的问题&quot; class=&quot;headerlink&quot; title=&quot;针对Win10不能正常使用的问题&quot;&gt;&lt;/a&gt;针对Win10不能正常使用的问题&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;进入安装目录&lt;/l
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Movie Recommendation with MLlib</title>
    <link href="http://yoursite.com/2017/04/26/Movie-Recommendation-with-MLlib/"/>
    <id>http://yoursite.com/2017/04/26/Movie-Recommendation-with-MLlib/</id>
    <published>2017-04-26T06:24:57.000Z</published>
    <updated>2017-04-26T07:27:36.490Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Spark-Summit-2014"><a href="#Spark-Summit-2014" class="headerlink" title="Spark Summit 2014"></a>Spark Summit 2014</h2><p><a href="https://databricks-training.s3.amazonaws.com/index.html" target="_blank" rel="external">https://databricks-training.s3.amazonaws.com/index.html</a></p><p>we will use MLlib to make personalized movie recommendations tailored <em>for you</em>. We will work with 10 million ratings from 72,000 users on 10,000 movies, collected by <a href="http://movielens.umn.edu/" target="_blank" rel="external">MovieLens</a>. This dataset is pre-loaded in your USB drive under <code>data/movielens/large</code>. For quick testing of your code, you may want to use a smaller dataset under <code>data/movielens/medium</code>, which contains 1 million ratings from 6000 users on 4000 movies.</p><h2 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h2><p>We will use two files from this MovieLens dataset: “<code>ratings.dat</code>” and “<code>movies.dat</code>”. All ratings are contained in the file “<code>ratings.dat</code>” and are in the following format:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">UserID::MovieID::Rating::Timestamp</div></pre></td></tr></table></figure><p>Movie information is in the file “<code>movies.dat</code>” and is in the following format:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">MovieID::Title::Genres</div></pre></td></tr></table></figure><h2 id="Collaborative-filtering"><a href="#Collaborative-filtering" class="headerlink" title="Collaborative filtering"></a>Collaborative filtering</h2><p>Collaborative filtering is commonly used for recommender systems. These techniques aim to fill in the missing entries of a user-item association matrix, in our case, the user-movie rating matrix. MLlib currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. In particular, we implement the alternating least squares (ALS) algorithm to learn these latent factors.</p><p><img src="https://databricks-training.s3.amazonaws.com/img/matrix_factorization.png" alt="cf"></p><h2 id="Create-training-examples"><a href="#Create-training-examples" class="headerlink" title="Create training examples"></a>Create training examples</h2><p><a href="https://github.com/ewanlee/spark-training" target="_blank" rel="external">https://github.com/ewanlee/spark-training</a></p><p>To make recommendation <em>for you</em>, we are going to learn your taste by asking you to rate a few movies. We have selected a small set of movies that have received the most ratings from users in the MovieLens dataset. You can rate those movies by running <code>bin/rateMovies</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python bin/rateMovies</div></pre></td></tr></table></figure><p>When you run the script, you should see prompt similar to the following:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Please rate the following movie (1-5 (best), or 0 if not seen):</div><div class="line">Toy Story (1995):</div></pre></td></tr></table></figure><p>After you’re done rating the movies, we save your ratings in <code>personalRatings.txt</code> in the MovieLens format, where a special user id <code>0</code> is assigned to you.</p><p><code>rateMovies</code> allows you to re-rate the movies if you’d like to see how your ratings affect your recommendations.</p><p>If you don’t have python installed, please copy <code>personalRatings.txt.template</code> to <code>personalRatings.txt</code> and replace <code>?</code>s with your ratings.</p><h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><p>We will be using a standalone project template for this exercise.</p><ul><li><p>In the training USB drive, this has been setup in</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">machine-learning/python/</div></pre></td></tr></table></figure></li><li><p>You should find the following items in the directory:</p></li><li><p><code>MovieLensALS.py</code>: Main Python program that you are going to edit, compile and run</p></li><li><p><code>solution</code>: Directory containing the solution code</p></li></ul><p><code>MovieLensALS.py</code> should look as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> itertools</div><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</div><div class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join, isfile, dirname</div><div class="line"></div><div class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</div><div class="line"><span class="keyword">from</span> pyspark.mllib.recommendation <span class="keyword">import</span> ALS</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseRating</span><span class="params">(line)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .</div><div class="line">    """</div><div class="line">    <span class="comment"># ...</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseMovie</span><span class="params">(line)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Parses a movie record in MovieLens format movieId::movieTitle .</div><div class="line">    """</div><div class="line">    <span class="comment"># ...</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadRatings</span><span class="params">(ratingsFile)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Load ratings from file.</div><div class="line">    """</div><div class="line">    <span class="comment"># ...</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeRmse</span><span class="params">(model, data, n)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Compute RMSE (Root Mean Squared Error).</div><div class="line">    """</div><div class="line">    <span class="comment"># ...</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    <span class="keyword">if</span> (len(sys.argv) != <span class="number">3</span>):</div><div class="line">        <span class="keyword">print</span> <span class="string">"Usage: [usb root directory]/spark/bin/spark-submit --driver-memory 2g "</span> + \</div><div class="line">          <span class="string">"MovieLensALS.py movieLensDataDir personalRatingsFile"</span></div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="comment"># set up environment</span></div><div class="line">    conf = SparkConf() \</div><div class="line">      .setAppName(<span class="string">"MovieLensALS"</span>) \</div><div class="line">      .set(<span class="string">"spark.executor.memory"</span>, <span class="string">"2g"</span>)</div><div class="line">    sc = SparkContext(conf=conf)</div><div class="line"></div><div class="line">    <span class="comment"># load personal ratings</span></div><div class="line">    myRatings = loadRatings(sys.argv[<span class="number">2</span>])</div><div class="line">    myRatingsRDD = sc.parallelize(myRatings, <span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># load ratings and movie titles</span></div><div class="line"></div><div class="line">    movieLensHomeDir = sys.argv[<span class="number">1</span>]</div><div class="line"></div><div class="line">    <span class="comment"># ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))</span></div><div class="line">    ratings = sc.textFile(join(movieLensHomeDir, <span class="string">"ratings.dat"</span>)).map(parseRating)</div><div class="line"></div><div class="line">    <span class="comment"># movies is an RDD of (movieId, movieTitle)</span></div><div class="line">    movies = dict(sc.textFile(join(movieLensHomeDir, <span class="string">"movies.dat"</span>)).map(parseMovie).collect())</div><div class="line"></div><div class="line">    <span class="comment"># your code here</span></div><div class="line">    </div><div class="line">    <span class="comment"># clean up</span></div><div class="line">    sc.stop()</div></pre></td></tr></table></figure><p>Let’s first take a closer look at our template code in a text editor, then we’ll start adding code to the template. Locate the<code>MovieLensALS</code> class and open it with a text editor.</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">usb/$ cd machine-learning/python</div><div class="line">vim MovieLensALS.py  # Or your editor of choice</div></pre></td></tr></table></figure><p>For any Spark computation, we first create a SparkConf object and use it to create a SparkContext object. Since we will be using spark-submit to execute the programs in this tutorial (more on spark-submit in the next section), we only need to configure the executor memory allocation and give the program a name, e.g. “MovieLensALS”, to identify it in Spark’s web UI. In local mode, the web UI can be access at <a href="http://localhost:4040/" target="_blank" rel="external"><code>localhost:4040</code></a> during the execution of a program.</p><p>This is what it looks like in our template code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">conf = SparkConf() \</div><div class="line">     .setAppName(<span class="string">"MovieLensALS"</span>) \</div><div class="line">     .set(<span class="string">"spark.executor.memory"</span>, <span class="string">"2g"</span>)</div><div class="line">   sc = SparkContext(conf=conf)</div></pre></td></tr></table></figure><p>Next, the code uses the SparkContext to read in ratings. Recall that the rating file is a text file with “<code>::</code>” as the delimiter. The code parses each line to create a RDD for ratings that contains <code>(Int, Rating)</code> pairs. We only keep the last digit of the timestamp as a random key. The <code>Rating</code> class is a wrapper around the tuple <code>(user: Int, product: Int, rating: Double)</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">movieLensHomeDir = sys.argv[<span class="number">1</span>]</div><div class="line"></div><div class="line"><span class="comment"># ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))</span></div><div class="line">ratings = sc.textFile(join(movieLensHomeDir, <span class="string">"ratings.dat"</span>)).map(parseRating)</div></pre></td></tr></table></figure><p>Next, the code read in movie ids and titles, collect them into a movie id to title map.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseMovie</span><span class="params">(line)</span>:</span></div><div class="line">      fields = line.split(<span class="string">"::"</span>)</div><div class="line">      <span class="keyword">return</span> int(fields[<span class="number">0</span>]), fields[<span class="number">1</span>]</div><div class="line"></div><div class="line">    movies = dict(sc.textFile(join(movieLensHomeDir, <span class="string">"movies.dat"</span>)).map(parseMovie).collect())</div></pre></td></tr></table></figure><p>Now, let’s make our first edit to add code to get a summary of the ratings.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">numRatings = ratings.count()</div><div class="line">numUsers = ratings.values().map(<span class="keyword">lambda</span> r: r[<span class="number">0</span>]).distinct().count()</div><div class="line">numMovies = ratings.values().map(<span class="keyword">lambda</span> r: r[<span class="number">1</span>]).distinct().count()</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"Got %d ratings from %d users on %d movies."</span> % (numRatings, numUsers, numMovies)</div></pre></td></tr></table></figure><h2 id="Running-the-program"><a href="#Running-the-program" class="headerlink" title="Running the program"></a>Running the program</h2><p>Before we compute movie recommendations, here is a quick reminder on how you can run the program at any point during this exercise. As mentioned above, we will use <code>spark-submit</code> to execute your program in local mode for this tutorial.</p><p>Starting with Spark 1.0, <code>spark-submit</code> is the recommended way for running Spark applications, both on clusters and locally in standalone mode.</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">usb/$ cd machine-learning/python</div><div class="line"></div><div class="line"># change the folder name from <span class="string">"medium"</span> to <span class="string">"large"</span> to run on the large data <span class="keyword">set</span></div><div class="line">[usb root directory]/spark/bin/spark-submit MovieLensALS.py [usb root directory]/data/movielens/medium/ ../personalRatings.txt</div></pre></td></tr></table></figure><p>You should see output similar to the following on your screen:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Got <span class="number">1000209</span> ratings from <span class="number">6040</span> users on <span class="number">3706</span> movies.</div></pre></td></tr></table></figure><h2 id="Splitting-training-data"><a href="#Splitting-training-data" class="headerlink" title="Splitting training data"></a>Splitting training data</h2><p>We will use MLlib’s <code>ALS</code> to train a <code>MatrixFactorizationModel</code>, which takes a <code>RDD[Rating]</code> object as input in Scala and <code>RDD[(user, product, rating)]</code> in Python. ALS has training parameters such as rank for matrix factors and regularization constants. To determine a good combination of the training parameters, we split the data into three non-overlapping subsets, named training, test, and validation, based on the last digit of the timestamp, and cache them. We will train multiple models based on the training set, select the best model on the validation set based on RMSE (Root Mean Squared Error), and finally evaluate the best model on the test set. We also add your ratings to the training set to make recommendations for you. We hold the training, validation, and test sets in memory by calling <code>cache</code> because we need to visit them multiple times.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">numPartitions = <span class="number">4</span></div><div class="line">training = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &lt; <span class="number">6</span>) \</div><div class="line">  .values() \</div><div class="line">  .union(myRatingsRDD) \</div><div class="line">  .repartition(numPartitions) \</div><div class="line">  .cache()</div><div class="line"></div><div class="line">validation = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &gt;= <span class="number">6</span> <span class="keyword">and</span> x[<span class="number">0</span>] &lt; <span class="number">8</span>) \</div><div class="line">  .values() \</div><div class="line">  .repartition(numPartitions) \</div><div class="line">  .cache()</div><div class="line"></div><div class="line">test = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &gt;= <span class="number">8</span>).values().cache()</div><div class="line"></div><div class="line">numTraining = training.count()</div><div class="line">numValidation = validation.count()</div><div class="line">numTest = test.count()</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"Training: %d, validation: %d, test: %d"</span> % (numTraining, numValidation, numTest)</div></pre></td></tr></table></figure><p>After the split, you should see</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Training: <span class="number">602251</span>, validation: <span class="number">198919</span>, test: <span class="number">199049.</span></div></pre></td></tr></table></figure><h2 id="Training-using-ALS"><a href="#Training-using-ALS" class="headerlink" title="Training using ALS"></a>Training using ALS</h2><p>In this section, we will use <code>ALS.train</code> to train a bunch of models, and select and evaluate the best. Among the training paramters of ALS, the most important ones are rank, lambda (regularization constant), and number of iterations. The <code>train</code>method of ALS we are going to use is defined as the following:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ALS</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(cls, ratings, rank, iterations=<span class="number">5</span>, lambda_=<span class="number">0.01</span>, blocks=<span class="number">-1</span>)</span>:</span></div><div class="line">    <span class="comment"># ...</span></div><div class="line">    <span class="keyword">return</span> MatrixFactorizationModel(sc, mod)</div></pre></td></tr></table></figure><p>deally, we want to try a large number of combinations of them in order to find the best one. Due to time constraint, we will test only 8 combinations resulting from the cross product of 2 different ranks (8 and 12), 2 different lambdas (1.0 and 10.0), and two different numbers of iterations (10 and 20). We use the provided method <code>computeRmse</code> to compute the RMSE on the validation set for each model. The model with the smallest RMSE on the validation set becomes the one selected and its RMSE on the test set is used as the final metric.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">ranks = [<span class="number">8</span>, <span class="number">12</span>]</div><div class="line">lambdas = [<span class="number">1.0</span>, <span class="number">10.0</span>]</div><div class="line">numIters = [<span class="number">10</span>, <span class="number">20</span>]</div><div class="line">bestModel = <span class="keyword">None</span></div><div class="line">bestValidationRmse = float(<span class="string">"inf"</span>)</div><div class="line">bestRank = <span class="number">0</span></div><div class="line">bestLambda = <span class="number">-1.0</span></div><div class="line">bestNumIter = <span class="number">-1</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> rank, lmbda, numIter <span class="keyword">in</span> itertools.product(ranks, lambdas, numIters):</div><div class="line">    model = ALS.train(training, rank, numIter, lmbda)</div><div class="line">    validationRmse = computeRmse(model, validation, numValidation)</div><div class="line">    <span class="keyword">print</span> <span class="string">"RMSE (validation) = %f for the model trained with "</span> % validationRmse + \</div><div class="line">          <span class="string">"rank = %d, lambda = %.1f, and numIter = %d."</span> % (rank, lmbda, numIter)</div><div class="line">    <span class="keyword">if</span> (validationRmse &lt; bestValidationRmse):</div><div class="line">        bestModel = model</div><div class="line">        bestValidationRmse = validationRmse</div><div class="line">        bestRank = rank</div><div class="line">        bestLambda = lmbda</div><div class="line">        bestNumIter = numIter</div><div class="line"></div><div class="line">testRmse = computeRmse(bestModel, test, numTest)</div><div class="line"></div><div class="line"><span class="comment"># evaluate the best model on the test set</span></div><div class="line"><span class="keyword">print</span> <span class="string">"The best model was trained with rank = %d and lambda = %.1f, "</span> % (bestRank, bestLambda) \</div><div class="line">  + <span class="string">"and numIter = %d, and its RMSE on the test set is %f."</span> % (bestNumIter, testRmse)</div></pre></td></tr></table></figure><p>Spark might take a minute or two to train the models. You should see the following on the screen:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">The best model was trained using rank <span class="number">8</span> <span class="keyword">and</span> <span class="keyword">lambda</span> <span class="number">10.0</span>, <span class="keyword">and</span> its RMSE on test <span class="keyword">is</span> <span class="number">0.8808492431998702</span>.</div></pre></td></tr></table></figure><h2 id="Recommending-movies-for-you"><a href="#Recommending-movies-for-you" class="headerlink" title="Recommending movies for you"></a>Recommending movies for you</h2><p>As the last part of our tutorial, let’s take a look at what movies our model recommends for you. This is done by generating <code>(0, movieId)</code> pairs for all movies you haven’t rated and calling the model’s <code>predict</code> method to get predictions. <code>0</code> is the special user id assigned to you.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MatrixFactorizationModel</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predictAll</span><span class="params">(self, usersProducts)</span>:</span></div><div class="line">        <span class="comment"># ...</span></div><div class="line">        <span class="keyword">return</span> RDD(self._java_model.predict(usersProductsJRDD._jrdd),</div><div class="line">                   self._context, RatingDeserializer())</div></pre></td></tr></table></figure><p>After we get all predictions, let us list the top 50 recommendations and see whether they look good to you.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">myRatedMovieIds = set([x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> myRatings])</div><div class="line">candidates = sc.parallelize([m <span class="keyword">for</span> m <span class="keyword">in</span> movies <span class="keyword">if</span> m <span class="keyword">not</span> <span class="keyword">in</span> myRatedMovieIds])</div><div class="line">predictions = bestModel.predictAll(candidates.map(<span class="keyword">lambda</span> x: (<span class="number">0</span>, x))).collect()</div><div class="line">recommendations = sorted(predictions, key=<span class="keyword">lambda</span> x: x[<span class="number">2</span>], reverse=<span class="keyword">True</span>)[:<span class="number">50</span>]</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"Movies recommended for you:"</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(recommendations)):</div><div class="line">    <span class="keyword">print</span> (<span class="string">"%2d: %s"</span> % (i + <span class="number">1</span>, movies[recommendations[i][<span class="number">1</span>]])).encode(<span class="string">'ascii'</span>, <span class="string">'ignore'</span>)</div></pre></td></tr></table></figure><p>The output should be similar to</p><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">Movies recommended for you:</div><div class="line"> 1: Silence of the Lambs, The (1991)</div><div class="line"> 2: Saving Private Ryan (1998)</div><div class="line"> 3: Godfather, The (1972)</div><div class="line"> 4: Star Wars: Episode IV - A New Hope (1977)</div><div class="line"> 5: Braveheart (1995)</div><div class="line"> 6: Schindler's List (1993)</div><div class="line"> 7: Shawshank Redemption, The (1994)</div><div class="line"> 8: Star Wars: Episode V - The Empire Strikes Back (1980)</div><div class="line"> 9: Pulp Fiction (1994)</div><div class="line">10: Alien (1979)</div><div class="line">...</div></pre></td></tr></table></figure><h2 id="Comparing-to-a-naive-baseline"><a href="#Comparing-to-a-naive-baseline" class="headerlink" title="Comparing to a naive baseline"></a>Comparing to a naive baseline</h2><p>Does ALS output a non-trivial model? We can compare the evaluation result with a naive baseline model that only outputs the average rating (or you may try one that outputs the average rating per movie). Computing the baseline’s RMSE is straightforward:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">meanRating = training.union(validation).map(<span class="keyword">lambda</span> x: x[<span class="number">2</span>]).mean()</div><div class="line">baselineRmse = sqrt(test.map(<span class="keyword">lambda</span> x: (meanRating - x[<span class="number">2</span>]) ** <span class="number">2</span>).reduce(add) / numTest)</div><div class="line">improvement = (baselineRmse - testRmse) / baselineRmse * <span class="number">100</span></div><div class="line"><span class="keyword">print</span> <span class="string">"The best model improves the baseline by %.2f"</span> % (improvement) + <span class="string">"%."</span></div></pre></td></tr></table></figure><p>The output should be similar to</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">The best model improves the baseline by <span class="number">20.96</span>%.</div></pre></td></tr></table></figure><p>It seems obvious that the trained model would outperform the naive baseline. However, a bad combination of training parameters would lead to a model worse than this naive baseline. Choosing the right set of parameters is quite important for this task.</p><h2 id="Solution-code"><a href="#Solution-code" class="headerlink" title="Solution code"></a>Solution code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> itertools</div><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</div><div class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join, isfile, dirname</div><div class="line"></div><div class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</div><div class="line"><span class="keyword">from</span> pyspark.mllib.recommendation <span class="keyword">import</span> ALS</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseRating</span><span class="params">(line)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .</div><div class="line">    """</div><div class="line">    fields = line.strip().split(<span class="string">"::"</span>)</div><div class="line">    <span class="keyword">return</span> long(fields[<span class="number">3</span>]) % <span class="number">10</span>, (int(fields[<span class="number">0</span>]), int(fields[<span class="number">1</span>]), float(fields[<span class="number">2</span>]))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseMovie</span><span class="params">(line)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Parses a movie record in MovieLens format movieId::movieTitle .</div><div class="line">    """</div><div class="line">    fields = line.strip().split(<span class="string">"::"</span>)</div><div class="line">    <span class="keyword">return</span> int(fields[<span class="number">0</span>]), fields[<span class="number">1</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadRatings</span><span class="params">(ratingsFile)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Load ratings from file.</div><div class="line">    """</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isfile(ratingsFile):</div><div class="line">        <span class="keyword">print</span> <span class="string">"File %s does not exist."</span> % ratingsFile</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    f = open(ratingsFile, <span class="string">'r'</span>)</div><div class="line">    ratings = filter(<span class="keyword">lambda</span> r: r[<span class="number">2</span>] &gt; <span class="number">0</span>, [parseRating(line)[<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> f])</div><div class="line">    f.close()</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ratings:</div><div class="line">        <span class="keyword">print</span> <span class="string">"No ratings provided."</span></div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> ratings</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeRmse</span><span class="params">(model, data, n)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Compute RMSE (Root Mean Squared Error).</div><div class="line">    """</div><div class="line">    predictions = model.predictAll(data.map(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>])))</div><div class="line">    predictionsAndRatings = predictions.map(<span class="keyword">lambda</span> x: ((x[<span class="number">0</span>], x[<span class="number">1</span>]), x[<span class="number">2</span>])) \</div><div class="line">      .join(data.map(<span class="keyword">lambda</span> x: ((x[<span class="number">0</span>], x[<span class="number">1</span>]), x[<span class="number">2</span>]))) \</div><div class="line">      .values()</div><div class="line">    <span class="keyword">return</span> sqrt(predictionsAndRatings.map(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>] - x[<span class="number">1</span>]) ** <span class="number">2</span>).reduce(add) / float(n))</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    <span class="keyword">if</span> (len(sys.argv) != <span class="number">3</span>):</div><div class="line">        <span class="keyword">print</span> <span class="string">"Usage: /path/to/spark/bin/spark-submit --driver-memory 2g "</span> + \</div><div class="line">          <span class="string">"MovieLensALS.py movieLensDataDir personalRatingsFile"</span></div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="comment"># set up environment</span></div><div class="line">    conf = SparkConf() \</div><div class="line">      .setAppName(<span class="string">"MovieLensALS"</span>) \</div><div class="line">      .set(<span class="string">"spark.executor.memory"</span>, <span class="string">"2g"</span>)</div><div class="line">    sc = SparkContext(conf=conf)</div><div class="line"></div><div class="line">    <span class="comment"># load personal ratings</span></div><div class="line">    myRatings = loadRatings(sys.argv[<span class="number">2</span>])</div><div class="line">    myRatingsRDD = sc.parallelize(myRatings, <span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># load ratings and movie titles</span></div><div class="line"></div><div class="line">    movieLensHomeDir = sys.argv[<span class="number">1</span>]</div><div class="line"></div><div class="line">    <span class="comment"># ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))</span></div><div class="line">    ratings = sc.textFile(join(movieLensHomeDir, <span class="string">"ratings.dat"</span>)).map(parseRating)</div><div class="line"></div><div class="line">    <span class="comment"># movies is an RDD of (movieId, movieTitle)</span></div><div class="line">    movies = dict(sc.textFile(join(movieLensHomeDir, <span class="string">"movies.dat"</span>)).map(parseMovie).collect())</div><div class="line"></div><div class="line">    numRatings = ratings.count()</div><div class="line">    numUsers = ratings.values().map(<span class="keyword">lambda</span> r: r[<span class="number">0</span>]).distinct().count()</div><div class="line">    numMovies = ratings.values().map(<span class="keyword">lambda</span> r: r[<span class="number">1</span>]).distinct().count()</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">"Got %d ratings from %d users on %d movies."</span> % (numRatings, numUsers, numMovies)</div><div class="line"></div><div class="line">    <span class="comment"># split ratings into train (60%), validation (20%), and test (20%) based on the </span></div><div class="line">    <span class="comment"># last digit of the timestamp, add myRatings to train, and cache them</span></div><div class="line"></div><div class="line">    <span class="comment"># training, validation, test are all RDDs of (userId, movieId, rating)</span></div><div class="line"></div><div class="line">    numPartitions = <span class="number">4</span></div><div class="line">    training = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &lt; <span class="number">6</span>) \</div><div class="line">      .values() \</div><div class="line">      .union(myRatingsRDD) \</div><div class="line">      .repartition(numPartitions) \</div><div class="line">      .cache()</div><div class="line"></div><div class="line">    validation = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &gt;= <span class="number">6</span> <span class="keyword">and</span> x[<span class="number">0</span>] &lt; <span class="number">8</span>) \</div><div class="line">      .values() \</div><div class="line">      .repartition(numPartitions) \</div><div class="line">      .cache()</div><div class="line"></div><div class="line">    test = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &gt;= <span class="number">8</span>).values().cache()</div><div class="line"></div><div class="line">    numTraining = training.count()</div><div class="line">    numValidation = validation.count()</div><div class="line">    numTest = test.count()</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">"Training: %d, validation: %d, test: %d"</span> % (numTraining, numValidation, numTest)</div><div class="line"></div><div class="line">    <span class="comment"># train models and evaluate them on the validation set</span></div><div class="line"></div><div class="line">    ranks = [<span class="number">8</span>, <span class="number">12</span>]</div><div class="line">    lambdas = [<span class="number">0.1</span>, <span class="number">10.0</span>]</div><div class="line">    numIters = [<span class="number">10</span>, <span class="number">20</span>]</div><div class="line">    bestModel = <span class="keyword">None</span></div><div class="line">    bestValidationRmse = float(<span class="string">"inf"</span>)</div><div class="line">    bestRank = <span class="number">0</span></div><div class="line">    bestLambda = <span class="number">-1.0</span></div><div class="line">    bestNumIter = <span class="number">-1</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> rank, lmbda, numIter <span class="keyword">in</span> itertools.product(ranks, lambdas, numIters):</div><div class="line">        model = ALS.train(training, rank, numIter, lmbda)</div><div class="line">        validationRmse = computeRmse(model, validation, numValidation)</div><div class="line">        <span class="keyword">print</span> <span class="string">"RMSE (validation) = %f for the model trained with "</span> % validationRmse + \</div><div class="line">              <span class="string">"rank = %d, lambda = %.1f, and numIter = %d."</span> % (rank, lmbda, numIter)</div><div class="line">        <span class="keyword">if</span> (validationRmse &lt; bestValidationRmse):</div><div class="line">            bestModel = model</div><div class="line">            bestValidationRmse = validationRmse</div><div class="line">            bestRank = rank</div><div class="line">            bestLambda = lmbda</div><div class="line">            bestNumIter = numIter</div><div class="line"></div><div class="line">    testRmse = computeRmse(bestModel, test, numTest)</div><div class="line"></div><div class="line">    <span class="comment"># evaluate the best model on the test set</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"The best model was trained with rank = %d and lambda = %.1f, "</span> % (bestRank, bestLambda) \</div><div class="line">      + <span class="string">"and numIter = %d, and its RMSE on the test set is %f."</span> % (bestNumIter, testRmse)</div><div class="line"></div><div class="line">    <span class="comment"># compare the best model with a naive baseline that always returns the mean rating</span></div><div class="line">    meanRating = training.union(validation).map(<span class="keyword">lambda</span> x: x[<span class="number">2</span>]).mean()</div><div class="line">    baselineRmse = sqrt(test.map(<span class="keyword">lambda</span> x: (meanRating - x[<span class="number">2</span>]) ** <span class="number">2</span>).reduce(add) / numTest)</div><div class="line">    improvement = (baselineRmse - testRmse) / baselineRmse * <span class="number">100</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"The best model improves the baseline by %.2f"</span> % (improvement) + <span class="string">"%."</span></div><div class="line"></div><div class="line">    <span class="comment"># make personalized recommendations</span></div><div class="line"></div><div class="line">    myRatedMovieIds = set([x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> myRatings])</div><div class="line">    candidates = sc.parallelize([m <span class="keyword">for</span> m <span class="keyword">in</span> movies <span class="keyword">if</span> m <span class="keyword">not</span> <span class="keyword">in</span> myRatedMovieIds])</div><div class="line">    predictions = bestModel.predictAll(candidates.map(<span class="keyword">lambda</span> x: (<span class="number">0</span>, x))).collect()</div><div class="line">    recommendations = sorted(predictions, key=<span class="keyword">lambda</span> x: x[<span class="number">2</span>], reverse=<span class="keyword">True</span>)[:<span class="number">50</span>]</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">"Movies recommended for you:"</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(recommendations)):</div><div class="line">        <span class="keyword">print</span> (<span class="string">"%2d: %s"</span> % (i + <span class="number">1</span>, movies[recommendations[i][<span class="number">1</span>]])).encode(<span class="string">'ascii'</span>, <span class="string">'ignore'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># clean up</span></div><div class="line">    sc.stop()</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Spark-Summit-2014&quot;&gt;&lt;a href=&quot;#Spark-Summit-2014&quot; class=&quot;headerlink&quot; title=&quot;Spark Summit 2014&quot;&gt;&lt;/a&gt;Spark Summit 2014&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;h
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="MLlib" scheme="http://yoursite.com/tags/MLlib/"/>
    
      <category term="recommendation system" scheme="http://yoursite.com/tags/recommendation-system/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning with MLlib of Spark</title>
    <link href="http://yoursite.com/2017/04/25/Machine-Learning-with-MLlib-of-Spark/"/>
    <id>http://yoursite.com/2017/04/25/Machine-Learning-with-MLlib-of-Spark/</id>
    <published>2017-04-25T11:13:07.000Z</published>
    <updated>2017-04-25T13:21:00.738Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Example-Spam-Classification"><a href="#Example-Spam-Classification" class="headerlink" title="Example: Spam Classification"></a>Example: Spam Classification</h2><p>This program uses two MLlib algorithms: <code>HashingTF</code>, which builds term frequency feature vectors from text data, and LogisticRegressionWithSGD, which implements the logistic regression procedure using stochastic gradient descent (<code>SGD</code>). We assume that we start with two files, spam.txt an normal.txt, each of which contains examples of spam and non-spam emails, one per line. We then turn the text in each file into a feature vector with <code>TF</code>, and train a logistic regression model to separate the two types of messages.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></div><div class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></div><div class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></div><div class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></div><div class="line"><span class="comment"># (the "License"); you may not use this file except in compliance with</span></div><div class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment">#    http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></div><div class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></div><div class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div><div class="line"><span class="comment"># See the License for the specific language governing permissions and</span></div><div class="line"><span class="comment"># limitations under the License.</span></div><div class="line"><span class="comment">#</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</div><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line"><span class="keyword">from</span> pyspark.mllib.classification <span class="keyword">import</span> LogisticRegressionWithSGD</div><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> HashingTF</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    sc = SparkContext(appName=<span class="string">"PythonBookExample"</span>)</div><div class="line"></div><div class="line">    <span class="comment"># Load 2 types of emails from text files: spam and ham (non-spam).</span></div><div class="line">    <span class="comment"># Each line has text from one email.</span></div><div class="line">    spam = sc.textFile(<span class="string">"file:///home/hduser/learning-spark/files/spam.txt"</span>)</div><div class="line">    ham = sc.textFile(<span class="string">"file:///home/hduser/learning-spark/files/ham.txt"</span>)</div><div class="line"></div><div class="line">    <span class="comment"># Create a HashingTF instance to map email text to vectors of 100 features.</span></div><div class="line">    tf = HashingTF(numFeatures = <span class="number">100</span>)</div><div class="line">    <span class="comment"># Each email is split into words, and each word is mapped to one feature.</span></div><div class="line">    spamFeatures = spam.map(<span class="keyword">lambda</span> email: tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line">    hamFeatures = ham.map(<span class="keyword">lambda</span> email: tf.transform(email.split(<span class="string">" "</span>)))</div><div class="line"></div><div class="line">    <span class="comment"># Create LabeledPoint datasets for positive (spam) and negative (ham) examples.</span></div><div class="line">    positiveExamples = spamFeatures.map(<span class="keyword">lambda</span> features: LabeledPoint(<span class="number">1</span>, features))</div><div class="line">    negativeExamples = hamFeatures.map(<span class="keyword">lambda</span> features: LabeledPoint(<span class="number">0</span>, features))</div><div class="line">    training_data = positiveExamples.union(negativeExamples)</div><div class="line">    training_data.cache() <span class="comment"># Cache data since Logistic Regression is an iterative algorithm.</span></div><div class="line"></div><div class="line">    <span class="comment"># Run Logistic Regression using the SGD optimizer.</span></div><div class="line">    <span class="comment"># regParam is model regularization, which can make models more robust.</span></div><div class="line">    model = LogisticRegressionWithSGD.train(training_data)</div><div class="line"></div><div class="line">    <span class="comment"># Test on a positive example (spam) and a negative one (ham).</span></div><div class="line">    <span class="comment"># First apply the same HashingTF feature transformation used on the training data.</span></div><div class="line">    posTestExample = tf.transform(<span class="string">"O M G GET cheap stuff by sending money to ..."</span>.split(<span class="string">" "</span>))</div><div class="line">    negTestExample = tf.transform(<span class="string">"Hi Dad, I started studying Spark the other ..."</span>.split(<span class="string">" "</span>))</div><div class="line"></div><div class="line">    <span class="comment"># Now use the learned model to predict spam/ham for new emails.</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"Prediction for positive test example: %g"</span> % model.predict(posTestExample)</div><div class="line">    <span class="keyword">print</span> <span class="string">"Prediction for negative test example: %g"</span> % model.predict(negTestExample)</div><div class="line"></div><div class="line">    sc.stop()</div></pre></td></tr></table></figure><h2 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h2><p><strong><em>Here only has some usual APIs.</em></strong></p><h3 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h3><h4 id="Scaling"><a href="#Scaling" class="headerlink" title="Scaling"></a>Scaling</h4><p>Most machine learning algorithms consider the magnitude of each element in the feature vector, and thus work best when the features are scaled so they weigh equally (e.g., all features have a mean of 0 and standard deviation of 1). Once you have built feature vectors, you can use the StandardScaler class in MLlib to do this scaling, both for the mean and the standard deviation. You create a StandardScaler, call fit() on a dataset to obtain a StandardScalerModel (i.e., compute the mean and variance of each column), and then call transform() on the model to scale a dataset.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> StandardScaler</div><div class="line"></div><div class="line">vectors = [Vectors.dense([<span class="number">-2.0</span>, <span class="number">5.0</span>, <span class="number">1.0</span>]), Vectors.dense([<span class="number">2.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>])]</div><div class="line">dataset = sc.parallelize(vectors)</div><div class="line">scaler = StandardScaler(withMean=<span class="keyword">True</span>, withStd=<span class="keyword">True</span>)</div><div class="line">model = scaler.fit(dataset)</div><div class="line">result = model.transform(dataset)</div><div class="line"></div><div class="line"><span class="comment"># Result: &#123;[-0.7071, 0.7071, 0.0], [0.7071, -0.7071, 0.0]&#125;</span></div></pre></td></tr></table></figure><h4 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h4><p>Simply use <code>Normalizer().transform(rdd)</code>. By default Normalizer uses the L 2 norm (i.e, Euclidean length), but you can also pass a power <code>p</code>to Normalizer to use the L p norm.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> Normalizer</div><div class="line"><span class="keyword">from</span> pyspark.mllib.util <span class="keyword">import</span> MLUtils</div><div class="line"></div><div class="line">data = MLUtils.loadLibSVMFile(sc, <span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</div><div class="line">labels = data.map(<span class="keyword">lambda</span> x: x.label)</div><div class="line">features = data.map(<span class="keyword">lambda</span> x: x.features)</div><div class="line"></div><div class="line">normalizer1 = Normalizer()</div><div class="line">normalizer2 = Normalizer(p=float(<span class="string">"inf"</span>))</div><div class="line"></div><div class="line"><span class="comment"># Each sample in data1 will be normalized using $L^2$ norm.</span></div><div class="line">data1 = labels.zip(normalizer1.transform(features))</div><div class="line"></div><div class="line"><span class="comment"># Each sample in data2 will be normalized using $L^\infty$ norm.</span></div><div class="line">data2 = labels.zip(normalizer2.transform(features))</div></pre></td></tr></table></figure><h4 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h4><p>Once you have trained the model (withWord2Vec.fit(rdd)), you will receive a Word2VecModel that can be used to transform() each word into a vector. Note that the size of the models in Word2Vec will be equal to the number of words in your vocabulary times the size of a vector (by default, 100). You may wish to filter out words that are not in a standard dictionary to limit the size. In general, a good size for the vocabulary is 100,000 words.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.feature <span class="keyword">import</span> Word2Vec</div><div class="line"></div><div class="line">inp = sc.textFile(<span class="string">"data/mllib/sample_lda_data.txt"</span>).map(<span class="keyword">lambda</span> row: row.split(<span class="string">" "</span>))</div><div class="line"></div><div class="line">word2vec = Word2Vec()</div><div class="line">model = word2vec.fit(inp)</div><div class="line"></div><div class="line">synonyms = model.findSynonyms(<span class="string">'1'</span>, <span class="number">5</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> word, cosine_distance <span class="keyword">in</span> synonyms:</div><div class="line">    print(<span class="string">"&#123;&#125;: &#123;&#125;"</span>.format(word, cosine_distance))</div></pre></td></tr></table></figure><h3 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h3><p><strong><em>Statistics.colStats(rdd)</em></strong><br>Computes a statistical summary of an RDD of vectors, which stores the min, max, mean, and variance for each column in the set of vectors. This can be used to obtain a wide variety of statistics in one pass.</p><p><strong><em>Statistics.corr(rdd, method)</em></strong><br>Computes the correlation matrix between columns in an RDD of vectors, using either the Pearson or Spearman correlation (method must be one of pearson and spearman).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.stat <span class="keyword">import</span> Statistics</div><div class="line"></div><div class="line">seriesX = sc.parallelize([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">3.0</span>, <span class="number">5.0</span>])  <span class="comment"># a series</span></div><div class="line"><span class="comment"># seriesY must have the same number of partitions and cardinality as seriesX</span></div><div class="line">seriesY = sc.parallelize([<span class="number">11.0</span>, <span class="number">22.0</span>, <span class="number">33.0</span>, <span class="number">33.0</span>, <span class="number">555.0</span>])</div><div class="line"></div><div class="line"><span class="comment"># Compute the correlation using Pearson's method. Enter "spearman" for Spearman's method.</span></div><div class="line"><span class="comment"># If a method is not specified, Pearson's method will be used by default.</span></div><div class="line">print(<span class="string">"Correlation is: "</span> + str(Statistics.corr(seriesX, seriesY, method=<span class="string">"pearson"</span>)))</div><div class="line"></div><div class="line">data = sc.parallelize(</div><div class="line">    [np.array([<span class="number">1.0</span>, <span class="number">10.0</span>, <span class="number">100.0</span>]), np.array([<span class="number">2.0</span>, <span class="number">20.0</span>, <span class="number">200.0</span>]), np.array([<span class="number">5.0</span>, <span class="number">33.0</span>, <span class="number">366.0</span>])]</div><div class="line">)  <span class="comment"># an RDD of Vectors</span></div><div class="line"></div><div class="line"><span class="comment"># calculate the correlation matrix using Pearson's method. Use "spearman" for Spearman's method.</span></div><div class="line"><span class="comment"># If a method is not specified, Pearson's method will be used by default.</span></div><div class="line">print(Statistics.corr(data, method=<span class="string">"pearson"</span>))</div></pre></td></tr></table></figure><p><strong><em>Statistics.corr(rdd1, rdd2, method)</em></strong><br>Computes the correlation between two RDDs of floating-point values, using either the Pearson or Spearman correlation (method must be one of pearson and spearman).</p><p><strong><em>Statistics.chiSqTest(rdd)</em></strong><br>Computes Pearson’s independence test for every feature with the label on an RDD of LabeledPoint objects. Returns an array of ChiSqTestResult objects that capture the p-value, test statistic, and degrees of freedom for each feature. Label and feature values must be categorical (i.e., discrete values).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.linalg <span class="keyword">import</span> Matrices, Vectors</div><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line"><span class="keyword">from</span> pyspark.mllib.stat <span class="keyword">import</span> Statistics</div><div class="line"></div><div class="line">vec = Vectors.dense(<span class="number">0.1</span>, <span class="number">0.15</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.25</span>)  <span class="comment"># a vector composed of the frequencies of events</span></div><div class="line"></div><div class="line"><span class="comment"># compute the goodness of fit. If a second vector to test against</span></div><div class="line"><span class="comment"># is not supplied as a parameter, the test runs against a uniform distribution.</span></div><div class="line">goodnessOfFitTestResult = Statistics.chiSqTest(vec)</div><div class="line"></div><div class="line"><span class="comment"># summary of the test including the p-value, degrees of freedom,</span></div><div class="line"><span class="comment"># test statistic, the method used, and the null hypothesis.</span></div><div class="line">print(<span class="string">"%s\n"</span> % goodnessOfFitTestResult)</div><div class="line"></div><div class="line">mat = Matrices.dense(<span class="number">3</span>, <span class="number">2</span>, [<span class="number">1.0</span>, <span class="number">3.0</span>, <span class="number">5.0</span>, <span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>])  <span class="comment"># a contingency matrix</span></div><div class="line"></div><div class="line"><span class="comment"># conduct Pearson's independence test on the input contingency matrix</span></div><div class="line">independenceTestResult = Statistics.chiSqTest(mat)</div><div class="line"></div><div class="line"><span class="comment"># summary of the test including the p-value, degrees of freedom,</span></div><div class="line"><span class="comment"># test statistic, the method used, and the null hypothesis.</span></div><div class="line">print(<span class="string">"%s\n"</span> % independenceTestResult)</div><div class="line"></div><div class="line">obs = sc.parallelize(</div><div class="line">    [LabeledPoint(<span class="number">1.0</span>, [<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>]),</div><div class="line">     LabeledPoint(<span class="number">1.0</span>, [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">0.0</span>]),</div><div class="line">     LabeledPoint(<span class="number">1.0</span>, [<span class="number">-1.0</span>, <span class="number">0.0</span>, <span class="number">-0.5</span>])]</div><div class="line">)  <span class="comment"># LabeledPoint(feature, label)</span></div><div class="line"></div><div class="line"><span class="comment"># The contingency table is constructed from an RDD of LabeledPoint and used to conduct</span></div><div class="line"><span class="comment"># the independence test. Returns an array containing the ChiSquaredTestResult for every feature</span></div><div class="line"><span class="comment"># against the label.</span></div><div class="line">featureTestResults = Statistics.chiSqTest(obs)</div><div class="line"></div><div class="line"><span class="keyword">for</span> i, result <span class="keyword">in</span> enumerate(featureTestResults):</div><div class="line">    print(<span class="string">"Column %d:\n%s"</span> % (i + <span class="number">1</span>, result))</div></pre></td></tr></table></figure><h3 id="Classification-and-Regression"><a href="#Classification-and-Regression" class="headerlink" title="Classification and Regression"></a>Classification and Regression</h3><p>MLlib includes a variety of methods for classification and regression, including simple linear methods and decision trees and forests.</p><h4 id="Linear-regression"><a href="#Linear-regression" class="headerlink" title="Linear regression"></a>Linear regression</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LinearRegressionWithSGD</div><div class="line"></div><div class="line">points = <span class="comment"># (create RDD of LabeledPoint)</span></div><div class="line">model = LinearRegressionWithSGD.train(points, iterations=<span class="number">200</span>, intercept=<span class="keyword">True</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"weights: %s, intercept: %s"</span> % (model.weights, model.intercept)</div></pre></td></tr></table></figure><h4 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h4><p>The logistic regression algorithm has a very similar API to linear regression, covered in the previous section. One difference is that there are two algorithms available for solving it: <code>SGD</code> and <code>LBFGS</code>. <code>LBFGS</code> is generally the best choice, but is not available in some earlier versions of <code>MLlib</code> (before <code>Spark 1.2</code>). These algorithms are available in the <code>mllib.classification.LogisticRegressionWithLBFGS</code> and <code>WithSGD</code> classes, which have interfaces similar to <code>LinearRegressionWithSGD</code>. They take all the same parameters as linear regression.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.classification <span class="keyword">import</span> LogisticRegressionWithLBFGS, LogisticRegressionModel</div><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line"></div><div class="line"><span class="comment"># Load and parse the data</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parsePoint</span><span class="params">(line)</span>:</span></div><div class="line">    values = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> line.split(<span class="string">' '</span>)]</div><div class="line">    <span class="keyword">return</span> LabeledPoint(values[<span class="number">0</span>], values[<span class="number">1</span>:])</div><div class="line"></div><div class="line">data = sc.textFile(<span class="string">"data/mllib/sample_svm_data.txt"</span>)</div><div class="line">parsedData = data.map(parsePoint)</div><div class="line"></div><div class="line"><span class="comment"># Build the model</span></div><div class="line">model = LogisticRegressionWithLBFGS.train(parsedData)</div><div class="line"></div><div class="line"><span class="comment"># Evaluating the model on training data</span></div><div class="line">labelsAndPreds = parsedData.map(<span class="keyword">lambda</span> p: (p.label, model.predict(p.features)))</div><div class="line">trainErr = labelsAndPreds.filter(<span class="keyword">lambda</span> (v, p): v != p).count() / float(parsedData.count())</div><div class="line">print(<span class="string">"Training Error = "</span> + str(trainErr))</div><div class="line"></div><div class="line"><span class="comment"># Save and load model</span></div><div class="line">model.save(sc, <span class="string">"target/tmp/pythonLogisticRegressionWithLBFGSModel"</span>)</div><div class="line">sameModel = LogisticRegressionModel.load(sc,</div><div class="line">                                         <span class="string">"target/tmp/pythonLogisticRegressionWithLBFGSModel"</span>)</div></pre></td></tr></table></figure><h4 id="Support-Vector-Machines"><a href="#Support-Vector-Machines" class="headerlink" title="Support Vector Machines"></a>Support Vector Machines</h4><p>They are available through the <code>SVMWithSGD</code> class, with similar parameters to linear and logisitic regression. The returned <code>SVMModel</code> uses a threshold for prediction like <code>LogisticRegressionModel</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.classification <span class="keyword">import</span> SVMWithSGD, SVMModel</div><div class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</div><div class="line"></div><div class="line"><span class="comment"># Load and parse the data</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parsePoint</span><span class="params">(line)</span>:</span></div><div class="line">    values = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> line.split(<span class="string">' '</span>)]</div><div class="line">    <span class="keyword">return</span> LabeledPoint(values[<span class="number">0</span>], values[<span class="number">1</span>:])</div><div class="line"></div><div class="line">data = sc.textFile(<span class="string">"data/mllib/sample_svm_data.txt"</span>)</div><div class="line">parsedData = data.map(parsePoint)</div><div class="line"></div><div class="line"><span class="comment"># Build the model</span></div><div class="line">model = SVMWithSGD.train(parsedData, iterations=<span class="number">100</span>)</div><div class="line"></div><div class="line"><span class="comment"># Evaluating the model on training data</span></div><div class="line">labelsAndPreds = parsedData.map(<span class="keyword">lambda</span> p: (p.label, model.predict(p.features)))</div><div class="line">trainErr = labelsAndPreds.filter(<span class="keyword">lambda</span> (v, p): v != p).count() / float(parsedData.count())</div><div class="line">print(<span class="string">"Training Error = "</span> + str(trainErr))</div><div class="line"></div><div class="line"><span class="comment"># Save and load model</span></div><div class="line">model.save(sc, <span class="string">"target/tmp/pythonSVMWithSGDModel"</span>)</div><div class="line">sameModel = SVMModel.load(sc, <span class="string">"target/tmp/pythonSVMWithSGDModel"</span>)</div></pre></td></tr></table></figure><h4 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h4><p>In <code>MLlib</code>, you can use <code>Naive Bayes</code> through the<code>mllib.classification.NaiveBayes</code> class. It supports one parameter, <code>lambda</code> (or <code>lambda_</code> in Python), used for smoothing. You can call it on an <code>RDD</code> of <code>LabeledPoints</code>, where the labels are between 0 and C–1 for C classes.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.classification <span class="keyword">import</span> NaiveBayes, NaiveBayesModel</div><div class="line"><span class="keyword">from</span> pyspark.mllib.util <span class="keyword">import</span> MLUtils</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Load and parse the data file.</span></div><div class="line">data = MLUtils.loadLibSVMFile(sc, <span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</div><div class="line"></div><div class="line"><span class="comment"># Split data approximately into training (60%) and test (40%)</span></div><div class="line">training, test = data.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>])</div><div class="line"></div><div class="line"><span class="comment"># Train a naive Bayes model.</span></div><div class="line">model = NaiveBayes.train(training, <span class="number">1.0</span>)</div><div class="line"></div><div class="line"><span class="comment"># Make prediction and test accuracy.</span></div><div class="line">predictionAndLabel = test.map(<span class="keyword">lambda</span> p: (model.predict(p.features), p.label))</div><div class="line">accuracy = <span class="number">1.0</span> * predictionAndLabel.filter(<span class="keyword">lambda</span> (x, v): x == v).count() / test.count()</div><div class="line">print(<span class="string">'model accuracy &#123;&#125;'</span>.format(accuracy))</div><div class="line"></div><div class="line"><span class="comment"># Save and load model</span></div><div class="line">output_dir = <span class="string">'target/tmp/myNaiveBayesModel'</span></div><div class="line">shutil.rmtree(output_dir, ignore_errors=<span class="keyword">True</span>)</div><div class="line">model.save(sc, output_dir)</div><div class="line">sameModel = NaiveBayesModel.load(sc, output_dir)</div><div class="line">predictionAndLabel = test.map(<span class="keyword">lambda</span> p: (sameModel.predict(p.features), p.label))</div><div class="line">accuracy = <span class="number">1.0</span> * predictionAndLabel.filter(<span class="keyword">lambda</span> (x, v): x == v).count() / test.count()</div><div class="line">print(<span class="string">'sameModel accuracy &#123;&#125;'</span>.format(accuracy))</div></pre></td></tr></table></figure><h4 id="Decision-trees-and-random-forests"><a href="#Decision-trees-and-random-forests" class="headerlink" title="Decision trees and random forests"></a>Decision trees and random forests</h4><p>In <code>MLlib</code>, you can train trees using the <code>mllib.tree.DecisionTree</code> class, through the static methods <code>trainClassifier()</code> and <code>trainRegressor()</code>. Unlike in some of the other algorithms, the Java and Scala APIs also use static methods instead of a <code>DecisionTree</code> object with setters.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.tree <span class="keyword">import</span> DecisionTree, DecisionTreeModel</div><div class="line"><span class="keyword">from</span> pyspark.mllib.util <span class="keyword">import</span> MLUtils</div><div class="line"></div><div class="line"><span class="comment"># Load and parse the data file into an RDD of LabeledPoint.</span></div><div class="line">data = MLUtils.loadLibSVMFile(sc, <span class="string">'data/mllib/sample_libsvm_data.txt'</span>)</div><div class="line"><span class="comment"># Split the data into training and test sets (30% held out for testing)</span></div><div class="line">(trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</div><div class="line"></div><div class="line"><span class="comment"># Train a DecisionTree model.</span></div><div class="line"><span class="comment">#  Empty categoricalFeaturesInfo indicates all features are continuous.</span></div><div class="line">model = DecisionTree.trainClassifier(trainingData, numClasses=<span class="number">2</span>, categoricalFeaturesInfo=&#123;&#125;,</div><div class="line">                                     impurity=<span class="string">'gini'</span>, maxDepth=<span class="number">5</span>, maxBins=<span class="number">32</span>)</div><div class="line"></div><div class="line"><span class="comment"># Evaluate model on test instances and compute test error</span></div><div class="line">predictions = model.predict(testData.map(<span class="keyword">lambda</span> x: x.features))</div><div class="line">labelsAndPredictions = testData.map(<span class="keyword">lambda</span> lp: lp.label).zip(predictions)</div><div class="line">testErr = labelsAndPredictions.filter(<span class="keyword">lambda</span> (v, p): v != p).count() / float(testData.count())</div><div class="line">print(<span class="string">'Test Error = '</span> + str(testErr))</div><div class="line">print(<span class="string">'Learned classification tree model:'</span>)</div><div class="line">print(model.toDebugString())</div><div class="line"></div><div class="line"><span class="comment"># Save and load model</span></div><div class="line">model.save(sc, <span class="string">"target/tmp/myDecisionTreeClassificationModel"</span>)</div><div class="line">sameModel = DecisionTreeModel.load(sc, <span class="string">"target/tmp/myDecisionTreeClassificationModel"</span>)</div></pre></td></tr></table></figure><h3 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h3><h4 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array</div><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"></div><div class="line"><span class="keyword">from</span> pyspark.mllib.clustering <span class="keyword">import</span> KMeans, KMeansModel</div><div class="line"></div><div class="line"><span class="comment"># Load and parse the data</span></div><div class="line">data = sc.textFile(<span class="string">"data/mllib/kmeans_data.txt"</span>)</div><div class="line">parsedData = data.map(<span class="keyword">lambda</span> line: array([float(x) <span class="keyword">for</span> x <span class="keyword">in</span> line.split(<span class="string">' '</span>)]))</div><div class="line"></div><div class="line"><span class="comment"># Build the model (cluster the data)</span></div><div class="line">clusters = KMeans.train(parsedData, <span class="number">2</span>, maxIterations=<span class="number">10</span>, initializationMode=<span class="string">"random"</span>)</div><div class="line"></div><div class="line"><span class="comment"># Evaluate clustering by computing Within Set Sum of Squared Errors</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">error</span><span class="params">(point)</span>:</span></div><div class="line">    center = clusters.centers[clusters.predict(point)]</div><div class="line">    <span class="keyword">return</span> sqrt(sum([x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> (point - center)]))</div><div class="line"></div><div class="line">WSSSE = parsedData.map(<span class="keyword">lambda</span> point: error(point)).reduce(<span class="keyword">lambda</span> x, y: x + y)</div><div class="line">print(<span class="string">"Within Set Sum of Squared Error = "</span> + str(WSSSE))</div><div class="line"></div><div class="line"><span class="comment"># Save and load model</span></div><div class="line">clusters.save(sc, <span class="string">"target/org/apache/spark/PythonKMeansExample/KMeansModel"</span>)</div><div class="line">sameModel = KMeansModel.load(sc, <span class="string">"target/org/apache/spark/PythonKMeansExample/KMeansModel"</span>)</div></pre></td></tr></table></figure><h3 id="Collaborative-Filtering-and-Recommendation"><a href="#Collaborative-Filtering-and-Recommendation" class="headerlink" title="Collaborative Filtering and Recommendation"></a>Collaborative Filtering and Recommendation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.mllib.recommendation <span class="keyword">import</span> ALS, MatrixFactorizationModel, Rating</div><div class="line"></div><div class="line"><span class="comment"># Load and parse the data</span></div><div class="line">data = sc.textFile(<span class="string">"data/mllib/als/test.data"</span>)</div><div class="line">ratings = data.map(<span class="keyword">lambda</span> l: l.split(<span class="string">','</span>))\</div><div class="line">    .map(<span class="keyword">lambda</span> l: Rating(int(l[<span class="number">0</span>]), int(l[<span class="number">1</span>]), float(l[<span class="number">2</span>])))</div><div class="line"></div><div class="line"><span class="comment"># Build the recommendation model using Alternating Least Squares</span></div><div class="line">rank = <span class="number">10</span></div><div class="line">numIterations = <span class="number">10</span></div><div class="line">model = ALS.train(ratings, rank, numIterations)</div><div class="line"></div><div class="line"><span class="comment"># Evaluate the model on training data</span></div><div class="line">testdata = ratings.map(<span class="keyword">lambda</span> p: (p[<span class="number">0</span>], p[<span class="number">1</span>]))</div><div class="line">predictions = model.predictAll(testdata).map(<span class="keyword">lambda</span> r: ((r[<span class="number">0</span>], r[<span class="number">1</span>]), r[<span class="number">2</span>]))</div><div class="line">ratesAndPreds = ratings.map(<span class="keyword">lambda</span> r: ((r[<span class="number">0</span>], r[<span class="number">1</span>]), r[<span class="number">2</span>])).join(predictions)</div><div class="line">MSE = ratesAndPreds.map(<span class="keyword">lambda</span> r: (r[<span class="number">1</span>][<span class="number">0</span>] - r[<span class="number">1</span>][<span class="number">1</span>])**<span class="number">2</span>).mean()</div><div class="line">print(<span class="string">"Mean Squared Error = "</span> + str(MSE))</div><div class="line"></div><div class="line"><span class="comment"># Save and load model</span></div><div class="line">model.save(sc, <span class="string">"target/tmp/myCollaborativeFilter"</span>)</div><div class="line">sameModel = MatrixFactorizationModel.load(sc, <span class="string">"target/tmp/myCollaborativeFilter"</span>)</div></pre></td></tr></table></figure><p>The <a href="https://databricks-training.s3.amazonaws.com/index.html" target="_blank" rel="external">training exercises</a> from the Spark Summit 2014 include a hands-on tutorial for <a href="https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html" target="_blank" rel="external">personalized movie recommendation with <code>spark.mllib</code></a>.</p><h3 id="Dimensionality-Reduction"><a href="#Dimensionality-Reduction" class="headerlink" title="Dimensionality Reduction"></a>Dimensionality Reduction</h3><h4 id="Principal-component-analysis"><a href="#Principal-component-analysis" class="headerlink" title="Principal component analysis"></a>Principal component analysis</h4><p>PCA in Scala</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Matrix</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.<span class="type">RowMatrix</span></div><div class="line"></div><div class="line"><span class="keyword">val</span> points: <span class="type">RDD</span>[<span class="type">Vector</span>] = <span class="comment">// ...</span></div><div class="line"><span class="keyword">val</span> mat: <span class="type">RowMatrix</span> = <span class="keyword">new</span> <span class="type">RowMatrix</span>(points)</div><div class="line"><span class="keyword">val</span> pc: <span class="type">Matrix</span> = mat.computePrincipalComponents(<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="comment">// Project points to low-dimensional space</span></div><div class="line"><span class="keyword">val</span> projected = mat.multiply(pc).rows</div><div class="line"></div><div class="line"><span class="comment">// Train a k-means model on the projected 2-dimensional data</span></div><div class="line"><span class="keyword">val</span> model = <span class="type">KMeans</span>.train(projected, <span class="number">10</span>)</div></pre></td></tr></table></figure><h4 id="Singular-value-decomposition"><a href="#Singular-value-decomposition" class="headerlink" title="Singular value decomposition"></a>Singular value decomposition</h4><p>SVD in Scala</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Compute the top 20 singular values of a RowMatrix mat and their singular vectors.</span></div><div class="line"><span class="keyword">val</span> svd: <span class="type">SingularValueDecomposition</span>[<span class="type">RowMatrix</span>, <span class="type">Matrix</span>] =</div><div class="line"> mat.computeSVD(<span class="number">20</span>, computeU=<span class="literal">true</span>)</div><div class="line"></div><div class="line"><span class="keyword">val</span> <span class="type">U</span>: <span class="type">RowMatrix</span> = svd.<span class="type">U</span> <span class="comment">// U is a distributed RowMatrix.</span></div><div class="line"><span class="keyword">val</span> s: <span class="type">Vector</span> = svd.s <span class="comment">// Singular values are a local dense vector.</span></div><div class="line"><span class="keyword">val</span> <span class="type">V</span>: <span class="type">Matrix</span> = svd.<span class="type">V</span> <span class="comment">// V is a local dense matrix.</span></div></pre></td></tr></table></figure><h3 id="Pipeline-API"><a href="#Pipeline-API" class="headerlink" title="Pipeline API"></a>Pipeline API</h3><p>Pipeline API version of spam classification in Scala</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.<span class="type">Pipeline</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.classification.<span class="type">LogisticRegression</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.feature.&#123;<span class="type">HashingTF</span>, <span class="type">Tokenizer</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.tuning.&#123;<span class="type">CrossValidator</span>, <span class="type">ParamGridBuilder</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.ml.evaluation.<span class="type">BinaryClassificationEvaluator</span></div><div class="line"></div><div class="line"><span class="comment">// A class to represent documents -- will be turned into a SchemaRDD</span></div><div class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">LabeledDocument</span>(<span class="params">id: <span class="type">Long</span>, text: <span class="type">String</span>, label: <span class="type">Double</span></span>)</span></div><div class="line"><span class="keyword">val</span> documents = <span class="comment">// (load RDD of LabeledDocument)</span></div><div class="line"></div><div class="line"><span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</div><div class="line"><span class="keyword">import</span> sqlContext._</div><div class="line"></div><div class="line"><span class="comment">// Configure an ML pipeline with three stages: tokenizer, tf, and lr; each stage</span></div><div class="line"><span class="comment">// outputs a column in a SchemaRDD and feeds it to the next stage's input column</span></div><div class="line"><span class="keyword">val</span> tokenizer = <span class="keyword">new</span> <span class="type">Tokenizer</span>() <span class="comment">// Splits each email into words</span></div><div class="line"> .setInputCol(<span class="string">"text"</span>)</div><div class="line"> .setOutputCol(<span class="string">"words"</span>)</div><div class="line"><span class="keyword">val</span> tf = <span class="keyword">new</span> <span class="type">HashingTF</span>() <span class="comment">// Maps email words to vectors of 10000 features</span></div><div class="line"> .setNumFeatures(<span class="number">10000</span>)</div><div class="line"> .setInputCol(tokenizer.getOutputCol)</div><div class="line"> .setOutputCol(<span class="string">"features"</span>)</div><div class="line"><span class="keyword">val</span> lr = <span class="keyword">new</span> <span class="type">LogisticRegression</span>() <span class="comment">// Uses "features" as inputCol by default</span></div><div class="line"><span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>().setStages(<span class="type">Array</span>(tokenizer, tf, lr))</div><div class="line"></div><div class="line"><span class="comment">// Fit the pipeline to the training documents</span></div><div class="line"><span class="keyword">val</span> model = pipeline.fit(documents)</div><div class="line"></div><div class="line"><span class="comment">// Alternatively, instead of fitting once with the parameters above, we can do a</span></div><div class="line"><span class="comment">// grid search over some parameters and pick the best model via cross-validation</span></div><div class="line"><span class="keyword">val</span> paramMaps = <span class="keyword">new</span> <span class="type">ParamGridBuilder</span>()</div><div class="line"> .addGrid(tf.numFeatures, <span class="type">Array</span>(<span class="number">10000</span>, <span class="number">20000</span>))</div><div class="line"> .addGrid(lr.maxIter, <span class="type">Array</span>(<span class="number">100</span>, <span class="number">200</span>))</div><div class="line"> .build() <span class="comment">// Builds all combinations of parameters</span></div><div class="line"><span class="keyword">val</span> eval = <span class="keyword">new</span> <span class="type">BinaryClassificationEvaluator</span>()</div><div class="line"><span class="keyword">val</span> cv = <span class="keyword">new</span> <span class="type">CrossValidator</span>()</div><div class="line"> .setEstimator(lr)</div><div class="line"> .setEstimatorParamMaps(paramMaps)</div><div class="line"> .setEvaluator(eval)</div><div class="line"><span class="keyword">val</span> bestModel = cv.fit(documents)</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Example-Spam-Classification&quot;&gt;&lt;a href=&quot;#Example-Spam-Classification&quot; class=&quot;headerlink&quot; title=&quot;Example: Spam Classification&quot;&gt;&lt;/a&gt;Exam
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="MLlib" scheme="http://yoursite.com/tags/MLlib/"/>
    
  </entry>
  
  <entry>
    <title>Solution for Bracket in markdown link address</title>
    <link href="http://yoursite.com/2017/04/23/%C2%96Solution-for-Bracket-in-markdown-link-address/"/>
    <id>http://yoursite.com/2017/04/23/Solution-for-Bracket-in-markdown-link-address/</id>
    <published>2017-04-23T11:56:40.000Z</published>
    <updated>2017-04-23T12:01:11.467Z</updated>
    
    <content type="html"><![CDATA[<p>Markdown创造一个链接或者图片是使用 <code>[title](link)</code> 和 <code>![title](link)</code>.</p><p>我们可以避免<code>[]</code>内出现中括号, 或者使用转义.</p><p>但是在小括号的链接里面就可能会出问题. 有些网址上面会具有小括号. 例如,</p><p><a href="https://github.com/CjTouzi/Learning-RSpark/blob/master/Zaharia%20M.%2C%20et%20al.%20Learning%20Spark%20%28O%27Reilly%2C%202015%29%28274s%29.pdf" target="_blank" rel="external">https://github.com/CjTouzi/Learning-RSpark/blob/master/Zaharia%20M.%2C%20et%20al.%20Learning%20Spark%20%28O%27Reilly%2C%202015%29%28274s%29.pdf</a></p><p>解决方法:</p><p><code>%28</code> 代替<code>(</code>, <code>%29</code>代替<code>)</code> 主要是后者会歧义链接部分的结束. 这是使用url符号码去代替ascii的符号. 能够解决这个问题</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Markdown创造一个链接或者图片是使用 &lt;code&gt;[title](link)&lt;/code&gt; 和 &lt;code&gt;![title](link)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;我们可以避免&lt;code&gt;[]&lt;/code&gt;内出现中括号, 或者使用转义.&lt;/p&gt;&lt;p&gt;但是在小括号的链
    
    </summary>
    
    
      <category term="markdown" scheme="http://yoursite.com/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>The first course of the Spark</title>
    <link href="http://yoursite.com/2017/04/23/The-first-course-of-the-Spark/"/>
    <id>http://yoursite.com/2017/04/23/The-first-course-of-the-Spark/</id>
    <published>2017-04-23T09:37:04.000Z</published>
    <updated>2017-04-23T11:54:53.876Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><ul><li>扩充了MapReduce计算模型</li><li>基于内存的计算</li><li>能够进行批处理、迭代式计算、交互查询和流处理<ul><li>降低里维护成本</li></ul></li><li>提供了Python、Java、Scala、SQL的API和丰富的内置库</li><li>可以与Hadoop、Kafka等整合</li></ul><h1 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h1><p><img src="http://o7ie0tcjk.bkt.clouddn.com/spark/first_course/spark_components.png" alt="components"></p><h2 id="Spark-Core"><a href="#Spark-Core" class="headerlink" title="Spark Core"></a>Spark Core</h2><p>Spark Core contains the basic functionality of Spark, including components for task scheduling, memory management, fault recovery, interacting with storage systems, and more. Spark Core is also home to the API that defines <em>resilient distributed datasets</em> (RDDs), which are Spark’s main programming abstraction. RDDs represent a collection of items distributed across many compute nodes that can be manipulated in parallel. Spark Core provides many APIs for building and manipulating these collections.</p><h2 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h2><p>Spark SQL is Spark’s package for working with structured data. It allows querying data via SQL as well as the Apache Hive variant of SQL—called the Hive Query Language (HQL)—and it supports many sources of data, including Hive tables, Parquet, and JSON. Beyond providing a SQL interface to Spark, Spark SQL allows developers to intermix SQL queries with the programmatic data manipulations supported by RDDs in Python, Java, and Scala, all within a single application, thus combining SQL with complex analytics. This tight integration with the rich computing environment provided by Spark makes Spark SQL unlike any other open source data warehouse tool. Spark SQL was added to Spark in version 1.0.</p><p>Shark was an older SQL-on-Spark project out of the University of California, Berkeley, that modified Apache Hive to run on Spark. It has now been replaced by Spark SQL to provide better integration with the Spark engine and language APIs.</p><h2 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h2><p>Spark Streaming is a Spark component that enables processing of live streams of data. Examples of data streams include logfiles generated by production web servers, or queues of messages containing status updates posted by users of a web service. Spark Streaming provides an API for manipulating data streams that closely matches the Spark Core’s RDD API, making it easy for programmers to learn the project and move between applications that manipulate data stored in memory, on disk, or arriving in real time. Underneath its API, Spark Streaming was designed to provide the same degree of fault tolerance, throughput, and scalability as Spark Core.</p><h2 id="MLlib"><a href="#MLlib" class="headerlink" title="MLlib"></a>MLlib</h2><p>Spark comes with a library containing common machine learning (ML) functionality, called MLlib. MLlib provides multiple types of machine learning algorithms, including classification, regression, clustering, and collaborative filtering, as well as supporting functionality such as model evaluation and data import. It also provides some lower-level ML primitives, including a generic gradient descent optimization algorithm. All of these methods are designed to scale out across a cluster.</p><h2 id="GraphX"><a href="#GraphX" class="headerlink" title="GraphX"></a>GraphX</h2><p>GraphX is a library for manipulating graphs (e.g., a social network’s friend graph) and performing graph-parallel computations. Like Spark Streaming and Spark SQL, GraphX extends the Spark RDD API, allowing us to create a directed graph with arbitrary properties attached to each vertex and edge. GraphX also provides various operators for manipulating graphs (e.g., <code>subgraph</code> and <code>mapVertices</code>) and a library of common graph algorithms (e.g., PageRank and triangle counting).</p><h2 id="Cluster-Managers"><a href="#Cluster-Managers" class="headerlink" title="Cluster Managers"></a>Cluster Managers</h2><p>Under the hood, Spark is designed to efficiently scale up from one to many thousands of compute nodes. To achieve this while maximizing flexibility, Spark can run over a variety of <em>cluster managers</em>, including Hadoop YARN, Apache Mesos, and a simple cluster manager included in Spark itself called the Standalone Scheduler. If you are just installing Spark on an empty set of machines, the Standalone Scheduler provides an easy way to get started; if you already have a Hadoop YARN or Mesos cluster, however, Spark’s support for these cluster managers allows your applications to also run on them.</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><ul><li>Spark由Scala编写，运行于JVM上，运行环境为Java 7+</li><li>如果使用Python API，需要安装Python 2.6+ 或者Python 3.4+</li><li>Spark 1.6.2 — Scala 2.10 / Spark 2.0.0 — Scala 2.11</li></ul><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p><a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">http://spark.apache.org/downloads.html</a></p><p>不需要Hadoop集群；如果已经搭建好Hadoop集群，可下载相应版本</p><h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li>README.md<ul><li>Contains short instructions for getting started with Spark.</li></ul></li><li>bin<ul><li>Contains executable files that can be used to interact with Spark in various ways (e.g., the Spark shell, which we will cover later in this chapter).</li></ul></li><li>core, streaming, python, …<ul><li>Contains the source code of major components of the Spark project.</li></ul></li><li>examples<ul><li>Contains some helpful Spark standalone jobs that you can look at and run tolearn about the Spark API.</li></ul></li></ul><h2 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h2><ul><li>Python Shell<ul><li><code>bin/pyspark</code></li></ul></li><li>Scala Shell<ul><li><code>bin/spark-shell</code></li></ul></li></ul><h1 id="开发环境搭建"><a href="#开发环境搭建" class="headerlink" title="开发环境搭建"></a>开发环境搭建</h1><h2 id="Scala安装"><a href="#Scala安装" class="headerlink" title="Scala安装"></a>Scala安装</h2><p><a href="https://www.scala-lang.org/download/" target="_blank" rel="external">https://www.scala-lang.org/download/</a></p><p>注意版本对应</p><h2 id="IntelliJ-IDEA安装"><a href="#IntelliJ-IDEA安装" class="headerlink" title="IntelliJ IDEA安装"></a>IntelliJ IDEA安装</h2><p><a href="https://www.jetbrains.com/idea/#chooseYourEdition" target="_blank" rel="external">https://www.jetbrains.com/idea/#chooseYourEdition</a></p><p>可以申请教育账号</p><h3 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h3><p><code>File-Settings-Plugins</code> 搜索Scala，安装</p><h3 id="项目创建"><a href="#项目创建" class="headerlink" title="项目创建"></a>项目创建</h3><p><code>File-New-Project-Scala-SBT</code></p><p>同样注意版本匹配（这里用的是Spark 2.1.0, Scala 2.11.11）</p><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>需要定义使用的Spark版本</p><p><code>build.sbt</code>追加</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">libraryDependencies ++= <span class="type">Seq</span>(</div><div class="line">  <span class="string">"org.apache.spark"</span> %% <span class="string">"spark-core"</span> % <span class="string">"2.1.0"</span></div><div class="line">)</div></pre></td></tr></table></figure><p>重建项目即可</p><h3 id="源程序编写"><a href="#源程序编写" class="headerlink" title="源程序编写"></a>源程序编写</h3><p><code>New-Scala Class-Class to Object</code></p><p><code>WordCount.scala</code></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkContext</span>, <span class="type">SparkConf</span>&#125;</div><div class="line"><span class="comment">/**</span></div><div class="line">  * Created by root on 4/23/17.</div><div class="line">  */</div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"wordcount"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> input = sc.textFile(<span class="string">"/home/hduser/Anaconda2-4.3.1-Linux-x86_64.sh"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> lines = input.flatMap(line =&gt; line.split(<span class="string">" "</span>))</div><div class="line">    <span class="keyword">val</span> count = lines.map(word =&gt; (word, <span class="number">1</span>)).reduceByKey&#123;<span class="keyword">case</span> (x, y) =&gt; x + y&#125;</div><div class="line">    <span class="keyword">val</span> output = count.saveAsTextFile(<span class="string">"/home/hduser/scala_wordcount_demo_output"</span>)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h3><p><code>File-Project Structure-Project Setting-Artifacts-Add-JAR-From modules with dependencies</code></p><p><code>Build-Build Artifacts-Build</code></p><h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><ul><li>启动master<ul><li><code>sbin/start-master.sh</code></li></ul></li><li>启动worker<ul><li><code>bin/spark-class org.apache.spark.deploy.worker.Worker spark://Ubuntu:7077</code></li><li>注意这里的spark服务器地址可以通过浏览器输入<code>localhost:8080</code>来查看</li></ul></li><li>提交作业<ul><li><code>bin/spark-submit --master spark://Ubuntu:7077 --class WordCount /home/hduser/scala_demo.jar</code></li><li>注意这里的<code>scala_demo.jar</code>文件为打包阶段生成</li></ul></li></ul><h1 id="TODO-RDDs"><a href="#TODO-RDDs" class="headerlink" title="TODO: RDDs"></a>TODO: RDDs</h1><p><a href="https://github.com/CjTouzi/Learning-RSpark/blob/master/Zaharia%20M.%2C%20et%20al.%20Learning%20Spark%20%28O%27Reilly%2C%202015%29%28274s%29.pdf" target="_blank" rel="external">Zaharia M., et al. Learning Spark (O’Reilly, 2015)(274s).pdf</a></p><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol><li>慕课网 <a href="http://www.imooc.com/learn/814" target="_blank" rel="external">http://www.imooc.com/learn/814</a></li><li>Zaharia M., et al. Learning Spark (O’Reilly, 2015)(274s).pdf</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;扩充了MapReduce计算模型&lt;/li&gt;&lt;li&gt;基于内存的计算&lt;/li&gt;&lt;li&gt;能够进行批处理、迭代式计算、交互查询和流处理&lt;u
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Implement k-means on the hadoop platform</title>
    <link href="http://yoursite.com/2017/04/21/Implement-k-means-on-the-hadoop-platform/"/>
    <id>http://yoursite.com/2017/04/21/Implement-k-means-on-the-hadoop-platform/</id>
    <published>2017-04-21T05:44:53.000Z</published>
    <updated>2017-04-21T06:14:35.823Z</updated>
    
    <content type="html"><![CDATA[<p>首先在单机上搭一个伪分布式环境，主要是对<code>*-site.xml</code>配置文件进行修改，具体修改如下：</p><p><code>core-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0"?&gt;</div><div class="line"><span class="comment">&lt;!-- core-site.xml --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure><p><code>hdfs-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0"?&gt;</div><div class="line"><span class="comment">&lt;!-- hdfs-site.xml --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure><p><code>yarn-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0"?&gt;</div><div class="line"><span class="comment">&lt;!-- yarn-site.xml --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure><p><code>mapred-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0"?&gt;</div><div class="line"><span class="comment">&lt;!-- mapred-site.xml --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure><p>然后启动<code>hadoop</code>，启动的流程如下：</p><ol><li><code>start-dfs.sh</code></li><li><code>start-yarn.sh</code></li><li><code>mr-jobhistory-daemon.sh start historyserver</code></li></ol><p><strong>注意，以上命令能够得到正确执行的前提是已经将<code>hadoop</code>的安装目录下的<code>bin</code>目录加到环境变量中</strong></p><p>由于很久没有使用<code>Java</code>，所以采用<code>Python</code>实现，这里需要用到一个<code>package</code>，也就是<code>mrjob</code></p><p>首先计划一下实现步骤：</p><p>[ Mapper ]</p><p><strong>Accepts</strong></p><ul><li>data</li><li>global constant representing the list of centers</li></ul><p><strong>Computes</strong></p><ul><li>the nearest center for each data instance</li></ul><p><strong>Emits</strong></p><ul><li>nearest centers (<strong>key</strong>) and points (<strong>value</strong>).</li></ul><hr><p>[ Reducer ]</p><p><strong>Accepts</strong></p><ul><li>center instance / coordinate (<strong>key</strong>)</li><li>points (<strong>value</strong>)</li></ul><p><strong>Computes</strong></p><ul><li>the new centers based on clusters</li></ul><p><strong>Emits</strong></p><ul><li>new centers</li></ul><p>You will provide the next epoch of K-Means with:</p><ol><li>the same data from your initial epoch</li><li>the centers emitted from the reducer as global constants</li></ol><p>Repeat until your stopping criteria are met.</p><p>如果要用<code>Python</code>进行相关的<code>Hadoop</code>操作的话，肯定是要使用<code>hadoop streaming</code>的，但是存在一个问题，也就是<code>streaming</code>流程只能跑一遍，但是很显然，作为一个<code>machine learning</code>算法，<code>k-means</code>是类似于<code>EM</code>算法要经过多步迭代的，那么最容易想到的就是使用shell脚本多次调用相关命令，但是这样显得十分<code>ugly</code>，因此可以采用<code>mrjob</code>包来帮助我们完成这个工作。</p><p>从上面看来，我们需要两个文件，一个是<code>python</code>实现的<code>map-reduce</code>，另一个是<code>mrjob</code>的<code>job</code>文件，相当于<code>master</code>，下面列出这两个文件，因为实现比较简单，因此不作过多解释.</p><p><code>kmeans.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</div><div class="line"><span class="keyword">import</span> mrjob</div><div class="line"><span class="comment"># MRJob is a python class which will be overloaded</span></div><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MRKMeans</span><span class="params">(MRJob)</span>:</span></div><div class="line"></div><div class="line">    SORT_VALUES = <span class="keyword">True</span></div><div class="line">    OUTPUT_PROTOCOL = mrjob.protocol.RawProtocol</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dist_vec</span><span class="params">(self, v1, v2)</span>:</span></div><div class="line">        <span class="comment"># calculate the ditance between two vectors (in two dimensions)</span></div><div class="line">        <span class="keyword">return</span> sqrt((v2[<span class="number">0</span>] - v1[<span class="number">0</span>]) * (v2[<span class="number">0</span>] - v1[<span class="number">0</span>]) + (v2[<span class="number">1</span>] - v1[<span class="number">1</span>]) * (v2[<span class="number">1</span>] - v1[<span class="number">1</span>]))</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">configure_options</span><span class="params">(self)</span>:</span></div><div class="line">        super(MRKMeans, self).configure_options()</div><div class="line">        <span class="comment"># the line below define that the file folowing the --c option is the</span></div><div class="line">        <span class="comment"># centroid and is loadable</span></div><div class="line">        self.add_file_option(<span class="string">'--c'</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_centroids</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        Definition : extracts centroids from the centroids file define afetr --c flag</div><div class="line">        Out : Return the list of centroids</div><div class="line">        """</div><div class="line">        <span class="comment"># self.options.c is the name of the file following --c option</span></div><div class="line">        f = open(self.options.c, <span class="string">'r'</span>)</div><div class="line">        centroids = []</div><div class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.read().split(<span class="string">'\n'</span>):</div><div class="line">            <span class="keyword">if</span> line:</div><div class="line">                x, y = line.split(<span class="string">', '</span>)</div><div class="line">                centroids.append([float(x), float(y)])</div><div class="line">        f.close()</div><div class="line">        <span class="keyword">return</span> centroids</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span><span class="params">(self, _, lines)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        Definition : Mapper take centroids extract form get_centroids()</div><div class="line">        and the point cloud and for each point, calculate the distance</div><div class="line">        to the centroids, find the mininum of it</div><div class="line">        Out : yield the point with it's class</div><div class="line">        """</div><div class="line">        centroids = self.get_centroids()</div><div class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> lines.split(<span class="string">'\n'</span>):</div><div class="line">            x, y = l.split(<span class="string">', '</span>)</div><div class="line">            point = [float(x), float(y)]</div><div class="line">            min_dist = <span class="number">100000000.0</span></div><div class="line">            classe = <span class="number">0</span></div><div class="line">            <span class="comment"># iterate over the centroids (Here we know that we are doing a 3means)</span></div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">                dist = self.dist_vec(point, centroids[i])</div><div class="line">                <span class="keyword">if</span> dist &lt; min_dist:</div><div class="line">                    min_dist = dist</div><div class="line">                    classe = i</div><div class="line">            <span class="keyword">yield</span> classe, point</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combiner</span><span class="params">(self, k, v)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        Definition : Calculate for each class, at the end of the mapper,</div><div class="line">        before reducer, the medium point of each class</div><div class="line">        Out: return for each class, the centroids for each mapper</div><div class="line">        """</div><div class="line">        count = <span class="number">0</span></div><div class="line">        moy_x = moy_y = <span class="number">0.0</span></div><div class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> v:</div><div class="line">            count += <span class="number">1</span></div><div class="line">            moy_x += t[<span class="number">0</span>]</div><div class="line">            moy_y += t[<span class="number">1</span>]</div><div class="line">        <span class="keyword">yield</span> k, (moy_x / count, moy_y / count)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer</span><span class="params">(self, k, v)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        Definition : for each class, get all the tmp centroids from each</div><div class="line">        combiner and calculate the new centroids.</div><div class="line">        """</div><div class="line">        <span class="comment"># k is class and v are medium points linked to the class</span></div><div class="line">        count = <span class="number">0</span></div><div class="line">        moy_x = moy_y = <span class="number">0.0</span></div><div class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> v:</div><div class="line">            count += <span class="number">1</span></div><div class="line">            moy_x += t[<span class="number">0</span>]</div><div class="line">            moy_y += t[<span class="number">1</span>]</div><div class="line">        <span class="keyword">print</span> str(k) + <span class="string">", "</span> + str(moy_x / count) + <span class="string">", "</span> + str(moy_y / count)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="comment"># just run mapreduce !</span></div><div class="line">    MRKMeans.run()</div></pre></td></tr></table></figure><p><code>main.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</div><div class="line"><span class="keyword">from</span> kmeans <span class="keyword">import</span> MRKMeans</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> os.path</div><div class="line"><span class="keyword">import</span> shutil</div><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line">input_c = <span class="string">"centroids"</span></div><div class="line"></div><div class="line">CENTROIDS_FILE = <span class="string">"/home/hduser/tmp/centroid"</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_c</span><span class="params">(job, runner)</span>:</span></div><div class="line">    c = []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> runner.stream_output():</div><div class="line">        <span class="comment"># print "stream_output: ", line</span></div><div class="line">        key, value = job.parse_output_line(line)</div><div class="line">        c.append(key)</div><div class="line">    <span class="keyword">return</span> c</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_first_c</span><span class="params">(fname)</span>:</span></div><div class="line">    f = open(fname, <span class="string">'r'</span>)</div><div class="line">    centroids = []</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.read().split(<span class="string">'\n'</span>):</div><div class="line">        <span class="keyword">if</span> line:</div><div class="line">            x, y = line.split(<span class="string">', '</span>)</div><div class="line">            centroids.append([float(x), float(y)])</div><div class="line">    f.close()</div><div class="line">    <span class="keyword">return</span> centroids</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_c</span><span class="params">(centroids)</span>:</span></div><div class="line">    f = open(CENTROIDS_FILE, <span class="string">"w"</span>)</div><div class="line">    centroids.sort()</div><div class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> centroids:</div><div class="line">        k, cx, cy = c.split(<span class="string">', '</span>)</div><div class="line">        <span class="comment"># print c</span></div><div class="line">        f.write(<span class="string">"%s, %s\n"</span> % (cx, cy))</div><div class="line">    f.close()</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dist_vec</span><span class="params">(v1, v2)</span>:</span></div><div class="line">    <span class="keyword">return</span> sqrt((v2[<span class="number">0</span>] - v1[<span class="number">0</span>]) * (v2[<span class="number">0</span>] - v1[<span class="number">0</span>]) + (v2[<span class="number">1</span>] - v1[<span class="number">1</span>]) * (v2[<span class="number">1</span>] - v1[<span class="number">1</span>]))</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">diff</span><span class="params">(cs1, cs2)</span>:</span></div><div class="line">    max_dist = <span class="number">0.0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</div><div class="line">        dist = dist_vec(cs1[i], cs2[i])</div><div class="line">        <span class="keyword">if</span> dist &gt; max_dist:</div><div class="line">            max_dist = dist</div><div class="line"></div><div class="line">    <span class="keyword">return</span> max_dist</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line"></div><div class="line">    args = sys.argv[<span class="number">1</span>:]</div><div class="line"></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(CENTROIDS_FILE):</div><div class="line">        shutil.copy(input_c, CENTROIDS_FILE)</div><div class="line"></div><div class="line">    old_c = get_first_c(input_c)</div><div class="line"></div><div class="line">    i = <span class="number">1</span></div><div class="line">    start = time.time()</div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        <span class="keyword">print</span> <span class="string">"Iteration #%i"</span> % i</div><div class="line">        mr_job = MRKMeans(args=args + [<span class="string">'--c='</span> + CENTROIDS_FILE])</div><div class="line">        <span class="comment"># print "start runner.."</span></div><div class="line"></div><div class="line">        <span class="keyword">with</span> mr_job.make_runner() <span class="keyword">as</span> runner:</div><div class="line">            runner.run()</div><div class="line">            centroids = get_c(mr_job, runner)</div><div class="line"></div><div class="line">        <span class="comment"># print "mr result: ", centroids</span></div><div class="line">        write_c(centroids)</div><div class="line">        n_c = get_first_c(CENTROIDS_FILE)</div><div class="line">        <span class="comment"># print "old_c", old_c</span></div><div class="line">        <span class="comment"># print "n_c", n_c </span></div><div class="line">        max_d = diff(n_c, old_c)</div><div class="line">        <span class="comment"># print "dist max = "+str(max_d)</span></div><div class="line">        <span class="keyword">if</span> max_d &lt; <span class="number">0.01</span>:</div><div class="line">            <span class="keyword">break</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            old_c = n_c</div><div class="line">            i = i + <span class="number">1</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"used time: "</span>, time.time() - start, <span class="string">'s'</span></div></pre></td></tr></table></figure><p>根据上面写的实现步骤可以看出，我们需要两个文件，一个存储输入数据，另一个存储<code>centroids</code>，由于只是一个demo，因此在这里我简化了具体问题。设所有的数据都是二维数据点，并且聚类个数为3。当然，如果真的是在大数据上进行工业级的处理的话，还是推荐使用<code>Spark</code>。下面列出这两个文件：</p><p><code>kmeans_data</code></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="number">1</span>, <span class="number">2</span></div><div class="line"><span class="number">2</span>, <span class="number">3</span></div><div class="line"><span class="number">1</span>, <span class="number">3.5</span></div><div class="line"><span class="number">4</span>, <span class="number">3.5</span></div><div class="line"><span class="number">3</span>, <span class="number">4.2</span></div><div class="line"><span class="number">2</span>, <span class="number">1.6</span></div><div class="line"><span class="number">5</span>, <span class="number">2.3</span></div><div class="line"><span class="number">1.5</span>, <span class="number">2.3</span></div><div class="line"><span class="number">3</span>, <span class="number">5.2</span></div><div class="line"><span class="number">2</span>, <span class="number">3</span></div><div class="line"><span class="number">1</span>, <span class="number">3.5</span></div><div class="line"><span class="number">4</span>, <span class="number">3.5</span></div><div class="line"><span class="number">3</span>, <span class="number">4.2</span></div><div class="line"><span class="number">2</span>, <span class="number">1.6</span></div><div class="line"><span class="number">5</span>, <span class="number">2.3</span></div><div class="line"><span class="number">1.5</span>, <span class="number">2.3</span></div><div class="line"><span class="number">3</span>, <span class="number">5</span></div></pre></td></tr></table></figure><p><code>centroids</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1, 2</div><div class="line">2, 3</div><div class="line">1, 3.5</div></pre></td></tr></table></figure><p>按照以下方式运行：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python main.py kmeans_data -r hadoop</div></pre></td></tr></table></figure><p>结果显示如下：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Iteration #<span class="number">1</span></div><div class="line">No handlers could be found <span class="keyword">for</span> logger <span class="string">"mrjob.hadoop"</span></div><div class="line">old_c [[<span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>], [<span class="number">1.0</span>, <span class="number">3.5</span>]]</div><div class="line">n_c [[<span class="number">1.625</span>, <span class="number">1.95833333333</span>], [<span class="number">3.4</span>, <span class="number">3.62</span>], [<span class="number">1.0</span>, <span class="number">3.5</span>]]</div><div class="line">Iteration #<span class="number">2</span></div><div class="line">old_c [[<span class="number">1.625</span>, <span class="number">1.95833333333</span>], [<span class="number">3.4</span>, <span class="number">3.62</span>], [<span class="number">1.0</span>, <span class="number">3.5</span>]]</div><div class="line">n_c [[<span class="number">1.72916666667</span>, <span class="number">2.2625</span>], [<span class="number">3.75</span>, <span class="number">3.775</span>], [<span class="number">1.0</span>, <span class="number">3.5</span>]]</div><div class="line">Iteration #<span class="number">3</span></div><div class="line">old_c [[<span class="number">1.72916666667</span>, <span class="number">2.2625</span>], [<span class="number">3.75</span>, <span class="number">3.775</span>], [<span class="number">1.0</span>, <span class="number">3.5</span>]]</div><div class="line">n_c [[<span class="number">1.72916666667</span>, <span class="number">2.2625</span>], [<span class="number">3.75</span>, <span class="number">3.775</span>], [<span class="number">1.0</span>, <span class="number">3.5</span>]]</div><div class="line">time:  <span class="number">148.277868032</span></div></pre></td></tr></table></figure><p>最后生成结果文件：</p><p><code>centroid</code></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="number">1.72916666667</span>, <span class="number">2.2625</span></div><div class="line"><span class="number">3.75</span>, <span class="number">3.775</span></div><div class="line"><span class="number">1.0</span>, <span class="number">3.5</span></div></pre></td></tr></table></figure><p>根据以上可以看出，对于小数据集，效率反而会比较低，因为整个程序运行过程中大部分的时间都没有花在实际的算法运行上。</p><p><strong>TODO：</strong></p><ol><li>用常规方法实现，作为baseline</li><li>在大数据集上继续实验，观察结果</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;首先在单机上搭一个伪分布式环境，主要是对&lt;code&gt;*-site.xml&lt;/code&gt;配置文件进行修改，具体修改如下：&lt;/p&gt;&lt;p&gt;&lt;code&gt;core-site.xml&lt;/code&gt;&lt;/p&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Something about cloudera</title>
    <link href="http://yoursite.com/2017/04/20/Something-about-cloudera/"/>
    <id>http://yoursite.com/2017/04/20/Something-about-cloudera/</id>
    <published>2017-04-20T01:55:41.000Z</published>
    <updated>2017-04-20T01:59:40.353Z</updated>
    
    <content type="html"><![CDATA[<p>最近发现了一个神器，cloudera</p><p><a href="https://www.cloudera.com/" target="_blank" rel="external">https://www.cloudera.com/</a></p><p>它其实是一个集成了Hadoop生态系统的CentOS 6.7的VM，可以跑在Docker、Virtual Box或者VMware上</p><p><a href="https://www.cloudera.com/downloads/quickstart_vms/5-10.html" target="_blank" rel="external">https://www.cloudera.com/downloads/quickstart_vms/5-10.html</a></p><p>虚拟机配置的时候需要分配至少8G的RAM以及2个Cores。</p><p>另外，第一次启动会有些慢，请耐心等待。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近发现了一个神器，cloudera&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.cloudera.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.cloudera.com/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;它其实是一个集成了
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop Distributed Filesystem notes</title>
    <link href="http://yoursite.com/2017/04/18/Hadoop-Distributed-Filesystem-notes/"/>
    <id>http://yoursite.com/2017/04/18/Hadoop-Distributed-Filesystem-notes/</id>
    <published>2017-04-18T03:53:51.000Z</published>
    <updated>2017-04-18T08:27:03.429Z</updated>
    
    <content type="html"><![CDATA[<h2 id="HDFS-Concepts"><a href="#HDFS-Concepts" class="headerlink" title="HDFS Concepts"></a>HDFS Concepts</h2><h3 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h3><ul><li>128 MB by default<ul><li>HDFS blocks are large compared to disk blocks, and the reason is to minimize the cost<br>of seeks.</li></ul></li><li>Having a block abstraction for a distributed filesystem brings several benefits<ul><li>A file can be larger than any single disk in the network.</li><li>Simplifies the storage subsystem.</li><li>Providing fault tolerance and availability.</li></ul></li><li><code>% hdfs fsck / -files -blocks</code></li></ul><h3 id="Namenodes-and-Datanodes"><a href="#Namenodes-and-Datanodes" class="headerlink" title="Namenodes and Datanodes"></a>Namenodes and Datanodes</h3><ul><li>An HDFS cluster has two types of nodes operating in a master−worker pattern<ul><li>namenode (the master)</li><li>datanodes (workers)</li></ul></li><li>Without the namenode, the filesystem cannot be used<ul><li>For this reason, it is important to make the namenode resilient to failure</li><li>The first way is to back up the files that make up the persistent state of the filesystem<br>metadata.</li><li>It is also possible to run a secondary namenode</li></ul></li></ul><h3 id="Block-Caching"><a href="#Block-Caching" class="headerlink" title="Block Caching"></a>Block Caching</h3><ul><li>For frequently accessed files the blocks may be explicitly cached in the datanode’s memory, in an off-heap block cache. By default, a block is cached in only one datanode’s memory.</li></ul><h3 id="HDFS-Federation"><a href="#HDFS-Federation" class="headerlink" title="HDFS Federation"></a>HDFS Federation</h3><ul><li>one namenode might manage all the files rooted under /user, say, and a second name‐<br>node might handle files under /share.<ul><li>namespace volume</li><li>block pool</li></ul></li><li>namenodes do not communicate with one another</li></ul><h3 id="HDFS-High-Avalibility"><a href="#HDFS-High-Avalibility" class="headerlink" title="HDFS High Avalibility"></a>HDFS High Avalibility</h3><ul><li>The new namenode is not able to serve requests until it has<ul><li>loaded its namespace image into memory</li><li>replayed its edit log</li><li>received enough block reports from the datanodes to leave safe mode.</li></ul></li><li>On large clusters with many files and blocks, the time it takes for a namenode to start from cold can be 30 minutes or more.</li><li>Hadoop 2 remedied this situation by adding support for HDFS high availability (HA).<ul><li>there are a pair of namenodes in an active-standby configuration. In the event of the failure of the active namenode, the standby takes over its duties to continue servicing client requests without a significant interruption.</li></ul></li><li>There are two choices for the highly available shared storage<ul><li>NFS filer</li><li>quorum journal manager (QJM)</li><li>The actual observed failover time will be longer in practice (around a minute or so)</li></ul></li><li>The transition from the active namenode to the standby is managed by a new entity in<br>the system called the failover controller<ul><li>default implementation uses ZooKeeper to ensure that only one namenode is active.</li><li>The QJM only allows one namenode to write to the edit log at one time</li></ul></li></ul><h2 id="The-Command-Line-Interface"><a href="#The-Command-Line-Interface" class="headerlink" title="The Command-Line Interface"></a>The Command-Line Interface</h2><h3 id="Basic-Filesystem-Operations"><a href="#Basic-Filesystem-Operations" class="headerlink" title="Basic Filesystem Operations"></a>Basic Filesystem Operations</h3><ul><li><p>copying a file from the local filesystem to HDFS</p><ul><li><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">% hadoop fs -copyFromLocal input/docs/quangle.txt \</div><div class="line"> hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div></pre></td></tr></table></figure></li></ul></li><li><p>copy the file back to the local filesystem and check whether it’s the same</p><ul><li><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">% hadoop fs -copyToLocal quangle.txt quangle.copy.txt</div><div class="line">% md5 input/docs/quangle.txt quangle.copy.txt</div><div class="line">e7891a2627cf263a079fb0f18256ffb2 input/docs/quangle.txt</div><div class="line">MD5 (quangle.copy.txt) = e7891a2627cf263a079fb0f18256ffb2</div></pre></td></tr></table></figure></li></ul></li><li><p>create a directory first just to see how it is displayed in the listing</p><ul><li><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">% hadoop fs -mkdir books</div><div class="line">% hadoop fs -ls .</div><div class="line">Found <span class="number">2</span> items</div><div class="line">drwxr-xr-x - tom supergroup <span class="number">0</span> <span class="number">2014</span><span class="number">-10</span><span class="number">-04</span> <span class="number">13</span>:<span class="number">22</span> books</div><div class="line">-rw-r--r-- <span class="number">1</span> tom supergroup <span class="number">119</span> <span class="number">2014</span><span class="number">-10</span><span class="number">-04</span> <span class="number">13</span>:<span class="number">21</span> quangle.txt</div></pre></td></tr></table></figure></li></ul></li></ul><h2 id="The-Java-Interface"><a href="#The-Java-Interface" class="headerlink" title="The Java Interface"></a>The Java Interface</h2><h3 id="Reading-Data-from-a-Hadoop-URL"><a href="#Reading-Data-from-a-Hadoop-URL" class="headerlink" title="Reading Data from a Hadoop URL"></a>Reading Data from a Hadoop URL</h3><p><em>Example. Displaying files from a Hadoop filesystem on standard output using a URLStreamHandler</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc URLCat Displays files from a Hadoop filesystem on standard output using a URLStreamHandler</span></div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.net.URL;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FsUrlStreamHandlerFactory;</div><div class="line"><span class="keyword">import</span> org.a</div><div class="line">  pache.hadoop.io.IOUtils;</div><div class="line"></div><div class="line"><span class="comment">// vv URLCat</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">URLCat</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">static</span> &#123;</div><div class="line">    URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    InputStream in = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      in = <span class="keyword">new</span> URL(args[<span class="number">0</span>]).openStream();</div><div class="line">      IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      IOUtils.closeStream(in);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ URLCat</span></div></pre></td></tr></table></figure><p><strong>There’s a little bit more work required to make Java recognize Hadoop’s hdfs URL scheme. This is achieved by calling the setURLStreamHandlerFactory() method on URL with an instance of FsUrlStreamHandlerFactory. This method can be called only once per JVM, so it is typically executed in a static block.</strong></p><p>Here’s a sample run:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">% <span class="keyword">export</span> HADOOP_CLASSPATH=hadoop-examples.jar</div><div class="line">% hadoop URLCat hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div><div class="line">On the top of the Crumpetty Tree</div><div class="line">The Quangle Wangle sat,</div><div class="line">But his face you could not see,</div><div class="line">On account of his Beaver Hat.</div></pre></td></tr></table></figure><h3 id="Reading-Data-Using-the-FileSystem-API"><a href="#Reading-Data-Using-the-FileSystem-API" class="headerlink" title="Reading Data Using the FileSystem API"></a>Reading Data Using the FileSystem API</h3><p><em>Example. Displaying files from a Hadoop filesystem on standard output by using the FileSystem directly</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc FileSystemCat Displays files from a Hadoop filesystem on standard output by using the FileSystem directly</span></div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div><div class="line"></div><div class="line"><span class="comment">// vv FileSystemCat</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileSystemCat</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    String uri = args[<span class="number">0</span>];</div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    FileSystem fs = FileSystem.get(URI.create(uri), conf);</div><div class="line">    InputStream in = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      in = fs.open(<span class="keyword">new</span> Path(uri));</div><div class="line">      IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      IOUtils.closeStream(in);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ FileSystemCat</span></div></pre></td></tr></table></figure><p>The program runs as follows:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">% hadoop FileSystemCat hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div><div class="line">On the top of the Crumpetty Tree</div><div class="line">The Quangle Wangle sat,</div><div class="line">But his face you could not see,</div><div class="line">On account of his Beaver Hat.</div></pre></td></tr></table></figure><h4 id="FSDataInputStream"><a href="#FSDataInputStream" class="headerlink" title="FSDataInputStream"></a>FSDataInputStream</h4><p><em>Example. Displaying files from a Hadoop filesystem on standard output twice, by using seek()</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc FileSystemDoubleCat Displays files from a Hadoop filesystem on standard output twice, by using seek</span></div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div><div class="line"></div><div class="line"><span class="comment">// vv FileSystemDoubleCat</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileSystemDoubleCat</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    String uri = args[<span class="number">0</span>];</div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    FileSystem fs = FileSystem.get(URI.create(uri), conf);</div><div class="line">    FSDataInputStream in = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      in = fs.open(<span class="keyword">new</span> Path(uri));</div><div class="line">      IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</div><div class="line">      in.seek(<span class="number">0</span>); <span class="comment">// go back to the start of the file</span></div><div class="line">      IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      IOUtils.closeStream(in);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ FileSystemDoubleCat</span></div></pre></td></tr></table></figure><p>Here’s the result of running it on a small file:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">% hadoop FileSystemDoubleCat hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div><div class="line">On the top of the Crumpetty Tree</div><div class="line">The Quangle Wangle sat,</div><div class="line">But his face you could not see,</div><div class="line">On account of his Beaver Hat.</div><div class="line">On the top of the Crumpetty Tree</div><div class="line">The Quangle Wangle sat,</div><div class="line">But his face you could not see,</div><div class="line">On account of his Beaver Hat.</div></pre></td></tr></table></figure><h3 id="Writing-Data"><a href="#Writing-Data" class="headerlink" title="Writing Data"></a>Writing Data</h3><p><em>Example. Copying a local file to a Hadoop filesystem</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc FileCopyWithProgress Copies a local file to a Hadoop filesystem, and shows progress</span></div><div class="line"><span class="keyword">import</span> java.io.BufferedInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.io.OutputStream;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.Progressable;</div><div class="line"></div><div class="line"><span class="comment">// vv FileCopyWithProgress</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileCopyWithProgress</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    String localSrc = args[<span class="number">0</span>];</div><div class="line">    String dst = args[<span class="number">1</span>];</div><div class="line">    </div><div class="line">    InputStream in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(localSrc));</div><div class="line">    </div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    FileSystem fs = FileSystem.get(URI.create(dst), conf);</div><div class="line">    OutputStream out = fs.create(<span class="keyword">new</span> Path(dst), <span class="keyword">new</span> Progressable() &#123;</div><div class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">progress</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.print(<span class="string">"."</span>);</div><div class="line">      &#125;</div><div class="line">    &#125;);</div><div class="line">    </div><div class="line">    IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">true</span>);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ FileCopyWithProgress</span></div></pre></td></tr></table></figure><p>Typical usage:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">% hadoop FileCopyWithProgress input/docs/<span class="number">1400</span><span class="number">-8.</span>txt</div><div class="line">hdfs:<span class="comment">//localhost/user/tom/1400-8.txt</span></div><div class="line">.................</div></pre></td></tr></table></figure><h3 id="Querying-the-Filesystem"><a href="#Querying-the-Filesystem" class="headerlink" title="Querying the Filesystem"></a>Querying the Filesystem</h3><p>The <code>FileStatus</code> class encapsulates filesystem metadata for files and directories, including file length, block size, replication, modification time, ownership, and permission information.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShowFileStatusTest</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> MiniDFSCluster cluster; <span class="comment">// use an in-process HDFS cluster for testing</span></div><div class="line">  <span class="keyword">private</span> FileSystem fs;</div><div class="line"></div><div class="line">  <span class="meta">@Before</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUp</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    <span class="keyword">if</span> (System.getProperty(<span class="string">"test.build.data"</span>) == <span class="keyword">null</span>) &#123;</div><div class="line">      System.setProperty(<span class="string">"test.build.data"</span>, <span class="string">"/tmp"</span>);</div><div class="line">    &#125;</div><div class="line">    cluster = <span class="keyword">new</span> MiniDFSCluster.Builder(conf).build();</div><div class="line">    fs = cluster.getFileSystem();</div><div class="line">    OutputStream out = fs.create(<span class="keyword">new</span> Path(<span class="string">"/dir/file"</span>));</div><div class="line">    out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">    out.close();</div><div class="line">  &#125;</div><div class="line"> </div><div class="line">  <span class="meta">@After</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">tearDown</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    <span class="keyword">if</span> (fs != <span class="keyword">null</span>) &#123; fs.close(); &#125;</div><div class="line">    <span class="keyword">if</span> (cluster != <span class="keyword">null</span>) &#123; cluster.shutdown(); &#125;</div><div class="line">  &#125;</div><div class="line"> </div><div class="line">  <span class="meta">@Test</span>(expected = FileNotFoundException.class)</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">throwsFileNotFoundForNonExistentFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    fs.getFileStatus(<span class="keyword">new</span> Path(<span class="string">"no-such-file"</span>));</div><div class="line">  &#125;</div><div class="line"> </div><div class="line">  <span class="meta">@Test</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fileStatusForFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Path file = <span class="keyword">new</span> Path(<span class="string">"/dir/file"</span>);</div><div class="line">    FileStatus stat = fs.getFileStatus(file);</div><div class="line">    assertThat(stat.getPath().toUri().getPath(), is(<span class="string">"/dir/file"</span>));</div><div class="line">    assertThat(stat.isDirectory(), is(<span class="keyword">false</span>));</div><div class="line">    assertThat(stat.getLen(), is(<span class="number">7L</span>));</div><div class="line">    assertThat(stat.getModificationTime(),</div><div class="line">    is(lessThanOrEqualTo(System.currentTimeMillis())));</div><div class="line">    assertThat(stat.getReplication(), is((<span class="keyword">short</span>) <span class="number">1</span>));</div><div class="line">    assertThat(stat.getBlockSize(), is(<span class="number">128</span> * <span class="number">1024</span> * <span class="number">1024L</span>));</div><div class="line">    assertThat(stat.getOwner(), is(System.getProperty(<span class="string">"user.name"</span>)));</div><div class="line">    assertThat(stat.getGroup(), is(<span class="string">"supergroup"</span>));</div><div class="line">    assertThat(stat.getPermission().toString(), is(<span class="string">"rw-r--r--"</span>));</div><div class="line"> &#125;</div><div class="line"> </div><div class="line">  <span class="meta">@Test</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fileStatusForDirectory</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Path dir = <span class="keyword">new</span> Path(<span class="string">"/dir"</span>);</div><div class="line">    FileStatus stat = fs.getFileStatus(dir);</div><div class="line">    assertThat(stat.getPath().toUri().getPath(), is(<span class="string">"/dir"</span>));</div><div class="line">    assertThat(stat.isDirectory(), is(<span class="keyword">true</span>));</div><div class="line">    assertThat(stat.getLen(), is(<span class="number">0L</span>));</div><div class="line">    assertThat(stat.getModificationTime(),</div><div class="line">    is(lessThanOrEqualTo(System.currentTimeMillis())));</div><div class="line">    assertThat(stat.getReplication(), is((<span class="keyword">short</span>) <span class="number">0</span>));</div><div class="line">    assertThat(stat.getBlockSize(), is(<span class="number">0L</span>));</div><div class="line">    assertThat(stat.getOwner(), is(System.getProperty(<span class="string">"user.name"</span>)));</div><div class="line">    assertThat(stat.getGroup(), is(<span class="string">"supergroup"</span>));</div><div class="line">    assertThat(stat.getPermission().toString(), is(<span class="string">"rwxr-xr-x"</span>));</div><div class="line">  &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="Listing-files"><a href="#Listing-files" class="headerlink" title="Listing files"></a>Listing files</h4><p><em>Example. Showing the file statuses for a collection of paths in a Hadoop filesystem</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc ListStatus Shows the file statuses for a collection of paths in a Hadoop filesystem </span></div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileUtil;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"></div><div class="line"><span class="comment">// vv ListStatus</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListStatus</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    String uri = args[<span class="number">0</span>];</div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    FileSystem fs = FileSystem.get(URI.create(uri), conf);</div><div class="line">    </div><div class="line">    Path[] paths = <span class="keyword">new</span> Path[args.length];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; paths.length; i++) &#123;</div><div class="line">      paths[i] = <span class="keyword">new</span> Path(args[i]);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    FileStatus[] status = fs.listStatus(paths);</div><div class="line">    Path[] listedPaths = FileUtil.stat2Paths(status);</div><div class="line">    <span class="keyword">for</span> (Path p : listedPaths) &#123;</div><div class="line">      System.out.println(p);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ ListStatus</span></div></pre></td></tr></table></figure><p>We can use this program to find the union of directory listings for a collection of paths:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">% hadoop ListStatus hdfs:<span class="comment">//localhost/ hdfs://localhost/user/tom</span></div><div class="line">hdfs:<span class="comment">//localhost/user</span></div><div class="line">hdfs:<span class="comment">//localhost/user/tom/books</span></div><div class="line">hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div></pre></td></tr></table></figure><h2 id="DataFlow"><a href="#DataFlow" class="headerlink" title="DataFlow"></a>DataFlow</h2><h3 id="Anatomy-of-a-File-Read"><a href="#Anatomy-of-a-File-Read" class="headerlink" title="Anatomy of a File Read"></a>Anatomy of a File Read</h3><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch03/hdfs_dataflow_read.png" alt="read"></p><h4 id="Network-Topology-and-Hadoop"><a href="#Network-Topology-and-Hadoop" class="headerlink" title="Network Topology and Hadoop"></a>Network Topology and Hadoop</h4><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch03/hdfs_dataflow_distance.png" alt="distance"></p><p><strong>Mathematically inclined readers will notice that this is an example of a distance metric.</strong></p><h3 id="Anatomy-of-a-File-Write"><a href="#Anatomy-of-a-File-Write" class="headerlink" title="Anatomy of a File Write"></a>Anatomy of a File Write</h3><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch03/hdfs_dataflow_write.png" alt="write"></p><p>A typical replica pipeline:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch03/hdfs_dataflow_replica.png" alt="replica"></p><h2 id="Coherency-Model"><a href="#Coherency-Model" class="headerlink" title="Coherency Model"></a>Coherency Model</h2><p>After creating a file, it is visible in the filesystem namespace, as expected:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Path p = <span class="keyword">new</span> Path(<span class="string">"p"</span>);</div><div class="line">fs.create(p);</div><div class="line">assertThat(fs.exists(p), is(<span class="keyword">true</span>));</div></pre></td></tr></table></figure><p>However, any content written to the file is not guaranteed to be visible, even if the stream is flushed. So, the file appears to have a length of zero:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Path p = <span class="keyword">new</span> Path(<span class="string">"p"</span>);</div><div class="line">OutputStream out = fs.create(p);</div><div class="line">out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">out.flush();</div><div class="line">assertThat(fs.getFileStatus(p).getLen(), is(<span class="number">0L</span>));</div></pre></td></tr></table></figure><p>HDFS provides a way to force all buffers to be flushed to the datanodes via the hflush() method on FSDataOutputStream. After a successful return from hflush(), HDFS guarantees that the data written up to that point in the file has reached all the datanodes in the write pipeline and is visible to all new readers:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Path p = <span class="keyword">new</span> Path(<span class="string">"p"</span>);</div><div class="line">FSDataOutputStream out = fs.create(p);</div><div class="line">out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">out.hflush();</div><div class="line">assertThat(fs.getFileStatus(p).getLen(), is(((<span class="keyword">long</span>) <span class="string">"content"</span>.length())));</div></pre></td></tr></table></figure><p>Note that hflush() does not guarantee that the datanodes have written the data to disk, only that it’s in the datanodes’ memory (so in the event of a data center power outage, for example, data could be lost). For this stronger guarantee, use hsync() instead.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">FileOutputStream out = <span class="keyword">new</span> FileOutputStream(localFile);</div><div class="line">out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">out.flush(); <span class="comment">// flush to operating system</span></div><div class="line">out.getFD().sync(); <span class="comment">// sync to disk</span></div><div class="line">assertThat(localFile.length(), is(((<span class="keyword">long</span>) <span class="string">"content"</span>.length())));</div></pre></td></tr></table></figure><p>Closing a file in HDFS performs an implicit hflush(), too:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Path p = <span class="keyword">new</span> Path(<span class="string">"p"</span>);</div><div class="line">OutputStream out = fs.create(p);</div><div class="line">out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">out.close();</div><div class="line">assertThat(fs.getFileStatus(p).getLen(), is(((<span class="keyword">long</span>) <span class="string">"content"</span>.length())));</div></pre></td></tr></table></figure><h2 id="Parallel-Copying-with-distcp"><a href="#Parallel-Copying-with-distcp" class="headerlink" title="Parallel Copying with distcp"></a>Parallel Copying with distcp</h2><p>One use for distcp is as an efficient replacement for hadoop fs -cp. For example, you can copy one file to another with:</p><p><code>% hadoop distcp file1 file2</code></p><p>You can also copy directories:</p><p><code>% hadoop distcp dir1 dir2</code></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;HDFS-Concepts&quot;&gt;&lt;a href=&quot;#HDFS-Concepts&quot; class=&quot;headerlink&quot; title=&quot;HDFS Concepts&quot;&gt;&lt;/a&gt;HDFS Concepts&lt;/h2&gt;&lt;h3 id=&quot;Blocks&quot;&gt;&lt;a href=&quot;#Blo
    
    </summary>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop namenode not getting started</title>
    <link href="http://yoursite.com/2017/04/18/Hadoop-namenode-not-getting-started/"/>
    <id>http://yoursite.com/2017/04/18/Hadoop-namenode-not-getting-started/</id>
    <published>2017-04-18T02:06:40.000Z</published>
    <updated>2017-04-18T02:15:12.035Z</updated>
    
    <content type="html"><![CDATA[<ol><li>First delete all contents from temporary folder: <code>rm -rf &lt;tmp dir&gt;</code> (my was /usr/local/hadoop/tmp)</li><li>Format the namenode: <code>bin/hadoop namenode -format</code></li><li>Start all processes again<ol><li><code>bin/start-dfs.sh</code></li><li><code>bin/start-yarn.sh</code></li><li><code>bin/mr-jobhistory-daemon.sh start historyserver</code></li></ol></li></ol><p>You may consider rolling back as well using checkpoint (if you had it enabled).</p>]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;&lt;li&gt;First delete all contents from temporary folder: &lt;code&gt;rm -rf &amp;lt;tmp dir&amp;gt;&lt;/code&gt; (my was /usr/local/hadoop/tmp)&lt;/li&gt;&lt;li&gt;Format t
    
    </summary>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop ch02 MapReduce notes</title>
    <link href="http://yoursite.com/2017/04/17/Hadoop-ch02-MapReduce-notes/"/>
    <id>http://yoursite.com/2017/04/17/Hadoop-ch02-MapReduce-notes/</id>
    <published>2017-04-17T09:32:26.000Z</published>
    <updated>2017-04-17T11:36:52.331Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>首先我们有一个数据集，关于天气的，然后它的每一条记录是这样的：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="number">0057</span></div><div class="line"><span class="number">332130</span> <span class="comment"># USAF weather station identifier</span></div><div class="line"><span class="number">99999</span> <span class="comment"># WBAN weather station identifier</span></div><div class="line"><span class="number">19500101</span> <span class="comment"># observation date</span></div><div class="line"><span class="number">0300</span> <span class="comment"># observation time</span></div><div class="line"><span class="number">4</span></div><div class="line">+<span class="number">51317</span> <span class="comment"># latitude (degrees x 1000)</span></div><div class="line">+<span class="number">02</span>8783 <span class="comment"># longitude (degrees x 1000)</span></div><div class="line">FM-<span class="number">12</span></div><div class="line">+<span class="number">0171</span> <span class="comment"># elevation (meters)</span></div><div class="line"><span class="number">99999</span></div><div class="line">V02<span class="number">0</span></div><div class="line"><span class="number">320</span> <span class="comment"># wind direction (degrees)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line">N</div><div class="line"><span class="number">0072</span></div><div class="line"><span class="number">1</span></div><div class="line"><span class="number">00450</span> <span class="comment"># sky ceiling height (meters)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line">C</div><div class="line">N</div><div class="line"><span class="number">010000</span> <span class="comment"># visibility distance (meters)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line">N</div><div class="line"><span class="number">9</span></div><div class="line">-<span class="number">012</span>8 <span class="comment"># air temperature (degrees Celsius x 10)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line">-<span class="number">013</span>9 <span class="comment"># dew point temperature (degrees Celsius x 10)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line"><span class="number">10268</span> <span class="comment"># atmospheric pressure (hectopascals x 10)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div></pre></td></tr></table></figure><p>当然以上数据是经过处理之后的，一开始它长这样：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="number">0067011</span>990999991950051507004...<span class="number">9999999</span>N9+<span class="number">00001</span>+<span class="number">99999999999</span>...</div><div class="line"><span class="number">0043011</span>990999991950051512004...<span class="number">9999999</span>N9+<span class="number">00221</span>+<span class="number">99999999999</span>...</div><div class="line"><span class="number">0043011</span>990999991950051518004...<span class="number">9999999</span>N9-<span class="number">00111</span>+<span class="number">99999999999</span>...</div><div class="line"><span class="number">0043012650</span>999991949032412004...<span class="number">0500001</span>N9+<span class="number">01111</span>+<span class="number">99999999999</span>...</div><div class="line"><span class="number">0043012650</span>999991949032418004...<span class="number">0500001</span>N9+<span class="number">007</span>81+<span class="number">99999999999</span>...</div></pre></td></tr></table></figure><p>Hmmm….</p><p>这个天气数据集按照<code>气象站编号-年份</code>的形式来组织的：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="number">010010</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010014</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010015</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010016</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010017</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010030</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010040</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">0100</span>8<span class="number">0</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010100</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010150</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div></pre></td></tr></table></figure><p>这个原始数据显然用起来不方便，所以按照年份给它聚个类，用了如下方法：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \</div><div class="line">  -D mapred.reduce.tasks=<span class="number">0</span> \</div><div class="line">  -D mapred.map.tasks.speculative.execution=<span class="literal">false</span> \</div><div class="line">  -D mapred.task.timeout=<span class="number">12000000</span> \</div><div class="line">  -input ncdc_files.txt \</div><div class="line">  -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat \</div><div class="line">  -output output \</div><div class="line">  -mapper load_ncdc_map.sh \</div><div class="line">  -file load_ncdc_map.sh</div></pre></td></tr></table></figure><p>然后里面用到的<code>ncdc_files</code>以及<code>load_ncdc_map.sh</code>这两个文件是这样的：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div></pre></td><td class="code"><pre><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1901.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1902.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1903.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1904.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1905.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1906.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1907.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1908.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1909.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1910.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1911.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1912.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1913.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1914.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1915.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1916.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1917.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1918.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1919.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1920.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1921.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1922.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1923.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1924.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1925.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1926.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1927.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1928.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1929.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1930.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1931.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1932.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1933.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1934.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1935.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1936.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1937.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1938.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1939.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1940.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1941.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1942.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1943.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1944.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1945.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1946.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1947.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1948.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1949.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1950.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1951.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1952.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1953.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1954.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1955.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1956.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1957.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1958.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1959.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1960.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1961.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1962.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1963.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1964.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1965.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1966.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1967.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1968.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1969.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1970.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1971.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1972.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1973.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1974.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1975.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1976.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1977.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1978.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1979.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1980.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1981.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1982.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1983.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1984.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1985.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1986.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1987.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1988.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1989.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1990.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1991.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1992.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1993.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1994.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1995.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1996.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1997.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1998.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1999.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-2000.tar.bz2</span></div></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env bash</div><div class="line"></div><div class="line"># NLineInputFormat gives a single line: key is offset, value is S3 URI</div><div class="line">read offset s3file</div><div class="line"></div><div class="line"># Retrieve file from S3 to local disk</div><div class="line">echo "reporter:status:Retrieving $s3file" &gt;&amp;2</div><div class="line">$HADOOP_INSTALL/bin/hadoop fs -get $s3file .</div><div class="line"></div><div class="line"># Un-bzip and un-tar the local file</div><div class="line">target=`basename $s3file .tar.bz2`</div><div class="line">mkdir -p $target</div><div class="line">echo "reporter:status:Un-tarring $s3file to $target" &gt;&amp;2</div><div class="line">tar jxf `basename $s3file` -C $target</div><div class="line"></div><div class="line"># Un-gzip each station file and concat into one file</div><div class="line">echo "reporter:status:Un-gzipping $target" &gt;&amp;2</div><div class="line">for file in $target/*/*</div><div class="line">do</div><div class="line">  gunzip -c $file &gt;&gt; $target.all</div><div class="line">  echo "reporter:status:Processed $file" &gt;&amp;2</div><div class="line">done</div><div class="line"></div><div class="line"># Put gzipped version into HDFS</div><div class="line">echo "reporter:status:Gzipping $target and putting in HDFS" &gt;&amp;2</div><div class="line">gzip -c $target.all | $HADOOP_INSTALL/bin/hadoop fs -put - gz/$target.gz</div></pre></td></tr></table></figure><p>嗯…顺便说一句，这个文件是存在<code>AWS</code>上的，所以想用的话要有一个<code>AWS</code>账号，想要有个账号呢，你得先有个可以支付美刀的信用卡。</p><p>Hmmmmm…</p><p>其实作者给的<code>sample data</code>也挺好的我觉得，<a href="https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc" target="_blank" rel="external">在这里</a>.</p><p>那么我们的问题就是说，找出每一年的最高的温度。先看看不用<code>Hadoop</code>的实现方法，事实证明我<code>shell</code>脚本还是宝刀未老的。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">#!<span class="regexp">/usr/</span>bin/env bash</div><div class="line"><span class="keyword">for</span> year <span class="keyword">in</span> all<span class="comment">/*</span></div><div class="line">do</div><div class="line"> echo -ne `basename $year .gz`"\t"</div><div class="line"> gunzip -c $year | \</div><div class="line"> awk '&#123; temp = substr($0, 88, 5) + 0;</div><div class="line"> q = substr($0, 93, 1);</div><div class="line"> if (temp !=9999 &amp;&amp; q ~ /[01459]/ &amp;&amp; temp &gt; max) max = temp &#125;</div><div class="line"> END &#123; print max &#125;'</div><div class="line">done</div></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">% ./max_temperature.sh</div><div class="line"><span class="number">1901</span> <span class="number">317</span></div><div class="line"><span class="number">1902</span> <span class="number">244</span></div><div class="line"><span class="number">1903</span> <span class="number">289</span></div><div class="line"><span class="number">1904</span> <span class="number">256</span></div><div class="line"><span class="number">1905</span> <span class="number">283</span></div><div class="line">...</div></pre></td></tr></table></figure><p>啊嘞，还不错的样子，但是对于大数据速度还是慢了点儿，所以直接上<code>Hadoop</code>看看。</p><p>对于以上的问题呢，<code>MapReduce</code>是这样解决的</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch02/mapred_pipeline.png" alt="mapred_pipeline"></p><p>注意了，上面一行是<code>hadoop</code>的术语，下面呢，其实就是<code>Unix</code>的<code>pipe</code>了，这给我们不用<code>Java</code>来实现提供了可能。</p><p>好了下面开始coding了，拿起键盘就是GAN</p><p>为了实现我们的任务，我们需要三个java文件，一个<code>mapper</code>，一个<code>reducer</code>。这俩是苦工，还要一个监工。</p><p><code>Mapper</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc MaxTemperatureMapper Mapper for maximum temperature example</span></div><div class="line"><span class="comment">// vv MaxTemperatureMapper</span></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxTemperatureMapper</span></span></div><div class="line">  <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; &#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MISSING = <span class="number">9999</span>;</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></div><div class="line">      <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">    </div><div class="line">    String line = value.toString();</div><div class="line">    String year = line.substring(<span class="number">15</span>, <span class="number">19</span>);</div><div class="line">    <span class="keyword">int</span> airTemperature;</div><div class="line">    <span class="keyword">if</span> (line.charAt(<span class="number">87</span>) == <span class="string">'+'</span>) &#123; <span class="comment">// parseInt doesn't like leading plus signs</span></div><div class="line">      airTemperature = Integer.parseInt(line.substring(<span class="number">88</span>, <span class="number">92</span>));</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      airTemperature = Integer.parseInt(line.substring(<span class="number">87</span>, <span class="number">92</span>));</div><div class="line">    &#125;</div><div class="line">    String quality = line.substring(<span class="number">92</span>, <span class="number">93</span>);</div><div class="line">    <span class="keyword">if</span> (airTemperature != MISSING &amp;&amp; quality.matches(<span class="string">"[01459]"</span>)) &#123;</div><div class="line">      context.write(<span class="keyword">new</span> Text(year), <span class="keyword">new</span> IntWritable(airTemperature));</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ MaxTemperatureMapper</span></div></pre></td></tr></table></figure><p><code>Reducer</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc MaxTemperatureReducer Reducer for maximum temperature example</span></div><div class="line"><span class="comment">// vv MaxTemperatureReducer</span></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxTemperatureReducer</span></span></div><div class="line">  <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; &#123;</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></div><div class="line">      Context context)</div><div class="line">      <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">    </div><div class="line">    <span class="keyword">int</span> maxValue = Integer.MIN_VALUE;</div><div class="line">    <span class="keyword">for</span> (IntWritable value : values) &#123;</div><div class="line">      maxValue = Math.max(maxValue, value.get());</div><div class="line">    &#125;</div><div class="line">    context.write(key, <span class="keyword">new</span> IntWritable(maxValue));</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ MaxTemperatureReducer</span></div></pre></td></tr></table></figure><p><code>Job</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc MaxTemperature Application to find the maximum temperature in the weather dataset</span></div><div class="line"><span class="comment">// vv MaxTemperature</span></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxTemperature</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</div><div class="line">      System.err.println(<span class="string">"Usage: MaxTemperature &lt;input path&gt; &lt;output path&gt;"</span>);</div><div class="line">      System.exit(-<span class="number">1</span>);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    Job job = <span class="keyword">new</span> Job();</div><div class="line">    job.setJarByClass(MaxTemperature.class);</div><div class="line">    job.setJobName(<span class="string">"Max temperature"</span>);</div><div class="line"></div><div class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">    </div><div class="line">    job.setMapperClass(MaxTemperatureMapper.class);</div><div class="line">    job.setReducerClass(MaxTemperatureReducer.class);</div><div class="line"></div><div class="line">    job.setOutputKeyClass(Text.class);</div><div class="line">    job.setOutputValueClass(IntWritable.class);</div><div class="line">    </div><div class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ MaxTemperature</span></div></pre></td></tr></table></figure><p>然后这么运行：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">% <span class="keyword">export</span> HADOOP_CLASSPATH=hadoop-examples.jar</div><div class="line">% hadoop MaxTemperature input/ncdc/sample.txt output</div></pre></td></tr></table></figure><p>但是如果数据量非常大的话，需要在<code>Mapper</code>和<code>Reducer</code>之间传递大量的数据，这个时候可以引入<code>Combiner</code>，它的机理是这样的。假如我有两个<code>mapper</code>，它们的输出结果是这样子的：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">(<span class="number">1950</span>, <span class="number">0</span>)</div><div class="line">(<span class="number">1950</span>, <span class="number">20</span>)</div><div class="line">(<span class="number">1950</span>, <span class="number">10</span>)</div></pre></td></tr></table></figure><p>以及这样子的：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(<span class="number">1950</span>, <span class="number">25</span>)</div><div class="line">(<span class="number">1950</span>, <span class="number">15</span>)</div></pre></td></tr></table></figure><p>如果没有<code>combiner</code>的话，它们会先变成这样子：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(<span class="number">1950</span>, [<span class="number">0</span>, <span class="number">20</span>, <span class="number">10</span>, <span class="number">25</span>, <span class="number">15</span>])</div></pre></td></tr></table></figure><p>然后作为<code>reducer</code>的输入，但是如果加入了<code>combiner</code>的话，相当于上面的问题变成了这样</p><p><code>max(0, 20, 10, 25, 15) = max(max(0, 20, 10), max(25, 15)) = max(20, 25) = 25</code></p><p>是不是简单多了。但是注意了，并不是所有的问题都是这样，比如下面这个问题：</p><p><code>mean(0, 20, 10, 25, 15) = 14</code></p><p><code>mean(mean(0, 20, 10), mean(25, 15)) = mean(10, 20) = 15</code></p><p>所以说要根据具体情况来定，不能直接套用。</p><p>好了我们继续<code>combiner</code>的话题，我们怎么把这货加到<code>hadoop</code>的流程中去呢，其实很简单，这样就可以：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc MaxTemperatureWithCombiner Application to find the maximum temperature, using a combiner function for efficiency</span></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line"><span class="comment">// vv MaxTemperatureWithCombiner</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxTemperatureWithCombiner</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</div><div class="line">      System.err.println(<span class="string">"Usage: MaxTemperatureWithCombiner &lt;input path&gt; "</span> +</div><div class="line">          <span class="string">"&lt;output path&gt;"</span>);</div><div class="line">      System.exit(-<span class="number">1</span>);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    Job job = <span class="keyword">new</span> Job();</div><div class="line">    job.setJarByClass(MaxTemperatureWithCombiner.class);</div><div class="line">    job.setJobName(<span class="string">"Max temperature"</span>);</div><div class="line"></div><div class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">    </div><div class="line">    job.setMapperClass(MaxTemperatureMapper.class);</div><div class="line">    <span class="comment">/*[*/</span>job.setCombinerClass(MaxTemperatureReducer.class)<span class="comment">/*]*/</span>;</div><div class="line">    job.setReducerClass(MaxTemperatureReducer.class);</div><div class="line"></div><div class="line">    job.setOutputKeyClass(Text.class);</div><div class="line">    job.setOutputValueClass(IntWritable.class);</div><div class="line">    </div><div class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ MaxTemperatureWithCombiner</span></div></pre></td></tr></table></figure><p>没错，<code>combiner</code>和<code>reducer</code>是一样的。其实仔细想想这也很自然，因为它们俩实际实现的功能是一样的。</p><h2 id="Hadoop-Streaming"><a href="#Hadoop-Streaming" class="headerlink" title="Hadoop Streaming"></a>Hadoop Streaming</h2><p>作为一个<code>machine learning</code>专业的，有时候用<code>Java</code>还是感觉挺不爽的，哪有<code>Python</code>啊，<code>Ruby</code>啊这种脚本语言方便嘛。所以<code>hadoop</code>还是很人性地提供了解决方法，就是标题所表示的技术。直接看代码怎么用吧。</p><h3 id="Ruby"><a href="#Ruby" class="headerlink" title="Ruby"></a>Ruby</h3><p><code>Map</code></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env ruby</span></div><div class="line"></div><div class="line">STDIN.each_line <span class="keyword">do</span> <span class="params">|line|</span></div><div class="line">  val = line</div><div class="line">  year, temp, q = val[<span class="number">15</span>,<span class="number">4</span>], val[<span class="number">87</span>,<span class="number">5</span>], val[<span class="number">92</span>,<span class="number">1</span>]</div><div class="line">  puts <span class="string">"<span class="subst">#&#123;year&#125;</span>\t<span class="subst">#&#123;temp&#125;</span>"</span> <span class="keyword">if</span> (temp != <span class="string">"+9999"</span> &amp;&amp; q =~ <span class="regexp">/[01459]/</span>)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p><code>Reduce</code></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env ruby</span></div><div class="line"></div><div class="line">last_key, max_val = <span class="literal">nil</span>, -<span class="number">1000000</span></div><div class="line">STDIN.each_line <span class="keyword">do</span> <span class="params">|line|</span></div><div class="line">  key, val = line.split(<span class="string">"\t"</span>)</div><div class="line">  <span class="keyword">if</span> last_key &amp;&amp; last_key != key</div><div class="line">    puts <span class="string">"<span class="subst">#&#123;last_key&#125;</span>\t<span class="subst">#&#123;max_val&#125;</span>"</span></div><div class="line">    last_key, max_val = key, val.to_i</div><div class="line">  <span class="keyword">else</span></div><div class="line">    last_key, max_val = key, [max_val, val.to_i].max</div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line">puts <span class="string">"<span class="subst">#&#123;last_key&#125;</span>\t<span class="subst">#&#123;max_val&#125;</span>"</span> <span class="keyword">if</span> last_key</div></pre></td></tr></table></figure><p>然后这样调用：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">% hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \</div><div class="line"> -input input/ncdc/sample.txt \</div><div class="line"> -output output \</div><div class="line"> -mapper ch02-mr-intro/src/main/ruby/max_temperature_map.rb \</div><div class="line"> -reducer ch02-mr-intro/src/main/ruby/max_temperature_reduce.rb</div></pre></td></tr></table></figure><p>是不是很方便？如果要加上<code>combiner</code>的话，更方便了，都不用再写额外的文件：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">% hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \</div><div class="line"> -files ch02-mr-intro/src/main/ruby/max_temperature_map.rb,\</div><div class="line">ch02-mr-intro/src/main/ruby/max_temperature_reduce.rb \</div><div class="line"> -input input/ncdc/all \</div><div class="line"> -output output \</div><div class="line"> -mapper ch02-mr-intro/src/main/ruby/max_temperature_map.rb \</div><div class="line"> -combiner ch02-mr-intro/src/main/ruby/max_temperature_reduce.rb \</div><div class="line"> -reducer ch02-mr-intro/src/main/ruby/max_temperature_reduce.rb</div></pre></td></tr></table></figure><p>注意，以上的<code>-files</code>命令是为了在集群环境下运行时，将脚本复制到各子节点上。</p><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>啊，<code>Python</code>大大出场，其实和<code>Ruby</code>没啥区别。</p><p><code>Map</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">  val = line.strip()</div><div class="line">  (year, temp, q) = (val[<span class="number">15</span>:<span class="number">19</span>], val[<span class="number">87</span>:<span class="number">92</span>], val[<span class="number">92</span>:<span class="number">93</span>])</div><div class="line">  <span class="keyword">if</span> (temp != <span class="string">"+9999"</span> <span class="keyword">and</span> re.match(<span class="string">"[01459]"</span>, q)):</div><div class="line">    <span class="keyword">print</span> <span class="string">"%s\t%s"</span> % (year, temp)</div></pre></td></tr></table></figure><p><code>Reduce</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line">(last_key, max_val) = (<span class="keyword">None</span>, -sys.maxint)</div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">  (key, val) = line.strip().split(<span class="string">"\t"</span>)</div><div class="line">  <span class="keyword">if</span> last_key <span class="keyword">and</span> last_key != key:</div><div class="line">    <span class="keyword">print</span> <span class="string">"%s\t%s"</span> % (last_key, max_val)</div><div class="line">    (last_key, max_val) = (key, int(val))</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    (last_key, max_val) = (key, max(max_val, int(val)))</div><div class="line"></div><div class="line"><span class="keyword">if</span> last_key:</div><div class="line">  <span class="keyword">print</span> <span class="string">"%s\t%s"</span> % (last_key, max_val)</div></pre></td></tr></table></figure><p>运行都是一样的，就不多做赘述了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;MapReduce&quot;&gt;&lt;a href=&quot;#MapReduce&quot; class=&quot;headerlink&quot; title=&quot;MapReduce&quot;&gt;&lt;/a&gt;MapReduce&lt;/h2&gt;&lt;p&gt;首先我们有一个数据集，关于天气的，然后它的每一条记录是这样的：&lt;/p&gt;&lt;figure
    
    </summary>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning [ECNU] Assignment 1</title>
    <link href="http://yoursite.com/2017/04/16/Machine-Learning-ECNU-Assignment-1/"/>
    <id>http://yoursite.com/2017/04/16/Machine-Learning-ECNU-Assignment-1/</id>
    <published>2017-04-16T05:04:17.000Z</published>
    <updated>2017-04-16T05:15:09.386Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Use a crawler to get at least 20 webpages from a website.</strong></p><p><strong>Count theoccurrences of words in the webpages on Hadoop.</strong></p><p>Hand in:</p><ol><li>Each one should crawl different websites, list the website URL, as well as the URLsof the crawled webpages.</li><li><p>Count the word occurrence on Hadoop, code in both JAVA and another language such asPig Latin. print out your code.</p></li><li><p>Print out your result.</p></li></ol><p>Home work due: <strong>4/12</strong></p><p>You are allowed toform a group of no more than 4 fellow students.</p><p><a href="https://github.com/ewanlee/machine-learning-ECNU-/blob/master/Hadoop%20wordcount%20demo_cutted.pdf" target="_blank" rel="external">https://github.com/ewanlee/machine-learning-ECNU-/blob/master/Hadoop%20wordcount%20demo_cutted.pdf</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Use a crawler to get at least 20 webpages from a website.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Count theoccurrences of words in the webpages on
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
      <category term="crawl" scheme="http://yoursite.com/tags/crawl/"/>
    
  </entry>
  
  <entry>
    <title>cs231n Assignments [2 &amp; 3]</title>
    <link href="http://yoursite.com/2017/04/16/cs231n-Assignments-2-3/"/>
    <id>http://yoursite.com/2017/04/16/cs231n-Assignments-2-3/</id>
    <published>2017-04-16T04:39:58.000Z</published>
    <updated>2017-04-16T04:51:45.556Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Assignment-2"><a href="#Assignment-2" class="headerlink" title="Assignment 2"></a>Assignment 2</h1><p>In this assignment you will practice writing backpropagation code, and training Neural Networks and Convolutional Neural Networks. The goals of this assignment are as follows:</p><ul><li>understand <strong>Neural Networks</strong> and how they are arranged in layered architectures</li><li>understand and be able to implement (vectorized) <strong>backpropagation</strong></li><li>implement various <strong>update rules</strong> used to optimize Neural Networks</li><li>implement <strong>batch normalization</strong> for training deep networks</li><li>implement <strong>dropout</strong> to regularize networks</li><li>effectively <strong>cross-validate</strong> and find the best hyperparameters for Neural Network architecture</li><li>understand the architecture of <strong>Convolutional Neural Networks</strong> and train gain experience with training these models on data</li></ul><h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><p>You can work on the assignment in one of two ways: locally on your own machine, or on a virtual machine through Terminal.com.</p><h3 id="Working-in-the-cloud-on-Terminal"><a href="#Working-in-the-cloud-on-Terminal" class="headerlink" title="Working in the cloud on Terminal"></a>Working in the cloud on Terminal</h3><p>Terminal has created a separate subdomain to serve our class, <a href="https://www.stanfordterminalcloud.com/" target="_blank" rel="external">www.stanfordterminalcloud.com</a>. Register your account there. The Assignment 2 snapshot can then be found <a href="https://www.stanfordterminalcloud.com/snapshot/6c95ca2c9866a962964ede3ea5813d4c2410ba48d92cf8d11a93fbb13e08b76a" target="_blank" rel="external">HERE</a>. If you are registered in the class you can contact the TA (see Piazza for more information) to request Terminal credits for use on the assignment. Once you boot up the snapshot everything will be installed for you, and you will be ready to start on your assignment right away. We have written a small tutorial on Terminal <a href="http://cs231n.github.io/terminal-tutorial" target="_blank" rel="external">here</a>.</p><h3 id="Working-locally"><a href="#Working-locally" class="headerlink" title="Working locally"></a>Working locally</h3><p>Get the code as a zip file <a href="http://cs231n.stanford.edu/assignments/2016/winter1516_assignment2.zip" target="_blank" rel="external">here</a>. As for the dependencies:</p><p><strong>[Option 1] Use Anaconda:</strong> The preferred approach for installing all the assignment dependencies is to use<a href="https://www.continuum.io/downloads" target="_blank" rel="external">Anaconda</a>, which is a Python distribution that includes many of the most popular Python packages for science, math, engineering and data analysis. Once you install it you can skip all mentions of requirements and you are ready to go directly to working on the assignment.</p><p><strong>[Option 2] Manual install, virtual environment:</strong> If you do not want to use Anaconda and want to go with a more manual and risky installation route you will likely want to create a <a href="http://docs.python-guide.org/en/latest/dev/virtualenvs/" target="_blank" rel="external">virtual environment</a> for the project. If you choose not to use a virtual environment, it is up to you to make sure that all dependencies for the code are installed globally on your machine. To set up a virtual environment, run the following:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">cd assignment2</div><div class="line">sudo pip install virtualenv      # This may already be installed</div><div class="line">virtualenv .env                  # Create a virtual environment</div><div class="line">source .env/bin/activate         # Activate the virtual environment</div><div class="line">pip install -r requirements.txt  # Install dependencies</div><div class="line"># Work on the assignment for a while ...</div><div class="line">deactivate                       # Exit the virtual environment</div></pre></td></tr></table></figure><p><strong>Download data:</strong> Once you have the starter code, you will need to download the CIFAR-10 dataset. Run the following from the <code>assignment2</code> directory:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd cs231n/datasets</div><div class="line">./get_datasets.sh</div></pre></td></tr></table></figure><p><strong>Compile the Cython extension:</strong> Convolutional Neural Networks require a very efficient implementation. We have implemented of the functionality using <a href="http://cython.org/" target="_blank" rel="external">Cython</a>; you will need to compile the Cython extension before you can run the code. From the <code>cs231n</code> directory, run the following command:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python setup.py build_ext --inplace</div></pre></td></tr></table></figure><p><strong>Start IPython:</strong> After you have the CIFAR-10 data, you should start the IPython notebook server from the <code>assignment2</code> directory. If you are unfamiliar with IPython, you should read our <a href="http://cs231n.github.io/ipython-tutorial" target="_blank" rel="external">IPython tutorial</a>.</p><p><strong>NOTE:</strong> If you are working in a virtual environment on OSX, you may encounter errors with matplotlib due to the<a href="http://matplotlib.org/faq/virtualenv_faq.html" target="_blank" rel="external">issues described here</a>. You can work around this issue by starting the IPython server using the<code>start_ipython_osx.sh</code> script from the <code>assignment2</code> directory; the script assumes that your virtual environment is named <code>.env</code>.</p><h3 id="Submitting-your-work"><a href="#Submitting-your-work" class="headerlink" title="Submitting your work:"></a>Submitting your work:</h3><p>Whether you work on the assignment locally or using Terminal, once you are done working run the <code>collectSubmission.sh</code> script; this will produce a file called <code>assignment2.zip</code>. Upload this file under the Assignments tab on <a href="https://coursework.stanford.edu/portal/site/W15-CS-231N-01/" target="_blank" rel="external">the coursework</a> page for the course.</p><h3 id="Q1-Fully-connected-Neural-Network-30-points"><a href="#Q1-Fully-connected-Neural-Network-30-points" class="headerlink" title="Q1: Fully-connected Neural Network (30 points)"></a>Q1: Fully-connected Neural Network (30 points)</h3><p>The IPython notebook <a href="https://github.com/ewanlee/cs231n/blob/master/cs231n-assignments/assignment2/FullyConnectedNets.ipynb" target="_blank" rel="external"><code>FullyConnectedNets.ipynb</code></a> will introduce you to our modular layer design, and then use those layers to implement fully-connected networks of arbitrary depth. To optimize these models you will implement several popular update rules.</p><h3 id="Q2-Batch-Normalization-30-points"><a href="#Q2-Batch-Normalization-30-points" class="headerlink" title="Q2: Batch Normalization (30 points)"></a>Q2: Batch Normalization (30 points)</h3><p>In the IPython notebook <a href="https://github.com/ewanlee/cs231n/blob/master/cs231n-assignments/assignment2/BatchNormalization.ipynb" target="_blank" rel="external"><code>BatchNormalization.ipynb</code></a> you will implement batch normalization, and use it to train deep fully-connected networks.</p><h3 id="Q3-Dropout-10-points"><a href="#Q3-Dropout-10-points" class="headerlink" title="Q3: Dropout (10 points)"></a>Q3: Dropout (10 points)</h3><p>The IPython notebook <a href="https://github.com/ewanlee/cs231n/blob/master/cs231n-assignments/assignment2/Dropout.ipynb" target="_blank" rel="external"><code>Dropout.ipynb</code></a> will help you implement Dropout and explore its effects on model generalization.</p><h3 id="Q4-ConvNet-on-CIFAR-10-30-points"><a href="#Q4-ConvNet-on-CIFAR-10-30-points" class="headerlink" title="Q4: ConvNet on CIFAR-10 (30 points)"></a>Q4: ConvNet on CIFAR-10 (30 points)</h3><p>In the IPython Notebook <a href="https://github.com/ewanlee/cs231n/blob/master/cs231n-assignments/assignment2/ConvolutionalNetworks.ipynb" target="_blank" rel="external"><code>ConvolutionalNetworks.ipynb</code></a> you will implement several new layers that are commonly used in convolutional networks. You will train a (shallow) convolutional network on CIFAR-10, and it will then be up to you to train the best network that you can.</p><h3 id="Q5-Do-something-extra-up-to-10-points"><a href="#Q5-Do-something-extra-up-to-10-points" class="headerlink" title="Q5: Do something extra! (up to +10 points)"></a>Q5: Do something extra! (up to +10 points)</h3><p>In the process of training your network, you should feel free to implement anything that you want to get better performance. You can modify the solver, implement additional layers, use different types of regularization, use an ensemble of models, or anything else that comes to mind. If you implement these or other ideas not covered in the assignment then you will be awarded some bonus points.](<a href="https://github.com/ewanlee/cs231n/tree/master/cs231n-assignments/assignment" target="_blank" rel="external">https://github.com/ewanlee/cs231n/tree/master/cs231n-assignments/assignment</a></p><h1 id="Assignment-3"><a href="#Assignment-3" class="headerlink" title="Assignment 3"></a>Assignment 3</h1><p>In this assignment you will implement recurrent networks, and apply them to image captioning on Microsoft COCO. We will also introduce the TinyImageNet dataset, and use a pretrained model on this dataset to explore different applications of image gradients.</p><p>The goals of this assignment are as follows:</p><ul><li>Understand the architecture of <em>recurrent neural networks (RNNs)</em> and how they operate on sequences by sharing weights over time</li><li>Understand the difference between vanilla RNNs and Long-Short Term Memory (LSTM) RNNs</li><li>Understand how to sample from an RNN at test-time</li><li>Understand how to combine convolutional neural nets and recurrent nets to implement an image captioning system</li><li>Understand how a trained convolutional network can be used to compute gradients with respect to the input image</li><li>Implement and different applications of image gradients, including saliency maps, fooling images, class visualizations, feature inversion, and DeepDream.</li></ul><h2 id="Setup-1"><a href="#Setup-1" class="headerlink" title="Setup"></a>Setup</h2><p>You can work on the assignment in one of two ways: locally on your own machine, or on a virtual machine through Terminal.com.</p><h3 id="Working-in-the-cloud-on-Terminal-1"><a href="#Working-in-the-cloud-on-Terminal-1" class="headerlink" title="Working in the cloud on Terminal"></a>Working in the cloud on Terminal</h3><p>Terminal has created a separate subdomain to serve our class, <a href="https://www.stanfordterminalcloud.com/" target="_blank" rel="external">www.stanfordterminalcloud.com</a>. Register your account there. The Assignment 3 snapshot can then be found <a href="https://www.stanfordterminalcloud.com/snapshot/29054ca27bc2e8bda888709ba3d9dd07a172cbbf0824152aac49b14a018ffbe5" target="_blank" rel="external">HERE</a>. If you are registered in the class you can contact the TA (see Piazza for more information) to request Terminal credits for use on the assignment. Once you boot up the snapshot everything will be installed for you, and you will be ready to start on your assignment right away. We have written a small tutorial on Terminal <a href="http://cs231n.github.io/terminal-tutorial" target="_blank" rel="external">here</a>.</p><h3 id="Working-locally-1"><a href="#Working-locally-1" class="headerlink" title="Working locally"></a>Working locally</h3><p>Get the code as a zip file <a href="http://cs231n.stanford.edu/assignments/2016/winter1516_assignment3.zip" target="_blank" rel="external">here</a>. As for the dependencies:</p><p><strong>[Option 1] Use Anaconda:</strong> The preferred approach for installing all the assignment dependencies is to use<a href="https://www.continuum.io/downloads" target="_blank" rel="external">Anaconda</a>, which is a Python distribution that includes many of the most popular Python packages for science, math, engineering and data analysis. Once you install it you can skip all mentions of requirements and you are ready to go directly to working on the assignment.</p><p><strong>[Option 2] Manual install, virtual environment:</strong> If you do not want to use Anaconda and want to go with a more manual and risky installation route you will likely want to create a <a href="http://docs.python-guide.org/en/latest/dev/virtualenvs/" target="_blank" rel="external">virtual environment</a> for the project. If you choose not to use a virtual environment, it is up to you to make sure that all dependencies for the code are installed globally on your machine. To set up a virtual environment, run the following:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">cd assignment3</div><div class="line">sudo pip install virtualenv      # This may already be installed</div><div class="line">virtualenv .env                  # Create a virtual environment</div><div class="line">source .env/bin/activate         # Activate the virtual environment</div><div class="line">pip install -r requirements.txt  # Install dependencies</div><div class="line"># Work on the assignment for a while ...</div><div class="line">deactivate                       # Exit the virtual environment</div></pre></td></tr></table></figure><p><strong>Download data:</strong> Once you have the starter code, you will need to download the processed MS-COCO dataset, the TinyImageNet dataset, and the pretrained TinyImageNet model. Run the following from the <code>assignment3</code>directory:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cd cs231n/datasets</div><div class="line">./get_coco_captioning.sh</div><div class="line">./get_tiny_imagenet_a.sh</div><div class="line">./get_pretrained_model.sh</div></pre></td></tr></table></figure><p><strong>Compile the Cython extension:</strong> Convolutional Neural Networks require a very efficient implementation. We have implemented of the functionality using <a href="http://cython.org/" target="_blank" rel="external">Cython</a>; you will need to compile the Cython extension before you can run the code. From the <code>cs231n</code> directory, run the following command:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python setup.py build_ext --inplace</div></pre></td></tr></table></figure><p><strong>Start IPython:</strong> After you have the data, you should start the IPython notebook server from the <code>assignment3</code>directory. If you are unfamiliar with IPython, you should read our <a href="http://cs231n.github.io/ipython-tutorial" target="_blank" rel="external">IPython tutorial</a>.</p><p><strong>NOTE:</strong> If you are working in a virtual environment on OSX, you may encounter errors with matplotlib due to the<a href="http://matplotlib.org/faq/virtualenv_faq.html" target="_blank" rel="external">issues described here</a>. You can work around this issue by starting the IPython server using the<code>start_ipython_osx.sh</code> script from the <code>assignment3</code> directory; the script assumes that your virtual environment is named <code>.env</code>.</p><h3 id="Submitting-your-work-1"><a href="#Submitting-your-work-1" class="headerlink" title="Submitting your work:"></a>Submitting your work:</h3><p>Whether you work on the assignment locally or using Terminal, once you are done working run the <code>collectSubmission.sh</code> script; this will produce a file called <code>assignment3.zip</code>. Upload this file under the Assignments tab on <a href="https://coursework.stanford.edu/portal/site/W15-CS-231N-01/" target="_blank" rel="external">the coursework</a> page for the course.</p><h3 id="Q1-Image-Captioning-with-Vanilla-RNNs-40-points"><a href="#Q1-Image-Captioning-with-Vanilla-RNNs-40-points" class="headerlink" title="Q1: Image Captioning with Vanilla RNNs (40 points)"></a>Q1: Image Captioning with Vanilla RNNs (40 points)</h3><p>The IPython notebook <a href="https://github.com/ewanlee/cs231n/blob/master/cs231n-assignments/assignment3/RNN_Captioning.ipynb" target="_blank" rel="external"><code>RNN_Captioning.ipynb</code></a> will walk you through the implementation of an image captioning system on MS-COCO using vanilla recurrent networks.</p><h3 id="Q2-Image-Captioning-with-LSTMs-35-points"><a href="#Q2-Image-Captioning-with-LSTMs-35-points" class="headerlink" title="Q2: Image Captioning with LSTMs (35 points)"></a>Q2: Image Captioning with LSTMs (35 points)</h3><p>The IPython notebook <a href="https://github.com/ewanlee/cs231n/blob/master/cs231n-assignments/assignment3/LSTM_Captioning.ipynb" target="_blank" rel="external"><code>LSTM_Captioning.ipynb</code></a>will walk you through the implementation of Long-Short Term Memory (LSTM) RNNs, and apply them to image captioning on MS-COCO.</p><h3 id="Q3-Image-Gradients-Saliency-maps-and-Fooling-Images-10-points"><a href="#Q3-Image-Gradients-Saliency-maps-and-Fooling-Images-10-points" class="headerlink" title="Q3: Image Gradients: Saliency maps and Fooling Images (10 points)"></a>Q3: Image Gradients: Saliency maps and Fooling Images (10 points)</h3><p>The IPython notebook <a href="https://github.com/ewanlee/cs231n/blob/master/cs231n-assignments/assignment3/ImageGradients.ipynb" target="_blank" rel="external"><code>ImageGradients.ipynb</code></a> will introduce the TinyImageNet dataset. You will use a pretrained model on this dataset to compute gradients with respect to the image, and use them to produce saliency maps and fooling images.</p><h3 id="Q4-Image-Generation-Classes-Inversion-DeepDream-15-points"><a href="#Q4-Image-Generation-Classes-Inversion-DeepDream-15-points" class="headerlink" title="Q4: Image Generation: Classes, Inversion, DeepDream (15 points)"></a>Q4: Image Generation: Classes, Inversion, DeepDream (15 points)</h3><p>In the IPython notebook <a href="https://github.com/ewanlee/cs231n/blob/master/cs231n-assignments/assignment3/ImageGeneration.ipynb" target="_blank" rel="external"><code>ImageGeneration.ipynb</code></a> you will use the pretrained TinyImageNet model to generate images. In particular you will generate class visualizations and implement feature inversion and DeepDream.</p><h3 id="Q5-Do-something-extra-up-to-10-points-1"><a href="#Q5-Do-something-extra-up-to-10-points-1" class="headerlink" title="Q5: Do something extra! (up to +10 points)"></a>Q5: Do something extra! (up to +10 points)</h3><p>Given the components of the assignment, try to do something cool. Maybe there is some way to generate images that we did not implement in the assignment?</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Assignment-2&quot;&gt;&lt;a href=&quot;#Assignment-2&quot; class=&quot;headerlink&quot; title=&quot;Assignment 2&quot;&gt;&lt;/a&gt;Assignment 2&lt;/h1&gt;&lt;p&gt;In this assignment you will pr
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>cs231n Software Packages notes</title>
    <link href="http://yoursite.com/2017/04/13/cs231n-Software-Packages-notes/"/>
    <id>http://yoursite.com/2017/04/13/cs231n-Software-Packages-notes/</id>
    <published>2017-04-13T09:22:10.000Z</published>
    <updated>2017-04-13T10:24:48.739Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Software-Packages"><a href="#Software-Packages" class="headerlink" title="Software Packages"></a>Software Packages</h1><h2 id="Caffe"><a href="#Caffe" class="headerlink" title="Caffe"></a>Caffe</h2><p><a href="http://caffe.berkeleyvision.org" target="_blank" rel="external">http://caffe.berkeleyvision.org</a></p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><ul><li>From U.C. Berkeley</li><li>Written in C++</li><li>Has Python and Matlab bindings</li><li>Good for training or finetuning feedforward models</li></ul><h3 id="Tip"><a href="#Tip" class="headerlink" title="Tip"></a>Tip</h3><p>Don’t be afraid to read the code!</p><h3 id="Main-classes"><a href="#Main-classes" class="headerlink" title="Main classes"></a>Main classes</h3><ul><li>Blob: Stores data and derivatives</li><li>Layer: Transforms bottom blobs to top blobs</li><li>Net:<ul><li>Many layers</li><li>Computes gradients via forward / backward</li></ul></li><li>Solver: Uses gradients to update weights</li></ul><h3 id="Protocol-Buffers"><a href="#Protocol-Buffers" class="headerlink" title="Protocol Buffers"></a>Protocol Buffers</h3><ul><li><p>“Typed JSON” from Google</p></li><li><p>Define “message types” in .proto files</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">message Person &#123;</div><div class="line">  required <span class="built_in">string</span> name = <span class="number">1</span>;</div><div class="line">  required int32 id = <span class="number">2</span>;</div><div class="line">  optional <span class="built_in">string</span> email = <span class="number">3</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></li><li><p>Serialize instances to text files (.prototxt)</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">name: <span class="string">"John Doe"</span></div><div class="line">id: <span class="number">1234</span></div><div class="line">email: <span class="string">"jdoe@example.com"</span></div></pre></td></tr></table></figure></li><li><p>Compile classes for different languages</p></li></ul><h3 id="Training-Finetuning"><a href="#Training-Finetuning" class="headerlink" title="Training / Finetuning"></a>Training / Finetuning</h3><ol><li>Convert data (run a script)</li><li>Define net (edit prototxt)</li><li>Define solver (edit prototxt)</li><li>Train (with pretrained weights) (run a script)</li></ol><h4 id="Step1-Convert-Data"><a href="#Step1-Convert-Data" class="headerlink" title="Step1: Convert Data"></a>Step1: Convert Data</h4><ul><li>DataLayer reading from LMDB is the easiest</li><li>Create LMDB using <a href="https://github.com/BVLC/caffe/blob/85bb397acfd383a676c125c75d877642d6b39ff6/tools/convert_imageset.cpp" target="_blank" rel="external">convert_imageset</a></li><li>Need text file where each line is<ul><li>“[path/to/image.jpeg][label]”</li></ul></li><li>Create HDF5 file yourself using h5py</li><li>[extras] some methods:<ul><li>ImageDataLayer: Read from image files</li><li>WindowDataLayer: For detection</li><li>HDF5Layer: Read from HDF5 file</li><li>From memory, using Python interface</li><li>All of these are harder to use (except Python)</li></ul></li></ul><h4 id="Step2-Define-Net"><a href="#Step2-Define-Net" class="headerlink" title="Step2: Define Net"></a>Step2: Define Net</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div></pre></td><td class="code"><pre><div class="line">name: <span class="string">"ResNet-152"</span></div><div class="line">input: <span class="string">"data"</span></div><div class="line">input_dim: <span class="number">1</span></div><div class="line">input_dim: <span class="number">3</span></div><div class="line">input_dim: <span class="number">224</span></div><div class="line">input_dim: <span class="number">224</span></div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"data"</span></div><div class="line">	top: <span class="string">"conv1"</span></div><div class="line">	name: <span class="string">"conv1"</span></div><div class="line">	type: <span class="string">"Convolution"</span></div><div class="line">	convolution_param &#123;</div><div class="line">		num_output: <span class="number">64</span></div><div class="line">		kernel_size: <span class="number">7</span></div><div class="line">		pad: <span class="number">3</span></div><div class="line">		stride: <span class="number">2</span></div><div class="line">		bias_term: <span class="literal">false</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"conv1"</span></div><div class="line">	top: <span class="string">"conv1"</span></div><div class="line">	name: <span class="string">"bn_conv1"</span></div><div class="line">	type: <span class="string">"BatchNorm"</span></div><div class="line">	batch_norm_param &#123;</div><div class="line">		use_global_stats: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"conv1"</span></div><div class="line">	top: <span class="string">"conv1"</span></div><div class="line">	name: <span class="string">"scale_conv1"</span></div><div class="line">	type: <span class="string">"Scale"</span></div><div class="line">	scale_param &#123;</div><div class="line">		bias_term: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	top: <span class="string">"conv1"</span></div><div class="line">	bottom: <span class="string">"conv1"</span></div><div class="line">	name: <span class="string">"conv1_relu"</span></div><div class="line">	type: <span class="string">"ReLU"</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"conv1"</span></div><div class="line">	top: <span class="string">"pool1"</span></div><div class="line">	name: <span class="string">"pool1"</span></div><div class="line">	type: <span class="string">"Pooling"</span></div><div class="line">	pooling_param &#123;</div><div class="line">		kernel_size: <span class="number">3</span></div><div class="line">		stride: <span class="number">2</span></div><div class="line">		pool: MAX</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"pool1"</span></div><div class="line">	top: <span class="string">"res2a_branch1"</span></div><div class="line">	name: <span class="string">"res2a_branch1"</span></div><div class="line">	type: <span class="string">"Convolution"</span></div><div class="line">	convolution_param &#123;</div><div class="line">		num_output: <span class="number">256</span></div><div class="line">		kernel_size: <span class="number">1</span></div><div class="line">		pad: <span class="number">0</span></div><div class="line">		stride: <span class="number">1</span></div><div class="line">		bias_term: <span class="literal">false</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"res2a_branch1"</span></div><div class="line">	top: <span class="string">"res2a_branch1"</span></div><div class="line">	name: <span class="string">"bn2a_branch1"</span></div><div class="line">	type: <span class="string">"BatchNorm"</span></div><div class="line">	batch_norm_param &#123;</div><div class="line">		use_global_stats: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"res2a_branch1"</span></div><div class="line">	top: <span class="string">"res2a_branch1"</span></div><div class="line">	name: <span class="string">"scale2a_branch1"</span></div><div class="line">	type: <span class="string">"Scale"</span></div><div class="line">	scale_param &#123;</div><div class="line">		bias_term: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"pool1"</span></div><div class="line">	top: <span class="string">"res2a_branch2a"</span></div><div class="line">	name: <span class="string">"res2a_branch2a"</span></div><div class="line">	type: <span class="string">"Convolution"</span></div><div class="line">	convolution_param &#123;</div><div class="line">		num_output: <span class="number">64</span></div><div class="line">		kernel_size: <span class="number">1</span></div><div class="line">		pad: <span class="number">0</span></div><div class="line">		stride: <span class="number">1</span></div><div class="line">		bias_term: <span class="literal">false</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"res2a_branch2a"</span></div><div class="line">	top: <span class="string">"res2a_branch2a"</span></div><div class="line">	name: <span class="string">"bn2a_branch2a"</span></div><div class="line">	type: <span class="string">"BatchNorm"</span></div><div class="line">	batch_norm_param &#123;</div><div class="line">		use_global_stats: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">layer &#123;</div><div class="line">	bottom: <span class="string">"res2a_branch2a"</span></div><div class="line">	top: <span class="string">"res2a_branch2a"</span></div><div class="line">	name: <span class="string">"scale2a_branch2a"</span></div><div class="line">	type: <span class="string">"Scale"</span></div><div class="line">	scale_param &#123;</div><div class="line">		bias_term: <span class="literal">true</span></div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><ul><li>.prototxt can get ugly for big models</li><li><a href="https://github.com/KaimingHe/deep-residual-networks/blob/master/prototxt/ResNet-152-deploy.prototxt" target="_blank" rel="external">ResNet-152 prototxt</a> is 6775 lines long!</li><li>Not “compositional”; can’t easily define a residual block and reuse</li></ul><h4 id="Step2-Define-Net-finetuning"><a href="#Step2-Define-Net-finetuning" class="headerlink" title="Step2: Define Net (finetuning)"></a>Step2: Define Net (finetuning)</h4><ul><li>Same name: weights copied</li><li>Different name: weights reinitialized</li></ul><h4 id="Step3-Define-Solver"><a href="#Step3-Define-Solver" class="headerlink" title="Step3: Define Solver"></a>Step3: Define Solver</h4><ul><li><p>Write a prototxt file defining a <a href="https://github.com/BVLC/caffe/blob/85bb397acfd383a676c125c75d877642d6b39ff6/src/caffe/proto/caffe.proto#L92" target="_blank" rel="external">SolverParameter</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div></pre></td><td class="code"><pre><div class="line">message SolverParameter &#123;</div><div class="line">  <span class="comment">//////////////////////////////////////////////////////////////////////////////</span></div><div class="line">  <span class="comment">// Specifying the train and test networks</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// Exactly one train net must be specified using one of the following fields:</span></div><div class="line">  <span class="comment">//     train_net_param, train_net, net_param, net</span></div><div class="line">  <span class="comment">// One or more test nets may be specified using any of the following fields:</span></div><div class="line">  <span class="comment">//     test_net_param, test_net, net_param, net</span></div><div class="line">  <span class="comment">// If more than one test net field is specified (e.g., both net and</span></div><div class="line">  <span class="comment">// test_net are specified), they will be evaluated in the field order given</span></div><div class="line">  <span class="comment">// above: (1) test_net_param, (2) test_net, (3) net_param/net.</span></div><div class="line">  <span class="comment">// A test_iter must be specified for each test_net.</span></div><div class="line">  <span class="comment">// A test_level and/or a test_stage may also be specified for each test_net.</span></div><div class="line">  <span class="comment">//////////////////////////////////////////////////////////////////////////////</span></div><div class="line"></div><div class="line">  <span class="comment">// Proto filename for the train net, possibly combined with one or more</span></div><div class="line">  <span class="comment">// test nets.</span></div><div class="line">  optional <span class="built_in">string</span> net = <span class="number">24</span>;</div><div class="line">  <span class="comment">// Inline train net param, possibly combined with one or more test nets.</span></div><div class="line">  optional NetParameter net_param = <span class="number">25</span>;</div><div class="line"></div><div class="line">  optional <span class="built_in">string</span> train_net = <span class="number">1</span>; <span class="comment">// Proto filename for the train net.</span></div><div class="line">  repeated <span class="built_in">string</span> test_net = <span class="number">2</span>; <span class="comment">// Proto filenames for the test nets.</span></div><div class="line">  optional NetParameter train_net_param = <span class="number">21</span>; <span class="comment">// Inline train net params.</span></div><div class="line">  repeated NetParameter test_net_param = <span class="number">22</span>; <span class="comment">// Inline test net params.</span></div><div class="line"></div><div class="line">  <span class="comment">// The states for the train/test nets. Must be unspecified or</span></div><div class="line">  <span class="comment">// specified once per net.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// By default, all states will have solver = true;</span></div><div class="line">  <span class="comment">// train_state will have phase = TRAIN,</span></div><div class="line">  <span class="comment">// and all test_state's will have phase = TEST.</span></div><div class="line">  <span class="comment">// Other defaults are set according to the NetState defaults.</span></div><div class="line">  optional NetState train_state = <span class="number">26</span>;</div><div class="line">  repeated NetState test_state = <span class="number">27</span>;</div><div class="line"></div><div class="line">  <span class="comment">// The number of iterations for each test net.</span></div><div class="line">  repeated int32 test_iter = <span class="number">3</span>;</div><div class="line"></div><div class="line">  <span class="comment">// The number of iterations between two testing phases.</span></div><div class="line">  optional int32 test_interval = <span class="number">4</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line">  optional <span class="keyword">bool</span> test_compute_loss = <span class="number">19</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line">  <span class="comment">// If true, run an initial test pass before the first iteration,</span></div><div class="line">  <span class="comment">// ensuring memory availability and printing the starting value of the loss.</span></div><div class="line">  optional <span class="keyword">bool</span> test_initialization = <span class="number">32</span> [<span class="keyword">default</span> = <span class="literal">true</span>];</div><div class="line">  optional <span class="keyword">float</span> base_lr = <span class="number">5</span>; <span class="comment">// The base learning rate</span></div><div class="line">  <span class="comment">// the number of iterations between displaying info. If display = 0, no info</span></div><div class="line">  <span class="comment">// will be displayed.</span></div><div class="line">  optional int32 display = <span class="number">6</span>;</div><div class="line">  <span class="comment">// Display the loss averaged over the last average_loss iterations</span></div><div class="line">  optional int32 average_loss = <span class="number">33</span> [<span class="keyword">default</span> = <span class="number">1</span>];</div><div class="line">  optional int32 max_iter = <span class="number">7</span>; <span class="comment">// the maximum number of iterations</span></div><div class="line">  optional <span class="built_in">string</span> lr_policy = <span class="number">8</span>; <span class="comment">// The learning rate decay policy.</span></div><div class="line">  optional <span class="keyword">float</span> gamma = <span class="number">9</span>; <span class="comment">// The parameter to compute the learning rate.</span></div><div class="line">  optional <span class="keyword">float</span> power = <span class="number">10</span>; <span class="comment">// The parameter to compute the learning rate.</span></div><div class="line">  optional <span class="keyword">float</span> momentum = <span class="number">11</span>; <span class="comment">// The momentum value.</span></div><div class="line">  optional <span class="keyword">float</span> weight_decay = <span class="number">12</span>; <span class="comment">// The weight decay.</span></div><div class="line">  <span class="comment">// regularization types supported: L1 and L2</span></div><div class="line">  <span class="comment">// controlled by weight_decay</span></div><div class="line">  optional <span class="built_in">string</span> regularization_type = <span class="number">29</span> [<span class="keyword">default</span> = <span class="string">"L2"</span>];</div><div class="line">  <span class="comment">// the stepsize for learning rate policy "step"</span></div><div class="line">  optional int32 stepsize = <span class="number">13</span>;</div><div class="line">  <span class="comment">// the stepsize for learning rate policy "multistep"</span></div><div class="line">  repeated int32 stepvalue = <span class="number">34</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Set clip_gradients to &gt;= 0 to clip parameter gradients to that L2 norm,</span></div><div class="line">  <span class="comment">// whenever their actual L2 norm is larger.</span></div><div class="line">  optional <span class="keyword">float</span> clip_gradients = <span class="number">35</span> [<span class="keyword">default</span> = <span class="number">-1</span>];</div><div class="line"></div><div class="line">  optional int32 snapshot = <span class="number">14</span> [<span class="keyword">default</span> = <span class="number">0</span>]; <span class="comment">// The snapshot interval</span></div><div class="line">  optional <span class="built_in">string</span> snapshot_prefix = <span class="number">15</span>; <span class="comment">// The prefix for the snapshot.</span></div><div class="line">  <span class="comment">// whether to snapshot diff in the results or not. Snapshotting diff will help</span></div><div class="line">  <span class="comment">// debugging but the final protocol buffer size will be much larger.</span></div><div class="line">  optional <span class="keyword">bool</span> snapshot_diff = <span class="number">16</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line">  <span class="comment">// the mode solver will use: 0 for CPU and 1 for GPU. Use GPU in default.</span></div><div class="line">  <span class="keyword">enum</span> SolverMode &#123;</div><div class="line">    CPU = <span class="number">0</span>;</div><div class="line">    GPU = <span class="number">1</span>;</div><div class="line">  &#125;</div><div class="line">  optional SolverMode solver_mode = <span class="number">17</span> [<span class="keyword">default</span> = GPU];</div><div class="line">  <span class="comment">// the device_id will that be used in GPU mode. Use device_id = 0 in default.</span></div><div class="line">  optional int32 device_id = <span class="number">18</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line">  <span class="comment">// If non-negative, the seed with which the Solver will initialize the Caffe</span></div><div class="line">  <span class="comment">// random number generator -- useful for reproducible results. Otherwise,</span></div><div class="line">  <span class="comment">// (and by default) initialize using a seed derived from the system clock.</span></div><div class="line">  optional int64 random_seed = <span class="number">20</span> [<span class="keyword">default</span> = <span class="number">-1</span>];</div><div class="line"></div><div class="line">  <span class="comment">// Solver type</span></div><div class="line">  <span class="keyword">enum</span> SolverType &#123;</div><div class="line">    SGD = <span class="number">0</span>;</div><div class="line">    NESTEROV = <span class="number">1</span>;</div><div class="line">    ADAGRAD = <span class="number">2</span>;</div><div class="line">  &#125;</div><div class="line">  optional SolverType solver_type = <span class="number">30</span> [<span class="keyword">default</span> = SGD];</div><div class="line">  <span class="comment">// numerical stability for AdaGrad</span></div><div class="line">  optional <span class="keyword">float</span> delta = <span class="number">31</span> [<span class="keyword">default</span> = <span class="number">1e-8</span>];</div><div class="line"></div><div class="line">  <span class="comment">// If true, print information about the state of the net that may help with</span></div><div class="line">  <span class="comment">// debugging learning problems.</span></div><div class="line">  optional <span class="keyword">bool</span> debug_info = <span class="number">23</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line"></div><div class="line">  <span class="comment">// If false, don't save a snapshot after training finishes.</span></div><div class="line">  optional <span class="keyword">bool</span> snapshot_after_train = <span class="number">28</span> [<span class="keyword">default</span> = <span class="literal">true</span>];</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A message that stores the solver snapshots</span></div><div class="line">message SolverState &#123;</div><div class="line">  optional int32 iter = <span class="number">1</span>; <span class="comment">// The current iteration</span></div><div class="line">  optional <span class="built_in">string</span> learned_net = <span class="number">2</span>; <span class="comment">// The file that stores the learned net.</span></div><div class="line">  repeated BlobProto history = <span class="number">3</span>; <span class="comment">// The history for sgd solvers</span></div><div class="line">  optional int32 current_step = <span class="number">4</span> [<span class="keyword">default</span> = <span class="number">0</span>]; <span class="comment">// The current step for learning rate</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">enum</span> Phase &#123;</div><div class="line">   TRAIN = <span class="number">0</span>;</div><div class="line">   TEST = <span class="number">1</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line">message NetState &#123;</div><div class="line">  optional Phase phase = <span class="number">1</span> [<span class="keyword">default</span> = TEST];</div><div class="line">  optional int32 level = <span class="number">2</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line">  repeated <span class="built_in">string</span> stage = <span class="number">3</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line">message NetStateRule &#123;</div><div class="line">  <span class="comment">// Set phase to require the NetState have a particular phase (TRAIN or TEST)</span></div><div class="line">  <span class="comment">// to meet this rule.</span></div><div class="line">  optional Phase phase = <span class="number">1</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Set the minimum and/or maximum levels in which the layer should be used.</span></div><div class="line">  <span class="comment">// Leave undefined to meet the rule regardless of level.</span></div><div class="line">  optional int32 min_level = <span class="number">2</span>;</div><div class="line">  optional int32 max_level = <span class="number">3</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Customizable sets of stages to include or exclude.</span></div><div class="line">  <span class="comment">// The net must have ALL of the specified stages and NONE of the specified</span></div><div class="line">  <span class="comment">// "not_stage"s to meet the rule.</span></div><div class="line">  <span class="comment">// (Use multiple NetStateRules to specify conjunctions of stages.)</span></div><div class="line">  repeated <span class="built_in">string</span> stage = <span class="number">4</span>;</div><div class="line">  repeated <span class="built_in">string</span> not_stage = <span class="number">5</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// Specifies training parameters (multipliers on global learning constants,</span></div><div class="line"><span class="comment">// and the name and other settings used for weight sharing).</span></div><div class="line">message ParamSpec &#123;</div><div class="line">  <span class="comment">// The names of the parameter blobs -- useful for sharing parameters among</span></div><div class="line">  <span class="comment">// layers, but never required otherwise.  To share a parameter between two</span></div><div class="line">  <span class="comment">// layers, give it a (non-empty) name.</span></div><div class="line">  optional <span class="built_in">string</span> name = <span class="number">1</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Whether to require shared weights to have the same shape, or just the same</span></div><div class="line">  <span class="comment">// count -- defaults to STRICT if unspecified.</span></div><div class="line">  optional DimCheckMode share_mode = <span class="number">2</span>;</div><div class="line">  <span class="keyword">enum</span> DimCheckMode &#123;</div><div class="line">    <span class="comment">// STRICT (default) requires that num, channels, height, width each match.</span></div><div class="line">    STRICT = <span class="number">0</span>;</div><div class="line">    <span class="comment">// PERMISSIVE requires only the count (num*channels*height*width) to match.</span></div><div class="line">    PERMISSIVE = <span class="number">1</span>;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// The multiplier on the global learning rate for this parameter.</span></div><div class="line">  optional <span class="keyword">float</span> lr_mult = <span class="number">3</span> [<span class="keyword">default</span> = <span class="number">1.0</span>];</div><div class="line"></div><div class="line">  <span class="comment">// The multiplier on the global weight decay for this parameter.</span></div><div class="line">  optional <span class="keyword">float</span> decay_mult = <span class="number">4</span> [<span class="keyword">default</span> = <span class="number">1.0</span>];</div><div class="line">&#125;</div></pre></td></tr></table></figure></li><li><p>If finetuning, copy existing solver.prototxt file</p><ul><li>Change net to be your net</li><li>Change snapshot_prefix to your output</li><li>Reduce base learning rate (divide by 100)</li><li>Maybe change max_iter and snapshot</li></ul></li></ul><h4 id="Step-4-Train"><a href="#Step-4-Train" class="headerlink" title="Step 4: Train"></a>Step 4: Train</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">./build/tools/caffe train \</div><div class="line"> -gpu 0 \</div><div class="line"> -model path/to/trainval.prototxt \</div><div class="line"> -solver path/to/solver.prototxt \</div><div class="line"> -weights path/to/pretrained_weights.caffemodel</div><div class="line"> </div><div class="line"> # -gpu -1 for CPU mode</div><div class="line"> # -gpu all for multi-GPU data parallelism</div></pre></td></tr></table></figure><h3 id="Model-Zoo"><a href="#Model-Zoo" class="headerlink" title="Model Zoo"></a>Model Zoo</h3><p><a href="https://github.com/BVLC/caffe/wiki/Model-Zoo" target="_blank" rel="external">https://github.com/BVLC/caffe/wiki/Model-Zoo</a></p><h3 id="Python-Interface"><a href="#Python-Interface" class="headerlink" title="Python Interface"></a>Python Interface</h3><p>Read the code! Two most important files:</p><ul><li><a href="https://github.com/BVLC/caffe/blob/master/python/caffe/_caffe.cpp" target="_blank" rel="external">caffe/python/caffe/_caffe.cpp</a><ul><li>Exports Blob, Layer, Net, and Solver classes</li></ul></li><li><a href="https://github.com/BVLC/caffe/blob/master/python/caffe/pycaffe.py" target="_blank" rel="external">caffe/python/caffe/pycaffe.py</a><ul><li>Adds extra methods to Net class</li></ul></li></ul><p>Good for:</p><ul><li>Interfacing with numpy</li><li>Extract features: Run net forward</li><li>Compute gradients: Run net backward (DeepDream, etc)</li><li>Define layers in Python with numpy (CPU only)</li></ul><h3 id="Pros-Cons"><a href="#Pros-Cons" class="headerlink" title="Pros / Cons"></a>Pros / Cons</h3><ul><li>(+) Good for feedforward networks</li><li>(+) Good for finetuning existing networks</li><li>(+) Train models without writing any code!</li><li>(+) Python interface is pretty useful!</li><li>(-) Need to write C++ / CUDA for new GPU layers</li><li>(-) Not good for recurrent networks</li><li>(-) Cumbersome for big networks (GoogLeNet, ResNet)</li></ul><h2 id="Torch"><a href="#Torch" class="headerlink" title="Torch"></a>Torch</h2><p><a href="http://torch.ch" target="_blank" rel="external">http://torch.ch</a></p><h3 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a>Overview</h3><ul><li>From NYU + IDIAP</li><li>Written in C and Lua</li><li>Used a lot a Facebook, DeepMind</li></ul><h3 id="Lua"><a href="#Lua" class="headerlink" title="Lua"></a>Lua</h3><p><a href="http://tylerneylon.com/a/learn-lua/" target="_blank" rel="external">Learn Lua in 15 Minutes</a></p><ul><li>High level scripting language, easy to interface with C</li><li>Similar to Javascript:<ul><li>One data structure: table == JS object</li><li>Prototypical inheritance: metatable == JS prototype</li><li>First-class functions</li></ul></li><li>Some gotchas:<ul><li>1-indexed =(</li><li>Variables global by default =(</li><li>Small standard library</li></ul></li></ul><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><p>Torch tensors are just like numpy arrays</p><p>Documentation on GitHub:</p><ul><li><a href="https://github.com/torch/torch7/blob/master/doc/tensor.md" target="_blank" rel="external">https://github.com/torch/torch7/blob/master/doc/tensor.md</a></li><li><a href="https://github.com/torch/torch7/blob/master/doc/maths.md" target="_blank" rel="external">https://github.com/torch/torch7/blob/master/doc/maths.md</a></li></ul><h3 id="nn"><a href="#nn" class="headerlink" title="nn"></a>nn</h3><p>nn module lets you easily build and train neural nets</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- our optimization procedure will iterate over the modules, so only share</span></div><div class="line"><span class="comment">-- the parameters</span></div><div class="line">mlp = nn.Sequential()</div><div class="line">linear = nn.Linear(<span class="number">2</span>,<span class="number">2</span>)</div><div class="line">linear_clone = linear:clone(<span class="string">'weight'</span>,<span class="string">'bias'</span>) <span class="comment">-- clone sharing the parameters</span></div><div class="line">mlp:add(linear)</div><div class="line">mlp:add(linear_clone)</div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">gradUpdate</span><span class="params">(mlp, x, y, criterion, learningRate)</span></span> </div><div class="line">  <span class="keyword">local</span> pred = mlp:forward(x)</div><div class="line">  <span class="keyword">local</span> err = criterion:forward(pred, y)</div><div class="line">  <span class="keyword">local</span> gradCriterion = criterion:backward(pred, y)</div><div class="line">  mlp:zeroGradParameters()</div><div class="line">  mlp:backward(x, gradCriterion)</div><div class="line">  mlp:updateParameters(learningRate)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">-- our optimization procedure will use all the parameters at once, because</span></div><div class="line"><span class="comment">-- it requires the flattened parameters and gradParameters Tensors. Thus,</span></div><div class="line"><span class="comment">-- we need to share both the parameters and the gradParameters</span></div><div class="line">mlp = nn.Sequential()</div><div class="line">linear = nn.Linear(<span class="number">2</span>,<span class="number">2</span>)</div><div class="line"><span class="comment">-- need to share the parameters and the gradParameters as well</span></div><div class="line">linear_clone = linear:clone(<span class="string">'weight'</span>,<span class="string">'bias'</span>,<span class="string">'gradWeight'</span>,<span class="string">'gradBias'</span>)</div><div class="line">mlp:add(linear)</div><div class="line">mlp:add(linear_clone)</div><div class="line">params, gradParams = mlp:getParameters()</div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">gradUpdate</span><span class="params">(mlp, x, y, criterion, learningRate, params, gradParams)</span></span></div><div class="line">  <span class="keyword">local</span> pred = mlp:forward(x)</div><div class="line">  <span class="keyword">local</span> err = criterion:forward(pred, y)</div><div class="line">  <span class="keyword">local</span> gradCriterion = criterion:backward(pred, y)</div><div class="line">  mlp:zeroGradParameters()</div><div class="line">  mlp:backward(x, gradCriterion)</div><div class="line">  <span class="comment">-- adds the gradients to all the parameters at once</span></div><div class="line">  params:add(-learningRate, gradParams)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><h3 id="cunn"><a href="#cunn" class="headerlink" title="cunn"></a>cunn</h3><p>Running on GPU is easy</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">local</span> model = nn.Sequential()</div><div class="line">model:add(nn.Linear(<span class="number">2</span>,<span class="number">2</span>))</div><div class="line">model:add(nn.LogSoftMax())</div><div class="line"></div><div class="line">model:cuda()  <span class="comment">-- convert model to CUDA</span></div><div class="line"></div><div class="line"><span class="keyword">local</span> input = torch.Tensor(<span class="number">32</span>,<span class="number">2</span>):uniform()</div><div class="line">input = input:cuda()</div><div class="line"><span class="keyword">local</span> output = model:forward(input)</div><div class="line"></div><div class="line"><span class="keyword">local</span> input = torch.CudaTensor(<span class="number">32</span>,<span class="number">2</span>):uniform()</div><div class="line"><span class="keyword">local</span> output = model:forward(input)</div></pre></td></tr></table></figure><h3 id="optim"><a href="#optim" class="headerlink" title="optim"></a>optim</h3><p>optim package implements different update rules: momentum, Adam, etc</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">require</span> <span class="string">'optim'</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> epoch = <span class="number">1</span>, <span class="number">50</span> <span class="keyword">do</span></div><div class="line">   <span class="comment">-- local function we give to optim</span></div><div class="line">   <span class="comment">-- it takes current weights as input, and outputs the loss</span></div><div class="line">   <span class="comment">-- and the gradient of the loss with respect to the weights</span></div><div class="line">   <span class="comment">-- gradParams is calculated implicitly by calling 'backward',</span></div><div class="line">   <span class="comment">-- because the model's weight and bias gradient tensors</span></div><div class="line">   <span class="comment">-- are simply views onto gradParams</span></div><div class="line">   <span class="function"><span class="keyword">function</span> <span class="title">feval</span><span class="params">(params)</span></span></div><div class="line">      gradParams:zero()</div><div class="line"></div><div class="line">      <span class="keyword">local</span> outputs = model:forward(batchInputs)</div><div class="line">      <span class="keyword">local</span> loss = criterion:forward(outputs, batchLabels)</div><div class="line">      <span class="keyword">local</span> dloss_doutputs = criterion:backward(outputs, batchLabels)</div><div class="line">      model:backward(batchInputs, dloss_doutputs)</div><div class="line"></div><div class="line">      <span class="keyword">return</span> loss, gradParams</div><div class="line">   <span class="keyword">end</span></div><div class="line">   optim.sgd(feval, params, optimState)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><h3 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h3><ul><li>Caffe has Nets and Layers; Torch just has Modules</li><li>Modules are classes written in Lua; easy to read and write</li><li>Forward / backward written in Lua using Tensor methods</li><li>Same code runs on CPU / GPU</li></ul><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">local</span> Linear, parent = torch.class(<span class="string">'nn.Linear'</span>, <span class="string">'nn.Module'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:__init</span><span class="params">(inputSize, outputSize, bias)</span></span></div><div class="line">   parent.__init(self)</div><div class="line">   <span class="keyword">local</span> bias = ((bias == <span class="keyword">nil</span>) <span class="keyword">and</span> <span class="keyword">true</span>) <span class="keyword">or</span> bias</div><div class="line">   self.weight = torch.Tensor(outputSize, inputSize)</div><div class="line">   self.gradWeight = torch.Tensor(outputSize, inputSize)</div><div class="line">   <span class="keyword">if</span> bias <span class="keyword">then</span></div><div class="line">      self.bias = torch.Tensor(outputSize)</div><div class="line">      self.gradBias = torch.Tensor(outputSize)</div><div class="line">   <span class="keyword">end</span></div><div class="line">   self:reset()</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:noBias</span><span class="params">()</span></span></div><div class="line">   self.bias = <span class="keyword">nil</span></div><div class="line">   self.gradBias = <span class="keyword">nil</span></div><div class="line">   <span class="keyword">return</span> self</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:reset</span><span class="params">(stdv)</span></span></div><div class="line">   <span class="keyword">if</span> stdv <span class="keyword">then</span></div><div class="line">      stdv = stdv * <span class="built_in">math</span>.sqrt(<span class="number">3</span>)</div><div class="line">   <span class="keyword">else</span></div><div class="line">      stdv = <span class="number">1.</span>/<span class="built_in">math</span>.sqrt(self.weight:size(<span class="number">2</span>))</div><div class="line">   <span class="keyword">end</span></div><div class="line">   <span class="keyword">if</span> nn.oldSeed <span class="keyword">then</span></div><div class="line">      <span class="keyword">for</span> i=<span class="number">1</span>,self.weight:size(<span class="number">1</span>) <span class="keyword">do</span></div><div class="line">         self.weight:<span class="built_in">select</span>(<span class="number">1</span>, i):apply(<span class="function"><span class="keyword">function</span><span class="params">()</span></span></div><div class="line">            <span class="keyword">return</span> torch.uniform(-stdv, stdv)</div><div class="line">         <span class="keyword">end</span>)</div><div class="line">      <span class="keyword">end</span></div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span></div><div class="line">         <span class="keyword">for</span> i=<span class="number">1</span>,self.bias:nElement() <span class="keyword">do</span></div><div class="line">            self.bias[i] = torch.uniform(-stdv, stdv)</div><div class="line">         <span class="keyword">end</span></div><div class="line">      <span class="keyword">end</span></div><div class="line">   <span class="keyword">else</span></div><div class="line">      self.weight:uniform(-stdv, stdv)</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span> self.bias:uniform(-stdv, stdv) <span class="keyword">end</span></div><div class="line">   <span class="keyword">end</span></div><div class="line">   <span class="keyword">return</span> self</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">updateAddBuffer</span><span class="params">(self, input)</span></span></div><div class="line">   <span class="keyword">local</span> nframe = input:size(<span class="number">1</span>)</div><div class="line">   self.addBuffer = self.addBuffer <span class="keyword">or</span> input.new()</div><div class="line">   <span class="keyword">if</span> self.addBuffer:nElement() ~= nframe <span class="keyword">then</span></div><div class="line">      self.addBuffer:resize(nframe):fill(<span class="number">1</span>)</div><div class="line">   <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:updateOutput</span><span class="params">(input)</span></span></div><div class="line">   <span class="keyword">if</span> input:dim() == <span class="number">1</span> <span class="keyword">then</span></div><div class="line">      self.output:resize(self.weight:size(<span class="number">1</span>))</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span> self.output:copy(self.bias) <span class="keyword">else</span> self.output:zero() <span class="keyword">end</span></div><div class="line">      self.output:addmv(<span class="number">1</span>, self.weight, input)</div><div class="line">   <span class="keyword">elseif</span> input:dim() == <span class="number">2</span> <span class="keyword">then</span></div><div class="line">      <span class="keyword">local</span> nframe = input:size(<span class="number">1</span>)</div><div class="line">      <span class="keyword">local</span> nElement = self.output:nElement()</div><div class="line">      self.output:resize(nframe, self.weight:size(<span class="number">1</span>))</div><div class="line">      <span class="keyword">if</span> self.output:nElement() ~= nElement <span class="keyword">then</span></div><div class="line">         self.output:zero()</div><div class="line">      <span class="keyword">end</span></div><div class="line">      updateAddBuffer(self, input)</div><div class="line">      self.output:addmm(<span class="number">0</span>, self.output, <span class="number">1</span>, input, self.weight:t())</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span> self.output:addr(<span class="number">1</span>, self.addBuffer, self.bias) <span class="keyword">end</span></div><div class="line">   <span class="keyword">else</span></div><div class="line">      <span class="built_in">error</span>(<span class="string">'input must be vector or matrix'</span>)</div><div class="line">   <span class="keyword">end</span></div><div class="line"></div><div class="line">   <span class="keyword">return</span> self.output</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:updateGradInput</span><span class="params">(input, gradOutput)</span></span></div><div class="line">   <span class="keyword">if</span> self.gradInput <span class="keyword">then</span></div><div class="line"></div><div class="line">      <span class="keyword">local</span> nElement = self.gradInput:nElement()</div><div class="line">      self.gradInput:resizeAs(input)</div><div class="line">      <span class="keyword">if</span> self.gradInput:nElement() ~= nElement <span class="keyword">then</span></div><div class="line">         self.gradInput:zero()</div><div class="line">      <span class="keyword">end</span></div><div class="line">      <span class="keyword">if</span> input:dim() == <span class="number">1</span> <span class="keyword">then</span></div><div class="line">         self.gradInput:addmv(<span class="number">0</span>, <span class="number">1</span>, self.weight:t(), gradOutput)</div><div class="line">      <span class="keyword">elseif</span> input:dim() == <span class="number">2</span> <span class="keyword">then</span></div><div class="line">         self.gradInput:addmm(<span class="number">0</span>, <span class="number">1</span>, gradOutput, self.weight)</div><div class="line">      <span class="keyword">end</span></div><div class="line"></div><div class="line">      <span class="keyword">return</span> self.gradInput</div><div class="line">   <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:accGradParameters</span><span class="params">(input, gradOutput, scale)</span></span></div><div class="line">   scale = scale <span class="keyword">or</span> <span class="number">1</span></div><div class="line">   <span class="keyword">if</span> input:dim() == <span class="number">1</span> <span class="keyword">then</span></div><div class="line">      self.gradWeight:addr(scale, gradOutput, input)</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span> self.gradBias:add(scale, gradOutput) <span class="keyword">end</span></div><div class="line">   <span class="keyword">elseif</span> input:dim() == <span class="number">2</span> <span class="keyword">then</span></div><div class="line">      self.gradWeight:addmm(scale, gradOutput:t(), input)</div><div class="line">      <span class="keyword">if</span> self.bias <span class="keyword">then</span></div><div class="line">         <span class="comment">-- update the size of addBuffer if the input is not the same size as the one we had in last updateGradInput</span></div><div class="line">         updateAddBuffer(self, input)</div><div class="line">         self.gradBias:addmv(scale, gradOutput:t(), self.addBuffer)</div><div class="line">      <span class="keyword">end</span></div><div class="line">   <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:sharedAccUpdateGradParameters</span><span class="params">(input, gradOutput, lr)</span></span></div><div class="line">   <span class="comment">-- we do not need to accumulate parameters when sharing:</span></div><div class="line">   self:defaultAccUpdateGradParameters(input, gradOutput, lr)</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:clearState</span><span class="params">()</span></span></div><div class="line">   <span class="keyword">if</span> self.addBuffer <span class="keyword">then</span> self.addBuffer:set() <span class="keyword">end</span></div><div class="line">   <span class="keyword">return</span> parent.clearState(self)</div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">Linear:__tostring__</span><span class="params">()</span></span></div><div class="line">  <span class="keyword">return</span> torch.<span class="built_in">type</span>(self) ..</div><div class="line">      <span class="built_in">string</span>.format(<span class="string">'(%d -&gt; %d)'</span>, self.weight:size(<span class="number">2</span>), self.weight:size(<span class="number">1</span>)) ..</div><div class="line">      (self.bias == <span class="keyword">nil</span> <span class="keyword">and</span> <span class="string">' without bias'</span> <span class="keyword">or</span> <span class="string">''</span>)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p>Tons of built-in modules and loss functions</p><p><a href="https://github.com/torch/nn" target="_blank" rel="external">https://github.com/torch/nn</a></p><h4 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h4><p>Container modules allow you to combine multiple modules</p><h3 id="nngraph"><a href="#nngraph" class="headerlink" title="nngraph"></a>nngraph</h3><p>A multi-layer network where each layer takes output of previous two layers as input.</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">input = nn.Identity()()</div><div class="line">L1 = nn.Tanh()(nn.Linear(<span class="number">10</span>, <span class="number">20</span>)(input))</div><div class="line">L2 = nn.Tanh()(nn.Linear(<span class="number">30</span>, <span class="number">60</span>)(nn.JoinTable(<span class="number">1</span>)(&#123;input, L1&#125;)))</div><div class="line">L3 = nn.Tanh()(nn.Linear(<span class="number">80</span>, <span class="number">160</span>)(nn.JoinTable(<span class="number">1</span>)(&#123;L1, L2&#125;)))</div><div class="line"></div><div class="line">g = nn.gModule(&#123;input&#125;, &#123;L3&#125;)</div><div class="line"></div><div class="line">indata = torch.rand(<span class="number">10</span>)</div><div class="line">gdata = torch.rand(<span class="number">160</span>)</div><div class="line">g:forward(indata)</div><div class="line">g:backward(indata, gdata)</div><div class="line"></div><div class="line">graph.dot(g.fg, <span class="string">'Forward Graph'</span>)</div><div class="line">graph.dot(g.bg, <span class="string">'Backward Graph'</span>)</div></pre></td></tr></table></figure><p><a href="https://github.com/torch/nngraph" target="_blank" rel="external">More Info</a></p><h3 id="Pretrained-Models"><a href="#Pretrained-Models" class="headerlink" title="Pretrained Models"></a>Pretrained Models</h3><ul><li>loadcaffe: Load pretrained Caffe models: AlexNet, VGG, some others<ul><li><a href="https://github.com/szagoruyko/loadcaffe" target="_blank" rel="external">https://github.com/szagoruyko/loadcaffe</a></li></ul></li><li>GoogLeNet v1: <a href="https://github.com/soumith/inception.torch" target="_blank" rel="external">https://github.com/soumith/inception.torch</a></li><li>GoogLeNet v3: <a href="https://github.com/Moodstocks/inception-v3.torch" target="_blank" rel="external">https://github.com/Moodstocks/inception-v3.torch</a></li><li>ResNet: <a href="https://github.com/facebook/fb.resnet.torch" target="_blank" rel="external">https://github.com/facebook/fb.resnet.torch</a></li></ul><h3 id="Package-Management"><a href="#Package-Management" class="headerlink" title="Package Management"></a>Package Management</h3><p>After installing torch, use luarocks to install or update Lua packages</p><p>(Similar to pip install from Python)</p><h3 id="Other-useful-packages"><a href="#Other-useful-packages" class="headerlink" title="Other useful packages"></a>Other useful packages</h3><ul><li>torch.cudnn: Bindings for NVIDIA cuDNN kernels<ul><li><a href="https://github.com/soumith/cudnn.torch" target="_blank" rel="external">https://github.com/soumith/cudnn.torch</a></li></ul></li><li>torch-hdf5: Read and write HDF5 files from Torch<ul><li><a href="https://github.com/deepmind/torch-hdf5" target="_blank" rel="external">https://github.com/deepmind/torch-hdf5</a></li></ul></li><li>lua-cjson: Read and write JSON files from Lua<ul><li><a href="https://luarocks.org/modules/luarocks/lua-cjson" target="_blank" rel="external">https://luarocks.org/modules/luarocks/lua-cjson</a></li></ul></li><li>cltorch, clnn: OpenCL backend for Torch, and port of nn<ul><li><a href="https://github.com/hughperkins/cltorch" target="_blank" rel="external">https://github.com/hughperkins/cltorch</a>, <a href="https://github.com/hughperkins/clnn" target="_blank" rel="external">https://github.com/hughperkins/clnn</a></li></ul></li><li>torch-autograd: Automatic differentiation; sort of like more powerful nngraph, similar to Theano or TensorFlow<ul><li><a href="https://github.com/twitter/torch-autograd" target="_blank" rel="external">https://github.com/twitter/torch-autograd</a></li></ul></li><li>fbcunn: Facebook: FFT conv, multi-GPU (DataParallel, ModelParallel)<ul><li><a href="https://github.com/facebook/fbcunn" target="_blank" rel="external">https://github.com/facebook/fbcunn</a></li></ul></li></ul><h3 id="Typical-Workflow"><a href="#Typical-Workflow" class="headerlink" title="Typical Workflow"></a>Typical Workflow</h3><ol><li>Preprocess data; usually use a Python script to dump data to HDF5</li><li>Train a model in Lua / Torch; read from HDF5 datafile, save trained model to disk</li><li>Use trained model for something, often with an evaluation script</li></ol><p>Example: <a href="https://github.com/jcjohnson/torch-rnn" target="_blank" rel="external">https://github.com/jcjohnson/torch-rnn</a></p><p>Step 1: Preprocess data; usually use a Python script to dump data to HDF5 (<a href="https://github.com/jcjohnson/torch-rnn/blob/master/scripts/preprocess.py" target="_blank" rel="external">https://github.com/jcjohnson/torch-rnn/blob/master/scripts/preprocess.py</a>)<br>Step 2: Train a model in Lua / Torch; read from HDF5 datafile, save trained model to disk (<a href="https://github.com/jcjohnson/torch-rnn/blob/master/train.lua" target="_blank" rel="external">https://github.com/jcjohnson/torch-rnn/blob/master/train.lua</a> )<br>Step 3: Use trained model for something, often with an evaluation script (<a href="https://github.com/jcjohnson/torch-rnn/blob/master/sample.lua" target="_blank" rel="external">https://github.com/jcjohnson/torch-rnn/blob/master/sample.lua</a>)</p><h3 id="Pros-Cons-1"><a href="#Pros-Cons-1" class="headerlink" title="Pros / Cons"></a>Pros / Cons</h3><ul><li>(-) Lua</li><li>(-) Less plug-and-play than Caffe<ul><li>You usually write your own training code</li></ul></li><li>(+) Lots of modular pieces that are easy to combine</li><li>(+) Easy to write your own layer types and run on GPU</li><li>(+) Most of the library code is in Lua, easy to read</li><li>(+) Lots of pretrained models!</li><li>(-) Not great for RNNs</li></ul><h2 id="Theano"><a href="#Theano" class="headerlink" title="Theano"></a>Theano</h2><p><a href="http://deeplearning.net/software/theano/" target="_blank" rel="external">http://deeplearning.net/software/theano/</a></p><h3 id="Overview-2"><a href="#Overview-2" class="headerlink" title="Overview"></a>Overview</h3><ul><li>From Yoshua Bengio’s group at University of Montreal</li><li>Embracing computation graphs, symbolic computation</li><li>High-level wrappers: Keras, Lasagne</li></ul><h3 id="Other-Topics"><a href="#Other-Topics" class="headerlink" title="Other Topics"></a>Other Topics</h3><p><strong>Conditionals</strong>: The <strong>ifelse</strong> and <strong>switch</strong> functions allow conditional control flow in the graph</p><p><strong>Loops</strong>: The <strong>scan</strong> function allows for (some types) of loops in the computational graph; good for RNNs</p><p><strong>Derivatives</strong>: Efficient Jacobian / vector products with R and L operators, symbolic hessians (gradient of gradient)</p><p><strong>Sparse matrices, optimizations, etc</strong></p><h3 id="Multi-GPU"><a href="#Multi-GPU" class="headerlink" title="Multi-GPU"></a>Multi-GPU</h3><p>Experimental model parallelism:<br><a href="http://deeplearning.net/software/theano/tutorial/using_multi_gpu.html" target="_blank" rel="external">http://deeplearning.net/software/theano/tutorial/using_multi_gpu.html</a></p><p>Data parallelism using platoon:<br><a href="https://github.com/mila-udem/platoon" target="_blank" rel="external">https://github.com/mila-udem/platoon</a></p><h3 id="High-level-wrapper"><a href="#High-level-wrapper" class="headerlink" title="High level wrapper"></a>High level wrapper</h3><ul><li>Lasagne</li><li>Keras</li></ul><h3 id="Pretrained-Models-1"><a href="#Pretrained-Models-1" class="headerlink" title="Pretrained Models"></a>Pretrained Models</h3><p><strong>Lasagne Model Zoo</strong> has pretrained common architectures:<br><a href="https://github.com/Lasagne/Recipes/tree/master/modelzoo" target="_blank" rel="external">https://github.com/Lasagne/Recipes/tree/master/modelzoo</a><br><strong>AlexNet with weights</strong>: <a href="https://github.com/uoguelph-mlrg/theano_alexnet" target="_blank" rel="external">https://github.com/uoguelph-mlrg/theano_alexnet</a><br><strong>sklearn-theano</strong>: Run OverFeat and GoogLeNet forward, but no fine-tuning? <a href="http://sklearn-theano.github.io" target="_blank" rel="external">http://sklearn-theano.github.io</a><br><strong>caffe-theano-conversion</strong>: CS 231n project from last year: load models and weights from caffe! Not sure if full-featured <a href="https://github.com/kitofans/caffe-theano-conversion" target="_blank" rel="external">https://github.com/kitofans/caffe-theano-conversion</a></p><h3 id="Pros-Cons-2"><a href="#Pros-Cons-2" class="headerlink" title="Pros / Cons"></a>Pros / Cons</h3><ul><li>(+) Python + numpy</li><li>(+) Computational graph is nice abstraction</li><li>(+) RNNs fit nicely in computational graph</li><li>(-) Raw Theano is somewhat low-level</li><li>(+) High level wrappers (Keras, Lasagne) ease the pain</li><li>(-) Error messages can be unhelpful</li><li>(-) Large models can have long compile times</li><li>(-) Much “fatter” than Torch; more magic</li><li>(-) Patchy support for pretrained models</li></ul><h2 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h2><p><a href="https://www.tensorflow.org" target="_blank" rel="external">https://www.tensorflow.org</a></p><h3 id="Overview-3"><a href="#Overview-3" class="headerlink" title="Overview"></a>Overview</h3><ul><li>From Google</li><li>Very similar to Theano - all about computation graphs</li><li>Easy visualizations (TensorBoard)</li><li>Multi-GPU and multi-node training</li></ul><h3 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h3><p>Tensorboard makes it easy to visualize what’s happening inside your models</p><h3 id="Multi-GPU-1"><a href="#Multi-GPU-1" class="headerlink" title="Multi-GPU"></a>Multi-GPU</h3><h3 id="Distributed"><a href="#Distributed" class="headerlink" title="Distributed"></a>Distributed</h3><h3 id="Pretrained-Models-2"><a href="#Pretrained-Models-2" class="headerlink" title="Pretrained Models"></a>Pretrained Models</h3><p>You can get a pretrained version of Inception here:<br><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md" target="_blank" rel="external">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md</a></p><p>(In an Android example?? Very well-hidden)</p><p>The only one I could find =(</p><h3 id="Pros-Cons-3"><a href="#Pros-Cons-3" class="headerlink" title="Pros / Cons"></a>Pros / Cons</h3><ul><li>(+) Python + numpy</li><li>(+) Computational graph abstraction, like Theano; great for RNNs</li><li>(+) Much faster compile times than Theano</li><li>(+) Slightly more convenient than raw Theano?</li><li>(+) TensorBoard for visualization</li><li>(+) Data AND model parallelism; best of all frameworks</li><li>(+/-) Distributed models, but not open-source yet</li><li>(-) Slower than other frameworks right now</li><li>(-) Much “fatter” than Torch; more magic</li><li>(-) Not many pretrained models</li></ul><h2 id="Use-Cases"><a href="#Use-Cases" class="headerlink" title="Use Cases"></a>Use Cases</h2><ul><li>Extract AlexNet or VGG features? <strong>Use Caffe</strong></li><li>Fine-tune AlexNet for new classes? <strong>Use Caffe</strong></li><li>Image Captioning with finetuning?<ul><li>-&gt; Need pretrained models (Caffe, Torch, Lasagne)</li><li>-&gt; Need RNNs (Torch or Lasagne)</li><li>-&gt; <strong>Use Torch or Lasagna</strong></li></ul></li><li>Segmentation? (Classify every pixel)<ul><li>-&gt; Need pretrained model (Caffe, Torch, Lasagna)</li><li>-&gt; Need funny loss function</li><li>-&gt; If loss function exists in Caffe: <strong>Use Caffe</strong></li><li>-&gt; If you want to write your own loss: <strong>Use Torch</strong></li></ul></li><li>Object Detection?<ul><li>-&gt; Need pretrained model (Torch, Caffe, Lasagne)</li><li>-&gt; Need lots of custom imperative code (NOT Lasagne)</li><li>-&gt; Use <strong>Caffe + Python</strong> or <strong>Torch</strong></li></ul></li><li>Language modeling with new <strong>RNN</strong> structure?<ul><li>-&gt; Need easy recurrent nets (NOT Caffe, Torch)</li><li>-&gt; No need for pretrained models</li><li>-&gt; <strong>Use Theano or TensorFlow</strong></li></ul></li><li>Implement BatchNorm?<ul><li>-&gt; Don’t want to derive gradient? <strong>Theano</strong> or <strong>TensorFlow</strong></li><li>-&gt; Implement efficient backward pass? <strong>Use Torch</strong></li></ul></li></ul><p><strong>Recommendation</strong>:</p><ul><li>Feature extraction / finetuning existing models: Use Caffe</li><li>Complex uses of pretrained models: Use Lasagne or Torch</li><li>Write your own layers: Use Torch</li><li>Crazy RNNs: Use Theano or Tensorflow</li><li>Huge model, need model parallelism: Use TensorFlow</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Software-Packages&quot;&gt;&lt;a href=&quot;#Software-Packages&quot; class=&quot;headerlink&quot; title=&quot;Software Packages&quot;&gt;&lt;/a&gt;Software Packages&lt;/h1&gt;&lt;h2 id=&quot;Caffe
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>usr/bin/ld: cannot find -lxxx Solutions</title>
    <link href="http://yoursite.com/2017/04/11/usr-bin-ld-cannot-find-lxxx-Solutions/"/>
    <id>http://yoursite.com/2017/04/11/usr-bin-ld-cannot-find-lxxx-Solutions/</id>
    <published>2017-04-11T00:59:11.000Z</published>
    <updated>2017-04-11T01:04:39.843Z</updated>
    
    <content type="html"><![CDATA[<p>在Ubuntu上运行Qt5的过程中报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">usr/bin/ld: cannot find -lGL</div></pre></td></tr></table></figure><p>最后发现问题是系统中没有对应的库文件 <code>libgl.so</code></p><p>那么解决方式也很简单，安装即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install libgl-dev</div></pre></td></tr></table></figure><p>Tada =)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在Ubuntu上运行Qt5的过程中报错：&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=
    
    </summary>
    
    
      <category term="ubuntu" scheme="http://yoursite.com/tags/ubuntu/"/>
    
      <category term="c++" scheme="http://yoursite.com/tags/c/"/>
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning (GT) Notes</title>
    <link href="http://yoursite.com/2017/04/10/Reinforcement-Learning-GT-Notes/"/>
    <id>http://yoursite.com/2017/04/10/Reinforcement-Learning-GT-Notes/</id>
    <published>2017-04-10T12:54:51.000Z</published>
    <updated>2017-04-10T12:55:44.597Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Decision-Making-amp-Reinforcement-Learning"><a href="#Decision-Making-amp-Reinforcement-Learning" class="headerlink" title="Decision Making &amp; Reinforcement Learning"></a>Decision Making &amp; Reinforcement Learning</h1><p>Supervised Learning: $y = f(x)$</p><p>Unsupervised Learning: $f(x)$</p><p>Reinforcement Learning: $y = f(x), z$</p><h2 id="Markov-Decision-Process"><a href="#Markov-Decision-Process" class="headerlink" title="Markov Decision Process"></a>Markov Decision Process</h2><p>States: $S$</p><p>Model: $T(s, a, s^{\prime}) \sim Pr(s^{\prime} | s, a)$</p><p>Actions: $A(s), A$</p><p>Reword: $R(s), R(s, a), R(s, a, s^{\prime})$</p><hr><p>Policy: $\pi(s) \rightarrow a$</p><p>​ $\pi^{*}$</p><h3 id="Sequences-of-Rewards-Assumption"><a href="#Sequences-of-Rewards-Assumption" class="headerlink" title="Sequences of Rewards: Assumption"></a>Sequences of Rewards: Assumption</h3><ul><li><p>Infinite Horizons</p></li><li><p>Utility of sequences</p><p>if $U(s_0, s_1, s_2, \cdots) &gt; U(s_0, s^{\prime}_1, s^{\prime}_2, \cdots)$</p><p>then $U(s_1, s_2, \cdots) &gt; U(s^{\prime}_1, s^{\prime}_2, \cdots)$</p></li></ul><script type="math/tex;mode=display">U(s_0, s_1, s_2, \cdots)=\sum_{t=0}^{\infty}\gamma^{t}R(s_t), 0 \leq \gamma \leq 1</script><script type="math/tex;mode=display">U\leq\frac{R_{max}}{1 - \gamma}</script><ul><li><p>Policies</p><script type="math/tex;mode=display">\pi^{\star}=argmax_{\pi} E[\sum_{t=0}^{\infty}\gamma^{t}R(S_t)|\pi]</script><script type="math/tex;mode=display">U^{\pi}(s)=E[\sum_{t=0}^{\infty}\gamma^{t}R(s_t)|\pi,s_0=s]</script><script type="math/tex;mode=display">\pi^{\star}(s)=argmax_{a}\sum_{s^{\prime}}T(s, a, s^{\prime})U(s^{\prime})</script><script type="math/tex;mode=display">U(s)=R(s)+\gamma \max_{a}\sum_{s^{\prime}}T(s, a, s^{\prime})U(s^{\prime})</script><p>Above is the <strong>Bellman Equation</strong>.</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Decision-Making-amp-Reinforcement-Learning&quot;&gt;&lt;a href=&quot;#Decision-Making-amp-Reinforcement-Learning&quot; class=&quot;headerlink&quot; title=&quot;Decision
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="reinforcement learning" scheme="http://yoursite.com/tags/reinforcement-learning/"/>
    
  </entry>
  
  <entry>
    <title>cs231n Lecture 11 Recap</title>
    <link href="http://yoursite.com/2017/04/10/cs231n-Lecture-11-Recap/"/>
    <id>http://yoursite.com/2017/04/10/cs231n-Lecture-11-Recap/</id>
    <published>2017-04-10T02:30:44.000Z</published>
    <updated>2017-04-10T03:00:37.566Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Working-with-CNNs-in-practice"><a href="#Working-with-CNNs-in-practice" class="headerlink" title="Working with CNNs in practice"></a>Working with CNNs in practice</h1><ul><li>Making the most of your data<ul><li>Data augmentation</li><li>Transfer learning</li></ul></li><li>All about convolutions<ul><li>How to arrange them</li><li>How to compute them fast</li></ul></li><li>Implementation details<ul><li>GPU / CPU, bottlenecks, ditributed training</li></ul></li></ul><h2 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h2><h3 id="Horizontal-flips"><a href="#Horizontal-flips" class="headerlink" title="Horizontal flips"></a>Horizontal flips</h3><h3 id="Random-crops-scales"><a href="#Random-crops-scales" class="headerlink" title="Random crops/scales"></a>Random crops/scales</h3><p><strong>Training:</strong> sample random crops /scales</p><p>ResNet:</p><ol><li>Pick random L in range [256, 480]</li><li>Resize training image, short side = L</li><li>Sample random 224 x 224 patch</li></ol><p><strong>Testing:</strong> average a fixed set of crops</p><p>ResNet:</p><ol><li>Resize image at 5 scales: {224, 256, 384, 480, 640}</li><li>For each size, use 10 224 x 224 crops: 4 corners + center, + flips</li></ol><h3 id="Color-jitter"><a href="#Color-jitter" class="headerlink" title="Color jitter"></a>Color jitter</h3><p><strong>Simple:</strong><br>Randomly jitter contrast</p><p><strong>Complex:</strong></p><ol><li>Apply PCA to all [R, G, B] pixels in training set</li><li>Sample a “color offset” along principal component directions</li><li>Add offset to all pixels of a training image</li></ol><p>(As seen in [Krizhevsky et al. 2012], ResNet, etc)</p><h2 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h2><p>“You need a lot of a data if you want to train/use CNNs”</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/cs231n/lec11/tl.png" alt="tl"></p><p>some tricks:</p><div class="table-container"><table><thead><tr><th></th><th>very similar dataset</th><th>very different dataset</th></tr></thead><tbody><tr><td>very little data</td><td>Use Linear Classifer on top layer</td><td>Try linear classifer from different stages</td></tr><tr><td>quite a lot of data</td><td>Finetune a few layers</td><td>Finetune a larger number of layers</td></tr></tbody></table></div><h2 id="All-about-Convolutions"><a href="#All-about-Convolutions" class="headerlink" title="All about Convolutions"></a>All about Convolutions</h2><h3 id="How-to-stack-them"><a href="#How-to-stack-them" class="headerlink" title="How to stack them"></a>How to stack them</h3><ul><li>Replace large convolutions (5 x 5, 7 x 7) with stacks of 3 x 3 convolutions</li><li>1 x 1 “bottleneck” convolutions are very efficient</li><li>Can factor N x N convolutions into 1 x N and N x 1</li><li>All of the above give fewer parameters, less compute, more nonlinearity</li></ul><h3 id="How-to-compute-them"><a href="#How-to-compute-them" class="headerlink" title="How to compute them"></a>How to compute them</h3><h4 id="im2col"><a href="#im2col" class="headerlink" title="im2col"></a>im2col</h4><p><img src="http://o7ie0tcjk.bkt.clouddn.com/cs231n/lec11/cs231n11_im2col.png" alt="im2col"></p><h4 id="BLAS"><a href="#BLAS" class="headerlink" title="BLAS"></a>BLAS</h4><h4 id="FFT"><a href="#FFT" class="headerlink" title="FFT"></a>FFT</h4><ol><li>Compute FFT of weights: F(W)</li><li>Compute FFT of image: F(X)</li><li>Compute elementwise product: F(W) ○ F(X)</li><li>Compute inverse FFT: Y = F-1(F(W) ○ F(X))</li></ol><p>FFT convolutions get a big speedup for larger filters</p><p>Not much speedup for 3x3 filters =(</p><h4 id="Fast-algorithms"><a href="#Fast-algorithms" class="headerlink" title="Fast algorithms"></a>Fast algorithms</h4><ul><li>Strassen’s Algorithm</li><li>And so on…</li></ul><h2 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h2><ul><li>GPUs much faster than CPUs</li><li>Distributed training is sometimes used<ul><li>Not needed for small problems</li></ul></li><li>Be aware of bottlenecks: CPU / GPU, CPU / disk</li><li>Low precison makes things faster and still works<ul><li>32 bit is standard now, 16 bit soon</li><li>In the future: binary nets?</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Working-with-CNNs-in-practice&quot;&gt;&lt;a href=&quot;#Working-with-CNNs-in-practice&quot; class=&quot;headerlink&quot; title=&quot;Working with CNNs in practice&quot;&gt;&lt;/a
    
    </summary>
    
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>Dynet xor demo [python version]</title>
    <link href="http://yoursite.com/2017/04/09/Dynet-xor-demo-python-version/"/>
    <id>http://yoursite.com/2017/04/09/Dynet-xor-demo-python-version/</id>
    <published>2017-04-09T06:15:18.000Z</published>
    <updated>2017-04-09T06:17:35.115Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> dynet <span class="keyword">as</span> dy</div><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line"><span class="comment"># Parameters of the model and training</span></div><div class="line">HIDDEN_SIZE = <span class="number">20</span></div><div class="line">NUM_EPOCHS = <span class="number">20</span></div><div class="line"></div><div class="line"><span class="comment"># Define the model and SGD optimizer</span></div><div class="line">model = dy.Model()</div><div class="line">W_xh_p = model.add_parameters((HIDDEN_SIZE, <span class="number">2</span>))</div><div class="line">b_h_p = model.add_parameters(HIDDEN_SIZE)</div><div class="line">W_hy_p = model.add_parameters((<span class="number">1</span>, HIDDEN_SIZE))</div><div class="line">b_y_p = model.add_parameters(<span class="number">1</span>)</div><div class="line">trainer = dy.SimpleSGDTrainer(model)</div><div class="line"></div><div class="line"><span class="comment"># Define the training data, consisting of (x,y) tuples</span></div><div class="line">data = [([<span class="number">1</span>,<span class="number">1</span>],<span class="number">1</span>), ([<span class="number">-1</span>,<span class="number">1</span>],<span class="number">-1</span>), ([<span class="number">1</span>,<span class="number">-1</span>],<span class="number">-1</span>), ([<span class="number">-1</span>,<span class="number">-1</span>],<span class="number">1</span>)]</div><div class="line"></div><div class="line"><span class="comment"># Define the function we would like to calculate</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_function</span><span class="params">(x)</span>:</span></div><div class="line">	dy.renew_cg()</div><div class="line">	w_xh = dy.parameter(W_xh_p)</div><div class="line">	b_h = dy.parameter(b_h_p)</div><div class="line">	W_hy = dy.parameter(W_hy_p)</div><div class="line">	b_y = dy.parameter(b_y_p)</div><div class="line">	x_val = dy.inputVector(x)</div><div class="line">	h_val = dy.tanh(w_xh * x_val + b_h)</div><div class="line">	y_val = W_hy * h_val + b_y</div><div class="line">	<span class="keyword">return</span> y_val</div><div class="line"></div><div class="line"><span class="comment"># Perform training</span></div><div class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(NUM_EPOCHS):</div><div class="line">	epoch_loss = <span class="number">0</span></div><div class="line">	random.shuffle(data)</div><div class="line">	<span class="keyword">for</span> x, ystar <span class="keyword">in</span> data:</div><div class="line">		y = calc_function(x)</div><div class="line">		loss = dy.squared_distance(y, dy.scalarInput(ystar))</div><div class="line">		epoch_loss += loss.value()</div><div class="line">		loss.backward()</div><div class="line">		trainer.update()</div><div class="line">	print(<span class="string">"Epoch %d: loss=%f"</span> % (epoch, epoch_loss))</div><div class="line"></div><div class="line"><span class="comment"># Print results of prediction</span></div><div class="line"><span class="keyword">for</span> x, ystar <span class="keyword">in</span> data:</div><div class="line">	y = calc_function(x)</div><div class="line">	print(<span class="string">"%r -&gt; %f"</span> % (x, y.value()))</div></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">[dynet] random seed: 1174664263</div><div class="line">[dynet] allocating memory: 512MB</div><div class="line">[dynet] memory allocation done.</div><div class="line">Epoch 0: loss=12.391680</div><div class="line">Epoch 1: loss=8.196088</div><div class="line">Epoch 2: loss=8.103037</div><div class="line">Epoch 3: loss=8.636450</div><div class="line">Epoch 4: loss=7.573008</div><div class="line">Epoch 5: loss=4.910318</div><div class="line">Epoch 6: loss=3.079966</div><div class="line">Epoch 7: loss=1.328273</div><div class="line">Epoch 8: loss=1.171368</div><div class="line">Epoch 9: loss=0.515850</div><div class="line">Epoch 10: loss=1.885216</div><div class="line">Epoch 11: loss=0.568994</div><div class="line">Epoch 12: loss=0.278629</div><div class="line">Epoch 13: loss=0.025215</div><div class="line">Epoch 14: loss=0.018466</div><div class="line">Epoch 15: loss=0.055305</div><div class="line">Epoch 16: loss=0.014131</div><div class="line">Epoch 17: loss=0.010476</div><div class="line">Epoch 18: loss=0.003893</div><div class="line">Epoch 19: loss=0.003332</div><div class="line">[1, 1] -&gt; 1.049703</div><div class="line">[-1, 1] -&gt; -0.996379</div><div class="line">[1, -1] -&gt; -0.974599</div><div class="line">[-1, -1] -&gt; 0.995763</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/d
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="dynet" scheme="http://yoursite.com/tags/dynet/"/>
    
  </entry>
  
</feed>
