<!doctype html><html class="theme-next mist use-motion" lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="Hexo, NexT"><link rel="alternate" href="/atom.xml" title="Abracadabra" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="Ewan&apos;s IT Blog"><meta property="og:type" content="website"><meta property="og:title" content="Abracadabra"><meta property="og:url" content="http://yoursite.com/page/15/index.html"><meta property="og:site_name" content="Abracadabra"><meta property="og:description" content="Ewan&apos;s IT Blog"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Abracadabra"><meta name="twitter:description" content="Ewan&apos;s IT Blog"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post"},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/page/15/"><title>Abracadabra</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?dc405a79ad500922134d14cdf288f646";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container one-collumn sidebar-position-left page-home"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Abracadabra</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Do it yourself</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><section id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/29/WGAN-implemented-by-PyTorch/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/29/WGAN-implemented-by-PyTorch/" itemprop="url">WGAN implemented by PyTorch</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-29T23:21:33+08:00">2017-04-29 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/29/WGAN-implemented-by-PyTorch/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/29/WGAN-implemented-by-PyTorch/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/29/WGAN-implemented-by-PyTorch/" class="leancloud_visitors" data-flag-title="WGAN implemented by PyTorch"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="comment"># Wasserstein Generative Adversarial Networks (WGAN) example in PyTorch.</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> torch</div><div class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div><div class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</div><div class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</div><div class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</div><div class="line"></div><div class="line"><span class="comment"># Data params</span></div><div class="line">data_mean = <span class="number">4</span></div><div class="line">data_stddev = <span class="number">1.25</span></div><div class="line"></div><div class="line"><span class="comment"># Model params</span></div><div class="line">g_input_size = <span class="number">1</span>     <span class="comment"># Random noise dimension coming into generator, per output vector</span></div><div class="line">g_hidden_size = <span class="number">50</span>   <span class="comment"># Generator complexity</span></div><div class="line">g_output_size = <span class="number">1</span>    <span class="comment"># size of generated output vector</span></div><div class="line">d_input_size = <span class="number">100</span>   <span class="comment"># Minibatch size - cardinality of distributions</span></div><div class="line">d_hidden_size = <span class="number">50</span>   <span class="comment"># Discriminator complexity</span></div><div class="line">d_output_size = <span class="number">1</span>    <span class="comment"># Single dimension for 'real' vs. 'fake'</span></div><div class="line">minibatch_size = d_input_size</div><div class="line"></div><div class="line">d_learning_rate = <span class="number">2e-4</span>  <span class="comment"># 2e-4</span></div><div class="line">g_learning_rate = <span class="number">2e-4</span></div><div class="line"><span class="comment"># optim_betas = (0.9, 0.999)</span></div><div class="line">num_epochs = <span class="number">30000</span></div><div class="line">print_interval = <span class="number">200</span></div><div class="line"><span class="comment"># d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator</span></div><div class="line">d_steps = <span class="number">5</span></div><div class="line">g_steps = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># ### Uncomment only one of these</span></div><div class="line"><span class="comment">#(name, preprocess, d_input_func) = ("Raw data", lambda data: data, lambda x: x)</span></div><div class="line">(name, preprocess, d_input_func) = (<span class="string">"Data and variances"</span>, <span class="keyword">lambda</span> data: decorate_with_diffs(data, <span class="number">2.0</span>), <span class="keyword">lambda</span> x: x * <span class="number">2</span>)</div><div class="line"></div><div class="line">print(<span class="string">"Using data [%s]"</span> % (name))</div><div class="line"></div><div class="line"><span class="comment"># ##### DATA: Target data and generator input data</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_distribution_sampler</span><span class="params">(mu, sigma)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> n: torch.Tensor(np.random.normal(mu, sigma, (<span class="number">1</span>, n)))  <span class="comment"># Gaussian</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_generator_input_sampler</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> m, n: torch.rand(m, n)  <span class="comment"># Uniform-dist data into generator, _NOT_ Gaussian</span></div><div class="line"></div><div class="line"><span class="comment"># ##### MODELS: Generator model and discriminator model</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Generator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.sigmoid(self.map2(x))</div><div class="line">        <span class="keyword">return</span> self.map3(x)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Discriminator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.elu(self.map2(x))</div><div class="line">        <span class="comment"># return F.sigmoid(self.map3(x))</span></div><div class="line">        <span class="keyword">return</span> self.map3(x)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract</span><span class="params">(v)</span>:</span></div><div class="line">    <span class="keyword">return</span> v.data.storage().tolist()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stats</span><span class="params">(d)</span>:</span></div><div class="line">    <span class="keyword">return</span> [np.mean(d), np.std(d)]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">decorate_with_diffs</span><span class="params">(data, exponent)</span>:</span></div><div class="line">    mean = torch.mean(data.data, <span class="number">1</span>)</div><div class="line">    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[<span class="number">0</span>][<span class="number">0</span>])</div><div class="line">    diffs = torch.pow(data - Variable(mean_broadcast), exponent)</div><div class="line">    <span class="keyword">return</span> torch.cat([data, diffs], <span class="number">1</span>)</div><div class="line"></div><div class="line">d_sampler = get_distribution_sampler(data_mean, data_stddev)</div><div class="line">gi_sampler = get_generator_input_sampler()</div><div class="line">G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)</div><div class="line">D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)</div><div class="line"><span class="comment"># criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss</span></div><div class="line"><span class="comment"># d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)</span></div><div class="line"><span class="comment"># g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)</span></div><div class="line">d_optimizer = optim.RMSprop(D.parameters(), lr=d_learning_rate)</div><div class="line">g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate)</div><div class="line"></div><div class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</div><div class="line">    <span class="keyword">for</span> d_index <span class="keyword">in</span> range(d_steps):</div><div class="line">        <span class="comment"># 1. Train D on real+fake</span></div><div class="line">        D.zero_grad()</div><div class="line"></div><div class="line">        <span class="comment">#  1A: Train D on real</span></div><div class="line">        d_real_data = Variable(d_sampler(d_input_size))</div><div class="line">        d_real_decision = D(preprocess(d_real_data))</div><div class="line">        <span class="comment"># d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true</span></div><div class="line">        d_real_error = -torch.mean(d_real_decision)</div><div class="line">        d_real_error.backward() <span class="comment"># compute/store gradients, but don't change params</span></div><div class="line"></div><div class="line">        <span class="comment">#  1B: Train D on fake</span></div><div class="line">        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        d_fake_data = G(d_gen_input).detach()  <span class="comment"># detach to avoid training G on these labels</span></div><div class="line">        d_fake_decision = D(preprocess(d_fake_data.t()))</div><div class="line">        <span class="comment"># d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake</span></div><div class="line">        d_fake_error = torch.mean(d_fake_decision)</div><div class="line">        d_fake_error.backward()</div><div class="line">        d_optimizer.step()     <span class="comment"># Only optimizes D's parameters; changes based on stored gradients from backward()</span></div><div class="line">        <span class="comment"># Weight Clipping</span></div><div class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> D.parameters():</div><div class="line">        	p.data.clamp_(<span class="number">-0.01</span>, <span class="number">0.01</span>)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> g_index <span class="keyword">in</span> range(g_steps):</div><div class="line">        <span class="comment"># 2. Train G on D's response (but DO NOT train D on these labels)</span></div><div class="line">        G.zero_grad()</div><div class="line"></div><div class="line">        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        g_fake_data = G(gen_input)</div><div class="line">        dg_fake_decision = D(preprocess(g_fake_data.t()))</div><div class="line">        <span class="comment"># g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine</span></div><div class="line">        g_error = -torch.mean(dg_fake_decision)</div><div class="line"></div><div class="line">        g_error.backward()</div><div class="line">        g_optimizer.step()  <span class="comment"># Only optimizes G's parameters</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> epoch % print_interval == <span class="number">0</span>:</div><div class="line">        print(<span class="string">"%s: D: %s/%s G: %s (Real: %s, Fake: %s) "</span> % (epoch,</div><div class="line">                                                            extract(d_real_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(d_fake_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(g_error)[<span class="number">0</span>],</div><div class="line">                                                            stats(extract(d_real_data)),</div><div class="line">                                                            stats(extract(d_fake_data))))</div></pre></td></tr></table></figure><p>与<a href="https://ewanlee.github.io/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/">之前的文章</a>所做的修改仅仅只有以下几点（理论支持参考我之前转发的一篇<a href="https://ewanlee.github.io/2017/04/29/The-awesome-Wasserstein-GAN/">博文</a>）:</p><ul><li><p>判别模型最后一层直接用线型激活函数，而不是用Sigmoid函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Discriminator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.elu(self.map2(x))</div><div class="line">        <span class="comment"># return F.sigmoid(self.map3(x))</span></div><div class="line">        <span class="keyword">return</span> self.map3(x)</div></pre></td></tr></table></figure></li><li><p>生成模型与判别模型的loss函数进行修改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 生成模型</span></div><div class="line"><span class="comment"># d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true</span></div><div class="line">d_real_error = -torch.mean(d_real_decision)</div><div class="line"><span class="comment"># d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake</span></div><div class="line">d_fake_error = torch.mean(d_fake_decision)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 判别模型</span></div><div class="line"><span class="comment"># g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine</span></div><div class="line">g_error = -torch.mean(dg_fake_decision)</div></pre></td></tr></table></figure></li><li><p>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c (这里取的是0.01)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Weight Clipping</span></div><div class="line"><span class="keyword">for</span> p <span class="keyword">in</span> D.parameters():</div><div class="line">    p.data.clamp_(<span class="number">-0.01</span>, <span class="number">0.01</span>)</div></pre></td></tr></table></figure></li><li><p>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)</span></div><div class="line"><span class="comment"># g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)</span></div><div class="line">d_optimizer = optim.RMSprop(D.parameters(), lr=d_learning_rate)</div><div class="line">g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate)</div></pre></td></tr></table></figure><p>​</p></li></ul><p>实验结果如下：</p><div class="post-button text-center"><a class="btn" href="/2017/04/29/WGAN-implemented-by-PyTorch/#more" rel="contents">Read more &raquo;</a></div></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/" itemprop="url">Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-28T19:46:55+08:00">2017-04-28 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/28/Generative-Adversarial-Networks-GANs-in-50-lines-of-code-PyTorch/" class="leancloud_visitors" data-flag-title="Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p><a href="https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f" target="_blank" rel="external">Source Blog</a></p><p>PyTorch Install: <a href="http://pytorch.org/" target="_blank" rel="external">http://pytorch.org/</a></p><p>The models play two distinct (literally, <em>adversarial</em>) roles. Given some real data set <strong>R</strong>, <strong>G</strong> is the <em>generator</em>, trying to create fake data that looks just like the genuine data, while <strong>D</strong> is the <em>discriminator</em>, getting data from either the real set or <strong>G </strong>and labeling the difference. Goodfellow’s metaphor (and a fine one it is) was that <strong>G</strong> was like a team of forgers trying to match real paintings with their output, while <strong>D</strong> was the team of detectives trying to tell the difference. (Except that in this case, the forgers <strong>G</strong> never get to see the original data — only the judgments of <strong>D</strong>. They’re like <em>blind</em> forgers.)</p><p><img src="https://cdn-images-1.medium.com/max/800/1*-gFsbymY9oJUQJ-A3GTfeg.png" alt="img"></p><p>In the ideal case, both <strong>D</strong> and <strong>G</strong> would get better over time until <strong>G</strong> had essentially become a “master forger” of the genuine article and <strong>D</strong> was at a loss, “unable to differentiate between the two distributions.”</p><p>In practice, what Goodfellow had shown was that <strong>G</strong> would be able to perform a form of <em>unsupervised learning</em> on the original dataset, finding some way of representing that data in a (possibly) much lower-dimensional manner. And as Yann LeCun famously stated, <a href="https://www.facebook.com/yann.lecun/posts/10153426023477143" target="_blank" rel="external">unsupervised learning is the “cake” of true AI</a>.</p><hr><p>This powerful technique seems like it must require a <strong>metric ton</strong> of code just to get started, right? Nope. Using <a href="http://pytorch.org/" target="_blank" rel="external">PyTorch</a>, we can actually create a very simple GAN in under 50 lines of code. There are really only 5 components to think about:</p><ul><li><strong>R</strong>: The original, genuine data set</li><li><strong>I</strong>: The random noise that goes into the generator as a source of entropy</li><li><strong>G</strong>: The generator which tries to copy/mimic the original data set</li><li><strong>D</strong>: The discriminator which tries to tell apart <strong>G</strong>’s output from <strong>R</strong></li><li>The actual ‘training’ loop where we teach <strong>G</strong> to trick <strong>D</strong> and <strong>D </strong>to <em>beware</em> <strong>G</strong>.</li></ul><p><strong>1.) R</strong>: In our case, we’ll start with the simplest possible <strong>R</strong> — a bell curve. This function takes a mean and a standard deviation and returns a function which provides the right shape of sample data from a Gaussian with those parameters. In our sample code, we’ll use a mean of 4.0 and a standard deviation of 1.25.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*xsuE-nhsJOzk9lfI3rayuw.png" alt="img"></p><p><strong>2.) I</strong>: The input into the generator is also random, but to make our job a little bit harder, let’s use a uniform distribution rather than a normal one. This means that our model <strong>G</strong> can’t simply shift/scale the input to copy <strong>R, </strong>but has to reshape the data in a non-linear way.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*wuhEVnK25V3zXQzuCwFDAg.png" alt="img"></p><p><strong>3.) G</strong>: The generator is a standard feedforward graph — two hidden layers, three linear maps. We’re using an <a href="http://pytorch.org/docs/nn.html#elu" target="_blank" rel="external">ELU (exponential linear unit)</a> because<a href="https://www.linkedin.com/pulse/exponential-linear-units-elu-deep-network-learning-martin-heusel" target="_blank" rel="external">they’re the new black, yo.</a> <strong>G</strong> is going to get the uniformly distributed data samples from <strong>I</strong> and somehow mimic the normally distributed samples from <strong>R</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*NM6wfbhZLSiVnCX33f7eBw.png" alt="img"></p><p><strong>4.) D</strong>: The discriminator code is very similar to <strong>G</strong>’s generator code; a feedforward graph with two hidden layers and three linear maps. It’s going to get samples from either <strong>R</strong> or <strong>G</strong> and will output a single scalar between 0 and 1, interpreted as ‘fake’ vs. ‘real’. This is about as milquetoast as a neural net can get.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*5x9hrP5oozp3e2pm-Mtqmw.png" alt="img"></p><p><strong>5.)</strong> Finally, the training loop alternates between two modes: first training <strong>D</strong> on real data vs. fake data, with <em>accurate</em> labels (think of this as <a href="https://en.wikipedia.org/wiki/Police_Academy_%28film%29" target="_blank" rel="external">Police Academy</a>); and then training <strong>G</strong> to fool <strong>D</strong>, with <em>inaccurate</em> labels (this is more like those preparation montages from <a href="https://en.wikipedia.org/wiki/Ocean%27s_Eleven" target="_blank" rel="external">Ocean’s Eleven</a>). It’s a fight between good and evil, people.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*MESLBNZIWxJp553TWKUADQ.png" alt="img"></p><p>Even if you haven’t seen PyTorch before, you can probably tell what’s going on. In the first (green) section, we push both types of data through <strong>D</strong> and apply a differentiable criterion to <strong>D</strong>’s guesses vs. the actual labels. That pushing is the ‘forward’ step; we then call ‘backward()’ explicitly in order to calculate gradients, which are then used to update <strong>D</strong>’s parameters in the d_optimizer step() call. <strong>G</strong> is used but isn’t trained here.</p><p>Then in the last (red) section, we do the same thing for <strong>G</strong> — note that we also run <strong>G</strong>’s output through <strong>D</strong> (we’re essentially giving the forger a detective to practice on) but we <em>do not optimize or change</em> <strong>D</strong> at this step. We don’t want the detective <strong>D</strong> to learn the wrong labels. Hence, we only call g_optimizer.step().</p><p>And…<em>that’s all</em>. There’s some other boilerplate code but the GAN-specific stuff is just those 5 components, nothing else.</p><hr><p>After a few thousand rounds of this forbidden dance between <strong>D</strong> and <strong>G</strong>, what do we get? The discriminator <strong>D</strong> gets good very quickly (while <strong>G</strong> slowly moves up), but once it gets to a certain level of power, <strong>G</strong> has a worthy adversary and begins to improve. <em>Really</em> improve.</p><p>Over 20,000 training rounds, the mean of <strong>G</strong>’s output overshoots 4.0 but then comes back in a fairly stable, correct range (left). Likewise, the standard deviation initially drops in the wrong direction but then rises up to the desired 1.25 range (right), matching <strong>R</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*2Qm33RqWBKVF3g1Vg2HnVg.png" alt="img"></p><p>Ok, so the basic stats match <strong>R</strong>, eventually. How about the higher moments? Does the shape of the distribution look right? After all, you could certainly have a uniform distribution with a mean of 4.0 and a standard deviation of 1.25, but that wouldn’t really match <strong>R</strong>. Let’s show the final distribution emitted by <strong>G</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*Ary_6gaLxIijk7j2trroBQ.png" alt="img"></p><p>Not bad. The left tail is a bit longer than the right, but the skew and kurtosis are, shall we say, <em>evocative</em> of the original Gaussian.</p><p><strong>G</strong> recovers the original distribution <strong>R</strong> nearly perfectly — and <strong>D</strong> is left cowering in the corner, mumbling to itself, unable to tell fact from fiction. This is <em>precisely</em> the behavior we want (see <a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank" rel="external">Figure 1 in Goodfellow</a>). <strong>From fewer than 50 lines of code</strong>.</p><p>Goodfellow would go on to publish many other papers on GANs, including a <a href="https://arxiv.org/pdf/1606.03498.pdf" target="_blank" rel="external">2016 gem describing some practical improvements</a>, including the minibatch discrimination method adapted here. And <a href="https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks" target="_blank" rel="external">here’s a 2-hour tutorial he presented at NIPS 2016</a>. For TensorFlow users, here’s a parallel <a href="http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/" target="_blank" rel="external">post from Aylien on GANs</a>.</p><p>Ok. Enough talk. <a href="https://github.com/devnag/pytorch-generative-adversarial-networks" target="_blank" rel="external"><strong>Go look at the code</strong></a>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="comment"># Generative Adversarial Networks (GAN) example in PyTorch.</span></div><div class="line"><span class="comment"># See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> torch</div><div class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div><div class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</div><div class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</div><div class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</div><div class="line"></div><div class="line"><span class="comment"># Data params</span></div><div class="line">data_mean = <span class="number">4</span></div><div class="line">data_stddev = <span class="number">1.25</span></div><div class="line"></div><div class="line"><span class="comment"># Model params</span></div><div class="line">g_input_size = <span class="number">1</span>     <span class="comment"># Random noise dimension coming into generator, per output vector</span></div><div class="line">g_hidden_size = <span class="number">50</span>   <span class="comment"># Generator complexity</span></div><div class="line">g_output_size = <span class="number">1</span>    <span class="comment"># size of generated output vector</span></div><div class="line">d_input_size = <span class="number">100</span>   <span class="comment"># Minibatch size - cardinality of distributions</span></div><div class="line">d_hidden_size = <span class="number">50</span>   <span class="comment"># Discriminator complexity</span></div><div class="line">d_output_size = <span class="number">1</span>    <span class="comment"># Single dimension for 'real' vs. 'fake'</span></div><div class="line">minibatch_size = d_input_size</div><div class="line"></div><div class="line">d_learning_rate = <span class="number">2e-4</span>  <span class="comment"># 2e-4</span></div><div class="line">g_learning_rate = <span class="number">2e-4</span></div><div class="line">optim_betas = (<span class="number">0.9</span>, <span class="number">0.999</span>)</div><div class="line">num_epochs = <span class="number">30000</span></div><div class="line">print_interval = <span class="number">200</span></div><div class="line">d_steps = <span class="number">1</span>  <span class="comment"># 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator</span></div><div class="line">g_steps = <span class="number">1</span></div><div class="line"></div><div class="line"><span class="comment"># ### Uncomment only one of these</span></div><div class="line"><span class="comment">#(name, preprocess, d_input_func) = ("Raw data", lambda data: data, lambda x: x)</span></div><div class="line">(name, preprocess, d_input_func) = (<span class="string">"Data and variances"</span>, <span class="keyword">lambda</span> data: decorate_with_diffs(data, <span class="number">2.0</span>), <span class="keyword">lambda</span> x: x * <span class="number">2</span>)</div><div class="line"></div><div class="line">print(<span class="string">"Using data [%s]"</span> % (name))</div><div class="line"></div><div class="line"><span class="comment"># ##### DATA: Target data and generator input data</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_distribution_sampler</span><span class="params">(mu, sigma)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> n: torch.Tensor(np.random.normal(mu, sigma, (<span class="number">1</span>, n)))  <span class="comment"># Gaussian</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_generator_input_sampler</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="keyword">lambda</span> m, n: torch.rand(m, n)  <span class="comment"># Uniform-dist data into generator, _NOT_ Gaussian</span></div><div class="line"></div><div class="line"><span class="comment"># ##### MODELS: Generator model and discriminator model</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Generator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.sigmoid(self.map2(x))</div><div class="line">        <span class="keyword">return</span> self.map3(x)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_size, output_size)</span>:</span></div><div class="line">        super(Discriminator, self).__init__()</div><div class="line">        self.map1 = nn.Linear(input_size, hidden_size)</div><div class="line">        self.map2 = nn.Linear(hidden_size, hidden_size)</div><div class="line">        self.map3 = nn.Linear(hidden_size, output_size)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = F.elu(self.map1(x))</div><div class="line">        x = F.elu(self.map2(x))</div><div class="line">        <span class="keyword">return</span> F.sigmoid(self.map3(x))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract</span><span class="params">(v)</span>:</span></div><div class="line">    <span class="keyword">return</span> v.data.storage().tolist()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stats</span><span class="params">(d)</span>:</span></div><div class="line">    <span class="keyword">return</span> [np.mean(d), np.std(d)]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">decorate_with_diffs</span><span class="params">(data, exponent)</span>:</span></div><div class="line">    mean = torch.mean(data.data, <span class="number">1</span>)</div><div class="line">    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[<span class="number">0</span>][<span class="number">0</span>])</div><div class="line">    diffs = torch.pow(data - Variable(mean_broadcast), exponent)</div><div class="line">    <span class="keyword">return</span> torch.cat([data, diffs], <span class="number">1</span>)</div><div class="line"></div><div class="line">d_sampler = get_distribution_sampler(data_mean, data_stddev)</div><div class="line">gi_sampler = get_generator_input_sampler()</div><div class="line">G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)</div><div class="line">D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)</div><div class="line">criterion = nn.BCELoss()  <span class="comment"># Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss</span></div><div class="line">d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)</div><div class="line">g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)</div><div class="line"></div><div class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</div><div class="line">    <span class="keyword">for</span> d_index <span class="keyword">in</span> range(d_steps):</div><div class="line">        <span class="comment"># 1. Train D on real+fake</span></div><div class="line">        D.zero_grad()</div><div class="line"></div><div class="line">        <span class="comment">#  1A: Train D on real</span></div><div class="line">        d_real_data = Variable(d_sampler(d_input_size))</div><div class="line">        d_real_decision = D(preprocess(d_real_data))</div><div class="line">        d_real_error = criterion(d_real_decision, Variable(torch.ones(<span class="number">1</span>)))  <span class="comment"># ones = true</span></div><div class="line">        d_real_error.backward() <span class="comment"># compute/store gradients, but don't change params</span></div><div class="line"></div><div class="line">        <span class="comment">#  1B: Train D on fake</span></div><div class="line">        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        d_fake_data = G(d_gen_input).detach()  <span class="comment"># detach to avoid training G on these labels</span></div><div class="line">        d_fake_decision = D(preprocess(d_fake_data.t()))</div><div class="line">        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(<span class="number">1</span>)))  <span class="comment"># zeros = fake</span></div><div class="line">        d_fake_error.backward()</div><div class="line">        d_optimizer.step()     <span class="comment"># Only optimizes D's parameters; changes based on stored gradients from backward()</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> g_index <span class="keyword">in</span> range(g_steps):</div><div class="line">        <span class="comment"># 2. Train G on D's response (but DO NOT train D on these labels)</span></div><div class="line">        G.zero_grad()</div><div class="line"></div><div class="line">        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))</div><div class="line">        g_fake_data = G(gen_input)</div><div class="line">        dg_fake_decision = D(preprocess(g_fake_data.t()))</div><div class="line">        g_error = criterion(dg_fake_decision, Variable(torch.ones(<span class="number">1</span>)))  <span class="comment"># we want to fool, so pretend it's all genuine</span></div><div class="line"></div><div class="line">        g_error.backward()</div><div class="line">        g_optimizer.step()  <span class="comment"># Only optimizes G's parameters</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> epoch % print_interval == <span class="number">0</span>:</div><div class="line">        print(<span class="string">"%s: D: %s/%s G: %s (Real: %s, Fake: %s) "</span> % (epoch,</div><div class="line">                                                            extract(d_real_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(d_fake_error)[<span class="number">0</span>],</div><div class="line">                                                            extract(g_error)[<span class="number">0</span>],</div><div class="line">                                                            stats(extract(d_real_data)),</div><div class="line">                                                            stats(extract(d_fake_data))))</div></pre></td></tr></table></figure><p>Result：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div></pre></td><td class="code"><pre><div class="line">ewan<span class="meta">@ubuntu</span>:~<span class="regexp">/Documents/g</span>an/pytorch-generative-adversarial-networks$ python gan_pytorch.py </div><div class="line">Using data [Data and variances]</div><div class="line"><span class="number">0</span>: D: <span class="number">0.636019647121</span>/<span class="number">0.687892377377</span> G: <span class="number">0.692580163479</span> (Real: [<span class="number">4.0121619534492492</span>, <span class="number">1.3228379995364423</span>], Fake: [<span class="number">0.36497069358825684</span>, <span class="number">0.0040907625909989871</span>]) </div><div class="line"><span class="number">200</span>: D: <span class="number">2.92067015835e-05</span>/<span class="number">0.474851727486</span> G: <span class="number">1.00973010063</span> (Real: [<span class="number">4.0935744738578794</span>, <span class="number">1.3016500752040552</span>], Fake: [<span class="number">-0.5716635638475418</span>, <span class="number">0.019948046232028654</span>]) </div><div class="line"><span class="number">400</span>: D: <span class="number">0.0014917049557</span>/<span class="number">0.502498149872</span> G: <span class="number">0.943185687065</span> (Real: [<span class="number">4.198446000814438</span>, <span class="number">1.1262929992527102</span>], Fake: [<span class="number">-0.21786054879426955</span>, <span class="number">0.0067362612730766476</span>]) </div><div class="line"><span class="number">600</span>: D: <span class="number">6.4969262894e-06</span>/<span class="number">0.384293109179</span> G: <span class="number">1.15257537365</span> (Real: [<span class="number">3.8602226501703263</span>, <span class="number">1.3292726136430937</span>], Fake: [<span class="number">-0.29857088595628739</span>, <span class="number">0.03924369275813562</span>]) </div><div class="line"><span class="number">800</span>: D: <span class="number">1.84774467016e-06</span>/<span class="number">0.211148008704</span> G: <span class="number">1.67116880417</span> (Real: [<span class="number">4.0269100540876392</span>, <span class="number">1.2954351206409835</span>], Fake: [<span class="number">-0.32296697288751602</span>, <span class="number">0.14901211840131676</span>]) </div><div class="line"><span class="number">1000</span>: D: <span class="number">9.02455067262e-05</span>/<span class="number">0.0219078511</span> G: <span class="number">4.19585323334</span> (Real: [<span class="number">3.9491306754946707</span>, <span class="number">1.3613105655283608</span>], Fake: [<span class="number">0.13110455054789782</span>, <span class="number">0.5252103421913964</span>]) </div><div class="line"><span class="number">1200</span>: D: <span class="number">0.00441630883142</span>/<span class="number">0.137605398893</span> G: <span class="number">2.78980493546</span> (Real: [<span class="number">4.238747425079346</span>, <span class="number">1.1837142728845262</span>], Fake: [<span class="number">2.3851456820964811</span>, <span class="number">0.69947230698573948</span>]) </div><div class="line"><span class="number">1400</span>: D: <span class="number">0.291683584452</span>/<span class="number">0.824121117592</span> G: <span class="number">0.26126781106</span> (Real: [<span class="number">3.8486315739154815</span>, <span class="number">1.2074486225815622</span>], Fake: [<span class="number">3.4868409335613251</span>, <span class="number">1.2438192602257458</span>]) </div><div class="line"><span class="number">1600</span>: D: <span class="number">0.503275632858</span>/<span class="number">1.08712184429</span> G: <span class="number">0.628099560738</span> (Real: [<span class="number">3.7856648898124696</span>, <span class="number">1.1925325100947208</span>], Fake: [<span class="number">3.9149187129735945</span>, <span class="number">1.5374543372663099</span>]) </div><div class="line"><span class="number">1800</span>: D: <span class="number">0.992162883282</span>/<span class="number">0.955306172371</span> G: <span class="number">0.215137541294</span> (Real: [<span class="number">3.9097139459848402</span>, <span class="number">1.3729001379532129</span>], Fake: [<span class="number">4.9751595187187192</span>, <span class="number">1.2850838287273094</span>]) </div><div class="line"><span class="number">2000</span>: D: <span class="number">0.701098382473</span>/<span class="number">0.634775817394</span> G: <span class="number">0.389043629169</span> (Real: [<span class="number">3.9641699814796447</span>, <span class="number">1.1512756986625183</span>], Fake: [<span class="number">5.0374661159515384</span>, <span class="number">1.5190411587235346</span>]) </div><div class="line"><span class="number">2200</span>: D: <span class="number">0.510353624821</span>/<span class="number">0.350295126438</span> G: <span class="number">1.5988701582</span> (Real: [<span class="number">4.0406568145751951</span>, <span class="number">1.3612318676859239</span>], Fake: [<span class="number">5.4763065743446351</span>, <span class="number">1.2736378899688456</span>]) </div><div class="line"><span class="number">2400</span>: D: <span class="number">0.895085930824</span>/<span class="number">0.400622785091</span> G: <span class="number">0.922062814236</span> (Real: [<span class="number">3.8292097043991089</span>, <span class="number">1.1506111704583193</span>], Fake: [<span class="number">4.5642045128345492</span>, <span class="number">1.7082890861364539</span>]) </div><div class="line"><span class="number">2600</span>: D: <span class="number">0.802581310272</span>/<span class="number">0.717123866081</span> G: <span class="number">0.572393655777</span> (Real: [<span class="number">4.0654918360710148</span>, <span class="number">1.2552944260604222</span>], Fake: [<span class="number">5.1286249160766602</span>, <span class="number">1.0479449058428656</span>]) </div><div class="line"><span class="number">2800</span>: D: <span class="number">0.51098883152</span>/<span class="number">0.489002883434</span> G: <span class="number">0.842381119728</span> (Real: [<span class="number">4.0405197954177856</span>, <span class="number">1.136660175398452</span>], Fake: [<span class="number">3.9549839448928834</span>, <span class="number">1.1751749984899784</span>]) </div><div class="line"><span class="number">3000</span>: D: <span class="number">0.496278882027</span>/<span class="number">0.97537201643</span> G: <span class="number">0.753688693047</span> (Real: [<span class="number">4.0026307255029678</span>, <span class="number">1.2446167315972034</span>], Fake: [<span class="number">3.2340782660245897</span>, <span class="number">1.2949288892421307</span>]) </div><div class="line"><span class="number">3200</span>: D: <span class="number">0.696556508541</span>/<span class="number">0.829834342003</span> G: <span class="number">0.475445389748</span> (Real: [<span class="number">3.9983750417828561</span>, <span class="number">1.2828095340103229</span>], Fake: [<span class="number">3.5434492731094362</span>, <span class="number">0.98673911467128028</span>]) </div><div class="line"><span class="number">3400</span>: D: <span class="number">0.479906737804</span>/<span class="number">0.477254271507</span> G: <span class="number">1.2421528101</span> (Real: [<span class="number">4.1585888534784319</span>, <span class="number">1.2672863214247221</span>], Fake: [<span class="number">3.3173918831348419</span>, <span class="number">1.156708995162234</span>]) </div><div class="line"><span class="number">3600</span>: D: <span class="number">1.36562228203</span>/<span class="number">0.508370876312</span> G: <span class="number">0.550418972969</span> (Real: [<span class="number">4.0406067597866056</span>, <span class="number">1.1363201759386616</span>], Fake: [<span class="number">4.4300824308395388</span>, <span class="number">1.0639278538481793</span>]) </div><div class="line"><span class="number">3800</span>: D: <span class="number">0.538426816463</span>/<span class="number">0.622343420982</span> G: <span class="number">0.786149024963</span> (Real: [<span class="number">4.0097330248355867</span>, <span class="number">1.1609232820569348</span>], Fake: [<span class="number">4.5179304122924808</span>, <span class="number">1.2347411732817635</span>]) </div><div class="line"><span class="number">4000</span>: D: <span class="number">0.350504934788</span>/<span class="number">0.361344873905</span> G: <span class="number">0.728424191475</span> (Real: [<span class="number">3.7975878280401232</span>, <span class="number">1.2378775025626094</span>], Fake: [<span class="number">4.3484812033176423</span>, <span class="number">1.4327683271077338</span>]) </div><div class="line"><span class="number">4200</span>: D: <span class="number">0.912463009357</span>/<span class="number">0.779066801071</span> G: <span class="number">0.840294659138</span> (Real: [<span class="number">3.9861780107021332</span>, <span class="number">1.2293009498211762</span>], Fake: [<span class="number">4.0718169224262235</span>, <span class="number">1.2044778720046834</span>]) </div><div class="line"><span class="number">4400</span>: D: <span class="number">0.814347147942</span>/<span class="number">0.794115483761</span> G: <span class="number">0.889387726784</span> (Real: [<span class="number">3.9556436133384705</span>, <span class="number">1.1131208050960595</span>], Fake: [<span class="number">3.6148070895671847</span>, <span class="number">1.1790021094109027</span>]) </div><div class="line"><span class="number">4600</span>: D: <span class="number">0.637132883072</span>/<span class="number">0.639598190784</span> G: <span class="number">0.835896074772</span> (Real: [<span class="number">4.0807307386398319</span>, <span class="number">1.1590112689981971</span>], Fake: [<span class="number">3.6376679444313051</span>, <span class="number">1.2540016088688517</span>]) </div><div class="line"><span class="number">4800</span>: D: <span class="number">0.816388785839</span>/<span class="number">0.629823803902</span> G: <span class="number">0.6337043643</span> (Real: [<span class="number">4.1595975148677828</span>, <span class="number">1.2996693029809485</span>], Fake: [<span class="number">4.0303308999538423</span>, <span class="number">1.3050560562935769</span>]) </div><div class="line"><span class="number">5000</span>: D: <span class="number">1.38226401806</span>/<span class="number">0.714248239994</span> G: <span class="number">1.17240273952</span> (Real: [<span class="number">3.9217003214359285</span>, <span class="number">1.3408209709046912</span>], Fake: [<span class="number">4.4204820060729979</span>, <span class="number">1.0378887480226417</span>]) </div><div class="line"><span class="number">5200</span>: D: <span class="number">0.752707779408</span>/<span class="number">0.432243227959</span> G: <span class="number">0.735915839672</span> (Real: [<span class="number">4.033863249272108</span>, <span class="number">1.417255801501303</span>], Fake: [<span class="number">3.7434970003366472</span>, <span class="number">1.4305561672741818</span>]) </div><div class="line"><span class="number">5400</span>: D: <span class="number">0.672449588776</span>/<span class="number">0.694190680981</span> G: <span class="number">0.671269893646</span> (Real: [<span class="number">3.9849637061357499</span>, <span class="number">1.3054745436415693</span>], Fake: [<span class="number">3.7987613070011137</span>, <span class="number">1.1584021967574571</span>]) </div><div class="line"><span class="number">5600</span>: D: <span class="number">0.633513212204</span>/<span class="number">0.678804934025</span> G: <span class="number">0.736048042774</span> (Real: [<span class="number">3.8742538380622862</span>, <span class="number">1.1924929483627851</span>], Fake: [<span class="number">4.0905960440635685</span>, <span class="number">1.0496450658176097</span>]) </div><div class="line"><span class="number">5800</span>: D: <span class="number">0.954816102982</span>/<span class="number">0.619474828243</span> G: <span class="number">0.847522497177</span> (Real: [<span class="number">4.0848416697978971</span>, <span class="number">1.2377045321962332</span>], Fake: [<span class="number">4.5059887909889218</span>, <span class="number">1.0769809353783582</span>]) </div><div class="line"><span class="number">6000</span>: D: <span class="number">0.634225904942</span>/<span class="number">0.653471052647</span> G: <span class="number">0.402414888144</span> (Real: [<span class="number">3.9909452509880068</span>, <span class="number">1.2152347623325401</span>], Fake: [<span class="number">3.9412865948677065</span>, <span class="number">1.2808620107297906</span>]) </div><div class="line"><span class="number">6200</span>: D: <span class="number">0.733776032925</span>/<span class="number">0.414616316557</span> G: <span class="number">0.969770550728</span> (Real: [<span class="number">4.0096452310681343</span>, <span class="number">1.2858629342885464</span>], Fake: [<span class="number">3.4776910370588303</span>, <span class="number">1.4216167469252254</span>]) </div><div class="line"><span class="number">6400</span>: D: <span class="number">0.483776688576</span>/<span class="number">0.456314682961</span> G: <span class="number">0.42595911026</span> (Real: [<span class="number">4.16927042722702</span>, <span class="number">1.2557057135387499</span>], Fake: [<span class="number">3.905275868177414</span>, <span class="number">1.3509040440658031</span>]) </div><div class="line"><span class="number">6600</span>: D: <span class="number">1.06177055836</span>/<span class="number">0.443961560726</span> G: <span class="number">0.910483181477</span> (Real: [<span class="number">4.0327691116929056</span>, <span class="number">1.1752792712434861</span>], Fake: [<span class="number">4.1322225379943847</span>, <span class="number">1.3041032842304898</span>]) </div><div class="line"><span class="number">6800</span>: D: <span class="number">0.911615252495</span>/<span class="number">0.851063728333</span> G: <span class="number">0.822307884693</span> (Real: [<span class="number">4.0429812586307525</span>, <span class="number">1.0149434426406105</span>], Fake: [<span class="number">4.181604235172272</span>, <span class="number">1.1091966315801844</span>]) </div><div class="line"><span class="number">7000</span>: D: <span class="number">0.859644412994</span>/<span class="number">0.819373309612</span> G: <span class="number">0.683367550373</span> (Real: [<span class="number">4.0413902151584624</span>, <span class="number">1.2697299173474621</span>], Fake: [<span class="number">3.6461249232292174</span>, <span class="number">1.1392232969008105</span>]) </div><div class="line"><span class="number">7200</span>: D: <span class="number">0.697537004948</span>/<span class="number">1.29639554024</span> G: <span class="number">0.567749083042</span> (Real: [<span class="number">3.9289280462265013</span>, <span class="number">1.1476723124689931</span>], Fake: [<span class="number">4.3612218284606934</span>, <span class="number">1.1698644305174593</span>]) </div><div class="line"><span class="number">7400</span>: D: <span class="number">0.892510712147</span>/<span class="number">0.93148213625</span> G: <span class="number">1.18729686737</span> (Real: [<span class="number">3.9838603484630584</span>, <span class="number">1.10640478112829</span>], Fake: [<span class="number">4.1228645443916321</span>, <span class="number">1.2695625804586594</span>]) </div><div class="line"><span class="number">7600</span>: D: <span class="number">0.855136275291</span>/<span class="number">0.683420717716</span> G: <span class="number">0.87994658947</span> (Real: [<span class="number">4.1161885654926298</span>, <span class="number">1.1923004904972447</span>], Fake: [<span class="number">3.6958885985612868</span>, <span class="number">1.3379389180110717</span>]) </div><div class="line"><span class="number">7800</span>: D: <span class="number">0.549697399139</span>/<span class="number">1.37823116779</span> G: <span class="number">0.398991644382</span> (Real: [<span class="number">4.2173074555397037</span>, <span class="number">1.2371073094023581</span>], Fake: [<span class="number">3.8741448554396629</span>, <span class="number">1.3837623378110455</span>]) </div><div class="line"><span class="number">8000</span>: D: <span class="number">1.35398185253</span>/<span class="number">0.410179078579</span> G: <span class="number">0.527717351913</span> (Real: [<span class="number">3.9588229835033415</span>, <span class="number">1.3744496473744439</span>], Fake: [<span class="number">3.9429207968711855</span>, <span class="number">1.3684983506717674</span>]) </div><div class="line"><span class="number">8200</span>: D: <span class="number">0.700774013996</span>/<span class="number">0.295857429504</span> G: <span class="number">0.803082704544</span> (Real: [<span class="number">3.8515358114242555</span>, <span class="number">1.2566173136350174</span>], Fake: [<span class="number">3.7108538401126863</span>, <span class="number">1.3342916614304938</span>]) </div><div class="line"><span class="number">8400</span>: D: <span class="number">0.689352571964</span>/<span class="number">0.590398311615</span> G: <span class="number">0.698961615562</span> (Real: [<span class="number">3.965521250963211</span>, <span class="number">1.2231963456729893</span>], Fake: [<span class="number">4.6866454958915709</span>, <span class="number">1.1286615282559416</span>]) </div><div class="line"><span class="number">8600</span>: D: <span class="number">0.19632807374</span>/<span class="number">0.604559898376</span> G: <span class="number">0.812706291676</span> (Real: [<span class="number">3.8928249645233155</span>, <span class="number">1.3264703109197318</span>], Fake: [<span class="number">3.918080286383629</span>, <span class="number">1.2016505045193488</span>]) </div><div class="line"><span class="number">8800</span>: D: <span class="number">0.595732450485</span>/<span class="number">0.572122216225</span> G: <span class="number">0.738678693771</span> (Real: [<span class="number">3.7554583859443667</span>, <span class="number">1.2011572644775179</span>], Fake: [<span class="number">3.8252914756536485</span>, <span class="number">1.1905187885079342</span>]) </div><div class="line"><span class="number">9000</span>: D: <span class="number">0.232542961836</span>/<span class="number">1.26930451393</span> G: <span class="number">0.834500789642</span> (Real: [<span class="number">3.9203160056471824</span>, <span class="number">1.2725988502730134</span>], Fake: [<span class="number">4.1613124001026156</span>, <span class="number">1.2681795442466237</span>]) </div><div class="line"><span class="number">9200</span>: D: <span class="number">1.257376194</span>/<span class="number">0.5735257864</span> G: <span class="number">0.554405272007</span> (Real: [<span class="number">3.8860677522420883</span>, <span class="number">1.1041807259307903</span>], Fake: [<span class="number">3.9102136331796644</span>, <span class="number">1.3811967247690093</span>]) </div><div class="line"><span class="number">9400</span>: D: <span class="number">0.610212028027</span>/<span class="number">0.538761377335</span> G: <span class="number">0.558459818363</span> (Real: [<span class="number">4.0015355503559116</span>, <span class="number">0.99711450973270277</span>], Fake: [<span class="number">3.8555663478374482</span>, <span class="number">1.1037480705144518</span>]) </div><div class="line"><span class="number">9600</span>: D: <span class="number">0.702151358128</span>/<span class="number">0.81621837616</span> G: <span class="number">0.706716835499</span> (Real: [<span class="number">4.0513852632045744</span>, <span class="number">1.1984303669025829</span>], Fake: [<span class="number">4.2933621263504032</span>, <span class="number">1.1478353305254103</span>]) </div><div class="line"><span class="number">9800</span>: D: <span class="number">0.511451423168</span>/<span class="number">0.670217812061</span> G: <span class="number">0.873916983604</span> (Real: [<span class="number">3.935146123766899</span>, <span class="number">1.3218541944694313</span>], Fake: [<span class="number">4.2863738107681275</span>, <span class="number">1.1362357473661524</span>]) </div><div class="line"><span class="number">10000</span>: D: <span class="number">0.587130308151</span>/<span class="number">0.764386773109</span> G: <span class="number">0.714644312859</span> (Real: [<span class="number">4.0829932641983033</span>, <span class="number">1.1844677307174318</span>], Fake: [<span class="number">4.2149634605646131</span>, <span class="number">1.1542778585504672</span>]) </div><div class="line"><span class="number">10200</span>: D: <span class="number">0.454408079386</span>/<span class="number">0.390097141266</span> G: <span class="number">0.694087386131</span> (Real: [<span class="number">3.9480907583236693</span>, <span class="number">1.2586832917742197</span>], Fake: [<span class="number">3.9525690937042235</span>, <span class="number">1.3555640918653922</span>]) </div><div class="line"><span class="number">10400</span>: D: <span class="number">0.232991695404</span>/<span class="number">0.377689123154</span> G: <span class="number">0.839949011803</span> (Real: [<span class="number">3.9636431083083155</span>, <span class="number">1.2146210496905581</span>], Fake: [<span class="number">4.0022356742620468</span>, <span class="number">1.0348462356745984</span>]) </div><div class="line"><span class="number">10600</span>: D: <span class="number">0.887756228447</span>/<span class="number">0.452646583319</span> G: <span class="number">0.776298880577</span> (Real: [<span class="number">4.1107078218460087</span>, <span class="number">1.3061081296488184</span>], Fake: [<span class="number">4.3001403945684435</span>, <span class="number">1.3191353715419794</span>]) </div><div class="line"><span class="number">10800</span>: D: <span class="number">0.988030552864</span>/<span class="number">0.472889751196</span> G: <span class="number">2.00703763962</span> (Real: [<span class="number">4.1303015506267551</span>, <span class="number">1.2646447231333668</span>], Fake: [<span class="number">4.2425211107730867</span>, <span class="number">1.2706986066792705</span>]) </div><div class="line"><span class="number">11000</span>: D: <span class="number">0.962553679943</span>/<span class="number">1.00584948063</span> G: <span class="number">0.458068579435</span> (Real: [<span class="number">4.1017441129684444</span>, <span class="number">1.1564779436003478</span>], Fake: [<span class="number">3.861787896156311</span>, <span class="number">1.2478181443952361</span>]) </div><div class="line"><span class="number">11200</span>: D: <span class="number">0.404395908117</span>/<span class="number">0.560545325279</span> G: <span class="number">0.764987766743</span> (Real: [<span class="number">3.8819530367851258</span>, <span class="number">1.1290593525971337</span>], Fake: [<span class="number">4.0393019503355028</span>, <span class="number">1.1760851438968263</span>]) </div><div class="line"><span class="number">11400</span>: D: <span class="number">1.04482722282</span>/<span class="number">0.170368790627</span> G: <span class="number">0.979512214661</span> (Real: [<span class="number">4.0775347077846531</span>, <span class="number">1.1743573984958275</span>], Fake: [<span class="number">4.4076948529481887</span>, <span class="number">1.1430737801156545</span>]) </div><div class="line"><span class="number">11600</span>: D: <span class="number">0.767144262791</span>/<span class="number">0.419019073248</span> G: <span class="number">0.804197788239</span> (Real: [<span class="number">4.1507718646526337</span>, <span class="number">1.2935215526943189</span>], Fake: [<span class="number">4.2565110635757444</span>, <span class="number">1.1195747875890809</span>]) </div><div class="line"><span class="number">11800</span>: D: <span class="number">0.328228145838</span>/<span class="number">0.192100420594</span> G: <span class="number">0.694948136806</span> (Real: [<span class="number">4.2615561389923098</span>, <span class="number">1.3187283101366121</span>], Fake: [<span class="number">3.7841238260269163</span>, <span class="number">1.2796545407667934</span>]) </div><div class="line"><span class="number">12000</span>: D: <span class="number">0.939581632614</span>/<span class="number">0.512252509594</span> G: <span class="number">0.486280798912</span> (Real: [<span class="number">4.1770594882965089</span>, <span class="number">1.2492834466325793</span>], Fake: [<span class="number">4.0997331076860428</span>, <span class="number">1.0701209918243111</span>]) </div><div class="line"><span class="number">12200</span>: D: <span class="number">0.964525461197</span>/<span class="number">0.397465586662</span> G: <span class="number">1.45534229279</span> (Real: [<span class="number">3.9129967219382524</span>, <span class="number">1.3473476671217695</span>], Fake: [<span class="number">4.3561846733093263</span>, <span class="number">1.1667221650406194</span>]) </div><div class="line"><span class="number">12400</span>: D: <span class="number">0.516430974007</span>/<span class="number">0.255626231432</span> G: <span class="number">0.753806650639</span> (Real: [<span class="number">3.9942912605404852</span>, <span class="number">1.3623400447216258</span>], Fake: [<span class="number">4.2171517282724382</span>, <span class="number">1.2046534326031684</span>]) </div><div class="line"><span class="number">12600</span>: D: <span class="number">0.050210531801</span>/<span class="number">0.567070662975</span> G: <span class="number">0.887824892998</span> (Real: [<span class="number">3.9560802054405211</span>, <span class="number">1.3569670682588555</span>], Fake: [<span class="number">3.6434229278564452</span>, <span class="number">1.2798963544271591</span>]) </div><div class="line"><span class="number">12800</span>: D: <span class="number">0.566556215286</span>/<span class="number">1.45121753216</span> G: <span class="number">2.67591071129</span> (Real: [<span class="number">4.0868541407585148</span>, <span class="number">1.1440918337515926</span>], Fake: [<span class="number">3.7308121472597122</span>, <span class="number">1.2567484994327229</span>]) </div><div class="line"><span class="number">13000</span>: D: <span class="number">0.285438686609</span>/<span class="number">1.26493763924</span> G: <span class="number">0.714931368828</span> (Real: [<span class="number">4.0406689298152925</span>, <span class="number">1.2295255598171184</span>], Fake: [<span class="number">4.1976348906755447</span>, <span class="number">1.2778464434389283</span>]) </div><div class="line"><span class="number">13200</span>: D: <span class="number">0.420082330704</span>/<span class="number">0.20268279314</span> G: <span class="number">1.13221895695</span> (Real: [<span class="number">4.0006502330303189</span>, <span class="number">1.1790149224725006</span>], Fake: [<span class="number">4.2336275362968445</span>, <span class="number">1.2803975596845565</span>]) </div><div class="line"><span class="number">13400</span>: D: <span class="number">0.219869300723</span>/<span class="number">0.733704686165</span> G: <span class="number">1.4634616375</span> (Real: [<span class="number">3.8348834168910981</span>, <span class="number">1.240605849665303</span>], Fake: [<span class="number">3.8208065938949587</span>, <span class="number">1.3042463825727604</span>]) </div><div class="line"><span class="number">13600</span>: D: <span class="number">1.35286784172</span>/<span class="number">0.161317944527</span> G: <span class="number">2.29795908928</span> (Real: [<span class="number">4.0841373348236081</span>, <span class="number">1.2295542819596996</span>], Fake: [<span class="number">4.0513113558292391</span>, <span class="number">1.2789595441318489</span>]) </div><div class="line"><span class="number">13800</span>: D: <span class="number">0.188396275043</span>/<span class="number">0.38589566946</span> G: <span class="number">1.38826131821</span> (Real: [<span class="number">4.0228236329555509</span>, <span class="number">1.3524482715610078</span>], Fake: [<span class="number">4.2307587480545044</span>, <span class="number">1.2042737228043698</span>]) </div><div class="line"><span class="number">14000</span>: D: <span class="number">0.0101562952623</span>/<span class="number">0.363918542862</span> G: <span class="number">1.24292945862</span> (Real: [<span class="number">4.0695835274457934</span>, <span class="number">1.4484548400603423</span>], Fake: [<span class="number">4.3588982570171355</span>, <span class="number">1.2305509242343933</span>]) </div><div class="line"><span class="number">14200</span>: D: <span class="number">0.308517187834</span>/<span class="number">0.687216579914</span> G: <span class="number">0.831201374531</span> (Real: [<span class="number">4.1314239382743834</span>, <span class="number">1.2039768851618762</span>], Fake: [<span class="number">4.3469831347465515</span>, <span class="number">1.1622408025070994</span>]) </div><div class="line"><span class="number">14400</span>: D: <span class="number">1.05658388138</span>/<span class="number">0.777651846409</span> G: <span class="number">0.713593065739</span> (Real: [<span class="number">3.9307258637249469</span>, <span class="number">1.3932677098843045</span>], Fake: [<span class="number">3.8781710839271546</span>, <span class="number">1.3920662615905985</span>]) </div><div class="line"><span class="number">14600</span>: D: <span class="number">0.428974717855</span>/<span class="number">0.430344074965</span> G: <span class="number">0.865560889244</span> (Real: [<span class="number">4.2443156433105464</span>, <span class="number">1.4786604488020483</span>], Fake: [<span class="number">3.9386759352684022</span>, <span class="number">1.2173706417721266</span>]) </div><div class="line"><span class="number">14800</span>: D: <span class="number">0.358524769545</span>/<span class="number">0.631785154343</span> G: <span class="number">1.72760403156</span> (Real: [<span class="number">4.0897545439004901</span>, <span class="number">1.3611061267905207</span>], Fake: [<span class="number">4.0185626268386843</span>, <span class="number">1.2011546705663261</span>]) </div><div class="line"><span class="number">15000</span>: D: <span class="number">0.451200634241</span>/<span class="number">0.451773911715</span> G: <span class="number">1.10325527191</span> (Real: [<span class="number">3.9933083570003509</span>, <span class="number">1.0881706638388742</span>], Fake: [<span class="number">3.902902855873108</span>, <span class="number">1.1771562868487595</span>]) </div><div class="line"><span class="number">15200</span>: D: <span class="number">0.756480932236</span>/<span class="number">0.419855684042</span> G: <span class="number">0.942300021648</span> (Real: [<span class="number">4.1753564620018002</span>, <span class="number">1.3629881946025171</span>], Fake: [<span class="number">3.8721090507507325</span>, <span class="number">1.189488508024922</span>]) </div><div class="line"><span class="number">15400</span>: D: <span class="number">0.219109147787</span>/<span class="number">0.190036550164</span> G: <span class="number">2.20304942131</span> (Real: [<span class="number">3.9836783826351168</span>, <span class="number">1.4838718408508595</span>], Fake: [<span class="number">3.9491609585285188</span>, <span class="number">1.1700151592543104</span>]) </div><div class="line"><span class="number">15600</span>: D: <span class="number">1.01965582371</span>/<span class="number">0.519556045532</span> G: <span class="number">1.10594069958</span> (Real: [<span class="number">4.1213941669464109</span>, <span class="number">1.2398676800048194</span>], Fake: [<span class="number">4.1908504700660707</span>, <span class="number">1.1195751576139747</span>]) </div><div class="line"><span class="number">15800</span>: D: <span class="number">0.733263611794</span>/<span class="number">0.697221815586</span> G: <span class="number">0.84056687355</span> (Real: [<span class="number">4.0593542096018789</span>, <span class="number">1.1946663317303297</span>], Fake: [<span class="number">4.3031868946552274</span>, <span class="number">1.0306412415157991</span>]) </div><div class="line"><span class="number">16000</span>: D: <span class="number">0.400649875402</span>/<span class="number">0.377974271774</span> G: <span class="number">1.2899967432</span> (Real: [<span class="number">4.0140545344352718</span>, <span class="number">1.2630515897106358</span>], Fake: [<span class="number">4.1656066524982451</span>, <span class="number">1.1779954377184654</span>]) </div><div class="line"><span class="number">16200</span>: D: <span class="number">0.34089872241</span>/<span class="number">0.265896707773</span> G: <span class="number">1.11251270771</span> (Real: [<span class="number">4.0408088731765748</span>, <span class="number">1.3839176416694203</span>], Fake: [<span class="number">4.0593357777595518</span>, <span class="number">1.2213436233279213</span>]) </div><div class="line"><span class="number">16400</span>: D: <span class="number">0.00472234329209</span>/<span class="number">0.513436615467</span> G: <span class="number">1.63225841522</span> (Real: [<span class="number">4.1417997646331788</span>, <span class="number">1.2449733327544124</span>], Fake: [<span class="number">3.7269023895263671</span>, <span class="number">1.1296458384504016</span>]) </div><div class="line"><span class="number">16600</span>: D: <span class="number">0.756382524967</span>/<span class="number">0.66779255867</span> G: <span class="number">0.536718785763</span> (Real: [<span class="number">3.9379871004819869</span>, <span class="number">1.278594816781579</span>], Fake: [<span class="number">3.8750299978256226</span>, <span class="number">1.2829775944385431</span>]) </div><div class="line"><span class="number">16800</span>: D: <span class="number">0.879319548607</span>/<span class="number">0.169020995498</span> G: <span class="number">2.33787298203</span> (Real: [<span class="number">4.2075482982397077</span>, <span class="number">1.3725696551173026</span>], Fake: [<span class="number">3.6744112837314606</span>, <span class="number">1.3225226221432227</span>]) </div><div class="line"><span class="number">17000</span>: D: <span class="number">0.0482731573284</span>/<span class="number">1.43823099136</span> G: <span class="number">1.15067052841</span> (Real: [<span class="number">4.0404629743099214</span>, <span class="number">1.218948521692204</span>], Fake: [<span class="number">4.0387165582180025</span>, <span class="number">1.2794767516999943</span>]) </div><div class="line"><span class="number">17200</span>: D: <span class="number">2.88490628009e-05</span>/<span class="number">0.57872825861</span> G: <span class="number">0.495411038399</span> (Real: [<span class="number">3.9901529085636138</span>, <span class="number">1.4349120434336065</span>], Fake: [<span class="number">4.0573103535175328</span>, <span class="number">1.1918079188127153</span>]) </div><div class="line"><span class="number">17400</span>: D: <span class="number">0.231002807617</span>/<span class="number">1.2511702776</span> G: <span class="number">1.33606302738</span> (Real: [<span class="number">3.7472488379478452</span>, <span class="number">1.1658634335870959</span>], Fake: [<span class="number">3.9354779303073881</span>, <span class="number">1.2931455406139682</span>]) </div><div class="line"><span class="number">17600</span>: D: <span class="number">0.181431129575</span>/<span class="number">0.149175107479</span> G: <span class="number">2.51311731339</span> (Real: [<span class="number">4.1270963573455814</span>, <span class="number">1.312367798822683</span>], Fake: [<span class="number">4.3470913958549495</span>, <span class="number">1.1818067904116243</span>]) </div><div class="line"><span class="number">17800</span>: D: <span class="number">0.830040276051</span>/<span class="number">0.415931969881</span> G: <span class="number">1.57710897923</span> (Real: [<span class="number">3.99146986246109</span>, <span class="number">1.0836663745208763</span>], Fake: [<span class="number">4.3325731372833252</span>, <span class="number">1.266683405420135</span>]) </div><div class="line"><span class="number">18000</span>: D: <span class="number">0.20047518611</span>/<span class="number">0.460676729679</span> G: <span class="number">2.56421780586</span> (Real: [<span class="number">4.3388666504621503</span>, <span class="number">1.3881540592894346</span>], Fake: [<span class="number">3.9820314025878907</span>, <span class="number">1.0436684747098013</span>]) </div><div class="line"><span class="number">18200</span>: D: <span class="number">0.0659740716219</span>/<span class="number">0.428199917078</span> G: <span class="number">0.931035280228</span> (Real: [<span class="number">3.8892200005054476</span>, <span class="number">1.2217018988161374</span>], Fake: [<span class="number">3.8822696304321287</span>, <span class="number">1.304586899060783</span>]) </div><div class="line"><span class="number">18400</span>: D: <span class="number">0.791511416435</span>/<span class="number">0.56503880024</span> G: <span class="number">1.98549497128</span> (Real: [<span class="number">3.7894453473389147</span>, <span class="number">1.3567878969348022</span>], Fake: [<span class="number">4.0909739780426024</span>, <span class="number">1.2361544714927677</span>]) </div><div class="line"><span class="number">18600</span>: D: <span class="number">1.15297484398</span>/<span class="number">0.102882102132</span> G: <span class="number">1.85704553127</span> (Real: [<span class="number">4.2316720616817474</span>, <span class="number">1.2603607958456993</span>], Fake: [<span class="number">3.7415710711479186</span>, <span class="number">1.311454258421634</span>]) </div><div class="line"><span class="number">18800</span>: D: <span class="number">1.06078708172</span>/<span class="number">0.366641134024</span> G: <span class="number">0.914008259773</span> (Real: [<span class="number">3.9394708669185636</span>, <span class="number">1.2924449902046702</span>], Fake: [<span class="number">3.9466111737489702</span>, <span class="number">1.137776845711856</span>]) </div><div class="line"><span class="number">19000</span>: D: <span class="number">0.374139517546</span>/<span class="number">0.448283135891</span> G: <span class="number">0.701639294624</span> (Real: [<span class="number">3.9492650532722475</span>, <span class="number">1.2348435624999976</span>], Fake: [<span class="number">3.7365686148405075</span>, <span class="number">1.215777672310739</span>]) </div><div class="line"><span class="number">19200</span>: D: <span class="number">0.209440857172</span>/<span class="number">0.522395193577</span> G: <span class="number">0.707223057747</span> (Real: [<span class="number">3.8846979635953902</span>, <span class="number">1.2146658434075039</span>], Fake: [<span class="number">4.1696245861053463</span>, <span class="number">1.2979841463522084</span>]) </div><div class="line"><span class="number">19400</span>: D: <span class="number">0.15654887259</span>/<span class="number">0.133351936936</span> G: <span class="number">1.43907415867</span> (Real: [<span class="number">4.0292040088772776</span>, <span class="number">1.2291287794070285</span>], Fake: [<span class="number">3.8498308193683624</span>, <span class="number">1.1121767482065514</span>]) </div><div class="line"><span class="number">19600</span>: D: <span class="number">0.329566717148</span>/<span class="number">0.222448319197</span> G: <span class="number">0.429250627756</span> (Real: [<span class="number">3.7978928279876709</span>, <span class="number">1.1554982239517226</span>], Fake: [<span class="number">3.5122534275054931</span>, <span class="number">1.2462801759237472</span>]) </div><div class="line"><span class="number">19800</span>: D: <span class="number">0.0176634714007</span>/<span class="number">0.480926275253</span> G: <span class="number">0.39424943924</span> (Real: [<span class="number">4.0822606313228604</span>, <span class="number">1.2484518469881001</span>], Fake: [<span class="number">4.5482089626789097</span>, <span class="number">1.1266585202489452</span>]) </div><div class="line"><span class="number">20000</span>: D: <span class="number">0.45860773325</span>/<span class="number">0.517112135887</span> G: <span class="number">0.957448124886</span> (Real: [<span class="number">4.0875282829999922</span>, <span class="number">1.2310698313795749</span>], Fake: [<span class="number">4.2767848205566406</span>, <span class="number">1.1186856033319335</span>]) </div><div class="line"><span class="number">20200</span>: D: <span class="number">1.71172118187</span>/<span class="number">0.240745082498</span> G: <span class="number">0.314642876387</span> (Real: [<span class="number">3.8525538909435273</span>, <span class="number">1.2094100771830765</span>], Fake: [<span class="number">3.6543397814035417</span>, <span class="number">1.2917598911679764</span>]) </div><div class="line"><span class="number">20400</span>: D: <span class="number">0.583434104919</span>/<span class="number">0.703361749649</span> G: <span class="number">1.45571947098</span> (Real: [<span class="number">4.0388400733470915</span>, <span class="number">1.2267253073862441</span>], Fake: [<span class="number">3.9019298100471498</span>, <span class="number">1.0292402192122965</span>]) </div><div class="line"><span class="number">20600</span>: D: <span class="number">0.176266431808</span>/<span class="number">0.55411952734</span> G: <span class="number">0.962469100952</span> (Real: [<span class="number">4.0694609802961352</span>, <span class="number">1.2276659305759301</span>], Fake: [<span class="number">3.9728190612792971</span>, <span class="number">1.1212652107309595</span>]) </div><div class="line"><span class="number">20800</span>: D: <span class="number">1.17427504063</span>/<span class="number">0.212535098195</span> G: <span class="number">0.505771696568</span> (Real: [<span class="number">3.7983859290182589</span>, <span class="number">1.3565768879920506</span>], Fake: [<span class="number">4.0766829651594163</span>, <span class="number">1.1742807548541911</span>]) </div><div class="line"><span class="number">21000</span>: D: <span class="number">0.247546881437</span>/<span class="number">0.242251947522</span> G: <span class="number">2.533826828</span> (Real: [<span class="number">4.048124186992645</span>, <span class="number">1.2074367711533176</span>], Fake: [<span class="number">3.8443934541940687</span>, <span class="number">1.0964556009967605</span>]) </div><div class="line"><span class="number">21200</span>: D: <span class="number">0.000996549613774</span>/<span class="number">1.77280521393</span> G: <span class="number">0.741032421589</span> (Real: [<span class="number">3.8826335191726686</span>, <span class="number">1.3432952882949609</span>], Fake: [<span class="number">4.0052364200353621</span>, <span class="number">1.0658632049377181</span>]) </div><div class="line"><span class="number">21400</span>: D: <span class="number">0.0162861924618</span>/<span class="number">0.202122434974</span> G: <span class="number">0.640827775002</span> (Real: [<span class="number">3.949158318042755</span>, <span class="number">1.2312223613675215</span>], Fake: [<span class="number">3.9677765011787414</span>, <span class="number">1.1984950273079937</span>]) </div><div class="line"><span class="number">21600</span>: D: <span class="number">0.494586825371</span>/<span class="number">0.368914216757</span> G: <span class="number">1.73299539089</span> (Real: [<span class="number">4.2141097390651705</span>, <span class="number">1.3170628249721785</span>], Fake: [<span class="number">3.9259325069189073</span>, <span class="number">1.2402090610341174</span>]) </div><div class="line"><span class="number">21800</span>: D: <span class="number">1.72856020927</span>/<span class="number">0.280478566885</span> G: <span class="number">0.301942139864</span> (Real: [<span class="number">3.9425574642419816</span>, <span class="number">1.3421295277895979</span>], Fake: [<span class="number">4.1370714265108113</span>, <span class="number">1.3135434962232824</span>]) </div><div class="line"><span class="number">22000</span>: D: <span class="number">0.316263616085</span>/<span class="number">0.425417006016</span> G: <span class="number">4.6092467308</span> (Real: [<span class="number">3.9253722500801085</span>, <span class="number">1.1573266813219236</span>], Fake: [<span class="number">3.7590440094470976</span>, <span class="number">1.2176312271677099</span>]) </div><div class="line"><span class="number">22200</span>: D: <span class="number">1.70313096046</span>/<span class="number">0.166758075356</span> G: <span class="number">1.76803898811</span> (Real: [<span class="number">4.1788750314712528</span>, <span class="number">1.3796412025948377</span>], Fake: [<span class="number">4.4896411395072935</span>, <span class="number">0.88890948354147137</span>]) </div><div class="line"><span class="number">22400</span>: D: <span class="number">0.00245383195579</span>/<span class="number">0.618139982224</span> G: <span class="number">0.561835348606</span> (Real: [<span class="number">4.0531666296720505</span>, <span class="number">1.3030890495946361</span>], Fake: [<span class="number">3.9800510057806968</span>, <span class="number">1.2769573713555427</span>]) </div><div class="line"><span class="number">22600</span>: D: <span class="number">0.0456999950111</span>/<span class="number">0.270536243916</span> G: <span class="number">0.719259619713</span> (Real: [<span class="number">3.8036734467744826</span>, <span class="number">1.2489490089903446</span>], Fake: [<span class="number">4.2525720745325089</span>, <span class="number">1.3061806069103183</span>]) </div><div class="line"><span class="number">22800</span>: D: <span class="number">0.0318684391677</span>/<span class="number">0.34651991725</span> G: <span class="number">1.3301807642</span> (Real: [<span class="number">4.0768313544988635</span>, <span class="number">1.2930152979365797</span>], Fake: [<span class="number">4.4993063497543337</span>, <span class="number">1.2277717696258752</span>]) </div><div class="line"><span class="number">23000</span>: D: <span class="number">1.38112533092</span>/<span class="number">0.656377196312</span> G: <span class="number">0.700986683369</span> (Real: [<span class="number">4.0261077487468722</span>, <span class="number">1.1634786009859657</span>], Fake: [<span class="number">4.1274698692560197</span>, <span class="number">1.1909195549188023</span>]) </div><div class="line"><span class="number">23200</span>: D: <span class="number">0.7532761693</span>/<span class="number">0.30048418045</span> G: <span class="number">1.24321329594</span> (Real: [<span class="number">4.0255234652757643</span>, <span class="number">1.2277433432951119</span>], Fake: [<span class="number">4.0463824319839476</span>, <span class="number">1.2493841122917879</span>]) </div><div class="line"><span class="number">23400</span>: D: <span class="number">1.54497790337</span>/<span class="number">0.524266302586</span> G: <span class="number">1.88104653358</span> (Real: [<span class="number">4.1244187545776363</span>, <span class="number">1.2126284333800423</span>], Fake: [<span class="number">4.0199511092901226</span>, <span class="number">1.4125067136876193</span>]) </div><div class="line"><span class="number">23600</span>: D: <span class="number">0.838026106358</span>/<span class="number">1.1139113903</span> G: <span class="number">2.2735543251</span> (Real: [<span class="number">4.0352903008460999</span>, <span class="number">1.1687086536829701</span>], Fake: [<span class="number">4.5685070466995237</span>, <span class="number">1.4508884769834012</span>]) </div><div class="line"><span class="number">23800</span>: D: <span class="number">0.869914472103</span>/<span class="number">0.160864800215</span> G: <span class="number">1.42444908619</span> (Real: [<span class="number">4.1635012495517731</span>, <span class="number">1.1441051019240691</span>], Fake: [<span class="number">4.1520407730340958</span>, <span class="number">1.2022442680490875</span>]) </div><div class="line"><span class="number">24000</span>: D: <span class="number">0.0401677601039</span>/<span class="number">0.240127012134</span> G: <span class="number">1.21359109879</span> (Real: [<span class="number">4.0558859372138976</span>, <span class="number">1.1263029268841764</span>], Fake: [<span class="number">3.8535136532783509</span>, <span class="number">0.99055012605544335</span>]) </div><div class="line"><span class="number">24200</span>: D: <span class="number">0.444084912539</span>/<span class="number">0.761975646019</span> G: <span class="number">1.18176090717</span> (Real: [<span class="number">4.1462872040271757</span>, <span class="number">1.1670976588949802</span>], Fake: [<span class="number">4.0291124176979061</span>, <span class="number">1.4000525541431663</span>]) </div><div class="line"><span class="number">24400</span>: D: <span class="number">0.259448975325</span>/<span class="number">0.206390738487</span> G: <span class="number">0.850725114346</span> (Real: [<span class="number">4.2600694203376772</span>, <span class="number">1.3260391555100224</span>], Fake: [<span class="number">4.7161277580261229</span>, <span class="number">1.3763624799621637</span>]) </div><div class="line"><span class="number">24600</span>: D: <span class="number">0.821855664253</span>/<span class="number">0.381440609694</span> G: <span class="number">0.898442983627</span> (Real: [<span class="number">3.9929001557826997</span>, <span class="number">1.316718033939094</span>], Fake: [<span class="number">3.659836998283863</span>, <span class="number">1.033547623133473</span>]) </div><div class="line"><span class="number">24800</span>: D: <span class="number">0.869792580605</span>/<span class="number">0.143853545189</span> G: <span class="number">1.68244981766</span> (Real: [<span class="number">3.9503055346012115</span>, <span class="number">1.1980136516743376</span>], Fake: [<span class="number">4.3753550618886949</span>, <span class="number">1.4268488751378543</span>]) </div><div class="line"><span class="number">25000</span>: D: <span class="number">0.533834278584</span>/<span class="number">0.944993913174</span> G: <span class="number">1.35653877258</span> (Real: [<span class="number">3.8403973925113677</span>, <span class="number">1.1415226099240794</span>], Fake: [<span class="number">4.3022644245624546</span>, <span class="number">1.277824404897737</span>]) </div><div class="line"><span class="number">25200</span>: D: <span class="number">0.57686984539</span>/<span class="number">1.21011674404</span> G: <span class="number">0.49785476923</span> (Real: [<span class="number">4.1094828593730925</span>, <span class="number">1.0606124114518727</span>], Fake: [<span class="number">3.8350191235542299</span>, <span class="number">1.1822398134788241</span>]) </div><div class="line"><span class="number">25400</span>: D: <span class="number">1.30570268631</span>/<span class="number">0.127069279552</span> G: <span class="number">2.14658904076</span> (Real: [<span class="number">3.8440176880359651</span>, <span class="number">1.2759016439053388</span>], Fake: [<span class="number">4.2303895175457003</span>, <span class="number">1.2478330871411345</span>]) </div><div class="line"><span class="number">25600</span>: D: <span class="number">0.163877904415</span>/<span class="number">0.356351107359</span> G: <span class="number">1.50513041019</span> (Real: [<span class="number">3.9149920016527178</span>, <span class="number">1.3322359586431274</span>], Fake: [<span class="number">4.5107577931880947</span>, <span class="number">1.37733363996175</span>]) </div><div class="line"><span class="number">25800</span>: D: <span class="number">0.0257995054126</span>/<span class="number">0.501479804516</span> G: <span class="number">0.846267580986</span> (Real: [<span class="number">4.0328698861598973</span>, <span class="number">1.0891363228332751</span>], Fake: [<span class="number">4.2062628841400143</span>, <span class="number">1.2707193105443095</span>]) </div><div class="line"><span class="number">26000</span>: D: <span class="number">0.4208984375</span>/<span class="number">0.45090213418</span> G: <span class="number">1.24405300617</span> (Real: [<span class="number">4.0495267909765245</span>, <span class="number">1.3629959211491509</span>], Fake: [<span class="number">3.881335927248001</span>, <span class="number">1.1534035700479874</span>]) </div><div class="line"><span class="number">26200</span>: D: <span class="number">1.0977101326</span>/<span class="number">0.260044932365</span> G: <span class="number">0.274282753468</span> (Real: [<span class="number">4.0526520502567287</span>, <span class="number">1.1354404896569923</span>], Fake: [<span class="number">3.7989616423845289</span>, <span class="number">1.3036229409468019</span>]) </div><div class="line"><span class="number">26400</span>: D: <span class="number">0.836492598057</span>/<span class="number">0.194570705295</span> G: <span class="number">1.25769793987</span> (Real: [<span class="number">4.2580243301391603</span>, <span class="number">1.1229754918621602</span>], Fake: [<span class="number">4.9420129108428954</span>, <span class="number">1.4595622988211396</span>]) </div><div class="line"><span class="number">26600</span>: D: <span class="number">0.0381172671914</span>/<span class="number">0.229116663337</span> G: <span class="number">3.23367476463</span> (Real: [<span class="number">3.9871047949790954</span>, <span class="number">1.2891811878363044</span>], Fake: [<span class="number">5.5130027627944944</span>, <span class="number">1.3531596753079107</span>]) </div><div class="line"><span class="number">26800</span>: D: <span class="number">0.33750808239</span>/<span class="number">0.0588937625289</span> G: <span class="number">2.76632380486</span> (Real: [<span class="number">4.0901136839389798</span>, <span class="number">1.2240984948711151</span>], Fake: [<span class="number">5.9970619964599612</span>, <span class="number">1.3296608494175821</span>]) </div><div class="line"><span class="number">27000</span>: D: <span class="number">0.403919011354</span>/<span class="number">0.025144957006</span> G: <span class="number">5.00026988983</span> (Real: [<span class="number">3.9684947764873506</span>, <span class="number">1.1928812330565042</span>], Fake: [<span class="number">5.5821900677680967</span>, <span class="number">1.5869340992569609</span>]) </div><div class="line"><span class="number">27200</span>: D: <span class="number">1.26118826866</span>/<span class="number">1.14945113659</span> G: <span class="number">0.233536079526</span> (Real: [<span class="number">4.0953157800436024</span>, <span class="number">1.2000917970554563</span>], Fake: [<span class="number">3.457775202393532</span>, <span class="number">1.2362199991432059</span>]) </div><div class="line"><span class="number">27400</span>: D: <span class="number">0.842516124249</span>/<span class="number">0.577941656113</span> G: <span class="number">0.518706798553</span> (Real: [<span class="number">3.8673747038841246</span>, <span class="number">1.1826108239366226</span>], Fake: [<span class="number">3.6999527400732042</span>, <span class="number">1.2050256827670227</span>]) </div><div class="line"><span class="number">27600</span>: D: <span class="number">0.459548681974</span>/<span class="number">0.516558885574</span> G: <span class="number">1.69328427315</span> (Real: [<span class="number">4.0379843235015871</span>, <span class="number">1.267741160236167</span>], Fake: [<span class="number">4.3069088852405546</span>, <span class="number">1.2883256614455194</span>]) </div><div class="line"><span class="number">27800</span>: D: <span class="number">0.757292568684</span>/<span class="number">0.295852422714</span> G: <span class="number">0.82683211565</span> (Real: [<span class="number">3.6750951480865477</span>, <span class="number">1.1881818498282759</span>], Fake: [<span class="number">4.3079475378990173</span>, <span class="number">1.3863961893145142</span>]) </div><div class="line"><span class="number">28000</span>: D: <span class="number">1.0311729908</span>/<span class="number">0.836829304695</span> G: <span class="number">0.54562240839</span> (Real: [<span class="number">3.8109287106990815</span>, <span class="number">1.2699445078581264</span>], Fake: [<span class="number">4.0800623488426204</span>, <span class="number">1.2420579399013889</span>]) </div><div class="line"><span class="number">28200</span>: D: <span class="number">0.662180066109</span>/<span class="number">0.698618113995</span> G: <span class="number">0.430238395929</span> (Real: [<span class="number">3.8820258617401122</span>, <span class="number">1.3192879801078357</span>], Fake: [<span class="number">3.8678512275218964</span>, <span class="number">1.2100339116659864</span>]) </div><div class="line"><span class="number">28400</span>: D: <span class="number">0.857332766056</span>/<span class="number">0.637849986553</span> G: <span class="number">0.443328052759</span> (Real: [<span class="number">4.0044168281555175</span>, <span class="number">1.2977773729964786</span>], Fake: [<span class="number">3.77621297955513</span>, <span class="number">1.10884790779666</span>]) </div><div class="line"><span class="number">28600</span>: D: <span class="number">0.518617451191</span>/<span class="number">0.676390469074</span> G: <span class="number">0.824631929398</span> (Real: [<span class="number">3.9321113193035124</span>, <span class="number">1.189980080467403</span>], Fake: [<span class="number">4.1412628889083862</span>, <span class="number">1.4110153520360829</span>]) </div><div class="line"><span class="number">28800</span>: D: <span class="number">0.924657285213</span>/<span class="number">0.57682287693</span> G: <span class="number">0.867313206196</span> (Real: [<span class="number">3.8806186806410552</span>, <span class="number">1.2663798129949515</span>], Fake: [<span class="number">3.7928846073150635</span>, <span class="number">0.96599856269415929</span>]) </div><div class="line"><span class="number">29000</span>: D: <span class="number">0.681347727776</span>/<span class="number">0.833830595016</span> G: <span class="number">0.880895376205</span> (Real: [<span class="number">4.0122552135586735</span>, <span class="number">1.3382642859979685</span>], Fake: [<span class="number">3.8699622356891634</span>, <span class="number">1.5246898233773196</span>]) </div><div class="line"><span class="number">29200</span>: D: <span class="number">0.690975308418</span>/<span class="number">0.571468651295</span> G: <span class="number">0.539677977562</span> (Real: [<span class="number">3.9422134029865266</span>, <span class="number">1.2798402813873653</span>], Fake: [<span class="number">3.4796924066543578</span>, <span class="number">1.0078584415562459</span>]) </div><div class="line"><span class="number">29400</span>: D: <span class="number">0.600927650928</span>/<span class="number">0.692537486553</span> G: <span class="number">0.785535871983</span> (Real: [<span class="number">4.0494313037395475</span>, <span class="number">1.2729051468200046</span>], Fake: [<span class="number">4.0457676327228542</span>, <span class="number">1.2121629628604733</span>]) </div><div class="line"><span class="number">29600</span>: D: <span class="number">0.662378668785</span>/<span class="number">0.552553355694</span> G: <span class="number">0.665563106537</span> (Real: [<span class="number">3.8692034566402436</span>, <span class="number">1.1988600586203602</span>], Fake: [<span class="number">4.3626180648803707</span>, <span class="number">1.3098951956607312</span>]) </div><div class="line"><span class="number">29800</span>: D: <span class="number">0.844242811203</span>/<span class="number">0.719559967518</span> G: <span class="number">0.89226102829</span> (Real: [<span class="number">3.8751950478553772</span>, <span class="number">1.1053984789259368</span>], Fake: [<span class="number">3.9671442759037019</span>, <span class="number">1.1584875699071935</span>])</div></pre></td></tr></table></figure></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/26/LSTM-by-Example-using-Tensorflow-Text-Generate/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/26/LSTM-by-Example-using-Tensorflow-Text-Generate/" itemprop="url">LSTM by Example using Tensorflow (Text Generate)</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-26T21:05:01+08:00">2017-04-26 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/26/LSTM-by-Example-using-Tensorflow-Text-Generate/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/26/LSTM-by-Example-using-Tensorflow-Text-Generate/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/26/LSTM-by-Example-using-Tensorflow-Text-Generate/" class="leancloud_visitors" data-flag-title="LSTM by Example using Tensorflow (Text Generate)"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>In Deep Learning, Recurrent Neural Networks (RNN) are a family of neural networks that excels in learning from sequential data. A class of RNN that has found practical applications is Long Short-Term Memory (LSTM) because it is robust against the problems of long-term dependency.</p><p>What seems to be lacking is a good documentation and example on how to build an easy to understand Tensorflow application based on LSTM. This is the motivation behind this article.</p><p>Suppose we want to train a LSTM to predict the next word using a sample short story, <a href="http://www.taleswithmorals.com/" target="_blank" rel="external">Aesop’s Fables</a>:</p><blockquote><p>long ago , the mice had a general council to consider what measures they could take to outwit their common enemy , the cat . some said this , and some said that but at last a young mouse got up and said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger consists in the sly and treacherous manner in which the enemy approaches us . now , if we could receive some signal of her approach , we could easily escape from her . i venture , therefore , to propose that a small bell be procured , and attached by a ribbon round the neck of the cat . by this means we should always know when she was about , and could easily retire while she was in the neighbourhood . this proposal met with general applause , until an old mouse got up and said that is all very well , but who is to bell the cat ? the mice looked at one another and nobody spoke . then the old mouse said it is easy to propose impossible remedies .</p></blockquote><p>If we feed a LSTM with correct sequences from the text of 3 symbols as inputs and 1 labeled symbol, eventually the neural network will learn to predict the next symbol correctly.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*epcf2SBjRHBynBNFf-CpQA.png" alt="lstm"></p><p>Technically, LSTM inputs can only understand real numbers. A way to convert symbol to number is to assign a unique integer to each symbol based on frequency of occurrence. For example, there are 112 unique symbols in the text above. The function in Listing 2 builds a dictionary with the following entries [ “,” : 0 ][ “the” : 1 ], …, [ “council” : 37 ],…,[ “spoke” : 111 ]. The reverse dictionary is also generated since it will be used in decoding the output of LSTM.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dataset</span><span class="params">(words)</span>:</span></div><div class="line">    count = collections.Counter(words).most_common()</div><div class="line">    dictionary = dict()</div><div class="line">    <span class="keyword">for</span> word, _ <span class="keyword">in</span> count:</div><div class="line">        dictionary[word] = len(dictionary)</div><div class="line">    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))</div><div class="line">    <span class="keyword">return</span> dictionary, reverse_dictionary</div></pre></td></tr></table></figure><p>Similarly, the prediction is a unique integer identifying the index in the reverse dictionary of the predicted symbol. For example, if the prediction is 37, the predicted symbol is actually “council”.</p><p>The generation of output may sound simple but actually LSTM produces a 112-element vector of probabilities of prediction for the next symbol normalized by the softmax() function. The index of the element with the highest probability is the predicted index of the symbol in the reverse dictionary (ie a one-hot vector).</p><p><img src="https://cdn-images-1.medium.com/max/800/1*XAJdt_EbedqDlrTT9eqWvQ.png" alt="word-gen"></p><p>There is the source code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div></pre></td><td class="code"><pre><div class="line"><span class="string">'''</span></div><div class="line">A Recurrent Neural Network (LSTM) implementation example using TensorFlow..</div><div class="line">Next word prediction after n_input words learned from text file.</div><div class="line">A story is automatically generated if the predicted word is fed back as input.</div><div class="line">Author: Rowel Atienza</div><div class="line">Project: https://github.com/roatienza/Deep-Learning-Experiments</div><div class="line">'''</div><div class="line"></div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">from</span> tensorflow.contrib <span class="keyword">import</span> rnn</div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> collections</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line">start_time = time.time()</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">elapsed</span><span class="params">(sec)</span>:</span></div><div class="line">    <span class="keyword">if</span> sec&lt;<span class="number">60</span>:</div><div class="line">        <span class="keyword">return</span> str(sec) + <span class="string">" sec"</span></div><div class="line">    <span class="keyword">elif</span> sec&lt;(<span class="number">60</span>*<span class="number">60</span>):</div><div class="line">        <span class="keyword">return</span> str(sec/<span class="number">60</span>) + <span class="string">" min"</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> str(sec/(<span class="number">60</span>*<span class="number">60</span>)) + <span class="string">" hr"</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Target log path</span></div><div class="line">logs_path = <span class="string">'/tmp/tensorflow/rnn_words'</span></div><div class="line">writer = tf.summary.FileWriter(logs_path)</div><div class="line"></div><div class="line"><span class="comment"># Text file containing words for training</span></div><div class="line">training_file = <span class="string">'belling_the_cat.txt'</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span><span class="params">(fname)</span>:</span></div><div class="line">    <span class="keyword">with</span> open(fname) <span class="keyword">as</span> f:</div><div class="line">        content = f.readlines()</div><div class="line">    content = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> content]</div><div class="line">    content = [content[i].split() <span class="keyword">for</span> i <span class="keyword">in</span> range(len(content))]</div><div class="line">    content = np.array(content)</div><div class="line">    content = np.reshape(content, [<span class="number">-1</span>, ])</div><div class="line">    <span class="keyword">return</span> content</div><div class="line"></div><div class="line">training_data = read_data(training_file)</div><div class="line">print(<span class="string">"Loaded training data..."</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_dataset</span><span class="params">(words)</span>:</span></div><div class="line">    count = collections.Counter(words).most_common()</div><div class="line">    dictionary = dict()</div><div class="line">    <span class="keyword">for</span> word, _ <span class="keyword">in</span> count:</div><div class="line">        dictionary[word] = len(dictionary)</div><div class="line">    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))</div><div class="line">    <span class="keyword">return</span> dictionary, reverse_dictionary</div><div class="line"></div><div class="line">dictionary, reverse_dictionary = build_dataset(training_data)</div><div class="line">vocab_size = len(dictionary)</div><div class="line"></div><div class="line"><span class="comment"># Parameters</span></div><div class="line">learning_rate = <span class="number">0.001</span></div><div class="line">training_iters = <span class="number">50000</span></div><div class="line">display_step = <span class="number">1000</span></div><div class="line">n_input = <span class="number">3</span></div><div class="line"></div><div class="line"><span class="comment"># number of units in RNN cell</span></div><div class="line">n_hidden = <span class="number">512</span></div><div class="line"></div><div class="line"><span class="comment"># tf Graph input</span></div><div class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, n_input, <span class="number">1</span>])</div><div class="line">y = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, vocab_size])</div><div class="line"></div><div class="line"><span class="comment"># RNN output node weights and biases</span></div><div class="line">weights = &#123;</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_hidden, vocab_size]))</div><div class="line">&#125;</div><div class="line">biases = &#123;</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([vocab_size]))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">RNN</span><span class="params">(x, weights, biases)</span>:</span></div><div class="line"></div><div class="line">    <span class="comment"># reshape to [1, n_input]</span></div><div class="line">    x = tf.reshape(x, [<span class="number">-1</span>, n_input])</div><div class="line"></div><div class="line">    <span class="comment"># Generate a n_input-element sequence of inputs</span></div><div class="line">    <span class="comment"># (eg. [had] [a] [general] -&gt; [20] [6] [33])</span></div><div class="line">    x = tf.split(x,n_input,<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="comment"># 2-layer LSTM, each layer has n_hidden units.</span></div><div class="line">    <span class="comment"># Average Accuracy= 95.20% at 50k iter</span></div><div class="line">    </div><div class="line">    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])</div><div class="line"></div><div class="line">    <span class="comment"># 1-layer LSTM with n_hidden units but with lower accuracy.</span></div><div class="line">    <span class="comment"># Average Accuracy= 90.60% 50k iter</span></div><div class="line">    <span class="comment"># Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above</span></div><div class="line">    <span class="comment"># rnn_cell = rnn.BasicLSTMCell(n_hidden)</span></div><div class="line"></div><div class="line">    <span class="comment"># generate prediction</span></div><div class="line">    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)</div><div class="line"></div><div class="line">    <span class="comment"># there are n_input outputs but</span></div><div class="line">    <span class="comment"># we only want the last output</span></div><div class="line">    <span class="keyword">return</span> tf.matmul(outputs[<span class="number">-1</span>], weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</div><div class="line"></div><div class="line">pred = RNN(x, weights, biases)</div><div class="line"></div><div class="line"><span class="comment"># Loss and optimizer</span></div><div class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))</div><div class="line">optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)</div><div class="line"></div><div class="line"><span class="comment"># Model evaluation</span></div><div class="line">correct_pred = tf.equal(tf.argmax(pred,<span class="number">1</span>), tf.argmax(y,<span class="number">1</span>))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</div><div class="line"></div><div class="line"><span class="comment"># Initializing the variables</span></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line"><span class="comment"># Launch the graph</span></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</div><div class="line">    session.run(init)</div><div class="line">    step = <span class="number">0</span></div><div class="line">    offset = random.randint(<span class="number">0</span>,n_input+<span class="number">1</span>)</div><div class="line">    end_offset = n_input + <span class="number">1</span></div><div class="line">    acc_total = <span class="number">0</span></div><div class="line">    loss_total = <span class="number">0</span></div><div class="line"></div><div class="line">    writer.add_graph(session.graph)</div><div class="line"></div><div class="line">    <span class="keyword">while</span> step &lt; training_iters:</div><div class="line">        <span class="comment"># Generate a minibatch. Add some randomness on selection process.</span></div><div class="line">        <span class="keyword">if</span> offset &gt; (len(training_data)-end_offset):</div><div class="line">            offset = random.randint(<span class="number">0</span>, n_input+<span class="number">1</span>)</div><div class="line"></div><div class="line">        symbols_in_keys = [ [dictionary[ str(training_data[i])]] <span class="keyword">for</span> i <span class="keyword">in</span> range(offset, offset+n_input) ]</div><div class="line">        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [<span class="number">-1</span>, n_input, <span class="number">1</span>])</div><div class="line"></div><div class="line">        symbols_out_onehot = np.zeros([vocab_size], dtype=float)</div><div class="line">        symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = <span class="number">1.0</span></div><div class="line">        symbols_out_onehot = np.reshape(symbols_out_onehot,[<span class="number">1</span>,<span class="number">-1</span>])</div><div class="line"></div><div class="line">        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \</div><div class="line">                                                feed_dict=&#123;x: symbols_in_keys, y: symbols_out_onehot&#125;)</div><div class="line">        loss_total += loss</div><div class="line">        acc_total += acc</div><div class="line">        <span class="keyword">if</span> (step+<span class="number">1</span>) % display_step == <span class="number">0</span>:</div><div class="line">            print(<span class="string">"Iter= "</span> + str(step+<span class="number">1</span>) + <span class="string">", Average Loss= "</span> + \</div><div class="line">                  <span class="string">"&#123;:.6f&#125;"</span>.format(loss_total/display_step) + <span class="string">", Average Accuracy= "</span> + \</div><div class="line">                  <span class="string">"&#123;:.2f&#125;%"</span>.format(<span class="number">100</span>*acc_total/display_step))</div><div class="line">            acc_total = <span class="number">0</span></div><div class="line">            loss_total = <span class="number">0</span></div><div class="line">            symbols_in = [training_data[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(offset, offset + n_input)]</div><div class="line">            symbols_out = training_data[offset + n_input]</div><div class="line">            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, <span class="number">1</span>).eval())]</div><div class="line">            print(<span class="string">"%s - [%s] vs [%s]"</span> % (symbols_in,symbols_out,symbols_out_pred))</div><div class="line">        step += <span class="number">1</span></div><div class="line">        offset += (n_input+<span class="number">1</span>)</div><div class="line">    print(<span class="string">"Optimization Finished!"</span>)</div><div class="line">    print(<span class="string">"Elapsed time: "</span>, elapsed(time.time() - start_time))</div><div class="line">    print(<span class="string">"Run on command line."</span>)</div><div class="line">    print(<span class="string">"\ttensorboard --logdir=%s"</span> % (logs_path))</div><div class="line">    print(<span class="string">"Point your web browser to: http://localhost:6006/"</span>)</div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        prompt = <span class="string">"%s words: "</span> % n_input</div><div class="line">        sentence = input(prompt)</div><div class="line">        sentence = sentence.strip()</div><div class="line">        words = sentence.split(<span class="string">' '</span>)</div><div class="line">        <span class="keyword">if</span> len(words) != n_input:</div><div class="line">            <span class="keyword">continue</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            symbols_in_keys = [dictionary[str(words[i])] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(words))]</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">32</span>):</div><div class="line">                keys = np.reshape(np.array(symbols_in_keys), [<span class="number">-1</span>, n_input, <span class="number">1</span>])</div><div class="line">                onehot_pred = session.run(pred, feed_dict=&#123;x: keys&#125;)</div><div class="line">                onehot_pred_index = int(tf.argmax(onehot_pred, <span class="number">1</span>).eval())</div><div class="line">                sentence = <span class="string">"%s %s"</span> % (sentence,reverse_dictionary[onehot_pred_index])</div><div class="line">                symbols_in_keys = symbols_in_keys[<span class="number">1</span>:]</div><div class="line">                symbols_in_keys.append(onehot_pred_index)</div><div class="line">            print(sentence)</div><div class="line">        <span class="keyword">except</span>:</div><div class="line">            print(<span class="string">"Word not in dictionary"</span>)</div></pre></td></tr></table></figure><p><strong>source blog:</strong> <a href="https://medium.com/towards-data-science/lstm-by-example-using-tensorflow-feb0c1968537" target="_blank" rel="external">https://medium.com/towards-data-science/lstm-by-example-using-tensorflow-feb0c1968537</a></p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/26/Xiaomi-mini-wifi-cannot-build-the-connection/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/26/Xiaomi-mini-wifi-cannot-build-the-connection/" itemprop="url">Xiaomi mini wifi cannot build the connection</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-26T17:42:41+08:00">2017-04-26 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/26/Xiaomi-mini-wifi-cannot-build-the-connection/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/26/Xiaomi-mini-wifi-cannot-build-the-connection/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/26/Xiaomi-mini-wifi-cannot-build-the-connection/" class="leancloud_visitors" data-flag-title="Xiaomi mini wifi cannot build the connection"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="针对Win10不能正常使用的问题"><a href="#针对Win10不能正常使用的问题" class="headerlink" title="针对Win10不能正常使用的问题"></a>针对Win10不能正常使用的问题</h2><ol><li>进入安装目录</li><li>进入<code>drivers</code>文件夹</li><li>进入<code>Win81x64</code>文件夹</li><li>找到<code>netr28ux.inf</code>文件，右键安装之</li></ol></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/26/Movie-Recommendation-with-MLlib/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/26/Movie-Recommendation-with-MLlib/" itemprop="url">Movie Recommendation with MLlib</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-26T14:24:57+08:00">2017-04-26 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/26/Movie-Recommendation-with-MLlib/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/26/Movie-Recommendation-with-MLlib/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/26/Movie-Recommendation-with-MLlib/" class="leancloud_visitors" data-flag-title="Movie Recommendation with MLlib"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="Spark-Summit-2014"><a href="#Spark-Summit-2014" class="headerlink" title="Spark Summit 2014"></a>Spark Summit 2014</h2><p><a href="https://databricks-training.s3.amazonaws.com/index.html" target="_blank" rel="external">https://databricks-training.s3.amazonaws.com/index.html</a></p><p>we will use MLlib to make personalized movie recommendations tailored <em>for you</em>. We will work with 10 million ratings from 72,000 users on 10,000 movies, collected by <a href="http://movielens.umn.edu/" target="_blank" rel="external">MovieLens</a>. This dataset is pre-loaded in your USB drive under <code>data/movielens/large</code>. For quick testing of your code, you may want to use a smaller dataset under <code>data/movielens/medium</code>, which contains 1 million ratings from 6000 users on 4000 movies.</p><h2 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h2><p>We will use two files from this MovieLens dataset: “<code>ratings.dat</code>” and “<code>movies.dat</code>”. All ratings are contained in the file “<code>ratings.dat</code>” and are in the following format:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">UserID::MovieID::Rating::Timestamp</div></pre></td></tr></table></figure><p>Movie information is in the file “<code>movies.dat</code>” and is in the following format:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">MovieID::Title::Genres</div></pre></td></tr></table></figure><h2 id="Collaborative-filtering"><a href="#Collaborative-filtering" class="headerlink" title="Collaborative filtering"></a>Collaborative filtering</h2><p>Collaborative filtering is commonly used for recommender systems. These techniques aim to fill in the missing entries of a user-item association matrix, in our case, the user-movie rating matrix. MLlib currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. In particular, we implement the alternating least squares (ALS) algorithm to learn these latent factors.</p><p><img src="https://databricks-training.s3.amazonaws.com/img/matrix_factorization.png" alt="cf"></p><h2 id="Create-training-examples"><a href="#Create-training-examples" class="headerlink" title="Create training examples"></a>Create training examples</h2><p><a href="https://github.com/ewanlee/spark-training" target="_blank" rel="external">https://github.com/ewanlee/spark-training</a></p><p>To make recommendation <em>for you</em>, we are going to learn your taste by asking you to rate a few movies. We have selected a small set of movies that have received the most ratings from users in the MovieLens dataset. You can rate those movies by running <code>bin/rateMovies</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python bin/rateMovies</div></pre></td></tr></table></figure><p>When you run the script, you should see prompt similar to the following:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Please rate the following movie (1-5 (best), or 0 if not seen):</div><div class="line">Toy Story (1995):</div></pre></td></tr></table></figure><p>After you’re done rating the movies, we save your ratings in <code>personalRatings.txt</code> in the MovieLens format, where a special user id <code>0</code> is assigned to you.</p><p><code>rateMovies</code> allows you to re-rate the movies if you’d like to see how your ratings affect your recommendations.</p><p>If you don’t have python installed, please copy <code>personalRatings.txt.template</code> to <code>personalRatings.txt</code> and replace <code>?</code>s with your ratings.</p><h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><p>We will be using a standalone project template for this exercise.</p><ul><li><p>In the training USB drive, this has been setup in</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">machine-learning/python/</div></pre></td></tr></table></figure></li><li><p>You should find the following items in the directory:</p></li><li><p><code>MovieLensALS.py</code>: Main Python program that you are going to edit, compile and run</p></li><li><p><code>solution</code>: Directory containing the solution code</p></li></ul><p><code>MovieLensALS.py</code> should look as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> itertools</div><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</div><div class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join, isfile, dirname</div><div class="line"></div><div class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</div><div class="line"><span class="keyword">from</span> pyspark.mllib.recommendation <span class="keyword">import</span> ALS</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseRating</span><span class="params">(line)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .</div><div class="line">    """</div><div class="line">    <span class="comment"># ...</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseMovie</span><span class="params">(line)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Parses a movie record in MovieLens format movieId::movieTitle .</div><div class="line">    """</div><div class="line">    <span class="comment"># ...</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadRatings</span><span class="params">(ratingsFile)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Load ratings from file.</div><div class="line">    """</div><div class="line">    <span class="comment"># ...</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeRmse</span><span class="params">(model, data, n)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Compute RMSE (Root Mean Squared Error).</div><div class="line">    """</div><div class="line">    <span class="comment"># ...</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    <span class="keyword">if</span> (len(sys.argv) != <span class="number">3</span>):</div><div class="line">        <span class="keyword">print</span> <span class="string">"Usage: [usb root directory]/spark/bin/spark-submit --driver-memory 2g "</span> + \</div><div class="line">          <span class="string">"MovieLensALS.py movieLensDataDir personalRatingsFile"</span></div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="comment"># set up environment</span></div><div class="line">    conf = SparkConf() \</div><div class="line">      .setAppName(<span class="string">"MovieLensALS"</span>) \</div><div class="line">      .set(<span class="string">"spark.executor.memory"</span>, <span class="string">"2g"</span>)</div><div class="line">    sc = SparkContext(conf=conf)</div><div class="line"></div><div class="line">    <span class="comment"># load personal ratings</span></div><div class="line">    myRatings = loadRatings(sys.argv[<span class="number">2</span>])</div><div class="line">    myRatingsRDD = sc.parallelize(myRatings, <span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># load ratings and movie titles</span></div><div class="line"></div><div class="line">    movieLensHomeDir = sys.argv[<span class="number">1</span>]</div><div class="line"></div><div class="line">    <span class="comment"># ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))</span></div><div class="line">    ratings = sc.textFile(join(movieLensHomeDir, <span class="string">"ratings.dat"</span>)).map(parseRating)</div><div class="line"></div><div class="line">    <span class="comment"># movies is an RDD of (movieId, movieTitle)</span></div><div class="line">    movies = dict(sc.textFile(join(movieLensHomeDir, <span class="string">"movies.dat"</span>)).map(parseMovie).collect())</div><div class="line"></div><div class="line">    <span class="comment"># your code here</span></div><div class="line">    </div><div class="line">    <span class="comment"># clean up</span></div><div class="line">    sc.stop()</div></pre></td></tr></table></figure><p>Let’s first take a closer look at our template code in a text editor, then we’ll start adding code to the template. Locate the<code>MovieLensALS</code> class and open it with a text editor.</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">usb/$ cd machine-learning/python</div><div class="line">vim MovieLensALS.py  # Or your editor of choice</div></pre></td></tr></table></figure><p>For any Spark computation, we first create a SparkConf object and use it to create a SparkContext object. Since we will be using spark-submit to execute the programs in this tutorial (more on spark-submit in the next section), we only need to configure the executor memory allocation and give the program a name, e.g. “MovieLensALS”, to identify it in Spark’s web UI. In local mode, the web UI can be access at <a href="http://localhost:4040/" target="_blank" rel="external"><code>localhost:4040</code></a> during the execution of a program.</p><p>This is what it looks like in our template code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">conf = SparkConf() \</div><div class="line">     .setAppName(<span class="string">"MovieLensALS"</span>) \</div><div class="line">     .set(<span class="string">"spark.executor.memory"</span>, <span class="string">"2g"</span>)</div><div class="line">   sc = SparkContext(conf=conf)</div></pre></td></tr></table></figure><p>Next, the code uses the SparkContext to read in ratings. Recall that the rating file is a text file with “<code>::</code>” as the delimiter. The code parses each line to create a RDD for ratings that contains <code>(Int, Rating)</code> pairs. We only keep the last digit of the timestamp as a random key. The <code>Rating</code> class is a wrapper around the tuple <code>(user: Int, product: Int, rating: Double)</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">movieLensHomeDir = sys.argv[<span class="number">1</span>]</div><div class="line"></div><div class="line"><span class="comment"># ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))</span></div><div class="line">ratings = sc.textFile(join(movieLensHomeDir, <span class="string">"ratings.dat"</span>)).map(parseRating)</div></pre></td></tr></table></figure><p>Next, the code read in movie ids and titles, collect them into a movie id to title map.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseMovie</span><span class="params">(line)</span>:</span></div><div class="line">      fields = line.split(<span class="string">"::"</span>)</div><div class="line">      <span class="keyword">return</span> int(fields[<span class="number">0</span>]), fields[<span class="number">1</span>]</div><div class="line"></div><div class="line">    movies = dict(sc.textFile(join(movieLensHomeDir, <span class="string">"movies.dat"</span>)).map(parseMovie).collect())</div></pre></td></tr></table></figure><p>Now, let’s make our first edit to add code to get a summary of the ratings.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">numRatings = ratings.count()</div><div class="line">numUsers = ratings.values().map(<span class="keyword">lambda</span> r: r[<span class="number">0</span>]).distinct().count()</div><div class="line">numMovies = ratings.values().map(<span class="keyword">lambda</span> r: r[<span class="number">1</span>]).distinct().count()</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"Got %d ratings from %d users on %d movies."</span> % (numRatings, numUsers, numMovies)</div></pre></td></tr></table></figure><h2 id="Running-the-program"><a href="#Running-the-program" class="headerlink" title="Running the program"></a>Running the program</h2><p>Before we compute movie recommendations, here is a quick reminder on how you can run the program at any point during this exercise. As mentioned above, we will use <code>spark-submit</code> to execute your program in local mode for this tutorial.</p><p>Starting with Spark 1.0, <code>spark-submit</code> is the recommended way for running Spark applications, both on clusters and locally in standalone mode.</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">usb/$ cd machine-learning/python</div><div class="line"></div><div class="line"># change the folder name from <span class="string">"medium"</span> to <span class="string">"large"</span> to run on the large data <span class="keyword">set</span></div><div class="line">[usb root directory]/spark/bin/spark-submit MovieLensALS.py [usb root directory]/data/movielens/medium/ ../personalRatings.txt</div></pre></td></tr></table></figure><p>You should see output similar to the following on your screen:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Got <span class="number">1000209</span> ratings from <span class="number">6040</span> users on <span class="number">3706</span> movies.</div></pre></td></tr></table></figure><h2 id="Splitting-training-data"><a href="#Splitting-training-data" class="headerlink" title="Splitting training data"></a>Splitting training data</h2><p>We will use MLlib’s <code>ALS</code> to train a <code>MatrixFactorizationModel</code>, which takes a <code>RDD[Rating]</code> object as input in Scala and <code>RDD[(user, product, rating)]</code> in Python. ALS has training parameters such as rank for matrix factors and regularization constants. To determine a good combination of the training parameters, we split the data into three non-overlapping subsets, named training, test, and validation, based on the last digit of the timestamp, and cache them. We will train multiple models based on the training set, select the best model on the validation set based on RMSE (Root Mean Squared Error), and finally evaluate the best model on the test set. We also add your ratings to the training set to make recommendations for you. We hold the training, validation, and test sets in memory by calling <code>cache</code> because we need to visit them multiple times.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">numPartitions = <span class="number">4</span></div><div class="line">training = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &lt; <span class="number">6</span>) \</div><div class="line">  .values() \</div><div class="line">  .union(myRatingsRDD) \</div><div class="line">  .repartition(numPartitions) \</div><div class="line">  .cache()</div><div class="line"></div><div class="line">validation = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &gt;= <span class="number">6</span> <span class="keyword">and</span> x[<span class="number">0</span>] &lt; <span class="number">8</span>) \</div><div class="line">  .values() \</div><div class="line">  .repartition(numPartitions) \</div><div class="line">  .cache()</div><div class="line"></div><div class="line">test = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &gt;= <span class="number">8</span>).values().cache()</div><div class="line"></div><div class="line">numTraining = training.count()</div><div class="line">numValidation = validation.count()</div><div class="line">numTest = test.count()</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"Training: %d, validation: %d, test: %d"</span> % (numTraining, numValidation, numTest)</div></pre></td></tr></table></figure><p>After the split, you should see</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Training: <span class="number">602251</span>, validation: <span class="number">198919</span>, test: <span class="number">199049.</span></div></pre></td></tr></table></figure><h2 id="Training-using-ALS"><a href="#Training-using-ALS" class="headerlink" title="Training using ALS"></a>Training using ALS</h2><p>In this section, we will use <code>ALS.train</code> to train a bunch of models, and select and evaluate the best. Among the training paramters of ALS, the most important ones are rank, lambda (regularization constant), and number of iterations. The <code>train</code>method of ALS we are going to use is defined as the following:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ALS</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(cls, ratings, rank, iterations=<span class="number">5</span>, lambda_=<span class="number">0.01</span>, blocks=<span class="number">-1</span>)</span>:</span></div><div class="line">    <span class="comment"># ...</span></div><div class="line">    <span class="keyword">return</span> MatrixFactorizationModel(sc, mod)</div></pre></td></tr></table></figure><p>deally, we want to try a large number of combinations of them in order to find the best one. Due to time constraint, we will test only 8 combinations resulting from the cross product of 2 different ranks (8 and 12), 2 different lambdas (1.0 and 10.0), and two different numbers of iterations (10 and 20). We use the provided method <code>computeRmse</code> to compute the RMSE on the validation set for each model. The model with the smallest RMSE on the validation set becomes the one selected and its RMSE on the test set is used as the final metric.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">ranks = [<span class="number">8</span>, <span class="number">12</span>]</div><div class="line">lambdas = [<span class="number">1.0</span>, <span class="number">10.0</span>]</div><div class="line">numIters = [<span class="number">10</span>, <span class="number">20</span>]</div><div class="line">bestModel = <span class="keyword">None</span></div><div class="line">bestValidationRmse = float(<span class="string">"inf"</span>)</div><div class="line">bestRank = <span class="number">0</span></div><div class="line">bestLambda = <span class="number">-1.0</span></div><div class="line">bestNumIter = <span class="number">-1</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> rank, lmbda, numIter <span class="keyword">in</span> itertools.product(ranks, lambdas, numIters):</div><div class="line">    model = ALS.train(training, rank, numIter, lmbda)</div><div class="line">    validationRmse = computeRmse(model, validation, numValidation)</div><div class="line">    <span class="keyword">print</span> <span class="string">"RMSE (validation) = %f for the model trained with "</span> % validationRmse + \</div><div class="line">          <span class="string">"rank = %d, lambda = %.1f, and numIter = %d."</span> % (rank, lmbda, numIter)</div><div class="line">    <span class="keyword">if</span> (validationRmse &lt; bestValidationRmse):</div><div class="line">        bestModel = model</div><div class="line">        bestValidationRmse = validationRmse</div><div class="line">        bestRank = rank</div><div class="line">        bestLambda = lmbda</div><div class="line">        bestNumIter = numIter</div><div class="line"></div><div class="line">testRmse = computeRmse(bestModel, test, numTest)</div><div class="line"></div><div class="line"><span class="comment"># evaluate the best model on the test set</span></div><div class="line"><span class="keyword">print</span> <span class="string">"The best model was trained with rank = %d and lambda = %.1f, "</span> % (bestRank, bestLambda) \</div><div class="line">  + <span class="string">"and numIter = %d, and its RMSE on the test set is %f."</span> % (bestNumIter, testRmse)</div></pre></td></tr></table></figure><p>Spark might take a minute or two to train the models. You should see the following on the screen:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">The best model was trained using rank <span class="number">8</span> <span class="keyword">and</span> <span class="keyword">lambda</span> <span class="number">10.0</span>, <span class="keyword">and</span> its RMSE on test <span class="keyword">is</span> <span class="number">0.8808492431998702</span>.</div></pre></td></tr></table></figure><h2 id="Recommending-movies-for-you"><a href="#Recommending-movies-for-you" class="headerlink" title="Recommending movies for you"></a>Recommending movies for you</h2><p>As the last part of our tutorial, let’s take a look at what movies our model recommends for you. This is done by generating <code>(0, movieId)</code> pairs for all movies you haven’t rated and calling the model’s <code>predict</code> method to get predictions. <code>0</code> is the special user id assigned to you.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MatrixFactorizationModel</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predictAll</span><span class="params">(self, usersProducts)</span>:</span></div><div class="line">        <span class="comment"># ...</span></div><div class="line">        <span class="keyword">return</span> RDD(self._java_model.predict(usersProductsJRDD._jrdd),</div><div class="line">                   self._context, RatingDeserializer())</div></pre></td></tr></table></figure><p>After we get all predictions, let us list the top 50 recommendations and see whether they look good to you.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">myRatedMovieIds = set([x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> myRatings])</div><div class="line">candidates = sc.parallelize([m <span class="keyword">for</span> m <span class="keyword">in</span> movies <span class="keyword">if</span> m <span class="keyword">not</span> <span class="keyword">in</span> myRatedMovieIds])</div><div class="line">predictions = bestModel.predictAll(candidates.map(<span class="keyword">lambda</span> x: (<span class="number">0</span>, x))).collect()</div><div class="line">recommendations = sorted(predictions, key=<span class="keyword">lambda</span> x: x[<span class="number">2</span>], reverse=<span class="keyword">True</span>)[:<span class="number">50</span>]</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"Movies recommended for you:"</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(recommendations)):</div><div class="line">    <span class="keyword">print</span> (<span class="string">"%2d: %s"</span> % (i + <span class="number">1</span>, movies[recommendations[i][<span class="number">1</span>]])).encode(<span class="string">'ascii'</span>, <span class="string">'ignore'</span>)</div></pre></td></tr></table></figure><p>The output should be similar to</p><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">Movies recommended for you:</div><div class="line"> 1: Silence of the Lambs, The (1991)</div><div class="line"> 2: Saving Private Ryan (1998)</div><div class="line"> 3: Godfather, The (1972)</div><div class="line"> 4: Star Wars: Episode IV - A New Hope (1977)</div><div class="line"> 5: Braveheart (1995)</div><div class="line"> 6: Schindler's List (1993)</div><div class="line"> 7: Shawshank Redemption, The (1994)</div><div class="line"> 8: Star Wars: Episode V - The Empire Strikes Back (1980)</div><div class="line"> 9: Pulp Fiction (1994)</div><div class="line">10: Alien (1979)</div><div class="line">...</div></pre></td></tr></table></figure><h2 id="Comparing-to-a-naive-baseline"><a href="#Comparing-to-a-naive-baseline" class="headerlink" title="Comparing to a naive baseline"></a>Comparing to a naive baseline</h2><p>Does ALS output a non-trivial model? We can compare the evaluation result with a naive baseline model that only outputs the average rating (or you may try one that outputs the average rating per movie). Computing the baseline’s RMSE is straightforward:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">meanRating = training.union(validation).map(<span class="keyword">lambda</span> x: x[<span class="number">2</span>]).mean()</div><div class="line">baselineRmse = sqrt(test.map(<span class="keyword">lambda</span> x: (meanRating - x[<span class="number">2</span>]) ** <span class="number">2</span>).reduce(add) / numTest)</div><div class="line">improvement = (baselineRmse - testRmse) / baselineRmse * <span class="number">100</span></div><div class="line"><span class="keyword">print</span> <span class="string">"The best model improves the baseline by %.2f"</span> % (improvement) + <span class="string">"%."</span></div></pre></td></tr></table></figure><p>The output should be similar to</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">The best model improves the baseline by <span class="number">20.96</span>%.</div></pre></td></tr></table></figure><p>It seems obvious that the trained model would outperform the naive baseline. However, a bad combination of training parameters would lead to a model worse than this naive baseline. Choosing the right set of parameters is quite important for this task.</p><h2 id="Solution-code"><a href="#Solution-code" class="headerlink" title="Solution code"></a>Solution code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> itertools</div><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</div><div class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join, isfile, dirname</div><div class="line"></div><div class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</div><div class="line"><span class="keyword">from</span> pyspark.mllib.recommendation <span class="keyword">import</span> ALS</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseRating</span><span class="params">(line)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .</div><div class="line">    """</div><div class="line">    fields = line.strip().split(<span class="string">"::"</span>)</div><div class="line">    <span class="keyword">return</span> long(fields[<span class="number">3</span>]) % <span class="number">10</span>, (int(fields[<span class="number">0</span>]), int(fields[<span class="number">1</span>]), float(fields[<span class="number">2</span>]))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseMovie</span><span class="params">(line)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Parses a movie record in MovieLens format movieId::movieTitle .</div><div class="line">    """</div><div class="line">    fields = line.strip().split(<span class="string">"::"</span>)</div><div class="line">    <span class="keyword">return</span> int(fields[<span class="number">0</span>]), fields[<span class="number">1</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadRatings</span><span class="params">(ratingsFile)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Load ratings from file.</div><div class="line">    """</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isfile(ratingsFile):</div><div class="line">        <span class="keyword">print</span> <span class="string">"File %s does not exist."</span> % ratingsFile</div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    f = open(ratingsFile, <span class="string">'r'</span>)</div><div class="line">    ratings = filter(<span class="keyword">lambda</span> r: r[<span class="number">2</span>] &gt; <span class="number">0</span>, [parseRating(line)[<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> f])</div><div class="line">    f.close()</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ratings:</div><div class="line">        <span class="keyword">print</span> <span class="string">"No ratings provided."</span></div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> ratings</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeRmse</span><span class="params">(model, data, n)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Compute RMSE (Root Mean Squared Error).</div><div class="line">    """</div><div class="line">    predictions = model.predictAll(data.map(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>])))</div><div class="line">    predictionsAndRatings = predictions.map(<span class="keyword">lambda</span> x: ((x[<span class="number">0</span>], x[<span class="number">1</span>]), x[<span class="number">2</span>])) \</div><div class="line">      .join(data.map(<span class="keyword">lambda</span> x: ((x[<span class="number">0</span>], x[<span class="number">1</span>]), x[<span class="number">2</span>]))) \</div><div class="line">      .values()</div><div class="line">    <span class="keyword">return</span> sqrt(predictionsAndRatings.map(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>] - x[<span class="number">1</span>]) ** <span class="number">2</span>).reduce(add) / float(n))</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    <span class="keyword">if</span> (len(sys.argv) != <span class="number">3</span>):</div><div class="line">        <span class="keyword">print</span> <span class="string">"Usage: /path/to/spark/bin/spark-submit --driver-memory 2g "</span> + \</div><div class="line">          <span class="string">"MovieLensALS.py movieLensDataDir personalRatingsFile"</span></div><div class="line">        sys.exit(<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="comment"># set up environment</span></div><div class="line">    conf = SparkConf() \</div><div class="line">      .setAppName(<span class="string">"MovieLensALS"</span>) \</div><div class="line">      .set(<span class="string">"spark.executor.memory"</span>, <span class="string">"2g"</span>)</div><div class="line">    sc = SparkContext(conf=conf)</div><div class="line"></div><div class="line">    <span class="comment"># load personal ratings</span></div><div class="line">    myRatings = loadRatings(sys.argv[<span class="number">2</span>])</div><div class="line">    myRatingsRDD = sc.parallelize(myRatings, <span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># load ratings and movie titles</span></div><div class="line"></div><div class="line">    movieLensHomeDir = sys.argv[<span class="number">1</span>]</div><div class="line"></div><div class="line">    <span class="comment"># ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))</span></div><div class="line">    ratings = sc.textFile(join(movieLensHomeDir, <span class="string">"ratings.dat"</span>)).map(parseRating)</div><div class="line"></div><div class="line">    <span class="comment"># movies is an RDD of (movieId, movieTitle)</span></div><div class="line">    movies = dict(sc.textFile(join(movieLensHomeDir, <span class="string">"movies.dat"</span>)).map(parseMovie).collect())</div><div class="line"></div><div class="line">    numRatings = ratings.count()</div><div class="line">    numUsers = ratings.values().map(<span class="keyword">lambda</span> r: r[<span class="number">0</span>]).distinct().count()</div><div class="line">    numMovies = ratings.values().map(<span class="keyword">lambda</span> r: r[<span class="number">1</span>]).distinct().count()</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">"Got %d ratings from %d users on %d movies."</span> % (numRatings, numUsers, numMovies)</div><div class="line"></div><div class="line">    <span class="comment"># split ratings into train (60%), validation (20%), and test (20%) based on the </span></div><div class="line">    <span class="comment"># last digit of the timestamp, add myRatings to train, and cache them</span></div><div class="line"></div><div class="line">    <span class="comment"># training, validation, test are all RDDs of (userId, movieId, rating)</span></div><div class="line"></div><div class="line">    numPartitions = <span class="number">4</span></div><div class="line">    training = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &lt; <span class="number">6</span>) \</div><div class="line">      .values() \</div><div class="line">      .union(myRatingsRDD) \</div><div class="line">      .repartition(numPartitions) \</div><div class="line">      .cache()</div><div class="line"></div><div class="line">    validation = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &gt;= <span class="number">6</span> <span class="keyword">and</span> x[<span class="number">0</span>] &lt; <span class="number">8</span>) \</div><div class="line">      .values() \</div><div class="line">      .repartition(numPartitions) \</div><div class="line">      .cache()</div><div class="line"></div><div class="line">    test = ratings.filter(<span class="keyword">lambda</span> x: x[<span class="number">0</span>] &gt;= <span class="number">8</span>).values().cache()</div><div class="line"></div><div class="line">    numTraining = training.count()</div><div class="line">    numValidation = validation.count()</div><div class="line">    numTest = test.count()</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">"Training: %d, validation: %d, test: %d"</span> % (numTraining, numValidation, numTest)</div><div class="line"></div><div class="line">    <span class="comment"># train models and evaluate them on the validation set</span></div><div class="line"></div><div class="line">    ranks = [<span class="number">8</span>, <span class="number">12</span>]</div><div class="line">    lambdas = [<span class="number">0.1</span>, <span class="number">10.0</span>]</div><div class="line">    numIters = [<span class="number">10</span>, <span class="number">20</span>]</div><div class="line">    bestModel = <span class="keyword">None</span></div><div class="line">    bestValidationRmse = float(<span class="string">"inf"</span>)</div><div class="line">    bestRank = <span class="number">0</span></div><div class="line">    bestLambda = <span class="number">-1.0</span></div><div class="line">    bestNumIter = <span class="number">-1</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> rank, lmbda, numIter <span class="keyword">in</span> itertools.product(ranks, lambdas, numIters):</div><div class="line">        model = ALS.train(training, rank, numIter, lmbda)</div><div class="line">        validationRmse = computeRmse(model, validation, numValidation)</div><div class="line">        <span class="keyword">print</span> <span class="string">"RMSE (validation) = %f for the model trained with "</span> % validationRmse + \</div><div class="line">              <span class="string">"rank = %d, lambda = %.1f, and numIter = %d."</span> % (rank, lmbda, numIter)</div><div class="line">        <span class="keyword">if</span> (validationRmse &lt; bestValidationRmse):</div><div class="line">            bestModel = model</div><div class="line">            bestValidationRmse = validationRmse</div><div class="line">            bestRank = rank</div><div class="line">            bestLambda = lmbda</div><div class="line">            bestNumIter = numIter</div><div class="line"></div><div class="line">    testRmse = computeRmse(bestModel, test, numTest)</div><div class="line"></div><div class="line">    <span class="comment"># evaluate the best model on the test set</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"The best model was trained with rank = %d and lambda = %.1f, "</span> % (bestRank, bestLambda) \</div><div class="line">      + <span class="string">"and numIter = %d, and its RMSE on the test set is %f."</span> % (bestNumIter, testRmse)</div><div class="line"></div><div class="line">    <span class="comment"># compare the best model with a naive baseline that always returns the mean rating</span></div><div class="line">    meanRating = training.union(validation).map(<span class="keyword">lambda</span> x: x[<span class="number">2</span>]).mean()</div><div class="line">    baselineRmse = sqrt(test.map(<span class="keyword">lambda</span> x: (meanRating - x[<span class="number">2</span>]) ** <span class="number">2</span>).reduce(add) / numTest)</div><div class="line">    improvement = (baselineRmse - testRmse) / baselineRmse * <span class="number">100</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"The best model improves the baseline by %.2f"</span> % (improvement) + <span class="string">"%."</span></div><div class="line"></div><div class="line">    <span class="comment"># make personalized recommendations</span></div><div class="line"></div><div class="line">    myRatedMovieIds = set([x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> myRatings])</div><div class="line">    candidates = sc.parallelize([m <span class="keyword">for</span> m <span class="keyword">in</span> movies <span class="keyword">if</span> m <span class="keyword">not</span> <span class="keyword">in</span> myRatedMovieIds])</div><div class="line">    predictions = bestModel.predictAll(candidates.map(<span class="keyword">lambda</span> x: (<span class="number">0</span>, x))).collect()</div><div class="line">    recommendations = sorted(predictions, key=<span class="keyword">lambda</span> x: x[<span class="number">2</span>], reverse=<span class="keyword">True</span>)[:<span class="number">50</span>]</div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">"Movies recommended for you:"</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(recommendations)):</div><div class="line">        <span class="keyword">print</span> (<span class="string">"%2d: %s"</span> % (i + <span class="number">1</span>, movies[recommendations[i][<span class="number">1</span>]])).encode(<span class="string">'ascii'</span>, <span class="string">'ignore'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># clean up</span></div><div class="line">    sc.stop()</div></pre></td></tr></table></figure></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></section><nav class="pagination"><a class="extend prev" rel="prev" href="/page/14/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><span class="page-number current">15</span><a class="page-number" href="/page/16/">16</a><span class="space">&hellip;</span><a class="page-number" href="/page/25/">25</a><a class="extend next" rel="next" href="/page/16/"><i class="fa fa-angle-right"></i></a></nav></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ewan Li"><p class="site-author-name" itemprop="name">Ewan Li</p><p class="site-description motion-element" itemprop="description">Ewan's IT Blog</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">122</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">58</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/ewanlee" target="_blank" title="Github"><i class="fa fa-fw fa-globe"></i> Github </a></span><span class="links-of-author-item"><a href="http://weibo.com/3946248928/profile?topnav=1&wvr=6" target="_blank" title="Weibo"><i class="fa fa-fw fa-weibo"></i> Weibo</a></span></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Ewan Li</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user">本站访客数</i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人次</span> <span class="site-pv"><i class="fa fa-eye">本站总访问量</i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">_hcwp=window._hcwp||[],_hcwp.push({widget:"Bloggerstream",widget_id:89825,selector:".hc-comment-count",label:"{%COUNT%}"}),function(){if(!("HC_LOAD_INIT"in window)){HC_LOAD_INIT=!0;var t=(navigator.language||navigator.systemLanguage||navigator.userLanguage||"en").substr(0,2).toLowerCase(),e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src=("https:"==document.location.protocol?"https":"http")+"://w.hypercomments.com/widget/hc/89825/"+t+"/widget.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n.nextSibling)}}()</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("e27VKX5tTklQLCtF7iNMmhcA-gzGzoHsz","nnQn2znNgXXEdK7W2bVJ3bfK")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script></body></html>