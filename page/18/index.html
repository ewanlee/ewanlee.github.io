<!doctype html><html class="theme-next mist use-motion" lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="Hexo, NexT"><link rel="alternate" href="/atom.xml" title="Abracadabra" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="Ewan&apos;s IT Blog"><meta property="og:type" content="website"><meta property="og:title" content="Abracadabra"><meta property="og:url" content="http://yoursite.com/page/18/index.html"><meta property="og:site_name" content="Abracadabra"><meta property="og:description" content="Ewan&apos;s IT Blog"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Abracadabra"><meta name="twitter:description" content="Ewan&apos;s IT Blog"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post"},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/page/18/"><title>Abracadabra</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?dc405a79ad500922134d14cdf288f646";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container one-collumn sidebar-position-left page-home"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Abracadabra</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Do it yourself</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><section id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/20/Something-about-cloudera/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/20/Something-about-cloudera/" itemprop="url">Something about cloudera</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-20T09:55:41+08:00">2017-04-20 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/20/Something-about-cloudera/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/20/Something-about-cloudera/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/20/Something-about-cloudera/" class="leancloud_visitors" data-flag-title="Something about cloudera"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>最近发现了一个神器，cloudera</p><p><a href="https://www.cloudera.com/" target="_blank" rel="external">https://www.cloudera.com/</a></p><p>它其实是一个集成了Hadoop生态系统的CentOS 6.7的VM，可以跑在Docker、Virtual Box或者VMware上</p><p><a href="https://www.cloudera.com/downloads/quickstart_vms/5-10.html" target="_blank" rel="external">https://www.cloudera.com/downloads/quickstart_vms/5-10.html</a></p><p>虚拟机配置的时候需要分配至少8G的RAM以及2个Cores。</p><p>另外，第一次启动会有些慢，请耐心等待。</p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/18/Hadoop-Distributed-Filesystem-notes/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/18/Hadoop-Distributed-Filesystem-notes/" itemprop="url">Hadoop Distributed Filesystem notes</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-18T11:53:51+08:00">2017-04-18 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/18/Hadoop-Distributed-Filesystem-notes/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/18/Hadoop-Distributed-Filesystem-notes/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/18/Hadoop-Distributed-Filesystem-notes/" class="leancloud_visitors" data-flag-title="Hadoop Distributed Filesystem notes"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="HDFS-Concepts"><a href="#HDFS-Concepts" class="headerlink" title="HDFS Concepts"></a>HDFS Concepts</h2><h3 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h3><ul><li>128 MB by default<ul><li>HDFS blocks are large compared to disk blocks, and the reason is to minimize the cost<br>of seeks.</li></ul></li><li>Having a block abstraction for a distributed filesystem brings several benefits<ul><li>A file can be larger than any single disk in the network.</li><li>Simplifies the storage subsystem.</li><li>Providing fault tolerance and availability.</li></ul></li><li><code>% hdfs fsck / -files -blocks</code></li></ul><h3 id="Namenodes-and-Datanodes"><a href="#Namenodes-and-Datanodes" class="headerlink" title="Namenodes and Datanodes"></a>Namenodes and Datanodes</h3><ul><li>An HDFS cluster has two types of nodes operating in a master−worker pattern<ul><li>namenode (the master)</li><li>datanodes (workers)</li></ul></li><li>Without the namenode, the filesystem cannot be used<ul><li>For this reason, it is important to make the namenode resilient to failure</li><li>The first way is to back up the files that make up the persistent state of the filesystem<br>metadata.</li><li>It is also possible to run a secondary namenode</li></ul></li></ul><h3 id="Block-Caching"><a href="#Block-Caching" class="headerlink" title="Block Caching"></a>Block Caching</h3><ul><li>For frequently accessed files the blocks may be explicitly cached in the datanode’s memory, in an off-heap block cache. By default, a block is cached in only one datanode’s memory.</li></ul><h3 id="HDFS-Federation"><a href="#HDFS-Federation" class="headerlink" title="HDFS Federation"></a>HDFS Federation</h3><ul><li>one namenode might manage all the files rooted under /user, say, and a second name‐<br>node might handle files under /share.<ul><li>namespace volume</li><li>block pool</li></ul></li><li>namenodes do not communicate with one another</li></ul><h3 id="HDFS-High-Avalibility"><a href="#HDFS-High-Avalibility" class="headerlink" title="HDFS High Avalibility"></a>HDFS High Avalibility</h3><ul><li>The new namenode is not able to serve requests until it has<ul><li>loaded its namespace image into memory</li><li>replayed its edit log</li><li>received enough block reports from the datanodes to leave safe mode.</li></ul></li><li>On large clusters with many files and blocks, the time it takes for a namenode to start from cold can be 30 minutes or more.</li><li>Hadoop 2 remedied this situation by adding support for HDFS high availability (HA).<ul><li>there are a pair of namenodes in an active-standby configuration. In the event of the failure of the active namenode, the standby takes over its duties to continue servicing client requests without a significant interruption.</li></ul></li><li>There are two choices for the highly available shared storage<ul><li>NFS filer</li><li>quorum journal manager (QJM)</li><li>The actual observed failover time will be longer in practice (around a minute or so)</li></ul></li><li>The transition from the active namenode to the standby is managed by a new entity in<br>the system called the failover controller<ul><li>default implementation uses ZooKeeper to ensure that only one namenode is active.</li><li>The QJM only allows one namenode to write to the edit log at one time</li></ul></li></ul><h2 id="The-Command-Line-Interface"><a href="#The-Command-Line-Interface" class="headerlink" title="The Command-Line Interface"></a>The Command-Line Interface</h2><h3 id="Basic-Filesystem-Operations"><a href="#Basic-Filesystem-Operations" class="headerlink" title="Basic Filesystem Operations"></a>Basic Filesystem Operations</h3><ul><li><p>copying a file from the local filesystem to HDFS</p><ul><li><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">% hadoop fs -copyFromLocal input/docs/quangle.txt \</div><div class="line"> hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div></pre></td></tr></table></figure></li></ul></li><li><p>copy the file back to the local filesystem and check whether it’s the same</p><ul><li><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">% hadoop fs -copyToLocal quangle.txt quangle.copy.txt</div><div class="line">% md5 input/docs/quangle.txt quangle.copy.txt</div><div class="line">e7891a2627cf263a079fb0f18256ffb2 input/docs/quangle.txt</div><div class="line">MD5 (quangle.copy.txt) = e7891a2627cf263a079fb0f18256ffb2</div></pre></td></tr></table></figure></li></ul></li><li><p>create a directory first just to see how it is displayed in the listing</p><ul><li><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">% hadoop fs -mkdir books</div><div class="line">% hadoop fs -ls .</div><div class="line">Found <span class="number">2</span> items</div><div class="line">drwxr-xr-x - tom supergroup <span class="number">0</span> <span class="number">2014</span><span class="number">-10</span><span class="number">-04</span> <span class="number">13</span>:<span class="number">22</span> books</div><div class="line">-rw-r--r-- <span class="number">1</span> tom supergroup <span class="number">119</span> <span class="number">2014</span><span class="number">-10</span><span class="number">-04</span> <span class="number">13</span>:<span class="number">21</span> quangle.txt</div></pre></td></tr></table></figure></li></ul></li></ul><h2 id="The-Java-Interface"><a href="#The-Java-Interface" class="headerlink" title="The Java Interface"></a>The Java Interface</h2><h3 id="Reading-Data-from-a-Hadoop-URL"><a href="#Reading-Data-from-a-Hadoop-URL" class="headerlink" title="Reading Data from a Hadoop URL"></a>Reading Data from a Hadoop URL</h3><p><em>Example. Displaying files from a Hadoop filesystem on standard output using a URLStreamHandler</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc URLCat Displays files from a Hadoop filesystem on standard output using a URLStreamHandler</span></div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.net.URL;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FsUrlStreamHandlerFactory;</div><div class="line"><span class="keyword">import</span> org.a</div><div class="line">  pache.hadoop.io.IOUtils;</div><div class="line"></div><div class="line"><span class="comment">// vv URLCat</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">URLCat</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="keyword">static</span> &#123;</div><div class="line">    URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    InputStream in = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      in = <span class="keyword">new</span> URL(args[<span class="number">0</span>]).openStream();</div><div class="line">      IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      IOUtils.closeStream(in);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ URLCat</span></div></pre></td></tr></table></figure><p><strong>There’s a little bit more work required to make Java recognize Hadoop’s hdfs URL scheme. This is achieved by calling the setURLStreamHandlerFactory() method on URL with an instance of FsUrlStreamHandlerFactory. This method can be called only once per JVM, so it is typically executed in a static block.</strong></p><p>Here’s a sample run:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">% <span class="keyword">export</span> HADOOP_CLASSPATH=hadoop-examples.jar</div><div class="line">% hadoop URLCat hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div><div class="line">On the top of the Crumpetty Tree</div><div class="line">The Quangle Wangle sat,</div><div class="line">But his face you could not see,</div><div class="line">On account of his Beaver Hat.</div></pre></td></tr></table></figure><h3 id="Reading-Data-Using-the-FileSystem-API"><a href="#Reading-Data-Using-the-FileSystem-API" class="headerlink" title="Reading Data Using the FileSystem API"></a>Reading Data Using the FileSystem API</h3><p><em>Example. Displaying files from a Hadoop filesystem on standard output by using the FileSystem directly</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc FileSystemCat Displays files from a Hadoop filesystem on standard output by using the FileSystem directly</span></div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div><div class="line"></div><div class="line"><span class="comment">// vv FileSystemCat</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileSystemCat</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    String uri = args[<span class="number">0</span>];</div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    FileSystem fs = FileSystem.get(URI.create(uri), conf);</div><div class="line">    InputStream in = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      in = fs.open(<span class="keyword">new</span> Path(uri));</div><div class="line">      IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      IOUtils.closeStream(in);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ FileSystemCat</span></div></pre></td></tr></table></figure><p>The program runs as follows:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">% hadoop FileSystemCat hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div><div class="line">On the top of the Crumpetty Tree</div><div class="line">The Quangle Wangle sat,</div><div class="line">But his face you could not see,</div><div class="line">On account of his Beaver Hat.</div></pre></td></tr></table></figure><h4 id="FSDataInputStream"><a href="#FSDataInputStream" class="headerlink" title="FSDataInputStream"></a>FSDataInputStream</h4><p><em>Example. Displaying files from a Hadoop filesystem on standard output twice, by using seek()</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc FileSystemDoubleCat Displays files from a Hadoop filesystem on standard output twice, by using seek</span></div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div><div class="line"></div><div class="line"><span class="comment">// vv FileSystemDoubleCat</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileSystemDoubleCat</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    String uri = args[<span class="number">0</span>];</div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    FileSystem fs = FileSystem.get(URI.create(uri), conf);</div><div class="line">    FSDataInputStream in = <span class="keyword">null</span>;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">      in = fs.open(<span class="keyword">new</span> Path(uri));</div><div class="line">      IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</div><div class="line">      in.seek(<span class="number">0</span>); <span class="comment">// go back to the start of the file</span></div><div class="line">      IOUtils.copyBytes(in, System.out, <span class="number">4096</span>, <span class="keyword">false</span>);</div><div class="line">    &#125; <span class="keyword">finally</span> &#123;</div><div class="line">      IOUtils.closeStream(in);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ FileSystemDoubleCat</span></div></pre></td></tr></table></figure><p>Here’s the result of running it on a small file:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">% hadoop FileSystemDoubleCat hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div><div class="line">On the top of the Crumpetty Tree</div><div class="line">The Quangle Wangle sat,</div><div class="line">But his face you could not see,</div><div class="line">On account of his Beaver Hat.</div><div class="line">On the top of the Crumpetty Tree</div><div class="line">The Quangle Wangle sat,</div><div class="line">But his face you could not see,</div><div class="line">On account of his Beaver Hat.</div></pre></td></tr></table></figure><h3 id="Writing-Data"><a href="#Writing-Data" class="headerlink" title="Writing Data"></a>Writing Data</h3><p><em>Example. Copying a local file to a Hadoop filesystem</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc FileCopyWithProgress Copies a local file to a Hadoop filesystem, and shows progress</span></div><div class="line"><span class="keyword">import</span> java.io.BufferedInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.io.OutputStream;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.Progressable;</div><div class="line"></div><div class="line"><span class="comment">// vv FileCopyWithProgress</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileCopyWithProgress</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    String localSrc = args[<span class="number">0</span>];</div><div class="line">    String dst = args[<span class="number">1</span>];</div><div class="line">    </div><div class="line">    InputStream in = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(localSrc));</div><div class="line">    </div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    FileSystem fs = FileSystem.get(URI.create(dst), conf);</div><div class="line">    OutputStream out = fs.create(<span class="keyword">new</span> Path(dst), <span class="keyword">new</span> Progressable() &#123;</div><div class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">progress</span><span class="params">()</span> </span>&#123;</div><div class="line">        System.out.print(<span class="string">"."</span>);</div><div class="line">      &#125;</div><div class="line">    &#125;);</div><div class="line">    </div><div class="line">    IOUtils.copyBytes(in, out, <span class="number">4096</span>, <span class="keyword">true</span>);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ FileCopyWithProgress</span></div></pre></td></tr></table></figure><p>Typical usage:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">% hadoop FileCopyWithProgress input/docs/<span class="number">1400</span><span class="number">-8.</span>txt</div><div class="line">hdfs:<span class="comment">//localhost/user/tom/1400-8.txt</span></div><div class="line">.................</div></pre></td></tr></table></figure><h3 id="Querying-the-Filesystem"><a href="#Querying-the-Filesystem" class="headerlink" title="Querying the Filesystem"></a>Querying the Filesystem</h3><p>The <code>FileStatus</code> class encapsulates filesystem metadata for files and directories, including file length, block size, replication, modification time, ownership, and permission information.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShowFileStatusTest</span> </span>&#123;</div><div class="line">  <span class="keyword">private</span> MiniDFSCluster cluster; <span class="comment">// use an in-process HDFS cluster for testing</span></div><div class="line">  <span class="keyword">private</span> FileSystem fs;</div><div class="line"></div><div class="line">  <span class="meta">@Before</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUp</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    <span class="keyword">if</span> (System.getProperty(<span class="string">"test.build.data"</span>) == <span class="keyword">null</span>) &#123;</div><div class="line">      System.setProperty(<span class="string">"test.build.data"</span>, <span class="string">"/tmp"</span>);</div><div class="line">    &#125;</div><div class="line">    cluster = <span class="keyword">new</span> MiniDFSCluster.Builder(conf).build();</div><div class="line">    fs = cluster.getFileSystem();</div><div class="line">    OutputStream out = fs.create(<span class="keyword">new</span> Path(<span class="string">"/dir/file"</span>));</div><div class="line">    out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">    out.close();</div><div class="line">  &#125;</div><div class="line"> </div><div class="line">  <span class="meta">@After</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">tearDown</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    <span class="keyword">if</span> (fs != <span class="keyword">null</span>) &#123; fs.close(); &#125;</div><div class="line">    <span class="keyword">if</span> (cluster != <span class="keyword">null</span>) &#123; cluster.shutdown(); &#125;</div><div class="line">  &#125;</div><div class="line"> </div><div class="line">  <span class="meta">@Test</span>(expected = FileNotFoundException.class)</div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">throwsFileNotFoundForNonExistentFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    fs.getFileStatus(<span class="keyword">new</span> Path(<span class="string">"no-such-file"</span>));</div><div class="line">  &#125;</div><div class="line"> </div><div class="line">  <span class="meta">@Test</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fileStatusForFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Path file = <span class="keyword">new</span> Path(<span class="string">"/dir/file"</span>);</div><div class="line">    FileStatus stat = fs.getFileStatus(file);</div><div class="line">    assertThat(stat.getPath().toUri().getPath(), is(<span class="string">"/dir/file"</span>));</div><div class="line">    assertThat(stat.isDirectory(), is(<span class="keyword">false</span>));</div><div class="line">    assertThat(stat.getLen(), is(<span class="number">7L</span>));</div><div class="line">    assertThat(stat.getModificationTime(),</div><div class="line">    is(lessThanOrEqualTo(System.currentTimeMillis())));</div><div class="line">    assertThat(stat.getReplication(), is((<span class="keyword">short</span>) <span class="number">1</span>));</div><div class="line">    assertThat(stat.getBlockSize(), is(<span class="number">128</span> * <span class="number">1024</span> * <span class="number">1024L</span>));</div><div class="line">    assertThat(stat.getOwner(), is(System.getProperty(<span class="string">"user.name"</span>)));</div><div class="line">    assertThat(stat.getGroup(), is(<span class="string">"supergroup"</span>));</div><div class="line">    assertThat(stat.getPermission().toString(), is(<span class="string">"rw-r--r--"</span>));</div><div class="line"> &#125;</div><div class="line"> </div><div class="line">  <span class="meta">@Test</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fileStatusForDirectory</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    Path dir = <span class="keyword">new</span> Path(<span class="string">"/dir"</span>);</div><div class="line">    FileStatus stat = fs.getFileStatus(dir);</div><div class="line">    assertThat(stat.getPath().toUri().getPath(), is(<span class="string">"/dir"</span>));</div><div class="line">    assertThat(stat.isDirectory(), is(<span class="keyword">true</span>));</div><div class="line">    assertThat(stat.getLen(), is(<span class="number">0L</span>));</div><div class="line">    assertThat(stat.getModificationTime(),</div><div class="line">    is(lessThanOrEqualTo(System.currentTimeMillis())));</div><div class="line">    assertThat(stat.getReplication(), is((<span class="keyword">short</span>) <span class="number">0</span>));</div><div class="line">    assertThat(stat.getBlockSize(), is(<span class="number">0L</span>));</div><div class="line">    assertThat(stat.getOwner(), is(System.getProperty(<span class="string">"user.name"</span>)));</div><div class="line">    assertThat(stat.getGroup(), is(<span class="string">"supergroup"</span>));</div><div class="line">    assertThat(stat.getPermission().toString(), is(<span class="string">"rwxr-xr-x"</span>));</div><div class="line">  &#125; </div><div class="line">&#125;</div></pre></td></tr></table></figure><h4 id="Listing-files"><a href="#Listing-files" class="headerlink" title="Listing files"></a>Listing files</h4><p><em>Example. Showing the file statuses for a collection of paths in a Hadoop filesystem</em></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc ListStatus Shows the file statuses for a collection of paths in a Hadoop filesystem </span></div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileUtil;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"></div><div class="line"><span class="comment">// vv ListStatus</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ListStatus</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    String uri = args[<span class="number">0</span>];</div><div class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">    FileSystem fs = FileSystem.get(URI.create(uri), conf);</div><div class="line">    </div><div class="line">    Path[] paths = <span class="keyword">new</span> Path[args.length];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; paths.length; i++) &#123;</div><div class="line">      paths[i] = <span class="keyword">new</span> Path(args[i]);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    FileStatus[] status = fs.listStatus(paths);</div><div class="line">    Path[] listedPaths = FileUtil.stat2Paths(status);</div><div class="line">    <span class="keyword">for</span> (Path p : listedPaths) &#123;</div><div class="line">      System.out.println(p);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ ListStatus</span></div></pre></td></tr></table></figure><p>We can use this program to find the union of directory listings for a collection of paths:</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">% hadoop ListStatus hdfs:<span class="comment">//localhost/ hdfs://localhost/user/tom</span></div><div class="line">hdfs:<span class="comment">//localhost/user</span></div><div class="line">hdfs:<span class="comment">//localhost/user/tom/books</span></div><div class="line">hdfs:<span class="comment">//localhost/user/tom/quangle.txt</span></div></pre></td></tr></table></figure><h2 id="DataFlow"><a href="#DataFlow" class="headerlink" title="DataFlow"></a>DataFlow</h2><h3 id="Anatomy-of-a-File-Read"><a href="#Anatomy-of-a-File-Read" class="headerlink" title="Anatomy of a File Read"></a>Anatomy of a File Read</h3><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch03/hdfs_dataflow_read.png" alt="read"></p><h4 id="Network-Topology-and-Hadoop"><a href="#Network-Topology-and-Hadoop" class="headerlink" title="Network Topology and Hadoop"></a>Network Topology and Hadoop</h4><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch03/hdfs_dataflow_distance.png" alt="distance"></p><p><strong>Mathematically inclined readers will notice that this is an example of a distance metric.</strong></p><h3 id="Anatomy-of-a-File-Write"><a href="#Anatomy-of-a-File-Write" class="headerlink" title="Anatomy of a File Write"></a>Anatomy of a File Write</h3><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch03/hdfs_dataflow_write.png" alt="write"></p><p>A typical replica pipeline:</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch03/hdfs_dataflow_replica.png" alt="replica"></p><h2 id="Coherency-Model"><a href="#Coherency-Model" class="headerlink" title="Coherency Model"></a>Coherency Model</h2><p>After creating a file, it is visible in the filesystem namespace, as expected:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Path p = <span class="keyword">new</span> Path(<span class="string">"p"</span>);</div><div class="line">fs.create(p);</div><div class="line">assertThat(fs.exists(p), is(<span class="keyword">true</span>));</div></pre></td></tr></table></figure><p>However, any content written to the file is not guaranteed to be visible, even if the stream is flushed. So, the file appears to have a length of zero:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Path p = <span class="keyword">new</span> Path(<span class="string">"p"</span>);</div><div class="line">OutputStream out = fs.create(p);</div><div class="line">out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">out.flush();</div><div class="line">assertThat(fs.getFileStatus(p).getLen(), is(<span class="number">0L</span>));</div></pre></td></tr></table></figure><p>HDFS provides a way to force all buffers to be flushed to the datanodes via the hflush() method on FSDataOutputStream. After a successful return from hflush(), HDFS guarantees that the data written up to that point in the file has reached all the datanodes in the write pipeline and is visible to all new readers:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Path p = <span class="keyword">new</span> Path(<span class="string">"p"</span>);</div><div class="line">FSDataOutputStream out = fs.create(p);</div><div class="line">out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">out.hflush();</div><div class="line">assertThat(fs.getFileStatus(p).getLen(), is(((<span class="keyword">long</span>) <span class="string">"content"</span>.length())));</div></pre></td></tr></table></figure><p>Note that hflush() does not guarantee that the datanodes have written the data to disk, only that it’s in the datanodes’ memory (so in the event of a data center power outage, for example, data could be lost). For this stronger guarantee, use hsync() instead.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">FileOutputStream out = <span class="keyword">new</span> FileOutputStream(localFile);</div><div class="line">out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">out.flush(); <span class="comment">// flush to operating system</span></div><div class="line">out.getFD().sync(); <span class="comment">// sync to disk</span></div><div class="line">assertThat(localFile.length(), is(((<span class="keyword">long</span>) <span class="string">"content"</span>.length())));</div></pre></td></tr></table></figure><p>Closing a file in HDFS performs an implicit hflush(), too:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Path p = <span class="keyword">new</span> Path(<span class="string">"p"</span>);</div><div class="line">OutputStream out = fs.create(p);</div><div class="line">out.write(<span class="string">"content"</span>.getBytes(<span class="string">"UTF-8"</span>));</div><div class="line">out.close();</div><div class="line">assertThat(fs.getFileStatus(p).getLen(), is(((<span class="keyword">long</span>) <span class="string">"content"</span>.length())));</div></pre></td></tr></table></figure><h2 id="Parallel-Copying-with-distcp"><a href="#Parallel-Copying-with-distcp" class="headerlink" title="Parallel Copying with distcp"></a>Parallel Copying with distcp</h2><p>One use for distcp is as an efficient replacement for hadoop fs -cp. For example, you can copy one file to another with:</p><p><code>% hadoop distcp file1 file2</code></p><p>You can also copy directories:</p><p><code>% hadoop distcp dir1 dir2</code></p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/18/Hadoop-namenode-not-getting-started/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/18/Hadoop-namenode-not-getting-started/" itemprop="url">Hadoop namenode not getting started</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-18T10:06:40+08:00">2017-04-18 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/18/Hadoop-namenode-not-getting-started/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/18/Hadoop-namenode-not-getting-started/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/18/Hadoop-namenode-not-getting-started/" class="leancloud_visitors" data-flag-title="Hadoop namenode not getting started"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><ol><li>First delete all contents from temporary folder: <code>rm -rf &lt;tmp dir&gt;</code> (my was /usr/local/hadoop/tmp)</li><li>Format the namenode: <code>bin/hadoop namenode -format</code></li><li>Start all processes again<ol><li><code>bin/start-dfs.sh</code></li><li><code>bin/start-yarn.sh</code></li><li><code>bin/mr-jobhistory-daemon.sh start historyserver</code></li></ol></li></ol><p>You may consider rolling back as well using checkpoint (if you had it enabled).</p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/17/Hadoop-ch02-MapReduce-notes/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/17/Hadoop-ch02-MapReduce-notes/" itemprop="url">Hadoop ch02 MapReduce notes</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-17T17:32:26+08:00">2017-04-17 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/17/Hadoop-ch02-MapReduce-notes/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/17/Hadoop-ch02-MapReduce-notes/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/17/Hadoop-ch02-MapReduce-notes/" class="leancloud_visitors" data-flag-title="Hadoop ch02 MapReduce notes"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>首先我们有一个数据集，关于天气的，然后它的每一条记录是这样的：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="number">0057</span></div><div class="line"><span class="number">332130</span> <span class="comment"># USAF weather station identifier</span></div><div class="line"><span class="number">99999</span> <span class="comment"># WBAN weather station identifier</span></div><div class="line"><span class="number">19500101</span> <span class="comment"># observation date</span></div><div class="line"><span class="number">0300</span> <span class="comment"># observation time</span></div><div class="line"><span class="number">4</span></div><div class="line">+<span class="number">51317</span> <span class="comment"># latitude (degrees x 1000)</span></div><div class="line">+<span class="number">02</span>8783 <span class="comment"># longitude (degrees x 1000)</span></div><div class="line">FM-<span class="number">12</span></div><div class="line">+<span class="number">0171</span> <span class="comment"># elevation (meters)</span></div><div class="line"><span class="number">99999</span></div><div class="line">V02<span class="number">0</span></div><div class="line"><span class="number">320</span> <span class="comment"># wind direction (degrees)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line">N</div><div class="line"><span class="number">0072</span></div><div class="line"><span class="number">1</span></div><div class="line"><span class="number">00450</span> <span class="comment"># sky ceiling height (meters)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line">C</div><div class="line">N</div><div class="line"><span class="number">010000</span> <span class="comment"># visibility distance (meters)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line">N</div><div class="line"><span class="number">9</span></div><div class="line">-<span class="number">012</span>8 <span class="comment"># air temperature (degrees Celsius x 10)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line">-<span class="number">013</span>9 <span class="comment"># dew point temperature (degrees Celsius x 10)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div><div class="line"><span class="number">10268</span> <span class="comment"># atmospheric pressure (hectopascals x 10)</span></div><div class="line"><span class="number">1</span> <span class="comment"># quality code</span></div></pre></td></tr></table></figure><p>当然以上数据是经过处理之后的，一开始它长这样：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="number">0067011</span>990999991950051507004...<span class="number">9999999</span>N9+<span class="number">00001</span>+<span class="number">99999999999</span>...</div><div class="line"><span class="number">0043011</span>990999991950051512004...<span class="number">9999999</span>N9+<span class="number">00221</span>+<span class="number">99999999999</span>...</div><div class="line"><span class="number">0043011</span>990999991950051518004...<span class="number">9999999</span>N9-<span class="number">00111</span>+<span class="number">99999999999</span>...</div><div class="line"><span class="number">0043012650</span>999991949032412004...<span class="number">0500001</span>N9+<span class="number">01111</span>+<span class="number">99999999999</span>...</div><div class="line"><span class="number">0043012650</span>999991949032418004...<span class="number">0500001</span>N9+<span class="number">007</span>81+<span class="number">99999999999</span>...</div></pre></td></tr></table></figure><p>Hmmm….</p><p>这个天气数据集按照<code>气象站编号-年份</code>的形式来组织的：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="number">010010</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010014</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010015</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010016</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010017</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010030</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010040</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">0100</span>8<span class="number">0</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010100</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div><div class="line"><span class="number">010150</span>-<span class="number">99999</span>-<span class="number">1990</span>.gz</div></pre></td></tr></table></figure><p>这个原始数据显然用起来不方便，所以按照年份给它聚个类，用了如下方法：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \</div><div class="line">  -D mapred.reduce.tasks=<span class="number">0</span> \</div><div class="line">  -D mapred.map.tasks.speculative.execution=<span class="literal">false</span> \</div><div class="line">  -D mapred.task.timeout=<span class="number">12000000</span> \</div><div class="line">  -input ncdc_files.txt \</div><div class="line">  -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat \</div><div class="line">  -output output \</div><div class="line">  -mapper load_ncdc_map.sh \</div><div class="line">  -file load_ncdc_map.sh</div></pre></td></tr></table></figure><p>然后里面用到的<code>ncdc_files</code>以及<code>load_ncdc_map.sh</code>这两个文件是这样的：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div></pre></td><td class="code"><pre><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1901.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1902.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1903.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1904.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1905.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1906.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1907.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1908.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1909.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1910.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1911.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1912.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1913.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1914.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1915.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1916.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1917.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1918.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1919.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1920.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1921.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1922.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1923.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1924.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1925.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1926.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1927.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1928.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1929.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1930.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1931.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1932.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1933.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1934.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1935.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1936.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1937.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1938.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1939.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1940.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1941.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1942.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1943.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1944.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1945.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1946.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1947.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1948.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1949.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1950.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1951.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1952.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1953.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1954.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1955.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1956.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1957.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1958.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1959.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1960.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1961.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1962.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1963.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1964.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1965.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1966.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1967.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1968.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1969.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1970.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1971.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1972.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1973.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1974.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1975.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1976.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1977.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1978.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1979.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1980.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1981.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1982.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1983.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1984.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1985.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1986.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1987.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1988.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1989.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1990.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1991.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1992.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1993.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1994.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1995.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1996.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1997.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1998.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-1999.tar.bz2</span></div><div class="line">s3n:<span class="comment">//hadoopbook/ncdc/raw/isd-2000.tar.bz2</span></div></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env bash</div><div class="line"></div><div class="line"># NLineInputFormat gives a single line: key is offset, value is S3 URI</div><div class="line">read offset s3file</div><div class="line"></div><div class="line"># Retrieve file from S3 to local disk</div><div class="line">echo "reporter:status:Retrieving $s3file" &gt;&amp;2</div><div class="line">$HADOOP_INSTALL/bin/hadoop fs -get $s3file .</div><div class="line"></div><div class="line"># Un-bzip and un-tar the local file</div><div class="line">target=`basename $s3file .tar.bz2`</div><div class="line">mkdir -p $target</div><div class="line">echo "reporter:status:Un-tarring $s3file to $target" &gt;&amp;2</div><div class="line">tar jxf `basename $s3file` -C $target</div><div class="line"></div><div class="line"># Un-gzip each station file and concat into one file</div><div class="line">echo "reporter:status:Un-gzipping $target" &gt;&amp;2</div><div class="line">for file in $target/*/*</div><div class="line">do</div><div class="line">  gunzip -c $file &gt;&gt; $target.all</div><div class="line">  echo "reporter:status:Processed $file" &gt;&amp;2</div><div class="line">done</div><div class="line"></div><div class="line"># Put gzipped version into HDFS</div><div class="line">echo "reporter:status:Gzipping $target and putting in HDFS" &gt;&amp;2</div><div class="line">gzip -c $target.all | $HADOOP_INSTALL/bin/hadoop fs -put - gz/$target.gz</div></pre></td></tr></table></figure><p>嗯…顺便说一句，这个文件是存在<code>AWS</code>上的，所以想用的话要有一个<code>AWS</code>账号，想要有个账号呢，你得先有个可以支付美刀的信用卡。</p><p>Hmmmmm…</p><p>其实作者给的<code>sample data</code>也挺好的我觉得，<a href="https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc" target="_blank" rel="external">在这里</a>.</p><p>那么我们的问题就是说，找出每一年的最高的温度。先看看不用<code>Hadoop</code>的实现方法，事实证明我<code>shell</code>脚本还是宝刀未老的。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">#!<span class="regexp">/usr/</span>bin/env bash</div><div class="line"><span class="keyword">for</span> year <span class="keyword">in</span> all<span class="comment">/*</span></div><div class="line">do</div><div class="line"> echo -ne `basename $year .gz`"\t"</div><div class="line"> gunzip -c $year | \</div><div class="line"> awk '&#123; temp = substr($0, 88, 5) + 0;</div><div class="line"> q = substr($0, 93, 1);</div><div class="line"> if (temp !=9999 &amp;&amp; q ~ /[01459]/ &amp;&amp; temp &gt; max) max = temp &#125;</div><div class="line"> END &#123; print max &#125;'</div><div class="line">done</div></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">% ./max_temperature.sh</div><div class="line"><span class="number">1901</span> <span class="number">317</span></div><div class="line"><span class="number">1902</span> <span class="number">244</span></div><div class="line"><span class="number">1903</span> <span class="number">289</span></div><div class="line"><span class="number">1904</span> <span class="number">256</span></div><div class="line"><span class="number">1905</span> <span class="number">283</span></div><div class="line">...</div></pre></td></tr></table></figure><p>啊嘞，还不错的样子，但是对于大数据速度还是慢了点儿，所以直接上<code>Hadoop</code>看看。</p><p>对于以上的问题呢，<code>MapReduce</code>是这样解决的</p><p><img src="http://o7ie0tcjk.bkt.clouddn.com/hadoop/ch02/mapred_pipeline.png" alt="mapred_pipeline"></p><p>注意了，上面一行是<code>hadoop</code>的术语，下面呢，其实就是<code>Unix</code>的<code>pipe</code>了，这给我们不用<code>Java</code>来实现提供了可能。</p><p>好了下面开始coding了，拿起键盘就是GAN</p><p>为了实现我们的任务，我们需要三个java文件，一个<code>mapper</code>，一个<code>reducer</code>。这俩是苦工，还要一个监工。</p><p><code>Mapper</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc MaxTemperatureMapper Mapper for maximum temperature example</span></div><div class="line"><span class="comment">// vv MaxTemperatureMapper</span></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxTemperatureMapper</span></span></div><div class="line">  <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; &#123;</div><div class="line"></div><div class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MISSING = <span class="number">9999</span>;</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></div><div class="line">      <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">    </div><div class="line">    String line = value.toString();</div><div class="line">    String year = line.substring(<span class="number">15</span>, <span class="number">19</span>);</div><div class="line">    <span class="keyword">int</span> airTemperature;</div><div class="line">    <span class="keyword">if</span> (line.charAt(<span class="number">87</span>) == <span class="string">'+'</span>) &#123; <span class="comment">// parseInt doesn't like leading plus signs</span></div><div class="line">      airTemperature = Integer.parseInt(line.substring(<span class="number">88</span>, <span class="number">92</span>));</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      airTemperature = Integer.parseInt(line.substring(<span class="number">87</span>, <span class="number">92</span>));</div><div class="line">    &#125;</div><div class="line">    String quality = line.substring(<span class="number">92</span>, <span class="number">93</span>);</div><div class="line">    <span class="keyword">if</span> (airTemperature != MISSING &amp;&amp; quality.matches(<span class="string">"[01459]"</span>)) &#123;</div><div class="line">      context.write(<span class="keyword">new</span> Text(year), <span class="keyword">new</span> IntWritable(airTemperature));</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ MaxTemperatureMapper</span></div></pre></td></tr></table></figure><p><code>Reducer</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc MaxTemperatureReducer Reducer for maximum temperature example</span></div><div class="line"><span class="comment">// vv MaxTemperatureReducer</span></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxTemperatureReducer</span></span></div><div class="line">  <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; &#123;</div><div class="line">  </div><div class="line">  <span class="meta">@Override</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></div><div class="line">      Context context)</div><div class="line">      <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">    </div><div class="line">    <span class="keyword">int</span> maxValue = Integer.MIN_VALUE;</div><div class="line">    <span class="keyword">for</span> (IntWritable value : values) &#123;</div><div class="line">      maxValue = Math.max(maxValue, value.get());</div><div class="line">    &#125;</div><div class="line">    context.write(key, <span class="keyword">new</span> IntWritable(maxValue));</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ MaxTemperatureReducer</span></div></pre></td></tr></table></figure><p><code>Job</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc MaxTemperature Application to find the maximum temperature in the weather dataset</span></div><div class="line"><span class="comment">// vv MaxTemperature</span></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxTemperature</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</div><div class="line">      System.err.println(<span class="string">"Usage: MaxTemperature &lt;input path&gt; &lt;output path&gt;"</span>);</div><div class="line">      System.exit(-<span class="number">1</span>);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    Job job = <span class="keyword">new</span> Job();</div><div class="line">    job.setJarByClass(MaxTemperature.class);</div><div class="line">    job.setJobName(<span class="string">"Max temperature"</span>);</div><div class="line"></div><div class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">    </div><div class="line">    job.setMapperClass(MaxTemperatureMapper.class);</div><div class="line">    job.setReducerClass(MaxTemperatureReducer.class);</div><div class="line"></div><div class="line">    job.setOutputKeyClass(Text.class);</div><div class="line">    job.setOutputValueClass(IntWritable.class);</div><div class="line">    </div><div class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ MaxTemperature</span></div></pre></td></tr></table></figure><p>然后这么运行：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">% <span class="keyword">export</span> HADOOP_CLASSPATH=hadoop-examples.jar</div><div class="line">% hadoop MaxTemperature input/ncdc/sample.txt output</div></pre></td></tr></table></figure><p>但是如果数据量非常大的话，需要在<code>Mapper</code>和<code>Reducer</code>之间传递大量的数据，这个时候可以引入<code>Combiner</code>，它的机理是这样的。假如我有两个<code>mapper</code>，它们的输出结果是这样子的：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">(<span class="number">1950</span>, <span class="number">0</span>)</div><div class="line">(<span class="number">1950</span>, <span class="number">20</span>)</div><div class="line">(<span class="number">1950</span>, <span class="number">10</span>)</div></pre></td></tr></table></figure><p>以及这样子的：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(<span class="number">1950</span>, <span class="number">25</span>)</div><div class="line">(<span class="number">1950</span>, <span class="number">15</span>)</div></pre></td></tr></table></figure><p>如果没有<code>combiner</code>的话，它们会先变成这样子：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(<span class="number">1950</span>, [<span class="number">0</span>, <span class="number">20</span>, <span class="number">10</span>, <span class="number">25</span>, <span class="number">15</span>])</div></pre></td></tr></table></figure><p>然后作为<code>reducer</code>的输入，但是如果加入了<code>combiner</code>的话，相当于上面的问题变成了这样</p><p><code>max(0, 20, 10, 25, 15) = max(max(0, 20, 10), max(25, 15)) = max(20, 25) = 25</code></p><p>是不是简单多了。但是注意了，并不是所有的问题都是这样，比如下面这个问题：</p><p><code>mean(0, 20, 10, 25, 15) = 14</code></p><p><code>mean(mean(0, 20, 10), mean(25, 15)) = mean(10, 20) = 15</code></p><p>所以说要根据具体情况来定，不能直接套用。</p><p>好了我们继续<code>combiner</code>的话题，我们怎么把这货加到<code>hadoop</code>的流程中去呢，其实很简单，这样就可以：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// cc MaxTemperatureWithCombiner Application to find the maximum temperature, using a combiner function for efficiency</span></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line"><span class="comment">// vv MaxTemperatureWithCombiner</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxTemperatureWithCombiner</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">    <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</div><div class="line">      System.err.println(<span class="string">"Usage: MaxTemperatureWithCombiner &lt;input path&gt; "</span> +</div><div class="line">          <span class="string">"&lt;output path&gt;"</span>);</div><div class="line">      System.exit(-<span class="number">1</span>);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    Job job = <span class="keyword">new</span> Job();</div><div class="line">    job.setJarByClass(MaxTemperatureWithCombiner.class);</div><div class="line">    job.setJobName(<span class="string">"Max temperature"</span>);</div><div class="line"></div><div class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">    </div><div class="line">    job.setMapperClass(MaxTemperatureMapper.class);</div><div class="line">    <span class="comment">/*[*/</span>job.setCombinerClass(MaxTemperatureReducer.class)<span class="comment">/*]*/</span>;</div><div class="line">    job.setReducerClass(MaxTemperatureReducer.class);</div><div class="line"></div><div class="line">    job.setOutputKeyClass(Text.class);</div><div class="line">    job.setOutputValueClass(IntWritable.class);</div><div class="line">    </div><div class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// ^^ MaxTemperatureWithCombiner</span></div></pre></td></tr></table></figure><p>没错，<code>combiner</code>和<code>reducer</code>是一样的。其实仔细想想这也很自然，因为它们俩实际实现的功能是一样的。</p><h2 id="Hadoop-Streaming"><a href="#Hadoop-Streaming" class="headerlink" title="Hadoop Streaming"></a>Hadoop Streaming</h2><p>作为一个<code>machine learning</code>专业的，有时候用<code>Java</code>还是感觉挺不爽的，哪有<code>Python</code>啊，<code>Ruby</code>啊这种脚本语言方便嘛。所以<code>hadoop</code>还是很人性地提供了解决方法，就是标题所表示的技术。直接看代码怎么用吧。</p><h3 id="Ruby"><a href="#Ruby" class="headerlink" title="Ruby"></a>Ruby</h3><p><code>Map</code></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env ruby</span></div><div class="line"></div><div class="line">STDIN.each_line <span class="keyword">do</span> <span class="params">|line|</span></div><div class="line">  val = line</div><div class="line">  year, temp, q = val[<span class="number">15</span>,<span class="number">4</span>], val[<span class="number">87</span>,<span class="number">5</span>], val[<span class="number">92</span>,<span class="number">1</span>]</div><div class="line">  puts <span class="string">"<span class="subst">#&#123;year&#125;</span>\t<span class="subst">#&#123;temp&#125;</span>"</span> <span class="keyword">if</span> (temp != <span class="string">"+9999"</span> &amp;&amp; q =~ <span class="regexp">/[01459]/</span>)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure><p><code>Reduce</code></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env ruby</span></div><div class="line"></div><div class="line">last_key, max_val = <span class="literal">nil</span>, -<span class="number">1000000</span></div><div class="line">STDIN.each_line <span class="keyword">do</span> <span class="params">|line|</span></div><div class="line">  key, val = line.split(<span class="string">"\t"</span>)</div><div class="line">  <span class="keyword">if</span> last_key &amp;&amp; last_key != key</div><div class="line">    puts <span class="string">"<span class="subst">#&#123;last_key&#125;</span>\t<span class="subst">#&#123;max_val&#125;</span>"</span></div><div class="line">    last_key, max_val = key, val.to_i</div><div class="line">  <span class="keyword">else</span></div><div class="line">    last_key, max_val = key, [max_val, val.to_i].max</div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line">puts <span class="string">"<span class="subst">#&#123;last_key&#125;</span>\t<span class="subst">#&#123;max_val&#125;</span>"</span> <span class="keyword">if</span> last_key</div></pre></td></tr></table></figure><p>然后这样调用：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">% hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \</div><div class="line"> -input input/ncdc/sample.txt \</div><div class="line"> -output output \</div><div class="line"> -mapper ch02-mr-intro/src/main/ruby/max_temperature_map.rb \</div><div class="line"> -reducer ch02-mr-intro/src/main/ruby/max_temperature_reduce.rb</div></pre></td></tr></table></figure><p>是不是很方便？如果要加上<code>combiner</code>的话，更方便了，都不用再写额外的文件：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">% hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \</div><div class="line"> -files ch02-mr-intro/src/main/ruby/max_temperature_map.rb,\</div><div class="line">ch02-mr-intro/src/main/ruby/max_temperature_reduce.rb \</div><div class="line"> -input input/ncdc/all \</div><div class="line"> -output output \</div><div class="line"> -mapper ch02-mr-intro/src/main/ruby/max_temperature_map.rb \</div><div class="line"> -combiner ch02-mr-intro/src/main/ruby/max_temperature_reduce.rb \</div><div class="line"> -reducer ch02-mr-intro/src/main/ruby/max_temperature_reduce.rb</div></pre></td></tr></table></figure><p>注意，以上的<code>-files</code>命令是为了在集群环境下运行时，将脚本复制到各子节点上。</p><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>啊，<code>Python</code>大大出场，其实和<code>Ruby</code>没啥区别。</p><p><code>Map</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">  val = line.strip()</div><div class="line">  (year, temp, q) = (val[<span class="number">15</span>:<span class="number">19</span>], val[<span class="number">87</span>:<span class="number">92</span>], val[<span class="number">92</span>:<span class="number">93</span>])</div><div class="line">  <span class="keyword">if</span> (temp != <span class="string">"+9999"</span> <span class="keyword">and</span> re.match(<span class="string">"[01459]"</span>, q)):</div><div class="line">    <span class="keyword">print</span> <span class="string">"%s\t%s"</span> % (year, temp)</div></pre></td></tr></table></figure><p><code>Reduce</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line">(last_key, max_val) = (<span class="keyword">None</span>, -sys.maxint)</div><div class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</div><div class="line">  (key, val) = line.strip().split(<span class="string">"\t"</span>)</div><div class="line">  <span class="keyword">if</span> last_key <span class="keyword">and</span> last_key != key:</div><div class="line">    <span class="keyword">print</span> <span class="string">"%s\t%s"</span> % (last_key, max_val)</div><div class="line">    (last_key, max_val) = (key, int(val))</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    (last_key, max_val) = (key, max(max_val, int(val)))</div><div class="line"></div><div class="line"><span class="keyword">if</span> last_key:</div><div class="line">  <span class="keyword">print</span> <span class="string">"%s\t%s"</span> % (last_key, max_val)</div></pre></td></tr></table></figure><p>运行都是一样的，就不多做赘述了。</p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/16/Machine-Learning-ECNU-Assignment-1/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/04/16/Machine-Learning-ECNU-Assignment-1/" itemprop="url">Machine Learning [ECNU] Assignment 1</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-04-16T13:04:17+08:00">2017-04-16 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/04/16/Machine-Learning-ECNU-Assignment-1/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/04/16/Machine-Learning-ECNU-Assignment-1/" itemprop="commentsCount"></span> </a></span><span id="/2017/04/16/Machine-Learning-ECNU-Assignment-1/" class="leancloud_visitors" data-flag-title="Machine Learning [ECNU] Assignment 1"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p><strong>Use a crawler to get at least 20 webpages from a website.</strong></p><p><strong>Count theoccurrences of words in the webpages on Hadoop.</strong></p><p>Hand in:</p><ol><li>Each one should crawl different websites, list the website URL, as well as the URLsof the crawled webpages.</li><li><p>Count the word occurrence on Hadoop, code in both JAVA and another language such asPig Latin. print out your code.</p></li><li><p>Print out your result.</p></li></ol><p>Home work due: <strong>4/12</strong></p><p>You are allowed toform a group of no more than 4 fellow students.</p><p><a href="https://github.com/ewanlee/machine-learning-ECNU-/blob/master/Hadoop%20wordcount%20demo_cutted.pdf" target="_blank" rel="external">https://github.com/ewanlee/machine-learning-ECNU-/blob/master/Hadoop%20wordcount%20demo_cutted.pdf</a></p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></section><nav class="pagination"><a class="extend prev" rel="prev" href="/page/17/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><span class="page-number current">18</span><a class="page-number" href="/page/19/">19</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><a class="extend next" rel="next" href="/page/19/"><i class="fa fa-angle-right"></i></a></nav></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ewan Li"><p class="site-author-name" itemprop="name">Ewan Li</p><p class="site-description motion-element" itemprop="description">Ewan's IT Blog</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">128</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">63</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/ewanlee" target="_blank" title="Github"><i class="fa fa-fw fa-globe"></i> Github </a></span><span class="links-of-author-item"><a href="http://weibo.com/3946248928/profile?topnav=1&wvr=6" target="_blank" title="Weibo"><i class="fa fa-fw fa-weibo"></i> Weibo</a></span></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Ewan Li</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user">本站访客数</i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人次</span> <span class="site-pv"><i class="fa fa-eye">本站总访问量</i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">_hcwp=window._hcwp||[],_hcwp.push({widget:"Bloggerstream",widget_id:89825,selector:".hc-comment-count",label:"{%COUNT%}"}),function(){if(!("HC_LOAD_INIT"in window)){HC_LOAD_INIT=!0;var t=(navigator.language||navigator.systemLanguage||navigator.userLanguage||"en").substr(0,2).toLowerCase(),e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src=("https:"==document.location.protocol?"https":"http")+"://w.hypercomments.com/widget/hc/89825/"+t+"/widget.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n.nextSibling)}}()</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("e27VKX5tTklQLCtF7iNMmhcA-gzGzoHsz","nnQn2znNgXXEdK7W2bVJ3bfK")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script></body></html>