<!doctype html><html class="theme-next mist use-motion" lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="Hexo, NexT"><link rel="alternate" href="/atom.xml" title="Abracadabra" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="Ewan&apos;s IT Blog"><meta property="og:type" content="website"><meta property="og:title" content="Abracadabra"><meta property="og:url" content="http://yoursite.com/page/3/index.html"><meta property="og:site_name" content="Abracadabra"><meta property="og:description" content="Ewan&apos;s IT Blog"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Abracadabra"><meta name="twitter:description" content="Ewan&apos;s IT Blog"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post"},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/page/3/"><title>Abracadabra</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?dc405a79ad500922134d14cdf288f646";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container one-collumn sidebar-position-left page-home"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Abracadabra</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Do it yourself</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><section id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/11/Get-financial-data-from-Tushare/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2018/04/11/Get-financial-data-from-Tushare/" itemprop="url">Get financial data from Tushare</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-11T19:42:46+08:00">2018-04-11 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/04/11/Get-financial-data-from-Tushare/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2018/04/11/Get-financial-data-from-Tushare/" itemprop="commentsCount"></span> </a></span><span id="/2018/04/11/Get-financial-data-from-Tushare/" class="leancloud_visitors" data-flag-title="Get financial data from Tushare"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>TuShare is a famous free, open source python financial data interface package. Its official home page is: <a href="http://tushare.waditu.com/" target="_blank" rel="external">TuShare - financial data interface package</a>. The interface package now provides a large amount of financial data covering a wide range of data such as stocks, fundamentals, macros, news, etc. (Please check the official website for details) and keep updating. At present, the length of the stock’s data is three years. Although it is a bit short, it can basically meet the needs of quantitative beginners for testing.</p><h1 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h1><h2 id="Install-and-Import"><a href="#Install-and-Import" class="headerlink" title="Install and Import"></a>Install and Import</h2><p><strong>You need to install first:</strong></p><ul><li>Pandas</li><li>lxml</li></ul><p><strong>Two way to install tushare:</strong></p><ol><li><code>pip install tushare</code></li><li>visit <a href="https://pypi.python.org/pypi/Tushare/" target="_blank" rel="external">https://pypi.python.org/pypi/Tushare/</a>, download and install</li></ol><p><strong>How to update:</strong></p><p><code>pip install tushare --upgrade</code></p><p><strong>Import package and view package version:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tushare</div><div class="line"></div><div class="line">print(tushare.__version__)</div></pre></td></tr></table></figure><h2 id="Use-some-simple-function"><a href="#Use-some-simple-function" class="headerlink" title="Use some simple function"></a>Use some simple function</h2><h3 id="Stock-data"><a href="#Stock-data" class="headerlink" title="Stock data"></a>Stock data</h3><p><strong>update：Many of the quotes returned by the <code>get_hist_data</code> function are wrong, but both <code>get_h_data</code> and <code>get_k_data</code> can be used</strong></p><p>We should still master how to use <code>tushare</code> to obtain stock market data, using the <code>ts.get_hist_data()</code> function whose <strong>input parameters</strong> are:</p><ul><li><strong>code: </strong>Stock code, ie 6-digit code, or index code (sh = Shanghai index sz = Shenzhen index hs300 = CSI 300 index sz50 = SSE 50 zxb = small and medium board cyb = board)</li><li><strong>start: </strong>Start date, format YYYY-MM-DD</li><li><strong>end: </strong>End date, format YYYY-MM-DD</li><li><strong>ktype: </strong>Data type, D = day k line W = week M = month 5 = 5 minutes 15 = 15 minutes 30 = 30 minutes 60 = 60 minutes, the default is D</li><li><strong>retry_count: </strong>The number of retries after the network is abnormal. The default is 3</li><li><strong>pause: </strong>Pause seconds when retrying, default is 0</li></ul><p><strong>Return values:</strong></p><ul><li><strong>date</strong>：date</li><li><strong>open</strong>：Opening price</li><li><strong>high</strong>：Highest price</li><li><strong>close</strong>：Closing price</li><li><strong>low</strong>：Lowest price</li><li><strong>volume</strong>：Volume</li><li><strong>price_change</strong>：price fluncuation</li><li><strong>p_change</strong>：Quote change</li><li><strong>ma5</strong>：5-day average price</li><li><strong>ma10</strong>：10-day average price</li><li><strong>ma20</strong>: 20-day average price</li><li><strong>v_ma5</strong>: 5-day average volume</li><li><strong>v_ma10</strong>: 10-day average volume</li><li><strong>v_ma20</strong>: 20-day average volume</li><li><strong>turnover</strong>: Change in hand rate [Note: Index does not have this item]</li></ul><h4 id="Specific-examples"><a href="#Specific-examples" class="headerlink" title="Specific examples:"></a>Specific examples:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">ts.get_hist_data(<span class="string">'600848'</span>)</div><div class="line"></div><div class="line"> date       open    high   close     low     volume    p_change   ma5    </div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-11</span>   <span class="number">6.880</span>   <span class="number">7.380</span>   <span class="number">7.060</span>   <span class="number">6.880</span>   <span class="number">14129.96</span>     <span class="number">2.62</span>   <span class="number">7.060</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-12</span>   <span class="number">7.050</span>   <span class="number">7.100</span>   <span class="number">6.980</span>   <span class="number">6.900</span>    <span class="number">7895.19</span>    <span class="number">-1.13</span>   <span class="number">7.020</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-13</span>   <span class="number">6.950</span>   <span class="number">7.000</span>   <span class="number">6.700</span>   <span class="number">6.690</span>    <span class="number">6611.87</span>    <span class="number">-4.01</span>   <span class="number">6.913</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-16</span>   <span class="number">6.680</span>   <span class="number">6.750</span>   <span class="number">6.510</span>   <span class="number">6.480</span>    <span class="number">2941.63</span>    <span class="number">-2.84</span>   <span class="number">6.813</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-17</span>   <span class="number">6.660</span>   <span class="number">6.880</span>   <span class="number">6.860</span>   <span class="number">6.460</span>    <span class="number">8642.57</span>     <span class="number">5.38</span>   <span class="number">6.822</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-18</span>   <span class="number">7.000</span>   <span class="number">7.300</span>   <span class="number">6.890</span>   <span class="number">6.880</span>   <span class="number">13075.40</span>     <span class="number">0.44</span>   <span class="number">6.788</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-19</span>   <span class="number">6.690</span>   <span class="number">6.950</span>   <span class="number">6.890</span>   <span class="number">6.680</span>    <span class="number">6117.32</span>     <span class="number">0.00</span>   <span class="number">6.770</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-20</span>   <span class="number">6.870</span>   <span class="number">7.080</span>   <span class="number">7.010</span>   <span class="number">6.870</span>    <span class="number">6813.09</span>     <span class="number">1.74</span>   <span class="number">6.832</span></div><div class="line"></div><div class="line">date         ma10    ma20      v_ma5     v_ma10     v_ma20     turnover</div><div class="line"></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-11</span>   <span class="number">7.060</span>   <span class="number">7.060</span>   <span class="number">14129.96</span>   <span class="number">14129.96</span>   <span class="number">14129.96</span>     <span class="number">0.48</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-12</span>   <span class="number">7.020</span>   <span class="number">7.020</span>   <span class="number">11012.58</span>   <span class="number">11012.58</span>   <span class="number">11012.58</span>     <span class="number">0.27</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-13</span>   <span class="number">6.913</span>   <span class="number">6.913</span>    <span class="number">9545.67</span>    <span class="number">9545.67</span>    <span class="number">9545.67</span>     <span class="number">0.23</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-16</span>   <span class="number">6.813</span>   <span class="number">6.813</span>    <span class="number">7894.66</span>    <span class="number">7894.66</span>    <span class="number">7894.66</span>     <span class="number">0.10</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-17</span>   <span class="number">6.822</span>   <span class="number">6.822</span>    <span class="number">8044.24</span>    <span class="number">8044.24</span>    <span class="number">8044.24</span>     <span class="number">0.30</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-18</span>   <span class="number">6.833</span>   <span class="number">6.833</span>    <span class="number">7833.33</span>    <span class="number">8882.77</span>    <span class="number">8882.77</span>     <span class="number">0.45</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-19</span>   <span class="number">6.841</span>   <span class="number">6.841</span>    <span class="number">7477.76</span>    <span class="number">8487.71</span>    <span class="number">8487.71</span>     <span class="number">0.21</span></div><div class="line"><span class="number">2012</span><span class="number">-01</span><span class="number">-20</span>   <span class="number">6.863</span>   <span class="number">6.863</span>    <span class="number">7518.00</span>    <span class="number">8278.38</span>    <span class="number">8278.38</span>     <span class="number">0.23</span></div></pre></td></tr></table></figure><p>You can also set the start time and end time of historical data:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">ts.get_hist_data(<span class="string">'600848'</span>,start=<span class="string">'2015-01-05'</span>,end=<span class="string">'2015-01-09'</span>)</div><div class="line"></div><div class="line"> date       open    high   close     low    volume   p_change   ma5    ma10</div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">11.160</span>  <span class="number">11.390</span>  <span class="number">11.260</span>  <span class="number">10.890</span>  <span class="number">46383.57</span>     <span class="number">1.26</span>  <span class="number">11.156</span>  <span class="number">11.212</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">11.130</span>  <span class="number">11.660</span>  <span class="number">11.610</span>  <span class="number">11.030</span>  <span class="number">59199.93</span>     <span class="number">3.11</span>  <span class="number">11.182</span>  <span class="number">11.155</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-07</span>  <span class="number">11.580</span>  <span class="number">11.990</span>  <span class="number">11.920</span>  <span class="number">11.480</span>  <span class="number">86681.38</span>     <span class="number">2.67</span>  <span class="number">11.366</span>  <span class="number">11.251</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-08</span>  <span class="number">11.700</span>  <span class="number">11.920</span>  <span class="number">11.670</span>  <span class="number">11.640</span>  <span class="number">56845.71</span>    <span class="number">-2.10</span>  <span class="number">11.516</span>  <span class="number">11.349</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-09</span>  <span class="number">11.680</span>  <span class="number">11.710</span>  <span class="number">11.230</span>  <span class="number">11.190</span>  <span class="number">44851.56</span>    <span class="number">-3.77</span>  <span class="number">11.538</span>  <span class="number">11.363</span></div><div class="line"> date        ma20     v_ma5    v_ma10     v_ma20      turnover</div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-05</span>  <span class="number">11.198</span>  <span class="number">58648.75</span>  <span class="number">68429.87</span>   <span class="number">97141.81</span>     <span class="number">1.59</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-06</span>  <span class="number">11.382</span>  <span class="number">54854.38</span>  <span class="number">63401.05</span>   <span class="number">98686.98</span>     <span class="number">2.03</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-07</span>  <span class="number">11.543</span>  <span class="number">55049.74</span>  <span class="number">61628.07</span>  <span class="number">103010.58</span>     <span class="number">2.97</span></div><div class="line"><span class="number">2015</span><span class="number">-01</span><span class="number">-08</span>  <span class="number">11.647</span>  <span class="number">57268.99</span>  <span class="number">61376.00</span>  <span class="number">105823.50</span>     <span class="number">1.95</span></div></pre></td></tr></table></figure><p>Others:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'W'</span>) <span class="comment"># Get weekly k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'M'</span>) <span class="comment"># Get monthly k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'5'</span>) <span class="comment"># Get 5 minutes k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'15'</span>) <span class="comment"># Get 15 minutes k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'30'</span>) <span class="comment"># Get 30 minutes k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'600848'</span>, ktype=<span class="string">'60'</span>) <span class="comment"># Get 60 minutes k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'sh'</span>）<span class="comment"># Get data on the Shanghai index k-line, other parameters consistent with the stocks, the same below</span></div><div class="line">ts.get_hist_data(<span class="string">'sz'</span>）<span class="comment"># Get Shenzhen Chengzhi k line data</span></div><div class="line">ts.get_hist_data(<span class="string">'hs300'</span>）<span class="comment"># Get the CSI 300 k line data</span></div><div class="line">ts.get_hist_data(<span class="string">'sz50'</span>）<span class="comment"># Get SSE 50 Index k-line data</span></div><div class="line">ts.get_hist_data(<span class="string">'zxb'</span>）<span class="comment"># Get the k-line data of small and medium board indices</span></div><div class="line">ts.get_hist_data(<span class="string">'cyb'</span>）<span class="comment"># Get GEM Index k-line data</span></div></pre></td></tr></table></figure><h3 id="Fundamental-data"><a href="#Fundamental-data" class="headerlink" title="Fundamental data"></a>Fundamental data</h3><p>With <code>tushare</code> we can also get fundamental data through <code>ts.get_stock_basics()</code> (shown in the results section):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">ts.get_stock_basics()</div><div class="line"></div><div class="line">code    name      industry  area     pe     outstanding    totals   totalAssets                                                                   </div><div class="line"><span class="number">300563</span>    N神宇  通信设备   江苏    <span class="number">26.73</span>      <span class="number">2000.00</span>     <span class="number">8000.00</span>  <span class="number">4.216000e+04</span>   </div><div class="line"><span class="number">601882</span>   海天精工     机床制造   浙江    <span class="number">26.83</span>      <span class="number">5220.00</span>    <span class="number">52200.00</span>  <span class="number">1.877284e+05</span> </div><div class="line"><span class="number">601880</span>    大连港       港口   辽宁    <span class="number">76.40</span>    <span class="number">773582.00</span>  <span class="number">1289453.63</span>  <span class="number">3.263012e+06</span>   </div><div class="line"><span class="number">300556</span>   丝路视觉     软件服务   深圳   <span class="number">101.38</span>      <span class="number">2780.00</span>    <span class="number">11113.33</span>  <span class="number">4.448248e+04</span> </div><div class="line"><span class="number">600528</span>   中铁二局     建筑施工   四川   <span class="number">149.34</span>    <span class="number">145920.00</span>   <span class="number">145920.00</span>  <span class="number">5.709568e+06</span> </div><div class="line"><span class="number">002495</span>   佳隆股份       食品   广东   <span class="number">202.12</span>     <span class="number">66611.13</span>    <span class="number">93562.56</span>  <span class="number">1.169174e+05</span> </div><div class="line"><span class="number">600917</span>   重庆燃气     供气供热   重庆    <span class="number">76.87</span>     <span class="number">15600.00</span>   <span class="number">155600.00</span>  <span class="number">8.444600e+05</span> </div><div class="line"><span class="number">002752</span>   昇兴股份     广告包装   福建    <span class="number">75.14</span>     <span class="number">12306.83</span>    <span class="number">63000.00</span>  <span class="number">2.387493e+05</span> </div><div class="line"><span class="number">002346</span>   柘中股份     电气设备   上海   <span class="number">643.97</span>      <span class="number">7980.00</span>    <span class="number">44157.53</span>  <span class="number">2.263010e+05</span> </div><div class="line"><span class="number">000680</span>   山推股份     工程机械   山东     <span class="number">0.00</span>    <span class="number">105694.97</span>   <span class="number">124078.75</span>  <span class="number">9.050701e+05</span></div><div class="line">...</div></pre></td></tr></table></figure><h3 id="Macro-data"><a href="#Macro-data" class="headerlink" title="Macro data"></a>Macro data</h3><p>We use the resident consumer index as an example, which can be obtained through the <code>ts.get_cpi()</code> function (it will get 322 items at a time, some of them will be displayed):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> ts.get_cpi()</div><div class="line"></div><div class="line">       month     cpi</div><div class="line"><span class="number">0</span>    <span class="number">2016.10</span>  <span class="number">102.10</span></div><div class="line"><span class="number">1</span>     <span class="number">2016.9</span>  <span class="number">101.90</span></div><div class="line"><span class="number">2</span>     <span class="number">2016.8</span>  <span class="number">101.34</span></div><div class="line"><span class="number">3</span>     <span class="number">2016.7</span>  <span class="number">101.77</span></div><div class="line"><span class="number">4</span>     <span class="number">2016.6</span>  <span class="number">101.88</span></div><div class="line"><span class="number">5</span>     <span class="number">2016.5</span>  <span class="number">102.04</span></div><div class="line"><span class="number">6</span>     <span class="number">2016.4</span>  <span class="number">102.33</span></div><div class="line"><span class="number">7</span>     <span class="number">2016.3</span>  <span class="number">102.30</span></div><div class="line"><span class="number">8</span>     <span class="number">2016.2</span>  <span class="number">102.28</span></div><div class="line"><span class="number">9</span>     <span class="number">2016.1</span>  <span class="number">101.75</span></div><div class="line"><span class="number">10</span>   <span class="number">2015.12</span>  <span class="number">101.64</span></div><div class="line">...</div></pre></td></tr></table></figure><h3 id="Recent-news"><a href="#Recent-news" class="headerlink" title="Recent news"></a>Recent news</h3><p>The <code>tushare</code> package can use the <code>ts.get_latest_news()</code> function to view the latest news, and it will return 80. For reasons of space, we only show the first 15 here. We can see that it is all Sina Finance’s news data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> ts.get_latest_news();</div><div class="line"></div><div class="line">   classify                         title         time  \</div><div class="line"><span class="number">0</span>        美股            “特朗普通胀”预期升温 美国国债下挫  <span class="number">11</span><span class="number">-14</span> <span class="number">23</span>:<span class="number">10</span>   </div><div class="line"><span class="number">1</span>        美股          特朗普：脸书、推特等社交媒体助我入主白宫  <span class="number">11</span><span class="number">-14</span> <span class="number">23</span>:<span class="number">10</span>   </div><div class="line"><span class="number">2</span>        证券                <span class="number">11</span>月<span class="number">14</span>日晚增减持每日速览  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">54</span>   </div><div class="line"><span class="number">3</span>        美股          财经观察：日本为何急于推动TPP批准程序  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">54</span>   </div><div class="line"><span class="number">4</span>        美股              新总统谜题：特朗普会连续加息吗？  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">52</span>   </div><div class="line"><span class="number">5</span>        证券      神州专车财报遭质疑 增发<span class="number">100</span>亿股东退出需<span class="number">50</span>年  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">41</span>   </div><div class="line"><span class="number">6</span>        证券           恒大闪电杀回马枪锁仓半年 戒短炒了吗？  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">38</span>   </div><div class="line"><span class="number">7</span>      国内财经         楼继伟力推改革做派 或加快国有资本划拨社保  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">36</span>   </div><div class="line"><span class="number">8</span>        美股            开盘：美股周一小幅高开 延续上周涨势  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">32</span>   </div><div class="line"><span class="number">9</span>        美股            喜达屋创始人：当好总统就要走中庸之道  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">24</span>   </div><div class="line"><span class="number">10</span>       证券              北京高华：将乐视网评级下调至中性  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">09</span>   </div><div class="line"><span class="number">11</span>       美股             <span class="number">11</span>月<span class="number">14</span>日<span class="number">22</span>点交易员正关注要闻  <span class="number">11</span><span class="number">-14</span> <span class="number">22</span>:<span class="number">02</span>   </div><div class="line"><span class="number">12</span>       美股           摩根大通：新兴市场股市、货币的前景悲观  <span class="number">11</span><span class="number">-14</span> <span class="number">21</span>:<span class="number">55</span>   </div><div class="line"><span class="number">13</span>     国内财经        人民日报刊文谈全面深化改革这三年：啃下硬骨头  <span class="number">11</span><span class="number">-14</span> <span class="number">21</span>:<span class="number">46</span>   </div><div class="line"><span class="number">14</span>       证券       泽平宏观：经济L型延续 地产销量回落投资超预期  <span class="number">11</span><span class="number">-14</span> <span class="number">21</span>:<span class="number">43</span>   </div><div class="line"><span class="number">15</span>       证券       黄燕铭等五大券商大佬告诉你 <span class="number">2017</span>年买点啥？  <span class="number">11</span><span class="number">-14</span> <span class="number">21</span>:<span class="number">41</span>   </div><div class="line"></div><div class="line">url  </div><div class="line"><span class="number">0</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">1</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">2</span>   http://finance.sina.com.cn/stock/y/<span class="number">2016</span><span class="number">-11</span><span class="number">-14</span>/...  </div><div class="line"><span class="number">3</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">4</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">5</span>   http://finance.sina.com.cn/stock/marketresearc...  </div><div class="line"><span class="number">6</span>   http://finance.sina.com.cn/stock/marketresearc...  </div><div class="line"><span class="number">7</span>   http://finance.sina.com.cn/china/gncj/<span class="number">2016</span><span class="number">-11</span>-...  </div><div class="line"><span class="number">8</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">9</span>   http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">10</span>  http://finance.sina.com.cn/stock/s/<span class="number">2016</span><span class="number">-11</span><span class="number">-14</span>/...  </div><div class="line"><span class="number">11</span>  http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">12</span>  http://finance.sina.com.cn/stock/usstock/c/<span class="number">201.</span>..  </div><div class="line"><span class="number">13</span>  http://finance.sina.com.cn/china/gncj/<span class="number">2016</span><span class="number">-11</span>-...  </div><div class="line"><span class="number">14</span>  http://finance.sina.com.cn/stock/marketresearc...  </div><div class="line"><span class="number">15</span>  http://finance.sina.com.cn/stock/marketresearc...</div></pre></td></tr></table></figure></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/" itemprop="url">A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-10T16:34:47+08:00">2018-04-10 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/" itemprop="commentsCount"></span> </a></span><span id="/2018/04/10/A-Brief-History-of-CNNs-in-Image-Segmentation-From-R-CNN-to-Mask-R-CNN/" class="leancloud_visitors" data-flag-title="A Brief History of CNNs in Image Segmentation: From R-CNN to Mask R-CNN"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>Ever since <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="external">Alex Krizhevsky, Geoff Hinton, and Ilya Sutskever won ImageNet in 2012</a>, Convolutional Neural Networks(CNNs) have become the gold standard for image classification. In fact, since then, CNNs have improved to the point where they now outperform humans on the ImageNet challenge!</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*bGTawFxQwzc5yV1_szDrwQ.png" alt="img"></p><p>CNNs now outperform humans on the ImageNet challenge. The y-axis in the above graph is the error rate on ImageNet.</p><p>While these results are impressive, image classification is far simpler than the complexity and diversity of true human visual understanding.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*8GVucX9yhnL21KCtcyFDRQ.png" alt="img"></p><p>An example of an image used in the classification challenge. Note how the image is well framed and has just one object.</p><p>In classification, there’s generally an image with a single object as the focus and the task is to say what that image is (see above). But when we look at the world around us, we carry out far more complex tasks.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*eJjj2TVUVZDiVSTcnzh7fA.png" alt="img"></p><p>Sights in real life are often composed of a multitude of different, overlapping objects, backgrounds, and actions.</p><p>We see complicated sights with multiple overlapping objects, and different backgrounds and we not only classify these different objects but also identify their boundaries, differences, and relations to one another!</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*NdwfHMrW3rpj5SW_VQtWVw.png" alt="img"></p><p>In image segmentation, our goal is to classify the different objects in the image, and identify their boundaries. Source: Mask R-CNN paper.</p><p>Can CNNs help us with such complex tasks? Namely, given a more complicated image, can we use CNNs to identify the different objects in the image, and their boundaries? As has been shown by Ross Girshick and his peers over the last few years, the answer is conclusively yes.</p><h4 id="Goals-of-this-Post"><a href="#Goals-of-this-Post" class="headerlink" title="Goals of this Post"></a>Goals of this Post</h4><p>Through this post, we’ll cover the intuition behind some of the main techniques used in object detection and segmentation and see how they’ve evolved from one implementation to the next. In particular, we’ll cover R-CNN (Regional CNN), the original application of CNNs to this problem, along with its descendants Fast R-CNN, and Faster R-CNN. Finally, we’ll cover Mask R-CNN, a paper released recently by Facebook Research that extends such object detection techniques to provide pixel level segmentation. Here are the papers referenced in this post:</p><ol><li>R-CNN: <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="external">https://arxiv.org/abs/1311.2524</a></li><li>Fast R-CNN: <a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="external">https://arxiv.org/abs/1504.08083</a></li><li>Faster R-CNN: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a></li><li>Mask R-CNN: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a></li></ol><hr><h4 id="2014-R-CNN-An-Early-Application-of-CNNs-to-Object-Detection"><a href="#2014-R-CNN-An-Early-Application-of-CNNs-to-Object-Detection" class="headerlink" title="2014: R-CNN - An Early Application of CNNs to Object Detection"></a>2014: R-CNN - An Early Application of CNNs to Object Detection</h4><p><img src="https://cdn-images-1.medium.com/max/1000/1*r9ELExnk1B1zHnRReDW9Ow.png" alt="img"></p><p>Object detection algorithms such as R-CNN take in an image and identify the locations and classifications of the main objects in the image. Source: <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="external">https://arxiv.org/abs/1311.2524</a>.</p><p>Inspired by the research of Hinton’s lab at the University of Toronto, a small team at UC Berkeley, led by Professor Jitendra Malik, asked themselves what today seems like an inevitable question:</p><blockquote><p>To what extent do [Krizhevsky et. al’s results] generalize to object detection?</p></blockquote><p>Object detection is the task of finding the different objects in an image and classifying them (as seen in the image above). The team, comprised of Ross Girshick (a name we’ll see again), Jeff Donahue, and Trevor Darrel found that this problem can be solved with Krizhevsky’s results by testing on the PASCAL VOC Challenge, a popular object detection challenge akin to ImageNet. They write,</p><blockquote><p>This paper is the first to show that a CNN can lead to dramatically higher object detection performance on PASCAL VOC as compared to systems based on simpler HOG-like features.</p></blockquote><p>Let’s now take a moment to understand how their architecture, Regions With CNNs (R-CNN) works.</p><p><strong>Understanding R-CNN</strong></p><p>The goal of R-CNN is to take in an image, and correctly identify where the main objects (via a bounding box) in the image.</p><ul><li><strong>Inputs</strong>: Image</li><li><strong>Outputs</strong>: Bounding boxes + labels for each object in the image.</li></ul><p>But how do we find out where these bounding boxes are? R-CNN does what we might intuitively do as well - <strong>propose</strong> <strong>a bunch of boxes in the image and see if any of them actually correspond to an object</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*ZQ03Ib84bYioFKoho5HnKg.png" alt="img"></p><p>Selective Search looks through windows of multiple scales and looks for adjacent pixels that share textures, colors, or intensities. Image source: <a href="https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf" target="_blank" rel="external">https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf</a></p><p>R-CNN creates these bounding boxes, or region proposals, using a process called Selective Search which you can read about <a href="http://www.cs.cornell.edu/courses/cs7670/2014sp/slides/VisionSeminar14.pdf" target="_blank" rel="external">here</a>. At a high level, Selective Search (shown in the image above) looks at the image through windows of different sizes, and for each size tries to group together adjacent pixels by texture, color, or intensity to identify objects.</p><p><img src="https://cdn-images-1.medium.com/max/1000/0*Sdj6sKDRQyZpO6oH." alt="img"></p><p>After creating a set of region proposals, R-CNN passes the image through a modified version of AlexNet to determine whether or not it is a valid region. Source: <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="external">https://arxiv.org/abs/1311.2524</a>.</p><p>Once the proposals are created, R-CNN warps the region to a standard square size and passes it through to a modified version of AlexNet (the winning submission to ImageNet 2012 that inspired R-CNN), as shown above.</p><p>On the final layer of the CNN, R-CNN adds a Support Vector Machine (SVM) that simply classifies whether this is an object, and if so what object. This is step 4 in the image above.</p><p><strong>Improving the Bounding Boxes</strong></p><p>Now, having found the object in the box, can we tighten the box to fit the true dimensions of the object? We can, and this is the final step of R-CNN. R-CNN runs a simple linear regression on the region proposal to generate tighter bounding box coordinates to get our final result. Here are the inputs and outputs of this regression model:</p><ul><li><strong>Inputs</strong>: sub-regions of the image corresponding to objects.</li><li><strong>Outputs</strong>: New bounding box coordinates for the object in the sub-region.</li></ul><p>So, to summarize, R-CNN is just the following steps:</p><ol><li>Generate a set of proposals for bounding boxes.</li><li>Run the images in the bounding boxes through a pre-trained AlexNet and finally an SVM to see what object the image in the box is.</li><li>Run the box through a linear regression model to output tighter coordinates for the box once the object has been classified.</li></ol><hr><h4 id="2015-Fast-R-CNN-Speeding-up-and-Simplifying-R-CNN"><a href="#2015-Fast-R-CNN-Speeding-up-and-Simplifying-R-CNN" class="headerlink" title="2015: Fast R-CNN - Speeding up and Simplifying R-CNN"></a>2015: Fast R-CNN - Speeding up and Simplifying R-CNN</h4><p><img src="https://cdn-images-1.medium.com/max/1000/1*3xnXHBEAz6FGzb-EehXtkA.png" alt="img"></p><p>Ross Girshick wrote both R-CNN and Fast R-CNN. He continues to push the boundaries of Computer Vision at Facebook Research.</p><p>R-CNN works really well, but is really quite slow for a few simple reasons:</p><ol><li>It requires a forward pass of the CNN (AlexNet) for every single region proposal for every single image (that’s around 2000 forward passes per image!).</li><li>It has to train three different models separately - the CNN to generate image features, the classifier that predicts the class, and the regression model to tighten the bounding boxes. This makes the pipeline extremely hard to train.</li></ol><p>In 2015, Ross Girshick, the first author of R-CNN, solved both these problems, leading to the second algorithm in our short history - Fast R-CNN. Let’s now go over its main insights.</p><p><strong>Fast R-CNN Insight 1: RoI (Region of Interest) Pooling</strong></p><p>For the forward pass of the CNN, Girshick realized that for each image, a lot of proposed regions for the image invariably overlapped causing us to run the same CNN computation again and again (~2000 times!). His insight was simple — <strong>Why not run the CNN just once per image and then find a way to share that computation across the ~2000 proposals?</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/1*4K_Bq1AhAsTe9vlT0wsdXQ.png" alt="img"></p><p>In RoIPool, a full forward pass of the image is created and the conv features for each region of interest are extracted from the resulting forward pass. Source: Stanford’s CS231N slides by Fei Fei Li, Andrei Karpathy, and Justin Johnson.</p><p>This is exactly what Fast R-CNN does using a technique known as RoIPool (Region of Interest Pooling). At its core, RoIPool shares the forward pass of a CNN for an image across its subregions. In the image above, notice how the CNN features for each region are obtained by selecting a corresponding region from the CNN’s feature map. Then, the features in each region are pooled (usually using max pooling). So all it takes us is one pass of the original image as opposed to ~2000!</p><p><strong>Fast R-CNN Insight 2: Combine All Models into One Network</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/1*E_P1vAEbGT4HNYjqMtIz4g.png" alt="img"></p><p>Fast R-CNN combined the CNN, classifier, and bounding box regressor into one, single network. Source: <a href="https://www.slideshare.net/simplyinsimple/detection-52781995" target="_blank" rel="external">https://www.slideshare.net/simplyinsimple/detection-52781995</a>.</p><p>The second insight of Fast R-CNN is to jointly train the CNN, classifier, and bounding box regressor in a single model. Where earlier we had different models to extract image features (CNN), classify (SVM), and tighten bounding boxes (regressor), <strong>Fast R-CNN instead used a single network to compute all three.</strong></p><p>You can see how this was done in the image above. Fast R-CNN replaced the SVM classifier with a softmax layer on top of the CNN to output a classification. It also added a linear regression layer parallel to the softmax layer to output bounding box coordinates. In this way, all the outputs needed came from one single network! Here are the inputs and outputs to this overall model:</p><ul><li><strong>Inputs</strong>: Images with region proposals.</li><li><strong>Outputs</strong>: Object classifications of each region along with tighter bounding boxes.</li></ul><hr><h4 id="2016-Faster-R-CNN-Speeding-Up-Region-Proposal"><a href="#2016-Faster-R-CNN-Speeding-Up-Region-Proposal" class="headerlink" title="2016: Faster R-CNN - Speeding Up Region Proposal"></a>2016: Faster R-CNN - Speeding Up Region Proposal</h4><p>Even with all these advancements, there was still one remaining bottleneck in the Fast R-CNN process — the region proposer. As we saw, the very first step to detecting the locations of objects is generating a bunch of potential bounding boxes or regions of interest to test. In Fast R-CNN, these proposals were created using <strong>Selective Search</strong>, a fairly slow process that was found to be the bottleneck of the overall process.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*xY9rmw06KZWQlNIPk6ItqA.png" alt="img"></p><p>Jian Sun, a principal researcher at Microsoft Research, led the team behind Faster R-CNN. Source: <a href="https://blogs.microsoft.com/next/2015/12/10/microsoft-researchers-win-imagenet-computer-vision-challenge/#sm.00017fqnl1bz6fqf11amuo0d9ttdp" target="_blank" rel="external">https://blogs.microsoft.com/next/2015/12/10/microsoft-researchers-win-imagenet-computer-vision-challenge/#sm.00017fqnl1bz6fqf11amuo0d9ttdp</a></p><p>In the middle 2015, a team at Microsoft Research composed of Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun, found a way to make the region proposal step almost cost free through an architecture they (creatively) named Faster R-CNN.</p><p>The insight of Faster R-CNN was that region proposals depended on features of the image that were already calculated with the forward pass of the CNN (first step of classification). <strong>So why not reuse those same CNN results for region proposals instead of running a separate selective search algorithm?</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/0*_nNI03ESXm2P6YXO." alt="img"></p><p>In Faster R-CNN, a single CNN is used for region proposals, and classifications. Source: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a>.</p><p>Indeed, this is just what the Faster R-CNN team achieved. In the image above, you can see how a single CNN is used to both carry out region proposals and classification. This way, <strong>only one CNN needs to be trained</strong> and we get region proposals almost for free! The authors write:</p><blockquote><p>Our observation is that the convolutional feature maps used by region-based detectors, like Fast R- CNN, can also be used for generating region proposals [thus enabling nearly cost-free region proposals].</p></blockquote><p>Here are the inputs and outputs of their model:</p><ul><li><strong>Inputs</strong>: Images (Notice how region proposals are not needed).</li><li><strong>Outputs</strong>: Classifications and bounding box coordinates of objects in the images.</li></ul><p><strong>How the Regions are Generated</strong></p><p>Let’s take a moment to see how Faster R-CNN generates these region proposals from CNN features. Faster R-CNN adds a Fully Convolutional Network on top of the features of the CNN creating what’s known as the <strong>Region Proposal Network</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/0*n6pZEyvW47nlcdQz." alt="img"></p><p>The Region Proposal Network slides a window over the features of the CNN. At each window location, the network outputs a score and a bounding box per anchor (hence 4k box coordinates where k is the number of anchors). Source: <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a>.</p><p>The Region Proposal Network works by passing a sliding window over the CNN feature map and at each window, outputting <strong>k </strong>potential bounding boxes and scores for how good each of those boxes is expected to be. What do these <strong>k </strong>boxes represent?</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*pJ3OTVXjtp9vWfBOPsnWIw.png" alt="img"></p><p>We know that the bounding boxes for people tend to be rectangular and vertical. We can use this intuition to guide our Region Proposal networks through creating an anchor of such dimensions. Image Source: <a href="http://vlm1.uta.edu/~athitsos/courses/cse6367_spring2011/assignments/assignment1/bbox0062.jpg" target="_blank" rel="external">http://vlm1.uta.edu/~athitsos/courses/cse6367_spring2011/assignments/assignment1/bbox0062.jpg</a>.</p><p>Intuitively, we know that objects in an image should fit certain common aspect ratios and sizes. For instance, we know that we want some rectangular boxes that resemble the shapes of humans. Likewise, we know we won’t see many boxes that are very very thin. In such a way, we create <strong>k</strong> such common aspect ratios we call <strong>anchor boxes</strong>. For each such anchor box, we output one bounding box and score per position in the image.</p><p>With these anchor boxes in mind, let’s take a look at the inputs and outputs to this Region Proposal Network:</p><ul><li><strong>Inputs</strong>: CNN Feature Map.</li><li><strong>Outputs</strong>: A bounding box per anchor. A score representing how likely the image in that bounding box will be an object.</li></ul><p>We then pass each such bounding box that is likely to be an object into Fast R-CNN to generate a classification and tightened bounding boxes.</p><hr><h4 id="2017-Mask-R-CNN-Extending-Faster-R-CNN-for-Pixel-Level-Segmentation"><a href="#2017-Mask-R-CNN-Extending-Faster-R-CNN-for-Pixel-Level-Segmentation" class="headerlink" title="2017: Mask R-CNN - Extending Faster R-CNN for Pixel Level Segmentation"></a>2017: Mask R-CNN - Extending Faster R-CNN for Pixel Level Segmentation</h4><p><img src="https://cdn-images-1.medium.com/max/1000/1*E_5qBTrotLzclyaxsekBmQ.png" alt="img"></p><p>The goal of image instance segmentation is to identify, at a pixel level, what the different objets in a scene are. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><p>So far, we’ve seen how we’ve been able to use CNN features in many interesting ways to effectively locate different objects in an image with bounding boxes.</p><p>Can we extend such techniques to go one step further and locate exact pixels of each object instead of just bounding boxes? This problem, known as image segmentation, is what Kaiming He and a team of researchers, including Girshick, explored at Facebook AI using an architecture known as <strong>Mask R-CNN</strong>.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*cYW3EdKx75Stl1EreATdfw.png" alt="img"></p><p>Kaiming He, a researcher at Facebook AI, is lead author of Mask R-CNN and also a coauthor of Faster R-CNN.</p><p>Much like Fast R-CNN, and Faster R-CNN, Mask R-CNN’s underlying intuition is straight forward. Given that Faster R-CNN works so well for object detection, could we extend it to also carry out pixel level segmentation?</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*BiRpf-ogjxARQf5LxI17Jw.png" alt="img"></p><p>In Mask R-CNN, a Fully Convolutional Network (FCN) is added on top of the CNN features of Faster R-CNN to generate a mask (segmentation output). Notice how this is in parallel to the classification and bounding box regression network of Faster R-CNN. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><p>Mask R-CNN does this by adding a branch to Faster R-CNN that outputs a binary mask that says whether or not a given pixel is part of an object. The branch (in white in the above image), as before, is just a Fully Convolutional Network on top of a CNN based feature map. Here are its inputs and outputs:</p><ul><li><strong>Inputs</strong>: CNN Feature Map.</li><li><strong>Outputs</strong>: Matrix with 1s on all locations where the pixel belongs to the object and 0s elsewhere (this is known as a <a href="https://en.wikipedia.org/wiki/Mask_%28computing%29" target="_blank" rel="external">binary mask</a>).</li></ul><p>But the Mask R-CNN authors had to make one small adjustment to make this pipeline work as expected.</p><p><strong>RoiAlign - Realigning RoIPool to be More Accurate</strong></p><p><img src="https://cdn-images-1.medium.com/max/1000/0*KtaZfpUErYqwH4RX." alt="img"></p><p>Instead of RoIPool, the image gets passed through RoIAlign so that the regions of the feature map selected by RoIPool correspond more precisely to the regions of the original image. This is needed because pixel level segmentation requires more fine-grained alignment than bounding boxes. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><p>When run without modifications on the original Faster R-CNN architecture, the Mask R-CNN authors realized that the regions of the feature map selected by RoIPool were slightly misaligned from the regions of the original image. Since image segmentation requires pixel level specificity, unlike bounding boxes, this naturally led to inaccuracies.</p><p>The authors were able to solve this problem by cleverly adjusting RoIPool to be more precisely aligned using a method known as RoIAlign.</p><p><img src="https://cdn-images-1.medium.com/max/1000/1*VDGql5VDbLWU3jOhRmzwFQ.jpeg" alt="img"></p><p>How do we accurately map a region of interest from the original image onto the feature map?</p><p>Imagine we have an image of size <strong>128x128</strong> and a feature map of size <strong>25x25</strong>. Let’s imagine we want features the region corresponding to the top-left <strong>15x15</strong>pixels in the original image (see above). How might we select these pixels from the feature map?</p><p>We know each pixel in the original image corresponds to ~ 25/128 pixels in the feature map. To select 15 pixels from the original image, we just select 15 <em>25/128 ~= <em>*2.93</em></em> pixels.</p><p>In RoIPool, we would round this down and select 2 pixels causing a slight misalignment. However, in RoIAlign, <strong>we avoid such rounding.</strong> Instead, we use <a href="https://en.wikipedia.org/wiki/Bilinear_interpolation" target="_blank" rel="external">bilinear interpolation</a> to get a precise idea of what would be at pixel 2.93. This, at a high level, is what allows us to avoid the misalignments caused by RoIPool.</p><p>Once these masks are generated, Mask R-CNN combines them with the classifications and bounding boxes from Faster R-CNN to generate such wonderfully precise segmentations:</p><p><img src="https://cdn-images-1.medium.com/max/1250/1*6CClgIKH8zhZjmcftfNoEQ.png" alt="img"></p><p>Mask R-CNN is able to segment as well as classify the objects in an image. Source: <a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="external">https://arxiv.org/abs/1703.06870</a>.</p><hr><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>If you’re interested in trying out these algorithms yourselves, here are relevant repositories:</p><p><strong>Faster R-CNN</strong></p><ul><li>Caffe: <a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="external">https://github.com/rbgirshick/py-faster-rcnn</a></li><li>PyTorch: <a href="https://github.com/longcw/faster_rcnn_pytorch" target="_blank" rel="external">https://github.com/longcw/faster_rcnn_pytorch</a></li><li>MatLab: <a href="https://github.com/ShaoqingRen/faster_rcnn" target="_blank" rel="external">https://github.com/ShaoqingRen/faster_rcnn</a></li></ul><p><strong>Mask R-CNN</strong></p><ul><li>PyTorch: <a href="https://github.com/felixgwu/mask_rcnn_pytorch" target="_blank" rel="external">https://github.com/felixgwu/mask_rcnn_pytorch</a></li><li>TensorFlow: <a href="https://github.com/CharlesShang/FastMaskRCNN" target="_blank" rel="external">https://github.com/CharlesShang/FastMaskRCNN</a></li></ul><p>Reblog from <a href="https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4" target="_blank" rel="external">here</a>.</p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/10/Some-Paper-Summaries-of-Semantic-Segmentation-with-Deep-Learning/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2018/04/10/Some-Paper-Summaries-of-Semantic-Segmentation-with-Deep-Learning/" itemprop="url">Some Paper Summaries of Semantic Segmentation with Deep Learning</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-10T20:01:58+08:00">2018-04-10 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/04/10/Some-Paper-Summaries-of-Semantic-Segmentation-with-Deep-Learning/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2018/04/10/Some-Paper-Summaries-of-Semantic-Segmentation-with-Deep-Learning/" itemprop="commentsCount"></span> </a></span><span id="/2018/04/10/Some-Paper-Summaries-of-Semantic-Segmentation-with-Deep-Learning/" class="leancloud_visitors" data-flag-title="Some Paper Summaries of Semantic Segmentation with Deep Learning"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h3 id="What-exactly-is-semantic-segmentation"><a href="#What-exactly-is-semantic-segmentation" class="headerlink" title="What exactly is semantic segmentation?"></a>What exactly is semantic segmentation?</h3><p>Semantic segmentation is understanding an image at pixel level i.e, we want to assign each pixel in the image an object class. For example, check out the following images.</p><p><img src="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/images/21.jpg" alt="biker"> <img src="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/images/21_class.png" alt="biker"><br><em>Left</em>: Input image. <em>Right</em>: It’s semantic segmentation. <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/index.html" target="_blank" rel="external">Source.</a></p><p>Apart from recognizing the bike and the person riding it, we also have to delineate the boundaries of each object. Therefore, unlike classification, we need dense pixel-wise predictions from our models.</p><p><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/" target="_blank" rel="external">VOC2012</a> and <a href="http://mscoco.org/explore/" target="_blank" rel="external">MSCOCO</a> are the most important datasets for semantic segmentation.</p><h3 id="What-are-the-different-approaches"><a href="#What-are-the-different-approaches" class="headerlink" title="What are the different approaches?"></a>What are the different approaches?</h3><p>Before deep learning took over computer vision, people used approaches like <a href="http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2008-CVPR-semantic-texton-forests.pdf" target="_blank" rel="external">TextonForest</a> and <a href="http://www.cse.chalmers.se/edu/year/2011/course/TDA361/Advanced%20Computer%20Graphics/BodyPartRecognition.pdf" target="_blank" rel="external">Random Forest based classifiers</a> for semantic segmentation. As with image classification, convolutional neural networks (CNN) have had enormous success on segmentation problems.</p><p>One of the popular initial deep learning approaches was <a href="http://people.idsia.ch/~juergen/nips2012.pdf" target="_blank" rel="external">patch classification</a> where each pixel was separately classified into classes using a patch of image around it. Main reason to use patches was that classification networks usually have full connected layers and therefore required fixed size images.</p><p>In 2014, <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn" target="_blank" rel="external">Fully Convolutional Networks (FCN)</a> by Long et al. from Berkeley, popularized CNN architectures for dense predictions without any fully connected layers. This allowed segmentation maps to be generated for image of any size and was also much faster compared to the patch classification approach. Almost all the subsequent state of the art approaches on semantic segmentation adopted this paradigm.</p><p>Apart from fully connected layers, one of the main problems with using CNNs for segmentation is <em>pooling layers</em>. Pooling layers increase the field of view and are able to aggregate the context while discarding the ‘where’ information. However, semantic segmentation requires the exact alignment of class maps and thus, needs the ‘where’ information to be preserved. Two different classes of architectures evolved in the literature to tackle this issue.</p><p>First one is encoder-decoder architecture. Encoder gradually reduces the spatial dimension with pooling layers and decoder gradually recovers the object details and spatial dimension. There are usually shortcut connections from encoder to decoder to help decoder recover the object details better. <a href="https://arxiv.org/abs/1505.04597" target="_blank" rel="external">U-Net</a> is a popular architecture from this class.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/unet.png" alt="U-Net architecture"><br>U-Net: An encoder-decoder architecture. <a href="https://arxiv.org/abs/1505.04597" target="_blank" rel="external">Source</a>.</p><p>Architectures in the second class use what are called as <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated/atrous convolutions</a>and do away with pooling layers.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/dilated_conv.png" alt="Dilated/atrous convolutions"><br>Dilated/atrous convolutions. rate=1 is same as normal convolutions. <a href="https://arxiv.org/abs/1706.05587" target="_blank" rel="external">Source</a>.</p><p><a href="https://arxiv.org/abs/1210.5644" target="_blank" rel="external">Conditional Random Field (CRF) postprocessing</a> are usually used to improve the segmentation. CRFs are graphical models which ‘smooth’ segmentation based on the underlying image intensities. They work based on the observation that similar intensity pixels tend to be labeled as the same class. CRFs can boost scores by 1-2%.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/crf.png" alt="CRF"><br>CRF illustration. (b) Unary classifiers is the segmentation input to the CRF. (c, d, e) are variants of CRF with (e) being the widely used one. <a href="https://arxiv.org/abs/1210.5644" target="_blank" rel="external">Source</a>.</p><p>In the next section, I’ll summarize a few papers that represent the evolution of segmentation architectures starting from FCN. All these architectures are benchmarked on <a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php" target="_blank" rel="external">VOC2012 evaluation server</a>.</p><h3 id="Summaries"><a href="#Summaries" class="headerlink" title="Summaries"></a>Summaries</h3><p>Following papers are summarized (in chronological order):</p><ol><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn" target="_blank" rel="external">FCN</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#segnet" target="_blank" rel="external">SegNet</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">Dilated Convolutions</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLab (v1 &amp; v2)</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#refinenet" target="_blank" rel="external">RefineNet</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#pspnet" target="_blank" rel="external">PSPNet</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#large-kernel" target="_blank" rel="external">Large Kernel Matters</a></li><li><a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplabv3" target="_blank" rel="external">DeepLab v3</a></li></ol><p>For each of these papers, I list down their key contributions and explain them. I also show their benchmark scores (mean IOU) on VOC2012 test dataset.</p><h4 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h4><ul><li>Fully Convolutional Networks for Semantic Segmentation</li><li>Submitted on 14 Nov 2014</li><li><a href="https://arxiv.org/abs/1411.4038" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Popularize the use of end to end convolutional networks for semantic segmentation</li><li>Re-purpose imagenet pretrained networks for segmentation</li><li>Upsample using <em>deconvolutional</em> layers</li><li>Introduce skip connections to improve over the coarseness of upsampling</li></ul><p><em>Explanation</em>:</p><p>Key observation is that fully connected layers in classification networks can be viewed as convolutions with kernels that cover their entire input regions. This is equivalent to evaluating the original classification network on overlapping input patches but is much more efficient because computation is shared over the overlapping regions of patches. Although this observation is not unique to this paper (see <a href="https://arxiv.org/abs/1312.6229" target="_blank" rel="external">overfeat</a>, <a href="https://plus.google.com/+PierreSermanet/posts/VngsFR3tug9" target="_blank" rel="external">this post</a>), it improved the state of the art on VOC2012 significantly.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/FCN%20-%20illustration.png" alt="FCN architecture"><br>Fully connected layers as a convolution. <a href="https://arxiv.org/abs/1411.4038" target="_blank" rel="external">Source</a>.</p><p>After convolutionalizing fully connected layers in a imagenet pretrained network like VGG, feature maps still need to be upsampled because of pooling operations in CNNs. Instead of using simple bilinear interpolation, <em>deconvolutional layers</em> can learn the interpolation. This layer is also known as upconvolution, full convolution, transposed convolution or fractionally-strided convolution.</p><p>However, upsampling (even with deconvolutional layers) produces coarse segmentation maps because of loss of information during pooling. Therefore, shortcut/skip connections are introduced from higher resolution feature maps.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>62.2</td><td>-</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&amp;challengeid=11&amp;compid=6&amp;submid=6103#KEY_FCN-8s" target="_blank" rel="external">leaderboard</a></td></tr><tr><td>67.2</td><td>More momentum. Not described in paper</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&amp;challengeid=11&amp;compid=6&amp;submid=6103#KEY_FCN-8s-heavy" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><p><em>My Comments</em>:</p><ul><li>This was an important contribution but state of the art has improved a lot by now though.</li></ul><h4 id="SegNet"><a href="#SegNet" class="headerlink" title="SegNet"></a>SegNet</h4><ul><li>SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</li><li>Submitted on 2 Nov 2015</li><li><a href="https://arxiv.org/abs/1511.00561" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Maxpooling indices transferred to decoder to improve the segmentation resolution.</li></ul><p><em>Explanation</em>:</p><p>FCN, despite upconvolutional layers and a few shortcut connections produces coarse segmentation maps. Therefore, more shortcut connections are introduced. However, instead of copying the encoder features as in FCN, indices from maxpooling are copied. This makes SegNet more memory efficient than FCN.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/segnet_architecture.png" alt="SegNet Architecture"><br>Segnet Architecture. <a href="https://arxiv.org/abs/1511.00561" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>59.9</td><td>-</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_SegNet" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><p><em>My comments</em>:</p><ul><li>FCN and SegNet are one of the first encoder-decoder architectures.</li><li>Benchmarks for SegNet are not good enough to be used anymore.</li></ul><h4 id="Dilated-Convolutions"><a href="#Dilated-Convolutions" class="headerlink" title="Dilated Convolutions"></a>Dilated Convolutions</h4><ul><li>Multi-Scale Context Aggregation by Dilated Convolutions</li><li>Submitted on 23 Nov 2015</li><li><a href="https://arxiv.org/abs/1511.07122" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Use dilated convolutions, a convolutional layer for dense predictions.</li><li>Propose ‘context module’ which uses dilated convolutions for multi scale aggregation.</li></ul><p><em>Explanation</em>:</p><p>Pooling helps in classification networks because receptive field increases. But this is not the best thing to do for segmentation because pooling decreases the resolution. Therefore, authors use <em>dilated convolution</em> layer which works like this:</p><p><img src="https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/dilation.gif" alt="Dilated/Atrous Convolutions"><br>Dilated/Atrous Convolutions. <a href="https://github.com/vdumoulin/conv_arithmetic" target="_blank" rel="external">Source</a></p><p>Dilated convolutional layer (also called as atrous convolution in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLab</a>) allows for exponential increase in field of view without decrease of spatial dimensions.</p><p>Last two pooling layers from pretrained classification network (here, VGG) are removed and subsequent convolutional layers are replaced with dilated convolutions. In particular, convolutions between the pool-3 and pool-4 have dilation 2 and convolutions after pool-4 have dilation 4. With this module (called <em>frontend module</em> in the paper), dense predictions are obtained without any increase in number of parameters.</p><p>A module (called <em>context module</em> in the paper) is trained separately with the outputs of frontend module as inputs. This module is a cascade of dilated convolutions of different dilations so that multi scale context is aggregated and predictions from frontend are improved.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>71.3</td><td>frontend</td><td>reported in the paper</td></tr><tr><td>73.5</td><td>frontend + context</td><td>reported in the paper</td></tr><tr><td>74.7</td><td>frontend + context + CRF</td><td>reported in the paper</td></tr><tr><td>75.3</td><td>frontend + context + CRF-RNN</td><td>reported in the paper</td></tr></tbody></table><p><em>My comments</em>:</p><ul><li>Note that predicted segmentation map’s size is 1/8th of that of the image. This is the case with almost all the approaches. They are interpolated to get the final segmentation map.</li></ul><h4 id="DeepLab-v1-amp-v2"><a href="#DeepLab-v1-amp-v2" class="headerlink" title="DeepLab (v1 &amp; v2)"></a>DeepLab (v1 &amp; v2)</h4><ul><li><strong>v1</strong> : Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs</li><li>Submitted on 22 Dec 2014</li><li><a href="https://arxiv.org/abs/1412.7062" target="_blank" rel="external">Arxiv Link</a></li><li></li><li><strong>v2</strong> : DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</li><li>Submitted on 2 Jun 2016</li><li><a href="https://arxiv.org/abs/1606.00915" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Use atrous/dilated convolutions.</li><li>Propose atrous spatial pyramid pooling (ASPP)</li><li>Use Fully connected CRF</li></ul><p><em>Explanation</em>:</p><p>Atrous/Dilated convolutions increase the field of view without increasing the number of parameters. Net is modified like in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated convolutions paper</a>.</p><p>Multiscale processing is achieved either by passing multiple rescaled versions of original images to parallel CNN branches (Image pyramid) and/or by using multiple parallel atrous convolutional layers with different sampling rates (ASPP).</p><p>Structured prediction is done by fully connected CRF. CRF is trained/tuned separately as a post processing step.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/deeplabv2.png" alt="DeepLab2 Pipeline"><br>DeepLab2 Pipeline. <a href="https://arxiv.org/abs/1606.00915" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>79.7</td><td>ResNet-101 + atrous Convolutions + ASPP + CRF</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&amp;challengeid=11&amp;compid=6&amp;submid=6103#KEY_DeepLabv2-CRF" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><h4 id="RefineNet"><a href="#RefineNet" class="headerlink" title="RefineNet"></a>RefineNet</h4><ul><li>RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation</li><li>Submitted on 20 Nov 2016</li><li><a href="https://arxiv.org/abs/1611.06612" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Encoder-Decoder architecture with well thought-out decoder blocks</li><li>All the components follow residual connection design</li></ul><p><em>Explanation</em>:</p><p>Approach of using dilated/atrous convolutions are not without downsides. Dilated convolutions are computationally expensive and take a lot of memory because they have to be applied on large number of high resolution feature maps. This hampers the computation of high-res predictions. <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLab’s</a> predictions, for example are 1/8th the size of original input.</p><p>So, the paper proposes to use encoder-decoder architecture. Encoder part is ResNet-101 blocks. Decoder has RefineNet blocks which concatenate/fuse high resolution features from encoder and low resolution features from previous RefineNet block.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/refinenet%20-%20architecture.png" alt="RefineNet Architecture"><br>RefineNet Architecture. <a href="https://arxiv.org/abs/1611.06612" target="_blank" rel="external">Source</a>.</p><p>Each RefineNet block has a component to fuse the multi resolution features by upsampling the lower resolution features and a component to capture context based on repeated 5 x 5 <em>stride 1</em> pool layers. Each of these components employ the residual connection design following the identity map mindset.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/refinenet%20-%20block.png" alt="RefineNet Block"><br>RefineNet Block. <a href="https://arxiv.org/abs/1611.06612" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>84.2</td><td>Uses CRF, Multiscale inputs, COCO pretraining</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_Multipath-RefineNet" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><h4 id="PSPNet"><a href="#PSPNet" class="headerlink" title="PSPNet"></a>PSPNet</h4><ul><li>Pyramid Scene Parsing Network</li><li>Submitted on 4 Dec 2016</li><li><a href="https://arxiv.org/abs/1612.01105" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Propose pyramid pooling module to aggregate the context.</li><li>Use auxiliary loss</li></ul><p><em>Explanation</em>:</p><p>Global scene categories matter because it provides clues on the distribution of the segmentation classes. Pyramid pooling module captures this information by applying large kernel pooling layers.</p><p>Dilated convolutions are used as in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated convolutions paper</a> to modify Resnet and a pyramid pooling module is added to it. This module concatenates the feature maps from ResNet with upsampled output of parallel pooling layers with kernels covering whole, half of and small portions of image.</p><p>An auxiliary loss, additional to the loss on main branch, is applied after the fourth stage of ResNet (i.e input to pyramid pooling module). This idea was also called as intermediate supervision elsewhere.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/pspnet.png" alt="PSPNet Architecture"><br>PSPNet Architecture. <a href="https://arxiv.org/abs/1612.01105" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>85.4</td><td>MSCOCO pretraining, multi scale input, no CRF</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_PSPNet" target="_blank" rel="external">leaderboard</a></td></tr><tr><td>82.6</td><td>no MSCOCO pretraining, multi scale input, no CRF</td><td>reported in the paper</td></tr></tbody></table><h4 id="Large-Kernel-Matters"><a href="#Large-Kernel-Matters" class="headerlink" title="Large Kernel Matters"></a>Large Kernel Matters</h4><ul><li>Large Kernel Matters – Improve Semantic Segmentation by Global Convolutional Network</li><li>Submitted on 8 Mar 2017</li><li><a href="https://arxiv.org/abs/1703.02719" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Propose a encoder-decoder architecture with very large kernels convolutions</li></ul><p><em>Explanation</em>:</p><p>Semantic segmentation requires both segmentation and classification of the segmented objects. Since fully connected layers cannot be present in a segmentation architecture, convolutions with very large kernels are adopted instead.</p><p>Another reason to adopt large kernels is that although deeper networks like ResNet have very large receptive field, <a href="https://arxiv.org/abs/1412.6856" target="_blank" rel="external">studies</a> show that the network tends to gather information from a much smaller region (valid receptive filed).</p><p>Larger kernels are computationally expensive and have a lot of parameters. Therefore, k x k convolution is approximated with sum of 1 x k + k x 1 and k x 1 and 1 x k convolutions. This module is called as <em>Global Convolutional Network</em> (GCN) in the paper.</p><p>Coming to architecture, ResNet(without any dilated convolutions) forms encoder part of the architecture while GCNs and deconvolutions form decoder. A simple residual block called <em>Boundary Refinement</em> (BR) is also used.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/large_kernel_matter.png" alt="GCN Architecture"><br>GCN Architecture. <a href="https://arxiv.org/abs/1703.02719" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>82.2</td><td>-</td><td>reported in the paper</td></tr><tr><td>83.6</td><td>Improved training, not described in the paper</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_Large_Kernel_Matters" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><h4 id="DeepLab-v3"><a href="#DeepLab-v3" class="headerlink" title="DeepLab v3"></a>DeepLab v3</h4><ul><li>Rethinking Atrous Convolution for Semantic Image Segmentation</li><li>Submitted on 17 Jun 2017</li><li><a href="https://arxiv.org/abs/1706.05587" target="_blank" rel="external">Arxiv Link</a></li></ul><p><em>Key Contributions</em>:</p><ul><li>Improved atrous spatial pyramid pooling (ASPP)</li><li>Module which employ atrous convolutions in cascade</li></ul><p><em>Explanation</em>:</p><p>ResNet model is modified to use dilated/atrous convolutions as in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLabv2</a> and <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated convolutions</a>. Improved ASPP involves concatenation of image-level features, a 1x1 convolution and three 3x3 atrous convolutions with different rates. Batch normalization is used after each of the parallel convolutional layers.</p><p>Cascaded module is a resnet block except that component convolution layers are made atrous with different rates. This module is similar to context module used in <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation" target="_blank" rel="external">dilated convolutions paper</a> but this is applied directly on intermediate feature maps instead of belief maps (belief maps are final CNN feature maps with channels equal to number of classes).</p><p>Both the proposed models are evaluated independently and attempt to combine the both did not improve the performance. Both of them performed very similarly on val set with ASPP performing slightly better. CRF is not used.</p><p>Both these models outperform the best model from <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab" target="_blank" rel="external">DeepLabv2</a>. Authors note that the improvement comes from the batch normalization and better way to encode multi scale context.</p><p><img src="http://blog.qure.ai/assets/images/segmentation-review/deeplabv3.png" alt="DeepLabv3 ASPP"><br>DeepLabv3 ASPP (used for submission). <a href="https://arxiv.org/abs/1706.05587" target="_blank" rel="external">Source</a>.</p><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>85.7</td><td>used ASPP (no cascaded modules)</td><td><a href="http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=6#KEY_DeepLabv3" target="_blank" rel="external">leaderboard</a></td></tr></tbody></table><p>Reblog from <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#sec-2" target="_blank" rel="external">here</a>.</p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/27/Understanding-nested-list-comprehension-syntax-in-Python/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2018/03/27/Understanding-nested-list-comprehension-syntax-in-Python/" itemprop="url">Understanding nested list comprehension syntax in Python</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-27T21:04:02+08:00">2018-03-27 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/03/27/Understanding-nested-list-comprehension-syntax-in-Python/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2018/03/27/Understanding-nested-list-comprehension-syntax-in-Python/" itemprop="commentsCount"></span> </a></span><span id="/2018/03/27/Understanding-nested-list-comprehension-syntax-in-Python/" class="leancloud_visitors" data-flag-title="Understanding nested list comprehension syntax in Python"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>List comprehensions are one of the really nice and powerful features of Python. It is actually a smart way to introduce new users to functional programming concepts (after all a list comprehension is just a combination of map and filter) and compact statements.</p><p>However, one thing that always troubled me when using list comprehensions is their non intuitive syntax when nesting was needed. For example, let’s say that we just want to flatten a list of lists using a nested list comprehension:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">non_flat = [ [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>] ]</div></pre></td></tr></table></figure><p>To write that, somebody would think: For a simple list comprehension I need to write <code>[ x for x in non_flat ]</code> to get all its items - however I want to retrieve each element of the <code>x</code> list so I’ll write something like this:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>[y <span class="keyword">for</span> y <span class="keyword">in</span> x <span class="keyword">for</span> x <span class="keyword">in</span> non_flat]</div><div class="line">[<span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>]</div></pre></td></tr></table></figure><p>Well duh! At this time I’d need research google for a working list comprehension syntax and adjust it to my needs (or give up and write it as a double for loop).</p><p>Here’s the correct nested list comprehension people wondering:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>[y <span class="keyword">for</span> x <span class="keyword">in</span> non_flat <span class="keyword">for</span> y <span class="keyword">in</span> x]</div><div class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</div></pre></td></tr></table></figure><p>What if I wanted to add a third level of nesting or an if? Well I’d just bite the bullet and use for loops!</p><p>However, if you take a look at the document describing list comprehensions in python (PEP202) you’ll see the following phrase:</p><blockquote><p>It is proposed to allow conditional construction of list literals using for and if clauses. <strong>They would nest in the same way for loops and if statements nest now.</strong></p></blockquote><p>This statement explains everything! <em>Just think in for-loops syntax</em>. So, If I used for loops for the previous flattening, I’d do something like:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> x <span class="keyword">in</span> non_flat:</div><div class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> x:</div><div class="line">        y</div></pre></td></tr></table></figure><p>which, if y is moved to the front and joined in one line would be the correct nested list comprehension!</p><p>So that’s the way… What If I wanted to include only lists with more than 2 elements in the flattening (so [7,8] should not be included)? I’ll write it with for loops first:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> x <span class="keyword">in</span> non_flat:</div><div class="line">    <span class="keyword">if</span> len(x) &gt; <span class="number">2</span></div><div class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> x:</div><div class="line">            y</div></pre></td></tr></table></figure><p>so by convering this to list comprehension we get:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>[ y <span class="keyword">for</span> x <span class="keyword">in</span> non_flat <span class="keyword">if</span> len(x) &gt; <span class="number">2</span> <span class="keyword">for</span> y <span class="keyword">in</span> x ]</div><div class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</div></pre></td></tr></table></figure><p>Success!</p><p>One final, more complex example: Let’s say that we have a list of lists of words and we want to get a list of all the letters of these words along with the index of the list they belong to but only for words with more than two characters. Using the same for-loop syntax for the nested list comprehensions we’ll get:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>strings = [ [<span class="string">'foo'</span>, <span class="string">'bar'</span>], [<span class="string">'baz'</span>, <span class="string">'taz'</span>], [<span class="string">'w'</span>, <span class="string">'koko'</span>] ]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>[ (letter, idx) <span class="keyword">for</span> idx, lst <span class="keyword">in</span> enumerate(strings) <span class="keyword">for</span> word <span class="keyword">in</span> lst <span class="keyword">if</span> len(word)&gt;<span class="number">2</span> <span class="keyword">for</span> letter <span class="keyword">in</span> word]</div><div class="line">[(<span class="string">'f'</span>, <span class="number">0</span>), (<span class="string">'o'</span>, <span class="number">0</span>), (<span class="string">'o'</span>, <span class="number">0</span>), (<span class="string">'b'</span>, <span class="number">0</span>), (<span class="string">'a'</span>, <span class="number">0</span>), (<span class="string">'r'</span>, <span class="number">0</span>), (<span class="string">'b'</span>, <span class="number">1</span>), (<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'z'</span>, <span class="number">1</span>), (<span class="string">'t'</span>, <span class="number">1</span>), (<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'z'</span>, <span class="number">1</span>), (<span class="string">'k'</span>, <span class="number">2</span>), (<span class="string">'o'</span>, <span class="number">2</span>), (<span class="string">'k'</span>, <span class="number">2</span>), (<span class="string">'o'</span>, <span class="number">2</span>)]</div></pre></td></tr></table></figure><hr><p>source blog is <a href="https://spapas.github.io/2016/04/27/python-nested-list-comprehensions/" target="_blank" rel="external">here</a>.</p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/19/Python多核编程mpi4py实践/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2018/03/19/Python多核编程mpi4py实践/" itemprop="url">Python多核编程mpi4py实践</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-19T13:25:36+08:00">2018-03-19 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/03/19/Python多核编程mpi4py实践/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2018/03/19/Python多核编程mpi4py实践/" itemprop="commentsCount"></span> </a></span><span id="/2018/03/19/Python多核编程mpi4py实践/" class="leancloud_visitors" data-flag-title="Python多核编程mpi4py实践"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>转载自<a href="http://blog.csdn.net/ztf312/article/details/74997939" target="_blank" rel="external">这篇博文</a>.</p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>​ CPU从三十多年前的8086，到十年前的奔腾，再到当下的多核i7。一开始，以单核cpu的主频为目标，架构的改良和集成电路工艺的进步使得cpu的性能高速上升，单核cpu的主频从老爷车的MHz阶段一度接近4GHz高地。然而，也因为工艺和功耗等的限制，单核cpu遇到了人生的天花板，急需转换思维，以满足无止境的性能需求。多核cpu在此登上历史舞台。给你的老爷车多加两个引擎，让你有法拉利的感觉。现时代，连手机都到处叫嚣自己有4核8核处理器的时代，PC就更不用说了。</p><p>​ 扯远了，anyway，对于俺们程序员来说，如何利用如此强大的引擎完成我们的任务才是我们要考虑的。随着大规模数据处理、大规模问题和复杂系统求解需求的增加，以前的单核编程已经有心无力了。如果程序一跑就得几个小时，甚至一天，想想都无法原谅自己。那如何让自己更快的过度到高大上的多核并行编程中去呢？哈哈，广大人民的力量！</p><p>​ 目前工作中我所接触到的并行处理框架主要有MPI、OpenMP和MapReduce(Hadoop)三个（CUDA属于GPU并行编程，这里不提及）。MPI和Hadoop都可以在集群中运行，而OpenMP因为共享存储结构的关系，不能在集群上运行，只能单机。另外，MPI可以让数据保留在内存中，可以为节点间的通信和数据交互保存上下文，所以能执行迭代算法，而Hadoop却不具有这个特性。因此，需要迭代的机器学习算法大多使用MPI来实现。当然了，部分机器学习算法也是可以通过设计使用Hadoop来完成的。（浅见，如果错误，希望各位不吝指出，谢谢）。</p><p>​ 本文主要介绍Python环境下MPI编程的实践基础。</p><h1 id="MPI与mpi4py"><a href="#MPI与mpi4py" class="headerlink" title="MPI与mpi4py"></a>MPI与mpi4py</h1><p>​ MPI是Message Passing Interface的简称，也就是消息传递。消息传递指的是并行执行的各个进程具有自己独立的堆栈和代码段，作为互不相关的多个程序独立执行，进程之间的信息交互完全通过显示地调用通信函数来完成。</p><p>​ Mpi4py是构建在mpi之上的python库，使得python的数据结构可以在进程（或者多个cpu）之间进行传递。</p><h2 id="MPI的工作方式"><a href="#MPI的工作方式" class="headerlink" title="MPI的工作方式"></a>MPI的工作方式</h2><p>​ 很简单，就是你启动了一组MPI进程，每个进程都是执行同样的代码！然后每个进程都有一个ID，也就是rank来标记我是谁。什么意思呢？假设一个CPU是你请的一个工人，共有10个工人。你有100块砖头要搬，然后很公平，让每个工人搬10块。这时候，你把任务写到一个任务卡里面，让10个工人都执行这个任务卡中的任务，也就是搬砖！这个任务卡中的“搬砖”就是你写的代码。然后10个CPU执行同一段代码。需要注意的是，代码里面的所有变量都是每个进程独有的，虽然名字相同。</p><p>​ 例如，一个脚本test.py，里面包含以下代码：</p><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from mpi4py import MPI  </div><div class="line">print("hello world'')  </div><div class="line">print("my rank is: %d" %MPI.rank)</div></pre></td></tr></table></figure><p>​ 然后我们在命令行通过以下方式运行：</p><p>​ <code>mpirun –np 5 python test.py</code></p><p>​ <code>-np5</code> 指定启动5个mpi进程来执行后面的程序。相当于对脚本拷贝了5份，每个进程运行一份，互不干扰。在运行的时候代码里面唯一的不同，就是各自的rank也就是ID不一样。所以这个代码就会打印5个hello world和5个不同的rank值，从0到4.</p><h2 id="点对点通信"><a href="#点对点通信" class="headerlink" title="点对点通信"></a>点对点通信</h2><p>​ 点对点通信（Point-to-PointCommunication）的能力是信息传递系统最基本的要求。意思就是让两个进程直接可以传输数据，也就是一个发送数据，另一个接收数据。接口就两个，send和recv，来个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="comment"># point to point communication  </span></div><div class="line">data_send = [comm_rank]*<span class="number">5</span>  </div><div class="line">comm.send(data_send,dest=(comm_rank+<span class="number">1</span>)%comm_size)  </div><div class="line">data_recv =comm.recv(source=(comm_rank<span class="number">-1</span>)%comm_size)  </div><div class="line">print(<span class="string">"my rank is %d, and Ireceived:"</span> % comm_rank)  </div><div class="line"><span class="keyword">print</span> data_recv</div></pre></td></tr></table></figure><p>​ 启动5个进程运行以上代码，结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">my rank <span class="keyword">is</span> <span class="number">0</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]  </div><div class="line">my rank <span class="keyword">is</span> <span class="number">1</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]  </div><div class="line">my rank <span class="keyword">is</span> <span class="number">2</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]  </div><div class="line">my rank <span class="keyword">is</span> <span class="number">3</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]  </div><div class="line">my rank <span class="keyword">is</span> <span class="number">4</span>, <span class="keyword">and</span> I received:  </div><div class="line">[<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]</div></pre></td></tr></table></figure><p>​ 可以看到，每个进程都创建了一个数组，然后把它传递给下一个进程，最后的那个进程传递给第一个进程。<code>comm_size</code>就是mpi的进程个数，也就是<code>-np</code>指定的那个数。<code>MPI.COMM_WORLD</code>表示进程所在的通信组。</p><p>​ 但这里面有个需要注意的问题，如果我们要发送的数据比较小的话，mpi会缓存我们的数据，也就是说执行到<code>send</code>这个代码的时候，会缓存被send的数据，然后继续执行后面的指令，而不会等待对方进程执行<code>recv</code>指令接收完这个数据。但是，如果要发送的数据很大，那么进程就是挂起等待，直到接收进程执行了<code>recv</code>指令接收了这个数据，进程才继续往下执行。所以上述的代码发送[rank]<em>5没啥问题，如果发送[rank]</em>500程序就会半死不活的样子了。因为所有的进程都会卡在发送这条指令，等待下一个进程发起接收的这个指令，但是进程是执行完发送的指令才能执行接收的指令，这就和死锁差不多了。所以一般，我们将其修改成以下的方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line">data_send = [comm_rank]*<span class="number">5</span>  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   comm.send(data_send, dest=(comm_rank+<span class="number">1</span>)%comm_size)  </div><div class="line"><span class="keyword">if</span> comm_rank &gt; <span class="number">0</span>:  </div><div class="line">   data_recv = comm.recv(source=(comm_rank<span class="number">-1</span>)%comm_size)  </div><div class="line">   comm.send(data_send, dest=(comm_rank+<span class="number">1</span>)%comm_size)  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data_recv = comm.recv(source=(comm_rank<span class="number">-1</span>)%comm_size)  </div><div class="line">print(<span class="string">"my rank is %d, and Ireceived:"</span> % comm_rank)  </div><div class="line"><span class="keyword">print</span> data_recv</div></pre></td></tr></table></figure><p>​ 第一个进程一开始就发送数据，其他进程一开始都是在等待接收数据，这时候进程1接收了进程0的数据，然后发送进程1的数据，进程2接收了，再发送进程2的数据……知道最后进程0接收最后一个进程的数据，从而避免了上述问题。</p><p>​ 一个比较常用的方法是封一个组长，也就是一个主进程，一般是进程0作为主进程leader。主进程将数据发送给其他的进程，其他的进程处理数据，然后返回结果给进程0。换句话说，就是进程0来控制整个数据处理流程。</p><h2 id="群体通信"><a href="#群体通信" class="headerlink" title="群体通信"></a>群体通信</h2><p>​ 点对点通信是A发送给B，一个人将自己的秘密告诉另一个人，群体通信（Collective Communications）像是拿个大喇叭，一次性告诉所有的人。前者是一对一，后者是一对多。但是，群体通信是以更有效的方式工作的。它的原则就一个：尽量把所有的进程在所有的时刻都使用上！我们在下面的bcast小节讲述。</p><p>​ 群体通信还是发送和接收两类，一个是一次性把数据发给所有人，另一个是一次性从所有人那里回收结果。</p><h3 id="广播bcast"><a href="#广播bcast" class="headerlink" title="广播bcast"></a>广播bcast</h3><p>​ 将一份数据发送给所有的进程。例如我有200份数据，有10个进程，那么每个进程都会得到这200份数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data = range(comm_size)  </div><div class="line">data = comm.bcast(data <span class="keyword">if</span> comm_rank == <span class="number">0</span><span class="keyword">else</span> <span class="keyword">None</span>, root=<span class="number">0</span>)  </div><div class="line"><span class="keyword">print</span> <span class="string">'rank %d, got:'</span> % (comm_rank)  </div><div class="line"><span class="keyword">print</span> data</div></pre></td></tr></table></figure><p>​ 结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">rank <span class="number">0</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">1</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">2</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">3</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">4</span>, got:  </div><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</div></pre></td></tr></table></figure><p>​ Root进程自己建了一个列表，然后广播给所有的进程。这样所有的进程都拥有了这个列表。然后爱干嘛就干嘛了。</p><p>​ 对广播最直观的观点是某个特定进程将数据一一发送给每个进程。假设有n个进程，那么假设我们的数据在0进程，那么0进程就需要将数据发送给剩下的n-1个进程，这是非常低效的，复杂度是O(n)。那有没有高效的方式？一个最常用也是非常高效的手段是规约树广播：收到广播数据的所有进程都参与到数据广播的过程中。首先只有一个进程有数据，然后它把它发送给第一个进程，此时有两个进程有数据；然后这两个进程都参与到下一次的广播中，这时就会有4个进程有数据，……，以此类推，每次都会有2的次方个进程有数据。通过这种规约树的广播方法，广播的复杂度降为O(log n)。这就是上面说的群体通信的高效原则：充分利用所有的进程来实现数据的发送和接收。</p><h3 id="散播scatter"><a href="#散播scatter" class="headerlink" title="散播scatter"></a>散播scatter</h3><p>​ 将一份数据平分给所有的进程。例如我有200份数据，有10个进程，那么每个进程会分别得到20份数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data = range(comm_size)  </div><div class="line">   <span class="keyword">print</span> data  </div><div class="line"><span class="keyword">else</span>:  </div><div class="line">   data = <span class="keyword">None</span>  </div><div class="line">local_data = comm.scatter(data, root=<span class="number">0</span>)  </div><div class="line"><span class="keyword">print</span> <span class="string">'rank %d, got:'</span> % comm_rank  </div><div class="line"><span class="keyword">print</span> local_data</div></pre></td></tr></table></figure><p>​ 结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">0</span>, got:  </div><div class="line"><span class="number">0</span>  </div><div class="line">rank <span class="number">1</span>, got:  </div><div class="line"><span class="number">1</span>  </div><div class="line">rank <span class="number">2</span>, got:  </div><div class="line"><span class="number">2</span>  </div><div class="line">rank <span class="number">3</span>, got:  </div><div class="line"><span class="number">3</span>  </div><div class="line">rank <span class="number">4</span>, got:  </div><div class="line"><span class="number">4</span></div></pre></td></tr></table></figure><p>​ 这里root进程创建了一个list，然后将它散播给所有的进程，相当于对这个list做了划分，每个进程获得等分的数据，这里就是list的每一个数。（主要根据list的索引来划分，list索引为第i份的数据就发送给第i个进程）。如果是矩阵，那么就等分的划分行，每个进程获得相同的行数进行处理。</p><p>​ 需要注意的是，MPI的工作方式是每个进程都会执行所有的代码，所以每个进程都会执行scatter这个指令，但只有root执行它的时候，它才兼备发送者和接收者的身份（root也会得到属于自己的数据），对于其他进程来说，他们都只是接收者而已。</p><h3 id="收集gather"><a href="#收集gather" class="headerlink" title="收集gather"></a>收集gather</h3><p>​ 那有发送，就有一起回收的函数。Gather是将所有进程的数据收集回来，合并成一个列表。下面联合scatter和gather组成一个完成的分发和收回过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data = range(comm_size)  </div><div class="line">   <span class="keyword">print</span> data  </div><div class="line"><span class="keyword">else</span>:  </div><div class="line">   data = <span class="keyword">None</span>  </div><div class="line">local_data = comm.scatter(data, root=<span class="number">0</span>)  </div><div class="line">local_data = local_data * <span class="number">2</span>  </div><div class="line"><span class="keyword">print</span> <span class="string">'rank %d, got and do:'</span> % comm_rank  </div><div class="line"><span class="keyword">print</span> local_data  </div><div class="line">combine_data = comm.gather(local_data,root=<span class="number">0</span>)  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">printcombine_data</div></pre></td></tr></table></figure><p>​ 结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">0</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">0</span>  </div><div class="line">rank <span class="number">1</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">2</span>  </div><div class="line">rank <span class="number">2</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">4</span>  </div><div class="line">rank <span class="number">4</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">8</span>  </div><div class="line">rank <span class="number">3</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">6</span>  </div><div class="line">[<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]</div></pre></td></tr></table></figure><p>​ Root进程将数据通过scatter等分发给所有的进程，等待所有的进程都处理完后（这里只是简单的乘以2），root进程再通过gather回收他们的结果，和分发的原则一样，组成一个list。Gather还有一个变体就是allgather，可以理解为它在gather的基础上将gather的结果再bcast了一次。啥意思？意思是root进程将所有进程的结果都回收统计完后，再把整个统计结果告诉大家。这样，不仅root可以访问combine_data，所有的进程都可以访问combine_data了。</p><h3 id="规约reduce"><a href="#规约reduce" class="headerlink" title="规约reduce"></a>规约reduce</h3><p>​ 规约是指不但将所有的数据收集回来，收集回来的过程中还进行了简单的计算，例如求和，求最大值等等。为什么要有这个呢？我们不是可以直接用gather全部收集回来了，再对列表求个sum或者max就可以了吗？这样不是累死组长吗？为什么不充分使用每个工人呢？规约实际上是使用规约树来实现的。例如求max，完成可以让工人两两pk后，再返回两两pk的最大值，然后再对第二层的最大值两两pk，直到返回一个最终的max给组长。组长就非常聪明的将工作分配下工人高效的完成了。这是O(n)的复杂度，下降到O(log n)（底数为2）的复杂度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line">comm_size = comm.Get_size()  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">   data = range(comm_size)  </div><div class="line">   <span class="keyword">print</span> data  </div><div class="line"><span class="keyword">else</span>:  </div><div class="line">   data = <span class="keyword">None</span>  </div><div class="line">local_data = comm.scatter(data, root=<span class="number">0</span>)  </div><div class="line">local_data = local_data * <span class="number">2</span>  </div><div class="line"><span class="keyword">print</span> <span class="string">'rank %d, got and do:'</span> % comm_rank  </div><div class="line"><span class="keyword">print</span> local_data  </div><div class="line">all_sum = comm.reduce(local_data, root=<span class="number">0</span>,op=MPI.SUM)  </div><div class="line"><span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line"><span class="keyword">print</span> <span class="string">'sumis:%d'</span> % all_sum</div></pre></td></tr></table></figure><p>​ 结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]  </div><div class="line">rank <span class="number">0</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">0</span>  </div><div class="line">rank <span class="number">1</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">2</span>  </div><div class="line">rank <span class="number">2</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">4</span>  </div><div class="line">rank <span class="number">3</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">6</span>  </div><div class="line">rank <span class="number">4</span>, got <span class="keyword">and</span> do:  </div><div class="line"><span class="number">8</span>  </div><div class="line">sum <span class="keyword">is</span>:<span class="number">20</span></div></pre></td></tr></table></figure><p>​ 可以看到，最后可以得到一个sum值。</p><h1 id="常见用法"><a href="#常见用法" class="headerlink" title="常见用法"></a>常见用法</h1><h2 id="对一个文件的多个行并行处理"><a href="#对一个文件的多个行并行处理" class="headerlink" title="对一个文件的多个行并行处理"></a>对一个文件的多个行并行处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!usr/bin/env python  </span></div><div class="line"><span class="comment">#-*- coding: utf-8 -*-  </span></div><div class="line">   </div><div class="line"><span class="keyword">import</span> sys  </div><div class="line"><span class="keyword">import</span> os  </div><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </div><div class="line">   </div><div class="line">   </div><div class="line"><span class="comment">#  </span></div><div class="line"><span class="comment">#  Global variables for MPI  </span></div><div class="line"><span class="comment">#  </span></div><div class="line">   </div><div class="line"><span class="comment"># instance for invoking MPI relatedfunctions  </span></div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line"><span class="comment"># the node rank in the whole community  </span></div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line"><span class="comment"># the size of the whole community, i.e.,the total number of working nodes in the MPI cluster  </span></div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line">   </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:  </div><div class="line">   <span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">       sys.stderr.write(<span class="string">"processor root starts reading data...\n"</span>)  </div><div class="line">       all_lines = sys.stdin.readlines()  </div><div class="line">   all_lines = comm.bcast(all_lines <span class="keyword">if</span> comm_rank == <span class="number">0</span> <span class="keyword">else</span> <span class="keyword">None</span>, root = <span class="number">0</span>)  </div><div class="line">   num_lines = len(all_lines)  </div><div class="line">   local_lines_offset = np.linspace(<span class="number">0</span>, num_lines, comm_size +<span class="number">1</span>).astype(<span class="string">'int'</span>)  </div><div class="line">   local_lines = all_lines[local_lines_offset[comm_rank] :local_lines_offset[comm_rank + <span class="number">1</span>]]  </div><div class="line">   sys.stderr.write(<span class="string">"%d/%d processor gets %d/%d data \n"</span> %(comm_rank, comm_size, len(local_lines), num_lines))  </div><div class="line">   cnt = <span class="number">0</span>  </div><div class="line">   <span class="keyword">for</span> line <span class="keyword">in</span> local_lines:  </div><div class="line">       fields = line.strip().split(<span class="string">'\t'</span>)  </div><div class="line">       cnt += <span class="number">1</span>  </div><div class="line">       <span class="keyword">if</span> cnt % <span class="number">100</span> == <span class="number">0</span>:  </div><div class="line">           sys.stderr.write(<span class="string">"processor %d has processed %d/%d lines \n"</span> %(comm_rank, cnt, len(local_lines)))  </div><div class="line">       output = line.strip() + <span class="string">' process every line here'</span>  </div><div class="line">       <span class="keyword">print</span> output</div></pre></td></tr></table></figure><h2 id="对多个文件并行处理"><a href="#对多个文件并行处理" class="headerlink" title="对多个文件并行处理"></a>对多个文件并行处理</h2><p>​ 如果我们的文件太大，例如几千万行，那么mpi是没办法将这么大的数据bcast给所有的进程的，所以我们可以先把大的文件split成小的文件，再让每个进程处理少数的文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!usr/bin/env python  </span></div><div class="line"><span class="comment">#-*- coding: utf-8 -*-  </span></div><div class="line">   </div><div class="line"><span class="keyword">import</span> sys  </div><div class="line"><span class="keyword">import</span> os  </div><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </div><div class="line">   </div><div class="line"><span class="comment">#  </span></div><div class="line"><span class="comment">#  Global variables for MPI  </span></div><div class="line"><span class="comment">#  </span></div><div class="line">   </div><div class="line"><span class="comment"># instance for invoking MPI relatedfunctions  </span></div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line"><span class="comment"># the node rank in the whole community  </span></div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line"><span class="comment"># the size of the whole community, i.e.,the total number of working nodes in the MPI cluster  </span></div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line">   </div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:  </div><div class="line">   <span class="keyword">if</span> len(sys.argv) != <span class="number">2</span>:  </div><div class="line">       sys.stderr.write(<span class="string">"Usage: python *.py directoty_with_files\n"</span>)  </div><div class="line">       sys.exit(<span class="number">1</span>)  </div><div class="line">   path = sys.argv[<span class="number">1</span>]  </div><div class="line">   <span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">       file_list = os.listdir(path)  </div><div class="line">       sys.stderr.write(<span class="string">"%d files\n"</span> % len(file_list))  </div><div class="line">   file_list = comm.bcast(file_list <span class="keyword">if</span> comm_rank == <span class="number">0</span> <span class="keyword">else</span> <span class="keyword">None</span>, root = <span class="number">0</span>)  </div><div class="line">   num_files = len(file_list)  </div><div class="line">   local_files_offset = np.linspace(<span class="number">0</span>, num_files, comm_size +<span class="number">1</span>).astype(<span class="string">'int'</span>)  </div><div class="line">   local_files = file_list[local_files_offset[comm_rank] :local_files_offset[comm_rank + <span class="number">1</span>]]  </div><div class="line">   sys.stderr.write(<span class="string">"%d/%d processor gets %d/%d data \n"</span> %(comm_rank, comm_size, len(local_files), num_files))  </div><div class="line">    cnt = <span class="number">0</span>  </div><div class="line">   <span class="keyword">for</span> file_name <span class="keyword">in</span> local_files:  </div><div class="line">       hd = open(os.path.join(path, file_name))  </div><div class="line">       <span class="keyword">for</span> line <span class="keyword">in</span> hd:  </div><div class="line">           output = line.strip() + <span class="string">' process every line here'</span>  </div><div class="line">           <span class="keyword">print</span> output  </div><div class="line">       cnt += <span class="number">1</span>  </div><div class="line">       sys.stderr.write(<span class="string">"processor %d has processed %d/%d files \n"</span> %(comm_rank, cnt, len(local_files)))  </div><div class="line">       hd.close()</div></pre></td></tr></table></figure><h2 id="联合numpy对矩阵的多个行或者多列并行处理"><a href="#联合numpy对矩阵的多个行或者多列并行处理" class="headerlink" title="联合numpy对矩阵的多个行或者多列并行处理"></a>联合numpy对矩阵的多个行或者多列并行处理</h2><p>​ Mpi4py一个非常优秀的特性是完美支持numpy！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os, sys, time  </div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </div><div class="line"><span class="keyword">import</span> mpi4py.MPI <span class="keyword">as</span> MPI  </div><div class="line">   </div><div class="line">   </div><div class="line"><span class="comment">#  </span></div><div class="line"><span class="comment">#  Global variables for MPI  </span></div><div class="line"><span class="comment">#  </span></div><div class="line">   </div><div class="line">   </div><div class="line"><span class="comment"># instance for invoking MPI relatedfunctions  </span></div><div class="line">comm = MPI.COMM_WORLD  </div><div class="line"><span class="comment"># the node rank in the whole community  </span></div><div class="line">comm_rank = comm.Get_rank()  </div><div class="line"><span class="comment"># the size of the whole community, i.e.,the total number of working nodes in the MPI cluster  </span></div><div class="line">comm_size = comm.Get_size()  </div><div class="line">   </div><div class="line"><span class="comment"># test MPI  </span></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:  </div><div class="line">    <span class="comment">#create a matrix  </span></div><div class="line">   <span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">       all_data = np.arange(<span class="number">20</span>).reshape(<span class="number">4</span>, <span class="number">5</span>)  </div><div class="line">       <span class="keyword">print</span> <span class="string">"************ data ******************"</span>  </div><div class="line">       <span class="keyword">print</span> all_data  </div><div class="line">     </div><div class="line">    <span class="comment">#broadcast the data to all processors  </span></div><div class="line">   all_data = comm.bcast(all_data <span class="keyword">if</span> comm_rank == <span class="number">0</span> <span class="keyword">else</span> <span class="keyword">None</span>, root = <span class="number">0</span>)  </div><div class="line">     </div><div class="line">    <span class="comment">#divide the data to each processor  </span></div><div class="line">   num_samples = all_data.shape[<span class="number">0</span>]  </div><div class="line">   local_data_offset = np.linspace(<span class="number">0</span>, num_samples, comm_size + <span class="number">1</span>).astype(<span class="string">'int'</span>)  </div><div class="line">     </div><div class="line">    <span class="comment">#get the local data which will be processed in this processor  </span></div><div class="line">   local_data = all_data[local_data_offset[comm_rank] :local_data_offset[comm_rank + <span class="number">1</span>]]  </div><div class="line">   <span class="keyword">print</span> <span class="string">"****** %d/%d processor gets local data ****"</span> %(comm_rank, comm_size)  </div><div class="line">   <span class="keyword">print</span> local_data  </div><div class="line">     </div><div class="line">    <span class="comment">#reduce to get sum of elements  </span></div><div class="line">   local_sum = local_data.sum()  </div><div class="line">   all_sum = comm.reduce(local_sum, root = <span class="number">0</span>, op = MPI.SUM)  </div><div class="line">     </div><div class="line">    <span class="comment">#process in local  </span></div><div class="line">   local_result = local_data ** <span class="number">2</span>  </div><div class="line">     </div><div class="line">    <span class="comment">#gather the result from all processors and broadcast it  </span></div><div class="line">   result = comm.allgather(local_result)  </div><div class="line">   result = np.vstack(result)  </div><div class="line">     </div><div class="line">   <span class="keyword">if</span> comm_rank == <span class="number">0</span>:  </div><div class="line">       <span class="keyword">print</span> <span class="string">"*** sum: "</span>, all_sum  </div><div class="line">       <span class="keyword">print</span> <span class="string">"************ result ******************"</span>  </div><div class="line">       <span class="keyword">print</span> result</div></pre></td></tr></table></figure><h1 id="MPI和mpi4py的环境搭建"><a href="#MPI和mpi4py的环境搭建" class="headerlink" title="MPI和mpi4py的环境搭建"></a>MPI和mpi4py的环境搭建</h1><p>​ 这章放到这里是作为一个附录。我们的环境是linux，需要安装的包有python、openmpi、numpy、cpython和mpi4py，过程如下：</p><h2 id="安装Python"><a href="#安装Python" class="headerlink" title="安装Python"></a>安装Python</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">tar xzvf Python-2.7.tgz  </div><div class="line">cd Python-2.7  </div><div class="line">./configure--prefix=/home/work/vis/zouxiaoyi/my_tools  </div><div class="line">make  </div><div class="line">make install</div></pre></td></tr></table></figure><p>​ 先将Python放到环境变量里面，还有Python的插件库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">exportPATH=/home/work/vis/zouxiaoyi/my_tools/bin:$PATH  </div><div class="line">exportLD_LIBRARY_PATH=/home/work/vis/zouxiaoyi/my_tools/lib:$LD_LIBRARY_PATH</div></pre></td></tr></table></figure><p>​ 执行<code>python</code>，如果看到可爱的&gt;&gt;&gt;出来，就表示成功了。按<code>crtl+d</code>退出</p><h2 id="安装openmpi"><a href="#安装openmpi" class="headerlink" title="安装openmpi"></a>安装openmpi</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">wget http://www.open-mpi.org/software/ompi/v1.4/downloads/openmpi-1.4.1.tar.gz  </div><div class="line">tar xzvf openmpi-1.4.1.tar.gz  </div><div class="line">cd openmpi-1.4.1  </div><div class="line">./configure--prefix=/home/work/vis/zouxiaoyi/my_tools  </div><div class="line">make -j 8  </div><div class="line">make install</div></pre></td></tr></table></figure><p>​ 然后把bin路径加到环境变量里面：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">exportPATH=/home/work/vis/zouxiaoyi/my_tools/bin:$PATH  </div><div class="line">exportLD_LIBRARY_PATH=/home/work/vis/zouxiaoyi/my_tools/lib:$LD_LIBRARY_PATH</div></pre></td></tr></table></figure><p>​ 执行<code>mpirun</code>，如果有帮助信息打印出来，就表示安装好了。需要注意的是，我安装了几个版本都没有成功，最后安装了1.4.1这个版本才能成功，因此就看你的人品了。</p><h2 id="安装numpy和Cython"><a href="#安装numpy和Cython" class="headerlink" title="安装numpy和Cython"></a>安装numpy和Cython</h2><p>​ 安装python库的方法可以参考<a href="http://blog.csdn.net/zouxy09/article/details/48903179" target="_blank" rel="external">之前的博客</a>。过程一般如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar –xgvf Cython-0.20.2.tar.gz  </div><div class="line">cd Cython-0.20.2  </div><div class="line">python setup.py install</div></pre></td></tr></table></figure><p>​ 打开Python，import Cython，如果没有报错，就表示安装成功了</p><h2 id="安装mpi4py"><a href="#安装mpi4py" class="headerlink" title="安装mpi4py"></a>安装mpi4py</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar –xgvf mpi4py_1.3.1.tar.gz  </div><div class="line">cd mpi4py  </div><div class="line">vi mpi.cfg</div></pre></td></tr></table></figure><p>​ 在68行，<code>[openmpi]</code>下面，将刚才已经安装好的openmpi的目录给改上。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mpi_dir = /home/work/vis/zouxiaoyi/my_tools  </div><div class="line">python setup.py install</div></pre></td></tr></table></figure><p>​ 打开Python，<code>import mpi4py as MPI</code>，如果没有报错，就表示安装成功了</p><p>​ 下面就可以开始属于你的并行之旅了，勇敢探索多核的乐趣吧。</p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></section><nav class="pagination"><a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a></nav></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ewan Li"><p class="site-author-name" itemprop="name">Ewan Li</p><p class="site-description motion-element" itemprop="description">Ewan's IT Blog</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">119</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">58</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/ewanlee" target="_blank" title="Github"><i class="fa fa-fw fa-globe"></i> Github </a></span><span class="links-of-author-item"><a href="http://weibo.com/3946248928/profile?topnav=1&wvr=6" target="_blank" title="Weibo"><i class="fa fa-fw fa-weibo"></i> Weibo</a></span></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Ewan Li</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user">本站访客数</i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人次</span> <span class="site-pv"><i class="fa fa-eye">本站总访问量</i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">_hcwp=window._hcwp||[],_hcwp.push({widget:"Bloggerstream",widget_id:89825,selector:".hc-comment-count",label:"{%COUNT%}"}),function(){if(!("HC_LOAD_INIT"in window)){HC_LOAD_INIT=!0;var t=(navigator.language||navigator.systemLanguage||navigator.userLanguage||"en").substr(0,2).toLowerCase(),e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src=("https:"==document.location.protocol?"https":"http")+"://w.hypercomments.com/widget/hc/89825/"+t+"/widget.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n.nextSibling)}}()</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("e27VKX5tTklQLCtF7iNMmhcA-gzGzoHsz","nnQn2znNgXXEdK7W2bVJ3bfK")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script></body></html>