<!doctype html><html class="theme-next mist use-motion" lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css"><meta name="keywords" content="Hexo, NexT"><link rel="alternate" href="/atom.xml" title="Abracadabra" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0"><meta name="description" content="Ewan&apos;s IT Blog"><meta property="og:type" content="website"><meta property="og:title" content="Abracadabra"><meta property="og:url" content="http://yoursite.com/page/8/index.html"><meta property="og:site_name" content="Abracadabra"><meta property="og:description" content="Ewan&apos;s IT Blog"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Abracadabra"><meta name="twitter:description" content="Ewan&apos;s IT Blog"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"left",display:"post"},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"Author"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/page/8/"><title>Abracadabra</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="en"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?dc405a79ad500922134d14cdf288f646";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><div class="container one-collumn sidebar-position-left page-home"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Abracadabra</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Do it yourself</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>Home</a></li><li class="menu-item menu-item-categories"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>Categories</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>About</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>Tags</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>Search</a></li></ul><div class="site-search"><div class="popup"><span class="search-icon fa fa-search"></span> <input type="text" id="local-search-input"><div id="local-search-result"></div><span class="popup-btn-close">close</span></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><section id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/28/Understanding-LSTM-Networks-repost/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/11/28/Understanding-LSTM-Networks-repost/" itemprop="url">Understanding LSTM Networks [repost]</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-28T15:51:36+08:00">2017-11-28 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/11/28/Understanding-LSTM-Networks-repost/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/11/28/Understanding-LSTM-Networks-repost/" itemprop="commentsCount"></span> </a></span><span id="/2017/11/28/Understanding-LSTM-Networks-repost/" class="leancloud_visitors" data-flag-title="Understanding LSTM Networks [repost]"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>source post is <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">here</a>.</p><h2 id="Recurrent-Neural-Networks"><a href="#Recurrent-Neural-Networks" class="headerlink" title="Recurrent Neural Networks"></a>Recurrent Neural Networks</h2><p>Humans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. Your thoughts have persistence.</p><p>Traditional neural networks can’t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. It’s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones.</p><p>Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png" alt="img"></p><p><strong>Recurrent Neural Networks have loops.</strong></p><p>In the above diagram, a chunk of neural network, AA, looks at some input xtxt and outputs a value htht. A loop allows information to be passed from one step of the network to the next.</p><p>These loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they aren’t all that different than a normal neural network. A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. Consider what happens if we unroll the loop:</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png" alt="An unrolled recurrent neural network."></p><p><strong>An unrolled recurrent neural network.</strong></p><p>This chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. They’re the natural architecture of neural network to use for such data.</p><p>And they certainly are used! In the last few years, there have been incredible success applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioning… The list goes on. I’ll leave discussion of the amazing feats one can achieve with RNNs to Andrej Karpathy’s excellent blog post, <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">The Unreasonable Effectiveness of Recurrent Neural Networks</a>. But they really are pretty amazing.</p><p>Essential to these successes is the use of “LSTMs,” a very special kind of recurrent neural network which works, for many tasks, much much better than the standard version. Almost all exciting results based on recurrent neural networks are achieved with them. It’s these LSTMs that this essay will explore.</p><h2 id="The-Problem-of-Long-Term-Dependencies"><a href="#The-Problem-of-Long-Term-Dependencies" class="headerlink" title="The Problem of Long-Term Dependencies"></a>The Problem of Long-Term Dependencies</h2><p>One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame. If RNNs could do this, they’d be extremely useful. But can they? It depends.</p><p>Sometimes, we only need to look at recent information to perform the present task. For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in “the clouds are in the <em>sky</em>,” we don’t need any further context – it’s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that it’s needed is small, RNNs can learn to use the past information.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png" alt="img"></p><p>But there are also cases where we need more context. Consider trying to predict the last word in the text “I grew up in France… I speak fluent <em>French</em>.” Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It’s entirely possible for the gap between the relevant information and the point where it is needed to become very large.</p><p>Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png" alt="Neural networks struggle with long term dependencies."></p><p>In theory, RNNs are absolutely capable of handling such “long-term dependencies.” A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don’t seem to be able to learn them. The problem was explored in depth by <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf" target="_blank" rel="external">Hochreiter (1991) [German]</a> and <a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="external">Bengio, et al. (1994)</a>, who found some pretty fundamental reasons why it might be difficult.</p><p>Thankfully, LSTMs don’t have this problem!</p><h2 id="LSTM-Networks"><a href="#LSTM-Networks" class="headerlink" title="LSTM Networks"></a>LSTM Networks</h2><p>Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by <a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf" target="_blank" rel="external">Hochreiter &amp; Schmidhuber (1997)</a>, and were refined and popularized by many people in following work.<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/#fn1" target="_blank" rel="external">1</a> They work tremendously well on a large variety of problems, and are now widely used.</p><p>LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!</p><p>All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.</p><p><strong>The repeating module in a standard RNN contains a single layer.</strong></p><p>LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.</p><p><strong>The repeating module in an LSTM contains four interacting layers.</strong></p><p>Don’t worry about the details of what’s going on. We’ll walk through the LSTM diagram step by step later. For now, let’s just try to get comfortable with the notation we’ll be using.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM2-notation.png" alt="img"></p><p>In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers. Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations.</p><h2 id="The-Core-Idea-Behind-LSTMs"><a href="#The-Core-Idea-Behind-LSTMs" class="headerlink" title="The Core Idea Behind LSTMs"></a>The Core Idea Behind LSTMs</h2><p>The key to LSTMs is the cell state, the horizontal line running through the top of the diagram.</p><p>The cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some minor linear interactions. It’s very easy for information to just flow along it unchanged.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-C-line.png" alt="img"></p><p>The LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called gates.</p><p>Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-gate.png" alt="img"></p><p>The sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means “let nothing through,” while a value of one means “let everything through!”</p><p>An LSTM has three of these gates, to protect and control the cell state.</p><h2 id="Step-by-Step-LSTM-Walk-Through"><a href="#Step-by-Step-LSTM-Walk-Through" class="headerlink" title="Step-by-Step LSTM Walk Through"></a>Step-by-Step LSTM Walk Through</h2><p>The first step in our LSTM is to decide what information we’re going to throw away from the cell state. This decision is made by a sigmoid layer called the “forget gate layer.” It looks at ht−1ht−1and xtxt, and outputs a number between 00 and 11 for each number in the cell state Ct−1Ct−1. A 11represents “completely keep this” while a 00 represents “completely get rid of this.”</p><p>Let’s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png" alt="img"></p><p>The next step is to decide what new information we’re going to store in the cell state. This has two parts. First, a sigmoid layer called the “input gate layer” decides which values we’ll update. Next, a tanh layer creates a vector of new candidate values, C~tC~t, that could be added to the state. In the next step, we’ll combine these two to create an update to the state.</p><p>In the example of our language model, we’d want to add the gender of the new subject to the cell state, to replace the old one we’re forgetting.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png" alt="img"></p><p>It’s now time to update the old cell state, Ct−1Ct−1, into the new cell state CtCt. The previous steps already decided what to do, we just need to actually do it.</p><p>We multiply the old state by ftft, forgetting the things we decided to forget earlier. Then we add it∗C~tit∗C~t. This is the new candidate values, scaled by how much we decided to update each state value.</p><p>In the case of the language model, this is where we’d actually drop the information about the old subject’s gender and add the new information, as we decided in the previous steps.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png" alt="img"></p><p>Finally, we need to decide what we’re going to output. This output will be based on our cell state, but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we’re going to output. Then, we put the cell state through tanhtanh (to push the values to be between −1−1 and 11) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.</p><p>For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that’s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that’s what follows next.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png" alt="img"></p><h2 id="Variants-on-Long-Short-Term-Memory"><a href="#Variants-on-Long-Short-Term-Memory" class="headerlink" title="Variants on Long Short Term Memory"></a>Variants on Long Short Term Memory</h2><p>What I’ve described so far is a pretty normal LSTM. But not all LSTMs are the same as the above. In fact, it seems like almost every paper involving LSTMs uses a slightly different version. The differences are minor, but it’s worth mentioning some of them.</p><p>One popular LSTM variant, introduced by <a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="external">Gers &amp; Schmidhuber (2000)</a>, is adding “peephole connections.” This means that we let the gate layers look at the cell state.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-peepholes.png" alt="img"></p><p>The above diagram adds peepholes to all the gates, but many papers will give some peepholes and not others.</p><p>Another variation is to use coupled forget and input gates. Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when we’re going to input something in its place. We only input new values to the state when we forget something older.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-tied.png" alt="img"></p><p>A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by <a href="http://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="external">Cho, et al. (2014)</a>. It combines the forget and input gates into a single “update gate.” It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular.</p><p><img src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png" alt="A gated recurrent unit neural network."></p><p>These are only a few of the most notable LSTM variants. There are lots of others, like Depth Gated RNNs by <a href="http://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="external">Yao, et al. (2015)</a>. There’s also some completely different approach to tackling long-term dependencies, like Clockwork RNNs by <a href="http://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="external">Koutnik, et al. (2014)</a>.</p><p>Which of these variants is best? Do the differences matter? <a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="external">Greff, et al. (2015)</a> do a nice comparison of popular variants, finding that they’re all about the same. <a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="external">Jozefowicz, et al. (2015)</a>tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Earlier, I mentioned the remarkable results people are achieving with RNNs. Essentially all of these are achieved using LSTMs. They really work a lot better for most tasks!</p><p>Written down as a set of equations, LSTMs look pretty intimidating. Hopefully, walking through them step by step in this essay has made them a bit more approachable.</p><p>LSTMs were a big step in what we can accomplish with RNNs. It’s natural to wonder: is there another big step? A common opinion among researchers is: “Yes! There is a next step and it’s attention!” The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, <a href="http://arxiv.org/pdf/1502.03044v2.pdf" target="_blank" rel="external">Xu, <em>et al.</em>(2015)</a> do exactly this – it might be a fun starting point if you want to explore attention! There’s been a number of really exciting results using attention, and it seems like a lot more are around the corner…</p><p>Attention isn’t the only exciting thread in RNN research. For example, Grid LSTMs by <a href="http://arxiv.org/pdf/1507.01526v1.pdf" target="_blank" rel="external">Kalchbrenner, <em>et al.</em> (2015)</a> seem extremely promising. Work using RNNs in generative models – such as <a href="http://arxiv.org/pdf/1502.04623.pdf" target="_blank" rel="external">Gregor, <em>et al.</em> (2015)</a>, <a href="http://arxiv.org/pdf/1506.02216v3.pdf" target="_blank" rel="external">Chung, <em>et al.</em> (2015)</a>, or <a href="http://arxiv.org/pdf/1411.7610v3.pdf" target="_blank" rel="external">Bayer &amp; Osendorfer (2015)</a> – also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!</p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/21/A-Simple-Multi-Class-Classification-Task-Keras-and-Scikit-Learn/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/11/21/A-Simple-Multi-Class-Classification-Task-Keras-and-Scikit-Learn/" itemprop="url">A Simple Multi-Class Classification Task: Keras and Scikit-Learn</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-21T16:59:17+08:00">2017-11-21 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/11/21/A-Simple-Multi-Class-Classification-Task-Keras-and-Scikit-Learn/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/11/21/A-Simple-Multi-Class-Classification-Task-Keras-and-Scikit-Learn/" itemprop="commentsCount"></span> </a></span><span id="/2017/11/21/A-Simple-Multi-Class-Classification-Task-Keras-and-Scikit-Learn/" class="leancloud_visitors" data-flag-title="A Simple Multi-Class Classification Task: Keras and Scikit-Learn"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="1-Problem-Description"><a href="#1-Problem-Description" class="headerlink" title="1. Problem Description"></a>1. Problem Description</h2><p>In this tutorial, we will use the standard machine learning problem called the <a href="http://archive.ics.uci.edu/ml/datasets/Iris" target="_blank" rel="external">iris flowers dataset</a>.</p><p>This dataset is well studied and is a good problem for practicing on neural networks because all of the 4 input variables are numeric and have the same scale in centimeters. Each instance describes the properties of an observed flower measurements and the output variable is specific iris species.</p><p>This is a multi-class classification problem, meaning that there are more than two classes to be predicted, in fact there are three flower species. This is an important type of problem on which to practice with neural networks because the three class values require specialized handling.</p><p>The iris flower dataset is a well-studied problem and a such we can <a href="http://www.is.umk.pl/projects/rules.html#Iris" target="_blank" rel="external">expect to achieve a model accuracy</a> in the range of 95% to 97%. This provides a good target to aim for when developing our models.</p><p>You can <a href="http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data" target="_blank" rel="external">download the iris flowers dataset</a> from the UCI Machine Learning repository and place it in your current working directory with the filename “<em>iris.csv</em>“.</p><p>Need help with Deep Learning in Python?Take my free 2-week email course and discover MLPs, CNNs and LSTMs (with sample code).Click to sign-up now and also get a free PDF Ebook version of the course.<a href="https://machinelearningmastery.leadpages.co/leadbox/142d6e873f72a2%3A164f8be4f346dc/5657382461898752/" target="_blank" rel="external">Start Your FREE Mini-Course Now!</a></p><h2 id="2-Import-Classes-and-Functions"><a href="#2-Import-Classes-and-Functions" class="headerlink" title="2. Import Classes and Functions"></a>2. Import Classes and Functions</h2><p>We can begin by importing all of the classes and functions we will need in this tutorial.</p><p>This includes both the functionality we require from Keras, but also data loading from <a href="http://pandas.pydata.org/" target="_blank" rel="external">pandas</a>as well as data preparation and model evaluation from <a href="http://scikit-learn.org/" target="_blank" rel="external">scikit-learn</a>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">import</span> pandas</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</div><div class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</div><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</div></pre></td></tr></table></figure><h2 id="3-Initialize-Random-Number-Generator"><a href="#3-Initialize-Random-Number-Generator" class="headerlink" title="3. Initialize Random Number Generator"></a>3. Initialize Random Number Generator</h2><p>Next, we need to initialize the random number generator to a constant value (7).</p><p>This is important to ensure that the results we achieve from this model can be achieved again precisely. It ensures that the stochastic process of training a neural network model can be reproduced.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div></pre></td></tr></table></figure><h2 id="4-Load-The-Dataset"><a href="#4-Load-The-Dataset" class="headerlink" title="4. Load The Dataset"></a>4. Load The Dataset</h2><p>The dataset can be loaded directly. Because the output variable contains strings, it is easiest to load the data using pandas. We can then split the attributes (columns) into input variables (X) and output variables (Y).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># load dataset</span></div><div class="line">dataframe = pandas.read_csv(<span class="string">"iris.csv"</span>, header=<span class="keyword">None</span>)</div><div class="line">dataset = dataframe.values</div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">4</span>].astype(float)</div><div class="line">Y = dataset[:,<span class="number">4</span>]</div></pre></td></tr></table></figure><h2 id="5-Encode-The-Output-Variable"><a href="#5-Encode-The-Output-Variable" class="headerlink" title="5. Encode The Output Variable"></a>5. Encode The Output Variable</h2><p>The output variable contains three different string values.</p><p>When modeling multi-class classification problems using neural networks, it is good practice to reshape the output attribute from a vector that contains values for each class value to be a matrix with a boolean for each class value and whether or not a given instance has that class value or not.</p><p>This is called <a href="https://en.wikipedia.org/wiki/One-hot" target="_blank" rel="external">one hot encoding</a> or creating dummy variables from a categorical variable.</p><p>For example, in this problem three class values are Iris-setosa, Iris-versicolor and Iris-virginica. If we had the observations:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Iris-setosa</div><div class="line">Iris-versicolor</div><div class="line">Iris-virginica</div></pre></td></tr></table></figure><p>We can turn this into a one-hot encoded binary matrix for each data instance that would look as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Iris-setosa,	Iris-versicolor,	Iris-virginica</div><div class="line"><span class="number">1</span>,		<span class="number">0</span>,			<span class="number">0</span></div><div class="line"><span class="number">0</span>,		<span class="number">1</span>, 			<span class="number">0</span></div><div class="line"><span class="number">0</span>, 		<span class="number">0</span>, 			<span class="number">1</span></div></pre></td></tr></table></figure><p>We can do this by first encoding the strings consistently to integers using the scikit-learn class LabelEncoder. Then convert the vector of integers to a one hot encoding using the Keras function to_categorical().</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># encode class values as integers</span></div><div class="line">encoder = LabelEncoder()</div><div class="line">encoder.fit(Y)</div><div class="line">encoded_Y = encoder.transform(Y)</div><div class="line"><span class="comment"># convert integers to dummy variables (i.e. one hot encoded)</span></div><div class="line">dummy_y = np_utils.to_categorical(encoded_Y)</div></pre></td></tr></table></figure><h2 id="6-Define-The-Neural-Network-Model"><a href="#6-Define-The-Neural-Network-Model" class="headerlink" title="6. Define The Neural Network Model"></a>6. Define The Neural Network Model</h2><p>The Keras library provides wrapper classes to allow you to use neural network models developed with Keras in scikit-learn.</p><p>There is a KerasClassifier class in Keras that can be used as an Estimator in scikit-learn, the base type of model in the library. The KerasClassifier takes the name of a function as an argument. This function must return the constructed neural network model, ready for training.</p><p>Below is a function that will create a baseline neural network for the iris classification problem. It creates a simple fully connected network with one hidden layer that contains 8 neurons.</p><p>The hidden layer uses a rectifier activation function which is a good practice. Because we used a one-hot encoding for our iris dataset, the output layer must create 3 output values, one for each class. The output value with the largest value will be taken as the class predicted by the model.</p><p>The network topology of this simple one-layer neural network can be summarized as:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">4 inputs -&gt; [8 hidden nodes] -&gt; 3 outputs</div></pre></td></tr></table></figure><p>Note that we use a “<em>softmax</em>” activation function in the output layer. This is to ensure the output values are in the range of 0 and 1 and may be used as predicted probabilities.</p><p>Finally, the network uses the efficient Adam gradient descent optimization algorithm with a logarithmic loss function, which is called “<em>categorical_crossentropy</em>” in Keras.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># define baseline model</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">baseline_model</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(<span class="number">8</span>, input_dim=<span class="number">4</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(<span class="number">3</span>, activation=<span class="string">'softmax'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div></pre></td></tr></table></figure><p>We can now create our KerasClassifier for use in scikit-learn.</p><p>We can also pass arguments in the construction of the KerasClassifier class that will be passed on to the fit() function internally used to train the neural network. Here, we pass the number of epochs as 200 and batch size as 5 to use when training the model. Debugging is also turned off when training by setting verbose to 0.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">estimator = KerasClassifier(</div><div class="line">  build_fn=baseline_model, epochs=<span class="number">200</span>, batch_size=<span class="number">5</span>, verbose=<span class="number">0</span>)</div></pre></td></tr></table></figure><h2 id="7-Evaluate-The-Model-with-k-Fold-Cross-Validation"><a href="#7-Evaluate-The-Model-with-k-Fold-Cross-Validation" class="headerlink" title="7. Evaluate The Model with k-Fold Cross Validation"></a>7. Evaluate The Model with k-Fold Cross Validation</h2><p>We can now evaluate the neural network model on our training data.</p><p>The scikit-learn has excellent capability to evaluate models using a suite of techniques. The gold standard for evaluating machine learning models is k-fold cross validation.</p><p>First we can define the model evaluation procedure. Here, we set the number of folds to be 10 (an excellent default) and to shuffle the data before partitioning it.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kfold = KFold(n_splits=<span class="number">10</span>, shuffle=<span class="keyword">True</span>, random_state=seed)</div></pre></td></tr></table></figure><p>Now we can evaluate our model (estimator) on our dataset (X and dummy_y) using a 10-fold cross-validation procedure (kfold).</p><p>Evaluating the model only takes approximately 10 seconds and returns an object that describes the evaluation of the 10 constructed models for each of the splits of the dataset.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">results = cross_val_score(estimator, X, dummy_y, cv=kfold)</div><div class="line">print(<span class="string">"Baseline: %.2f%% (%.2f%%)"</span> % (results.mean()*<span class="number">100</span>, results.std()*<span class="number">100</span>))</div></pre></td></tr></table></figure><p>The results are summarized as both the mean and standard deviation of the model accuracy on the dataset. This is a reasonable estimation of the performance of the model on unseen data. It is also within the realm of known top results for this problem.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Accuracy: <span class="number">97.33</span>% (<span class="number">4.42</span>%)</div></pre></td></tr></table></figure></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/" itemprop="url">The Right Way to Oversample in Predictive Modeling</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-21T09:10:22+08:00">2017-11-21 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/" itemprop="commentsCount"></span> </a></span><span id="/2017/11/21/The-Right-Way-to-Oversample-in-Predictive-Modeling/" class="leancloud_visitors" data-flag-title="The Right Way to Oversample in Predictive Modeling"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><p>The Source Blog: <a href="https://beckernick.github.io/oversampling-modeling/" target="_blank" rel="external">https://beckernick.github.io/oversampling-modeling/</a></p><p>Imbalanced datasets spring up everywhere. Amazon wants to classify fake reviews, banks want to predict fraudulent credit card charges, and, as of this November, Facebook researchers are probably wondering if they can predict which news articles are fake.</p><p>In each of these cases, only a small fraction of observations are actually positives. I’d guess that only 1 in 10,000 credit card charges are fraudulent, at most. Recently, oversampling the minority class observations has become a common approach to improve the quality of predictive modeling. By oversampling, models are sometimes better able to learn patterns that differentiate classes.</p><p>However, this post isn’t about how this can improve modeling. Instead, it’s about how the <strong>*timing*</strong> of oversampling can affect the generalization ability of a model. Since one of the primary goals of model validation is to estimate how it will perform on unseen data, oversampling correctly is critical.</p><h1 id="Preparing-the-Data"><a href="#Preparing-the-Data" class="headerlink" title="Preparing the Data"></a>Preparing the Data</h1><p>I’m going to try to predict whether someone will default on or a creditor will have to charge off a loan, using data from Lending Club. I’ll start by importing some modules and loading the data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</div><div class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">loans = pd.read_csv(<span class="string">'../lending-club-data.csv.zip'</span>)</div><div class="line">loans.iloc[<span class="number">0</span>]</div></pre></td></tr></table></figure><p>There’s a lot of cool person and loan-specific information in this dataset. The target variable is <code>bad_loans</code>, which is 1 if the loan was charged off or the lessee defaulted, and 0 otherwise. I know this dataset should be imbalanced (most loans are paid off), but how imbalanced is it?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loans.bad_loans.value_counts()</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="number">0</span>    <span class="number">99457</span></div><div class="line"><span class="number">1</span>    <span class="number">23150</span></div><div class="line">Name: bad_loans, dtype: int64</div></pre></td></tr></table></figure><p>Charge offs occurred or people defaulted on about 19% of loans, so there’s some imbalance in the data but it’s not terrible. I’ll remove a few observations with missing values for a payment-to-income ratio and then pick a handful of features to use in a random forest model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loans = loans[~loans.payment_inc_ratio.isnull()]</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">model_variables = [<span class="string">'grade'</span>, <span class="string">'home_ownership'</span>,<span class="string">'emp_length_num'</span>, <span class="string">'sub_grade'</span>,<span class="string">'short_emp'</span>, <span class="string">'dti'</span>, <span class="string">'term'</span>, <span class="string">'purpose'</span>, <span class="string">'int_rate'</span>, <span class="string">'last_delinq_none'</span>, <span class="string">'last_major_derog_none'</span>, <span class="string">'revol_util'</span>, <span class="string">'total_rec_late_fee'</span>, <span class="string">'payment_inc_ratio'</span>, <span class="string">'bad_loans'</span>]</div><div class="line"></div><div class="line">loans_data_relevent = loans[model_variables]</div></pre></td></tr></table></figure><p>Next, I need to one-hot encode the categorical features as binary variables to use them in sklearn’s random forest classifier.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loans_relevant_enconded = pd.get_dummies(loans_data_relevent)</div></pre></td></tr></table></figure><h1 id="Creating-the-Training-and-Test-Sets"><a href="#Creating-the-Training-and-Test-Sets" class="headerlink" title="Creating the Training and Test Sets"></a>Creating the Training and Test Sets</h1><p>With the data prepared, I can create a training dataset and a test dataset. I’ll use the training dataset to build and validate the model, and treat the test dataset as the unseen new data I’d see if the model were in production.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">training_features, test_features, \</div><div class="line">training_target, test_target, = train_test_split(loans_relevant_enconded.drop([<span class="string">'bad_loans'</span>], axis=<span class="number">1</span>),                        loans_relevant_enconded[<span class="string">'bad_loans'</span>],</div><div class="line">			    test_size = <span class="number">.1</span>,</div><div class="line">			    random_state=<span class="number">12</span>)</div></pre></td></tr></table></figure><h1 id="The-Wrong-Way-to-Oversample"><a href="#The-Wrong-Way-to-Oversample" class="headerlink" title="The Wrong Way to Oversample"></a>The Wrong Way to Oversample</h1><p>With my training data created, I’ll upsample the bad loans using the <a href="https://www.jair.org/media/953/live-953-2037-jair.pdf" target="_blank" rel="external">SMOTE algorithm</a> (Synthetic Minority Oversampling Technique). At a high level, SMOTE creates synthetic observations of the minority class (bad loans) by:</p><ol><li>Finding the k-nearest-neighbors for minority class observations (finding similar observations)</li><li>Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observation.</li></ol><p>After upsampling to a class ratio of 1.0, I should have a balanced dataset. There’s no need (and often it’s not smart) to balance the classes, but it magnifies the issue caused by incorrectly timed oversampling.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sm = SMOTE(random_state=<span class="number">12</span>, ratio = <span class="number">1.0</span>)</div><div class="line">x_res, y_res = sm.fit_sample(training_features, training_target)</div><div class="line"><span class="keyword">print</span> training_target.value_counts(), np.bincount(y_res)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="number">0</span>    <span class="number">89493</span></div><div class="line"><span class="number">1</span>    <span class="number">20849</span></div><div class="line">Name: bad_loans, dtype: int64 [<span class="number">89493</span> <span class="number">89493</span>]</div></pre></td></tr></table></figure><p>After upsampling, I’ll split the data into separate training and validation sets and build a random forest model to classify the bad loans.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">x_train_res, x_val_res, y_train_res, y_val_res = train_test_split(x_res,</div><div class="line">                                                    y_res,</div><div class="line">                                                    test_size = <span class="number">.1</span>,</div><div class="line">                                                    random_state=<span class="number">12</span>)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">clf_rf = RandomForestClassifier(n_estimators=<span class="number">25</span>, random_state=<span class="number">12</span>)</div><div class="line">clf_rf.fit(x_train_res, y_train_res)</div><div class="line">clf_rf.score(x_val_res, y_val_res)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="number">0.88468629532376108</span></div></pre></td></tr></table></figure><p>88% accuracy looks good, but I’m not just interested in accuracy. I also want to know how well I can specifically classify bad loans, since they’re more important. In statistics, this is called <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" target="_blank" rel="external">recall</a>, and it’s the number of correctly predicted “positives” divided by the total number of “positives”.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">recall_score(y_val_res, clf_rf.predict(x_val_res))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="number">0.81192097332291546</span></div></pre></td></tr></table></figure><p>81% recall. That means the model correctly identified 81% of the total bad loans. That’s pretty great. But is this actually representative of how the model will perform? To find out, I’ll calculate the accuracy and recall for the model on the test dataset I created initially.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> clf_rf.score(test_features, test_target)</div><div class="line"><span class="keyword">print</span> recall_score(test_target, clf_rf.predict(test_features))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="number">0.801973737868</span></div><div class="line"><span class="number">0.129943502825</span></div></pre></td></tr></table></figure><p>Only 80% accuracy and 13% recall on the test data. That’s a <strong>huge</strong> difference!</p><h1 id="What-Happened"><a href="#What-Happened" class="headerlink" title="What Happened?"></a>What Happened?</h1><p>By oversampling before splitting into training and validation datasets, I “bleed” information from the validation set into the training of the model.</p><p>To see how this works, think about the case of simple oversampling (where I just duplicate observations). If I upsample a dataset before splitting it into a train and validation set, I could end up with the same observation in both datasets. As a result, a complex enough model will be able to perfectly predict the value for those observations when predicting on the validation set, inflating the accuracy and recall.</p><p>When upsampling using SMOTE, I don’t create duplicate observations. However, because the SMOTE algorithm uses the nearest neighbors of observations to create synthetic data, it still bleeds information. If the nearest neighbors of minority class observations in the training set end up in the validation set, their information is partially captured by the synthetic data in the training set. Since I’m splitting the data randomly, we’d expect to have this happen. As a result, the model will be better able to predict validation set values than completely new data.</p><h1 id="The-Right-Way-to-Oversample"><a href="#The-Right-Way-to-Oversample" class="headerlink" title="The Right Way to Oversample"></a>The Right Way to Oversample</h1><p>Okay, so I’ve gone through the wrong way to oversample. Now I’ll go through the right way: oversampling on only the training data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">x_train, x_val, y_train, y_val = \</div><div class="line">			train_test_split(training_features, 											    training_target,</div><div class="line">						    test_size = <span class="number">.1</span>,</div><div class="line">                              random_state=<span class="number">12</span>)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sm = SMOTE(random_state=<span class="number">12</span>, ratio = <span class="number">1.0</span>)</div><div class="line">x_train_res, y_train_res = sm.fit_sample(x_train, y_train)</div></pre></td></tr></table></figure><p>By oversampling only on the training data, none of the information in the validation data is being used to create synthetic observations. So these results should be generalizable. Let’s see if that’s true.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">clf_rf = RandomForestClassifier(n_estimators=<span class="number">25</span>, random_state=<span class="number">12</span>)</div><div class="line">clf_rf.fit(x_train_res, y_train_res)</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'Validation Results'</span></div><div class="line"><span class="keyword">print</span> clf_rf.score(x_val, y_val)</div><div class="line"><span class="keyword">print</span> recall_score(y_val, clf_rf.predict(x_val))</div><div class="line"><span class="keyword">print</span> <span class="string">'\nTest Results'</span></div><div class="line"><span class="keyword">print</span> clf_rf.score(test_features, test_target)</div><div class="line"><span class="keyword">print</span> recall_score(test_target, clf_rf.predict(test_features))</div></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Validation Results</div><div class="line"><span class="number">0.800362483009</span></div><div class="line"><span class="number">0.138195777351</span></div><div class="line"></div><div class="line">Test Results</div><div class="line"><span class="number">0.803278688525</span></div><div class="line"><span class="number">0.142546718818</span></div></pre></td></tr></table></figure><p>The validation results closely match the unseen test data results, which is exactly what I would want to see after putting a model into production.</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>Oversampling is a well-known way to potentially improve models trained on imbalanced data. But it’s important to remember that oversampling incorrectly can lead to thinking a model will generalize better than it actually does. Random forests are great because the model architecture reduces overfitting (see <a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf" target="_blank" rel="external">Brieman 2001</a> for a proof), but poor sampling practices can still lead to false conclusions about the quality of a model.</p><p>When the model is in production, it’s predicting on unseen data. The main point of model validation is to estimate how the model will generalize to new data. If the decision to put a model into production is based on how it performs on a validation set, it’s critical that oversampling is done correctly.</p></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/20/Note-of-the-DenseNet-contains-TensorFlow-and-PyTorch-Implementation/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/11/20/Note-of-the-DenseNet-contains-TensorFlow-and-PyTorch-Implementation/" itemprop="url">Note of the DenseNet (contains TensorFlow and PyTorch Implementation)</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-20T12:15:43+08:00">2017-11-20 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/11/20/Note-of-the-DenseNet-contains-TensorFlow-and-PyTorch-Implementation/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/11/20/Note-of-the-DenseNet-contains-TensorFlow-and-PyTorch-Implementation/" itemprop="commentsCount"></span> </a></span><span id="/2017/11/20/Note-of-the-DenseNet-contains-TensorFlow-and-PyTorch-Implementation/" class="leancloud_visitors" data-flag-title="Note of the DenseNet (contains TensorFlow and PyTorch Implementation)"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><blockquote><p><strong>The blog source:</strong></p><p><strong><a href="https://medium.com/intuitionmachine/notes-on-the-implementation-densenet-in-tensorflow-beeda9dd1504">https://medium.com/intuitionmachine/notes-on-the-implementation-densenet-in-tensorflow-beeda9dd1504</a>.</strong></p><p>I have added the PyTorch implementation from</p><p><strong><a href="https://github.com/gpleiss/efficient_densenet_pytorch">https://github.com/gpleiss/efficient_densenet_pytorch</a>.</strong></p></blockquote><p><a href="https://arxiv.org/abs/1608.06993">DenseNet</a>(Densely Connected Convolutional Networks) is one of the latest neural networks for visual object recognition. It’s quite similar to <a href="https://arxiv.org/abs/1512.03385">ResNet</a> but has some fundamental differences.</p><p>With all improvements DenseNets have one of the lowest error rates on CIFAR/SVHN datasets:</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*7WdURialIGTojNI9ltrplA.png" alt="img"></p><p><em>Error rates on various datasets(from source paper)</em></p><p>And for ImageNet dataset DenseNets require fewer parameters than ResNet with same accuracy:</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*N_o10WxGx_e6vBSNnV5k1A.png" alt="img"></p><p><em>Сomparison of the DenseNet and ResNet Top-1 error rates on the ImageNet classification dataset as a function of learned parameters (left) and flops during test-time (right)(from source paper).</em></p><p>This post assumes previous knowledge of neural networks(NN) and convolutions(convs). Here I will not explain how NN or convs work, but mainly focus on two topics:</p><ul><li>Why dense net differs from another convolution networks.</li><li>What difficulties I’ve met during the implementation of DenseNet in tensorflow.</li></ul><p>If you know how DenseNets works and interested only in tensorflow implementation feel free to jump to the <a href="https://medium.com/intuitionmachine/notes-on-the-implementation-densenet-in-tensorflow-beeda9dd1504#aabd">second chapter</a> or check the <a href="https://github.com/ikhlestov/vision_networks">source code on GitHub</a>. If you not familiar with any topics but want to get some knowledge — I highly advise you <a href="http://cs231n.github.io/">CS231n Stanford classes</a>.</p><h4 id="Compare-DenseNet-with-other-Convolution-Networks"><a href="#Compare-DenseNet-with-other-Convolution-Networks" class="headerlink" title="Compare DenseNet with other Convolution Networks"></a>Compare DenseNet with other Convolution Networks</h4><p>Usually, ConvNets work such way:<br>We have an initial image, say having a shape of (28, 28, 3). After we apply set of convolution/pooling filters on it, squeezing width and height dimensions and increasing features dimension.<br>So the output from the Lᵢ layer is input to the Lᵢ₊₁ layer. It seems like this:</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*1F8wom5X1DeCj5BWeGfJbw.jpeg" alt="img"></p><p><em>source: &lt;<a href="http://cs231n.github.io/convolutional-networks/">http://cs231n.github.io/convolutional-networks/</a></em>&gt;</p><p><a href="https://arxiv.org/abs/1512.03385">ResNet</a> architecture proposed Residual connection, from previous layers to the current one. Roughly saying, input to the Lᵢ layer was obtained by summation of outputs from previous layers.</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*-C2QoqhfCjG8xZRu-UwO_Q.png" alt="img"></p><p>In contrast, DenseNet paper proposes concatenating outputs from the previous layers instead of using the summation.<br>So, let’s imagine we have an image with shape(28, 28, 3). First, we spread image to initial 24 channels and receive the image (28, 28, 24). Every next convolution layer will generate k=12 features, and remain width and height the same.<br>The output from Lᵢ layer will be (28, 28, 12).<br>But input to the Lᵢ₊₁ will be (28, 28, 24+12), for Lᵢ₊₂ (28, 28, 24 + 12 + 12) and so on.</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*6JoB4BeIZyWDNGH5U63y_Q.png" alt="img"></p><p><em>Block of convolution layers with results concatenated</em></p><p>After a while, we receive the image with same width and height, but with plenty of features (28, 28, 48).<br>All these N layers are named Block in the paper. There’s also batch normalization, nonlinearity and dropout inside the block.<br>To reduce the size, DenseNet uses transition layers. These layers contain convolution with kernel size = 1 followed by 2x2 average pooling with stride = 2. It reduces height and width dimensions but leaves feature dimension the same. As a result, we receive the image with shapes (14, 14, 48).</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*-CQyW4huxxxMYpffb72emg.png" alt="img"></p><p><em>Transition layer</em></p><p>Now we can again pass the image through the block with N convolutions.<br>With this approach, DenseNet improved a flow of information and gradients throughout the network, which makes them easy to train.<br>Each layer has direct access to the gradients from the loss function and the original input signal, leading to an implicit deep supervision.</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*SSn5H14SKhhaZZ5XYWN3Cg.jpeg" alt="img"></p><p><em>Full DenseNet example with 3 blocks from source paper</em></p><h4 id="Notes-about-implementation"><a href="#Notes-about-implementation" class="headerlink" title="Notes about implementation"></a>Notes about implementation</h4><p>In the paper, there are two classes of networks exists: for ImageNet and CIFAR/SVHN datasets. I will discuss details about later one.</p><p>First of all, it was not clear how many blocks should be used depends on depth. After I’ve notice that quantity of blocks is a constant value equal to 3 and not depends on the network depth.</p><p>Second I’ve tried to understand how many features should network generate at the initial convolution layer(prior all blocks). As per original source code first features quantity should be equal to growth rate(k) * 2 .</p><p>Despite that we have three blocks as default, it was interesting for me to build net with another param. So every block was not manually hardcoded but called N times as function. The last iteration was performed without transition layer. Simplified example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> block <span class="keyword">in</span> range(required_blocks):</div><div class="line">    output = build_block(output)</div><div class="line">    <span class="keyword">if</span> block != (required_blocks — <span class="number">1</span>):</div><div class="line">        output = transition_layer(output)</div></pre></td></tr></table></figure><p>For weights initialization authors proposed use MRSA initialization(as per<a href="https://arxiv.org/abs/1502.01852">this paper</a>). In tensorflow this initialization can be easy implemented with<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/variance_scaling_initializer">variance scaling initializer</a>.</p><p>In the latest revision of paper DenseNets with bottle neck layers were introduced. The main difference of this networks that every block now contain two convolution filters. First is 1x1 conv, and second as usual 3x3 conv. So whole block now will be:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">batch norm -&gt; relu -&gt; conv 1x1 -&gt; dropout -&gt; batch norm -&gt; relu -&gt; conv 3x3 -&gt; dropout -&gt; output.</div></pre></td></tr></table></figure><p>Despite two conv filters, only last output will be concatenated to the main pool of features.</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*FvW30tjOQ2hDQ7LdEkCRLQ.png" alt="img"></p><p>Also at transition layers, not only width and height will be reduced but features also. So if we have image shape after one block (28, 28, 48) after transition layer, we will get (14, 14, 24).</p><p><img src="https://cdn-images-1.medium.com/max/1600/1*N-nU5WXQcrNfhnQMwxquFA.png" alt="img"></p><p>Where theta — some reduction values, in the range (0, 1).</p><p>In case of using DenseNet with bottleneck layers, total depth will be divided by 2. This means that if with depth 20 you previously have 16 3x3 convolution layer(some layers are transition ones), now you will have 8 1x1 convolution layers and 8 3x3 convolutions.</p><p>Last, but not least, about data preprocessing. In the paper per channel normalization was used. With this approach, every image channel should be reduced by its mean and divided by its standard deviation. In many implementations was another normalization used — just divide every image pixel by 255, so we have pixels values in the range [0, 1].</p><p>At first, I implemented a solution that divides image by 255. All works fine, but a little bit worse, than results reported in the paper. Ok, next I’ve implemented per channel normalization… And networks began works even worse. It was not clear for me why. So I’ve decided mail to the authors. Thanks to Zhuang Liu that answered me and point to another source code that I missed somehow. After precise debugging, it becomes apparent that images should be normalized by mean/std of all images in the dataset(train or test), not by its own only.</p><p>And some note about numpy implementation of per channel normalization. By default images provided with data type unit8. Before any manipulations, I highly advise to convert the images to any float representation. Because otherwise, a code may fail without any warnings or errors.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># without this line next slice assignment will silently fail!</span></div><div class="line"><span class="comment"># at least in numpy 1.12.0</span></div><div class="line">images = images.astype(‘float64’)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(channels):</div><div class="line">    images[:, :, :, i] = (</div><div class="line">        (images[:, :, :, i] — self.images_means[i]) /</div><div class="line">         self.images_stds[i])</div></pre></td></tr></table></figure><h4 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h4><p>DenseNets are powerful neural nets that achieve state of the art performance on many datasets. And it’s easy to implement them. I think the approach with concatenating features is very promising and may boost other fields in the machine learning in the future.</p><div class="post-button text-center"><a class="btn" href="/2017/11/20/Note-of-the-DenseNet-contains-TensorFlow-and-PyTorch-Implementation/#more" rel="contents">Read more &raquo;</a></div></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/06/30/Reinforcement-Learning-Resources/"><span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Ewan Li"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.jpg"></span><span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Abracadabra"><span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject"><img style="display:none" itemprop="url image" alt="Abracadabra" src=""></span></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><a class="post-title-link" href="/2017/06/30/Reinforcement-Learning-Resources/" itemprop="url">Machine Learning Resources</a></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">Posted on</span> <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-30T21:07:44+08:00">2017-06-30 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/06/30/Reinforcement-Learning-Resources/#comments" itemprop="discussionUrl"><span class="post-comments-count hc-comment-count" data-xid="2017/06/30/Reinforcement-Learning-Resources/" itemprop="commentsCount"></span> </a></span><span id="/2017/06/30/Reinforcement-Learning-Resources/" class="leancloud_visitors" data-flag-title="Machine Learning Resources"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">Visitors </span><span class="leancloud-visitors-count"></span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="Books"><a href="#Books" class="headerlink" title="Books"></a>Books</h1><ul><li>Sutton’s book has new <a href="https://github.com/ewanlee/RL-Resources/blob/master/book/bookdraft2017june.pdf" target="_blank" rel="external">update</a> (draft, version 2017) !</li><li><a href="https://github.com/ewanlee/RL-Resources/blob/master/book/RLAlgsInMDPs.pdf" target="_blank" rel="external">Algorithms for Reinforcement Learning (Morgan)</a></li></ul><h1 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h1><h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><ul><li><a href="https://arxiv.org/pdf/1509.06461.pdf" target="_blank" rel="external">Deep Reinforcement Learning with Double Q-learning</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Deep-Reinforcement-Learning-with-Double-Q-learning" target="_blank" rel="external">Summary</a></li><li><a href="https://ewanlee.github.io/2017/07/09/Using-Tensorflow-and-Deep-Q-Network-Double-DQN-to-Play-Breakout/" target="_blank" rel="external">Project</a></li></ul></li><li><a href="http://arxiv.org/abs/1511.05952" target="_blank" rel="external">Prioritized Experience Replay</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Prioritized-Experience-Replay" target="_blank" rel="external">Summary</a></li></ul></li><li><a href="https://arxiv.org/pdf/1511.06581.pdf" target="_blank" rel="external">Dueling Network Architectures for Deep Reinforcement Learning</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Dueling-Network-Architectures-for-Deep-Reinforcement-Learning" target="_blank" rel="external">Summary</a></li><li><a href="https://github.com/rlcode/reinforcement-learning/blob/master/3-atari/1-breakout/breakout_dueling_ddqn.py" target="_blank" rel="external">Project</a></li></ul></li><li><a href="http://iew3.technion.ac.il/CE/files/papers/Learning%20Tetris%20Using%20the%20Noisy%20Cross-Entropy%20Method.pdf" target="_blank" rel="external">Learning Tetris Using the Noisy Cross-Entropy Method</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Learning-Tetris-Using-the-Noisy-Cross-Entropy-Method" target="_blank" rel="external">Summary</a></li><li><a href="https://gist.github.com/andrewliao11/d52125b52f76a4af73433e1cf8405a8f" target="_blank" rel="external">Project</a></li></ul></li><li><a href="https://arxiv.org/abs/1511.03722" target="_blank" rel="external">Doubly Robust Off-policy Value Evaluation for Reinforcement Learning</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Doubly-Robust-Off-policy-Value-Evaluation-for-Reinforcement-Learning" target="_blank" rel="external">Summary</a></li></ul></li><li><a href="https://arxiv.org/abs/1705.08422" target="_blank" rel="external">Continuous State-Space Models for Optimal Sepsis Treatment: a Deep Reinforcement Learning Approach</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Continuous-State-Space-Models-for-Optimal-Sepsis-Treatment-a-Deep-Reinforcement-Learning-Approach" target="_blank" rel="external">Summary</a></li></ul></li><li><a href="https://arxiv.org/abs/1704.06300" target="_blank" rel="external">A Reinforcement Learning Approach to Weaning of Mechanical Ventilation in Intensive Care Units</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#A-Reinforcement-Learning-Approach-to-Weaning-of-Mechanical-Ventilation-in-Intensive-Care-Units" target="_blank" rel="external">Summary</a></li></ul></li><li><a href="https://drive.google.com/file/d/0B_j5EZzjlxchV2l3TGJPdTljM1k/view" target="_blank" rel="external">Deep Reinforcement Learning, Decision Making and Control (ICML 2017 Tutorial)</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Deep-Reinforcement-Learning-Decision-Making-and-Control-ICML-2017-Tutorial" target="_blank" rel="external">Summary</a></li></ul></li><li><a href="http://www.robots.ox.ac.uk/~mobile/Papers/DeepIRL_2015.pdf" target="_blank" rel="external">Maximum Entropy Deep Inverse Reinforcement Learning</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Maximum-Entropy-Deep-Inverse-Reinforcement-Learning" target="_blank" rel="external">Summary</a></li></ul></li><li><a href="https://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf" target="_blank" rel="external">Maximum Entropy Inverse Reinforcement Learning</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Maximum-Entropy-Inverse-Reinforcement-Learning" target="_blank" rel="external">Summary</a></li></ul></li><li><a href="http://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf" target="_blank" rel="external">Apprenticeship Learning via Inverse Reinforcement Learning</a><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#Apprenticeship-Learning-via-Inverse-Reinforcement-Learning" target="_blank" rel="external">Summary</a></li></ul></li></ul><h2 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h2><ul><li><p><a href="https://arxiv.org/pdf/1711.05225.pdf" target="_blank" rel="external">CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning</a></p><ul><li><a href="https://ewanlee.github.io/2017/07/08/Summary-of-the-papers/#CheXNet-Radiologist-Level-Pneumonia-Detection-on-Chest-X-Rays-with-Deep-Learning" target="_blank" rel="external">Summary</a></li></ul><p>​</p></li></ul><h1 id="Projects"><a href="#Projects" class="headerlink" title="Projects"></a>Projects</h1><ul><li><a href="https://ewanlee.github.io/2017/07/07/Using-Keras-and-Deep-Q-Network-to-Play-FlappyBird-Repost/" target="_blank" rel="external">Using Keras and Deep Q-Network to Play FlappyBird</a></li></ul><h1 id="Blogs"><a href="#Blogs" class="headerlink" title="Blogs"></a>Blogs</h1><ul><li><a href="https://ewanlee.github.io/2017/07/07/Demystifying-Deep-Reinforcement-Learning/" target="_blank" rel="external">Demystifying Deep Reinforcement Learning</a></li></ul></div><div></div><div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></section><nav class="pagination"><a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right"></i></a></nav></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ewan Li"><p class="site-author-name" itemprop="name">Ewan Li</p><p class="site-description motion-element" itemprop="description">Ewan's IT Blog</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives"><span class="site-state-item-count">129</span> <span class="site-state-item-name">posts</span></a></div><div class="site-state-item site-state-tags"><a href="/tags"><span class="site-state-item-count">64</span> <span class="site-state-item-name">tags</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/ewanlee" target="_blank" title="Github"><i class="fa fa-fw fa-globe"></i> Github </a></span><span class="links-of-author-item"><a href="https://twitter.com/tomaxent" target="_blank" title="Twitter"><i class="fa fa-fw fa-twitter"></i> Twitter</a></span></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Ewan Li</span></div><div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div><div class="theme-info">Theme - <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="busuanzi-count"><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="site-uv"><i class="fa fa-user">本站访客数</i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span>人次</span> <span class="site-pv"><i class="fa fa-eye">本站总访问量</i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span>次</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><script type="text/javascript">_hcwp=window._hcwp||[],_hcwp.push({widget:"Bloggerstream",widget_id:89825,selector:".hc-comment-count",label:"{%COUNT%}"}),function(){if(!("HC_LOAD_INIT"in window)){HC_LOAD_INIT=!0;var t=(navigator.language||navigator.systemLanguage||navigator.userLanguage||"en").substr(0,2).toLowerCase(),e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src=("https:"==document.location.protocol?"https":"http")+"://w.hypercomments.com/widget/hc/89825/"+t+"/widget.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n.nextSibling)}}()</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="popoverlay">').css("overflow","hidden"),$(".popup").toggle()}var isfetched=!1,search_path="search.xml";0==search_path.length&&(search_path="search.xml");var path="/"+search_path,searchFunc=function(e,t,a){"use strict";$.ajax({url:e,dataType:"xml",async:!0,success:function(e){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var r=$("entry",e).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),c=document.getElementById(t),n=document.getElementById(a);c.addEventListener("input",function(){var e=0,t='<ul class="search-result-list">',a=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length>1&&r.forEach(function(r){var c=!1,n=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),o=decodeURIComponent(r.url),i=-1,l=-1,p=-1;if(""!=n&&a.forEach(function(e,t){i=n.indexOf(e),l=s.indexOf(e),(i>=0||l>=0)&&(c=!0,0==t&&(p=l))}),c){e+=1,t+="<li><a href='"+o+"' class='search-result-title'>"+n+"</a>";var h=r.content.trim().replace(/<[^>]+>/g,"");if(p>=0){var u=p-20,d=p+80;u<0&&(u=0),0==u&&(d=50),d>h.length&&(d=h.length);var f=h.substring(u,d);a.forEach(function(e){var t=new RegExp(e,"gi");f=f.replace(t,'<b class="search-keyword">'+e+"</b>")}),t+='<p class="search-result">'+f+"...</p>"}t+="</li>"}}),t+="</ul>",0==e&&(t='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'),""==a&&(t='<div id="no-result"><i class="fa fa-search fa-5x" /></div>'),n.innerHTML=t}),proceedsearch()}})};$(".popup-trigger").click(function(e){e.stopPropagation(),0==isfetched?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(function(e){$(".popup").hide(),$(".popoverlay").remove(),$("body").css("overflow","")}),$(".popup").click(function(e){e.stopPropagation()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script><script>AV.initialize("e27VKX5tTklQLCtF7iNMmhcA-gzGzoHsz","nnQn2znNgXXEdK7W2bVJ3bfK")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script></body></html>