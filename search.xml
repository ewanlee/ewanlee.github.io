<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title></title>
      <url>%2F2017%2F03%2F07%2Fpython%20data%20analysis%20learning%20note%2009%2F</url>
      <content type="text"><![CDATA[ch09/*! * * Twitter Bootstrap * *//*! * Bootstrap v3.3.6 (http://getbootstrap.com) * Copyright 2011-2015 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE) *//*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:700}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{box-sizing:content-box;height:0}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0}button{overflow:visible}button,select{text-transform:none}button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}input{line-height:normal}input[type=checkbox],input[type=radio]{box-sizing:border-box;padding:0}input[type=number]::-webkit-inner-spin-button,input[type=number]::-webkit-outer-spin-button{height:auto}input[type=search]{-webkit-appearance:textfield;box-sizing:content-box}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration{-webkit-appearance:none}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{border:0;padding:0}textarea{overflow:auto}optgroup{font-weight:700}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */@media print{*,:after,:before{background:0 0!important;color:#000!important;box-shadow:none!important;text-shadow:none!important}a,a:visited{text-decoration:underline}a[href]:after{content:" (" attr(href) ")"}abbr[title]:after{content:" (" attr(title) ")"}a[href^="javascript:"]:after,a[href^="#"]:after{content:""}blockquote,pre{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}img,tr{page-break-inside:avoid}img{max-width:100%!important}h2,h3,p{orphans:3;widows:3}h2,h3{page-break-after:avoid}.navbar{display:none}.btn>.caret,.dropup>.btn>.caret{border-top-color:#000!important}.label{border:1px solid #000}.table{border-collapse:collapse!important}.table td,.table th{background-color:#fff!important}.table-bordered td,.table-bordered th{border:1px solid #ddd!important}}@font-face{font-family:'Glyphicons Halflings';src:url(../components/bootstrap/fonts/glyphicons-halflings-regular.eot);src:url(../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix) format('embedded-opentype'),url(../components/bootstrap/fonts/glyphicons-halflings-regular.woff2) format('woff2'),url(../components/bootstrap/fonts/glyphicons-halflings-regular.woff) format('woff'),url(../components/bootstrap/fonts/glyphicons-halflings-regular.ttf) format('truetype'),url(../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular) format('svg')}.glyphicon{position:relative;top:1px;display:inline-block;font-family:'Glyphicons Halflings';font-style:normal;font-weight:400;line-height:1;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.glyphicon-asterisk:before{content:"\002a"}.glyphicon-plus:before{content:"\002b"}.glyphicon-eur:before,.glyphicon-euro:before{content:"\20ac"}.glyphicon-minus:before{content:"\2212"}.glyphicon-cloud:before{content:"\2601"}.glyphicon-envelope:before{content:"\2709"}.glyphicon-pencil:before{content:"\270f"}.glyphicon-glass:before{content:"\e001"}.glyphicon-music:before{content:"\e002"}.glyphicon-search:before{content:"\e003"}.glyphicon-heart:before{content:"\e005"}.glyphicon-star:before{content:"\e006"}.glyphicon-star-empty:before{content:"\e007"}.glyphicon-user:before{content:"\e008"}.glyphicon-film:before{content:"\e009"}.glyphicon-th-large:before{content:"\e010"}.glyphicon-th:before{content:"\e011"}.glyphicon-th-list:before{content:"\e012"}.glyphicon-ok:before{content:"\e013"}.glyphicon-remove:before{content:"\e014"}.glyphicon-zoom-in:before{content:"\e015"}.glyphicon-zoom-out:before{content:"\e016"}.glyphicon-off:before{content:"\e017"}.glyphicon-signal:before{content:"\e018"}.glyphicon-cog:before{content:"\e019"}.glyphicon-trash:before{content:"\e020"}.glyphicon-home:before{content:"\e021"}.glyphicon-file:before{content:"\e022"}.glyphicon-time:before{content:"\e023"}.glyphicon-road:before{content:"\e024"}.glyphicon-download-alt:before{content:"\e025"}.glyphicon-download:before{content:"\e026"}.glyphicon-upload:before{content:"\e027"}.glyphicon-inbox:before{content:"\e028"}.glyphicon-play-circle:before{content:"\e029"}.glyphicon-repeat:before{content:"\e030"}.glyphicon-refresh:before{content:"\e031"}.glyphicon-list-alt:before{content:"\e032"}.glyphicon-lock:before{content:"\e033"}.glyphicon-flag:before{content:"\e034"}.glyphicon-headphones:before{content:"\e035"}.glyphicon-volume-off:before{content:"\e036"}.glyphicon-volume-down:before{content:"\e037"}.glyphicon-volume-up:before{content:"\e038"}.glyphicon-qrcode:before{content:"\e039"}.glyphicon-barcode:before{content:"\e040"}.glyphicon-tag:before{content:"\e041"}.glyphicon-tags:before{content:"\e042"}.glyphicon-book:before{content:"\e043"}.glyphicon-bookmark:before{content:"\e044"}.glyphicon-print:before{content:"\e045"}.glyphicon-camera:before{content:"\e046"}.glyphicon-font:before{content:"\e047"}.glyphicon-bold:before{content:"\e048"}.glyphicon-italic:before{content:"\e049"}.glyphicon-text-height:before{content:"\e050"}.glyphicon-text-width:before{content:"\e051"}.glyphicon-align-left:before{content:"\e052"}.glyphicon-align-center:before{content:"\e053"}.glyphicon-align-right:before{content:"\e054"}.glyphicon-align-justify:before{content:"\e055"}.glyphicon-list:before{content:"\e056"}.glyphicon-indent-left:before{content:"\e057"}.glyphicon-indent-right:before{content:"\e058"}.glyphicon-facetime-video:before{content:"\e059"}.glyphicon-picture:before{content:"\e060"}.glyphicon-map-marker:before{content:"\e062"}.glyphicon-adjust:before{content:"\e063"}.glyphicon-tint:before{content:"\e064"}.glyphicon-edit:before{content:"\e065"}.glyphicon-share:before{content:"\e066"}.glyphicon-check:before{content:"\e067"}.glyphicon-move:before{content:"\e068"}.glyphicon-step-backward:before{content:"\e069"}.glyphicon-fast-backward:before{content:"\e070"}.glyphicon-backward:before{content:"\e071"}.glyphicon-play:before{content:"\e072"}.glyphicon-pause:before{content:"\e073"}.glyphicon-stop:before{content:"\e074"}.glyphicon-forward:before{content:"\e075"}.glyphicon-fast-forward:before{content:"\e076"}.glyphicon-step-forward:before{content:"\e077"}.glyphicon-eject:before{content:"\e078"}.glyphicon-chevron-left:before{content:"\e079"}.glyphicon-chevron-right:before{content:"\e080"}.glyphicon-plus-sign:before{content:"\e081"}.glyphicon-minus-sign:before{content:"\e082"}.glyphicon-remove-sign:before{content:"\e083"}.glyphicon-ok-sign:before{content:"\e084"}.glyphicon-question-sign:before{content:"\e085"}.glyphicon-info-sign:before{content:"\e086"}.glyphicon-screenshot:before{content:"\e087"}.glyphicon-remove-circle:before{content:"\e088"}.glyphicon-ok-circle:before{content:"\e089"}.glyphicon-ban-circle:before{content:"\e090"}.glyphicon-arrow-left:before{content:"\e091"}.glyphicon-arrow-right:before{content:"\e092"}.glyphicon-arrow-up:before{content:"\e093"}.glyphicon-arrow-down:before{content:"\e094"}.glyphicon-share-alt:before{content:"\e095"}.glyphicon-resize-full:before{content:"\e096"}.glyphicon-resize-small:before{content:"\e097"}.glyphicon-exclamation-sign:before{content:"\e101"}.glyphicon-gift:before{content:"\e102"}.glyphicon-leaf:before{content:"\e103"}.glyphicon-fire:before{content:"\e104"}.glyphicon-eye-open:before{content:"\e105"}.glyphicon-eye-close:before{content:"\e106"}.glyphicon-warning-sign:before{content:"\e107"}.glyphicon-plane:before{content:"\e108"}.glyphicon-calendar:before{content:"\e109"}.glyphicon-random:before{content:"\e110"}.glyphicon-comment:before{content:"\e111"}.glyphicon-magnet:before{content:"\e112"}.glyphicon-chevron-up:before{content:"\e113"}.glyphicon-chevron-down:before{content:"\e114"}.glyphicon-retweet:before{content:"\e115"}.glyphicon-shopping-cart:before{content:"\e116"}.glyphicon-folder-close:before{content:"\e117"}.glyphicon-folder-open:before{content:"\e118"}.glyphicon-resize-vertical:before{content:"\e119"}.glyphicon-resize-horizontal:before{content:"\e120"}.glyphicon-hdd:before{content:"\e121"}.glyphicon-bullhorn:before{content:"\e122"}.glyphicon-bell:before{content:"\e123"}.glyphicon-certificate:before{content:"\e124"}.glyphicon-thumbs-up:before{content:"\e125"}.glyphicon-thumbs-down:before{content:"\e126"}.glyphicon-hand-right:before{content:"\e127"}.glyphicon-hand-left:before{content:"\e128"}.glyphicon-hand-up:before{content:"\e129"}.glyphicon-hand-down:before{content:"\e130"}.glyphicon-circle-arrow-right:before{content:"\e131"}.glyphicon-circle-arrow-left:before{content:"\e132"}.glyphicon-circle-arrow-up:before{content:"\e133"}.glyphicon-circle-arrow-down:before{content:"\e134"}.glyphicon-globe:before{content:"\e135"}.glyphicon-wrench:before{content:"\e136"}.glyphicon-tasks:before{content:"\e137"}.glyphicon-filter:before{content:"\e138"}.glyphicon-briefcase:before{content:"\e139"}.glyphicon-fullscreen:before{content:"\e140"}.glyphicon-dashboard:before{content:"\e141"}.glyphicon-paperclip:before{content:"\e142"}.glyphicon-heart-empty:before{content:"\e143"}.glyphicon-link:before{content:"\e144"}.glyphicon-phone:before{content:"\e145"}.glyphicon-pushpin:before{content:"\e146"}.glyphicon-usd:before{content:"\e148"}.glyphicon-gbp:before{content:"\e149"}.glyphicon-sort:before{content:"\e150"}.glyphicon-sort-by-alphabet:before{content:"\e151"}.glyphicon-sort-by-alphabet-alt:before{content:"\e152"}.glyphicon-sort-by-order:before{content:"\e153"}.glyphicon-sort-by-order-alt:before{content:"\e154"}.glyphicon-sort-by-attributes:before{content:"\e155"}.glyphicon-sort-by-attributes-alt:before{content:"\e156"}.glyphicon-unchecked:before{content:"\e157"}.glyphicon-expand:before{content:"\e158"}.glyphicon-collapse-down:before{content:"\e159"}.glyphicon-collapse-up:before{content:"\e160"}.glyphicon-log-in:before{content:"\e161"}.glyphicon-flash:before{content:"\e162"}.glyphicon-log-out:before{content:"\e163"}.glyphicon-new-window:before{content:"\e164"}.glyphicon-record:before{content:"\e165"}.glyphicon-save:before{content:"\e166"}.glyphicon-open:before{content:"\e167"}.glyphicon-saved:before{content:"\e168"}.glyphicon-import:before{content:"\e169"}.glyphicon-export:before{content:"\e170"}.glyphicon-send:before{content:"\e171"}.glyphicon-floppy-disk:before{content:"\e172"}.glyphicon-floppy-saved:before{content:"\e173"}.glyphicon-floppy-remove:before{content:"\e174"}.glyphicon-floppy-save:before{content:"\e175"}.glyphicon-floppy-open:before{content:"\e176"}.glyphicon-credit-card:before{content:"\e177"}.glyphicon-transfer:before{content:"\e178"}.glyphicon-cutlery:before{content:"\e179"}.glyphicon-header:before{content:"\e180"}.glyphicon-compressed:before{content:"\e181"}.glyphicon-earphone:before{content:"\e182"}.glyphicon-phone-alt:before{content:"\e183"}.glyphicon-tower:before{content:"\e184"}.glyphicon-stats:before{content:"\e185"}.glyphicon-sd-video:before{content:"\e186"}.glyphicon-hd-video:before{content:"\e187"}.glyphicon-subtitles:before{content:"\e188"}.glyphicon-sound-stereo:before{content:"\e189"}.glyphicon-sound-dolby:before{content:"\e190"}.glyphicon-sound-5-1:before{content:"\e191"}.glyphicon-sound-6-1:before{content:"\e192"}.glyphicon-sound-7-1:before{content:"\e193"}.glyphicon-copyright-mark:before{content:"\e194"}.glyphicon-registration-mark:before{content:"\e195"}.glyphicon-cloud-download:before{content:"\e197"}.glyphicon-cloud-upload:before{content:"\e198"}.glyphicon-tree-conifer:before{content:"\e199"}.glyphicon-tree-deciduous:before{content:"\e200"}.glyphicon-cd:before{content:"\e201"}.glyphicon-save-file:before{content:"\e202"}.glyphicon-open-file:before{content:"\e203"}.glyphicon-level-up:before{content:"\e204"}.glyphicon-copy:before{content:"\e205"}.glyphicon-paste:before{content:"\e206"}.glyphicon-alert:before{content:"\e209"}.glyphicon-equalizer:before{content:"\e210"}.glyphicon-king:before{content:"\e211"}.glyphicon-queen:before{content:"\e212"}.glyphicon-pawn:before{content:"\e213"}.glyphicon-bishop:before{content:"\e214"}.glyphicon-knight:before{content:"\e215"}.glyphicon-baby-formula:before{content:"\e216"}.glyphicon-tent:before{content:"\26fa"}.glyphicon-blackboard:before{content:"\e218"}.glyphicon-bed:before{content:"\e219"}.glyphicon-apple:before{content:"\f8ff"}.glyphicon-erase:before{content:"\e221"}.glyphicon-hourglass:before{content:"\231b"}.glyphicon-lamp:before{content:"\e223"}.glyphicon-duplicate:before{content:"\e224"}.glyphicon-piggy-bank:before{content:"\e225"}.glyphicon-scissors:before{content:"\e226"}.glyphicon-bitcoin:before{content:"\e227"}.glyphicon-btc:before{content:"\e227"}.glyphicon-xbt:before{content:"\e227"}.glyphicon-yen:before{content:"\00a5"}.glyphicon-jpy:before{content:"\00a5"}.glyphicon-ruble:before{content:"\20bd"}.glyphicon-rub:before{content:"\20bd"}.glyphicon-scale:before{content:"\e230"}.glyphicon-ice-lolly:before{content:"\e231"}.glyphicon-ice-lolly-tasted:before{content:"\e232"}.glyphicon-education:before{content:"\e233"}.glyphicon-option-horizontal:before{content:"\e234"}.glyphicon-option-vertical:before{content:"\e235"}.glyphicon-menu-hamburger:before{content:"\e236"}.glyphicon-modal-window:before{content:"\e237"}.glyphicon-oil:before{content:"\e238"}.glyphicon-grain:before{content:"\e239"}.glyphicon-sunglasses:before{content:"\e240"}.glyphicon-text-size:before{content:"\e241"}.glyphicon-text-color:before{content:"\e242"}.glyphicon-text-background:before{content:"\e243"}.glyphicon-object-align-top:before{content:"\e244"}.glyphicon-object-align-bottom:before{content:"\e245"}.glyphicon-object-align-horizontal:before{content:"\e246"}.glyphicon-object-align-left:before{content:"\e247"}.glyphicon-object-align-vertical:before{content:"\e248"}.glyphicon-object-align-right:before{content:"\e249"}.glyphicon-triangle-right:before{content:"\e250"}.glyphicon-triangle-left:before{content:"\e251"}.glyphicon-triangle-bottom:before{content:"\e252"}.glyphicon-triangle-top:before{content:"\e253"}.glyphicon-console:before{content:"\e254"}.glyphicon-superscript:before{content:"\e255"}.glyphicon-subscript:before{content:"\e256"}.glyphicon-menu-left:before{content:"\e257"}.glyphicon-menu-right:before{content:"\e258"}.glyphicon-menu-down:before{content:"\e259"}.glyphicon-menu-up:before{content:"\e260"}*{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}:after,:before{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}html{font-size:10px;-webkit-tap-highlight-color:transparent}body{font-family:"Helvetica Neue",Helvetica,Arial,sans-serif;font-size:13px;line-height:1.42857143;color:#000;background-color:#fff}button,input,select,textarea{font-family:inherit;font-size:inherit;line-height:inherit}a{color:#337ab7;text-decoration:none}a:focus,a:hover{color:#23527c;text-decoration:underline}a:focus{outline:thin dotted;outline:5px auto -webkit-focus-ring-color;outline-offset:-2px}figure{margin:0}img{vertical-align:middle}.carousel-inner>.item>a>img,.carousel-inner>.item>img,.img-responsive,.thumbnail a>img,.thumbnail>img{display:block;max-width:100%;height:auto}.img-rounded{border-radius:3px}.img-thumbnail{padding:4px;line-height:1.42857143;background-color:#fff;border:1px solid #ddd;border-radius:2px;-webkit-transition:all .2s ease-in-out;-o-transition:all .2s ease-in-out;transition:all .2s ease-in-out;display:inline-block;max-width:100%;height:auto}.img-circle{border-radius:50%}hr{margin-top:18px;margin-bottom:18px;border:0;border-top:1px solid #eee}.sr-only{position:absolute;width:1px;height:1px;margin:-1px;padding:0;overflow:hidden;clip:rect(0,0,0,0);border:0}.sr-only-focusable:active,.sr-only-focusable:focus{position:static;width:auto;height:auto;margin:0;overflow:visible;clip:auto}[role=button]{cursor:pointer}.h1,.h2,.h3,.h4,.h5,.h6,h1,h2,h3,h4,h5,h6{font-family:inherit;font-weight:500;line-height:1.1;color:inherit}.h1 .small,.h1 small,.h2 .small,.h2 small,.h3 .small,.h3 small,.h4 .small,.h4 small,.h5 .small,.h5 small,.h6 .small,.h6 small,h1 .small,h1 small,h2 .small,h2 small,h3 .small,h3 small,h4 .small,h4 small,h5 .small,h5 small,h6 .small,h6 small{font-weight:400;line-height:1;color:#777}.h1,.h2,.h3,h1,h2,h3{margin-top:18px;margin-bottom:9px}.h1 .small,.h1 small,.h2 .small,.h2 small,.h3 .small,.h3 small,h1 .small,h1 small,h2 .small,h2 small,h3 .small,h3 small{font-size:65%}.h4,.h5,.h6,h4,h5,h6{margin-top:9px;margin-bottom:9px}.h4 .small,.h4 small,.h5 .small,.h5 small,.h6 .small,.h6 small,h4 .small,h4 small,h5 .small,h5 small,h6 .small,h6 small{font-size:75%}.h1,h1{font-size:33px}.h2,h2{font-size:27px}.h3,h3{font-size:23px}.h4,h4{font-size:17px}.h5,h5{font-size:13px}.h6,h6{font-size:12px}p{margin:0 0 9px}.lead{margin-bottom:18px;font-size:14px;font-weight:300;line-height:1.4}@media (min-width:768px){.lead{font-size:19.5px}}.small,small{font-size:92%}.mark,mark{background-color:#fcf8e3;padding:.2em}.text-left{text-align:left}.text-right{text-align:right}.text-center{text-align:center}.text-justify{text-align:justify}.text-nowrap{white-space:nowrap}.text-lowercase{text-transform:lowercase}.text-uppercase{text-transform:uppercase}.text-capitalize{text-transform:capitalize}.text-muted{color:#777}.text-primary{color:#337ab7}a.text-primary:focus,a.text-primary:hover{color:#286090}.text-success{color:#3c763d}a.text-success:focus,a.text-success:hover{color:#2b542c}.text-info{color:#31708f}a.text-info:focus,a.text-info:hover{color:#245269}.text-warning{color:#8a6d3b}a.text-warning:focus,a.text-warning:hover{color:#66512c}.text-danger{color:#a94442}a.text-danger:focus,a.text-danger:hover{color:#843534}.bg-primary{color:#fff;background-color:#337ab7}a.bg-primary:focus,a.bg-primary:hover{background-color:#286090}.bg-success{background-color:#dff0d8}a.bg-success:focus,a.bg-success:hover{background-color:#c1e2b3}.bg-info{background-color:#d9edf7}a.bg-info:focus,a.bg-info:hover{background-color:#afd9ee}.bg-warning{background-color:#fcf8e3}a.bg-warning:focus,a.bg-warning:hover{background-color:#f7ecb5}.bg-danger{background-color:#f2dede}a.bg-danger:focus,a.bg-danger:hover{background-color:#e4b9b9}.page-header{padding-bottom:8px;margin:36px 0 18px;border-bottom:1px solid #eee}ol,ul{margin-top:0;margin-bottom:9px}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}.list-unstyled{padding-left:0;list-style:none}.list-inline{padding-left:0;list-style:none;margin-left:-5px}.list-inline>li{display:inline-block;padding-left:5px;padding-right:5px}dl{margin-top:0;margin-bottom:18px}dd,dt{line-height:1.42857143}dt{font-weight:700}dd{margin-left:0}@media (min-width:541px){.dl-horizontal dt{float:left;width:160px;clear:left;text-align:right;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.dl-horizontal dd{margin-left:180px}}abbr[data-original-title],abbr[title]{cursor:help;border-bottom:1px dotted #777}.initialism{font-size:90%;text-transform:uppercase}blockquote{padding:9px 18px;margin:0 0 18px;font-size:inherit;border-left:5px solid #eee}blockquote ol:last-child,blockquote p:last-child,blockquote ul:last-child{margin-bottom:0}blockquote .small,blockquote footer,blockquote small{display:block;font-size:80%;line-height:1.42857143;color:#777}blockquote .small:before,blockquote footer:before,blockquote small:before{content:'\2014 \00A0'}.blockquote-reverse,blockquote.pull-right{padding-right:15px;padding-left:0;border-right:5px solid #eee;border-left:0;text-align:right}.blockquote-reverse .small:before,.blockquote-reverse footer:before,.blockquote-reverse small:before,blockquote.pull-right .small:before,blockquote.pull-right footer:before,blockquote.pull-right small:before{content:''}.blockquote-reverse .small:after,.blockquote-reverse footer:after,.blockquote-reverse small:after,blockquote.pull-right .small:after,blockquote.pull-right footer:after,blockquote.pull-right small:after{content:'\00A0 \2014'}address{margin-bottom:18px;font-style:normal;line-height:1.42857143}code,kbd,pre,samp{font-family:monospace}code{padding:2px 4px;font-size:90%;color:#c7254e;background-color:#f9f2f4;border-radius:2px}kbd{padding:2px 4px;font-size:90%;color:#888;background-color:transparent;border-radius:1px;box-shadow:inset 0 -1px 0 rgba(0,0,0,.25)}kbd kbd{padding:0;font-size:100%;font-weight:700;box-shadow:none}pre{display:block;padding:8.5px;margin:0 0 9px;font-size:12px;line-height:1.42857143;word-break:break-all;word-wrap:break-word;color:#333;background-color:#f5f5f5;border:1px solid #ccc;border-radius:2px}pre code{padding:0;font-size:inherit;color:inherit;white-space:pre-wrap;background-color:transparent;border-radius:0}.pre-scrollable{max-height:340px;overflow-y:scroll}.container{margin-right:auto;margin-left:auto;padding-left:0;padding-right:0}@media (min-width:768px){.container{width:768px}}@media (min-width:992px){.container{width:940px}}@media (min-width:1200px){.container{width:1140px}}.container-fluid{margin-right:auto;margin-left:auto;padding-left:0;padding-right:0}.row{margin-left:0;margin-right:0}.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9{position:relative;min-height:1px;padding-left:0;padding-right:0}.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9{float:left}.col-xs-12{width:100%}.col-xs-11{width:91.66666667%}.col-xs-10{width:83.33333333%}.col-xs-9{width:75%}.col-xs-8{width:66.66666667%}.col-xs-7{width:58.33333333%}.col-xs-6{width:50%}.col-xs-5{width:41.66666667%}.col-xs-4{width:33.33333333%}.col-xs-3{width:25%}.col-xs-2{width:16.66666667%}.col-xs-1{width:8.33333333%}.col-xs-pull-12{right:100%}.col-xs-pull-11{right:91.66666667%}.col-xs-pull-10{right:83.33333333%}.col-xs-pull-9{right:75%}.col-xs-pull-8{right:66.66666667%}.col-xs-pull-7{right:58.33333333%}.col-xs-pull-6{right:50%}.col-xs-pull-5{right:41.66666667%}.col-xs-pull-4{right:33.33333333%}.col-xs-pull-3{right:25%}.col-xs-pull-2{right:16.66666667%}.col-xs-pull-1{right:8.33333333%}.col-xs-pull-0{right:auto}.col-xs-push-12{left:100%}.col-xs-push-11{left:91.66666667%}.col-xs-push-10{left:83.33333333%}.col-xs-push-9{left:75%}.col-xs-push-8{left:66.66666667%}.col-xs-push-7{left:58.33333333%}.col-xs-push-6{left:50%}.col-xs-push-5{left:41.66666667%}.col-xs-push-4{left:33.33333333%}.col-xs-push-3{left:25%}.col-xs-push-2{left:16.66666667%}.col-xs-push-1{left:8.33333333%}.col-xs-push-0{left:auto}.col-xs-offset-12{margin-left:100%}.col-xs-offset-11{margin-left:91.66666667%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-0{margin-left:0}@media (min-width:768px){.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9{float:left}.col-sm-12{width:100%}.col-sm-11{width:91.66666667%}.col-sm-10{width:83.33333333%}.col-sm-9{width:75%}.col-sm-8{width:66.66666667%}.col-sm-7{width:58.33333333%}.col-sm-6{width:50%}.col-sm-5{width:41.66666667%}.col-sm-4{width:33.33333333%}.col-sm-3{width:25%}.col-sm-2{width:16.66666667%}.col-sm-1{width:8.33333333%}.col-sm-pull-12{right:100%}.col-sm-pull-11{right:91.66666667%}.col-sm-pull-10{right:83.33333333%}.col-sm-pull-9{right:75%}.col-sm-pull-8{right:66.66666667%}.col-sm-pull-7{right:58.33333333%}.col-sm-pull-6{right:50%}.col-sm-pull-5{right:41.66666667%}.col-sm-pull-4{right:33.33333333%}.col-sm-pull-3{right:25%}.col-sm-pull-2{right:16.66666667%}.col-sm-pull-1{right:8.33333333%}.col-sm-pull-0{right:auto}.col-sm-push-12{left:100%}.col-sm-push-11{left:91.66666667%}.col-sm-push-10{left:83.33333333%}.col-sm-push-9{left:75%}.col-sm-push-8{left:66.66666667%}.col-sm-push-7{left:58.33333333%}.col-sm-push-6{left:50%}.col-sm-push-5{left:41.66666667%}.col-sm-push-4{left:33.33333333%}.col-sm-push-3{left:25%}.col-sm-push-2{left:16.66666667%}.col-sm-push-1{left:8.33333333%}.col-sm-push-0{left:auto}.col-sm-offset-12{margin-left:100%}.col-sm-offset-11{margin-left:91.66666667%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-0{margin-left:0}}@media (min-width:992px){.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9{float:left}.col-md-12{width:100%}.col-md-11{width:91.66666667%}.col-md-10{width:83.33333333%}.col-md-9{width:75%}.col-md-8{width:66.66666667%}.col-md-7{width:58.33333333%}.col-md-6{width:50%}.col-md-5{width:41.66666667%}.col-md-4{width:33.33333333%}.col-md-3{width:25%}.col-md-2{width:16.66666667%}.col-md-1{width:8.33333333%}.col-md-pull-12{right:100%}.col-md-pull-11{right:91.66666667%}.col-md-pull-10{right:83.33333333%}.col-md-pull-9{right:75%}.col-md-pull-8{right:66.66666667%}.col-md-pull-7{right:58.33333333%}.col-md-pull-6{right:50%}.col-md-pull-5{right:41.66666667%}.col-md-pull-4{right:33.33333333%}.col-md-pull-3{right:25%}.col-md-pull-2{right:16.66666667%}.col-md-pull-1{right:8.33333333%}.col-md-pull-0{right:auto}.col-md-push-12{left:100%}.col-md-push-11{left:91.66666667%}.col-md-push-10{left:83.33333333%}.col-md-push-9{left:75%}.col-md-push-8{left:66.66666667%}.col-md-push-7{left:58.33333333%}.col-md-push-6{left:50%}.col-md-push-5{left:41.66666667%}.col-md-push-4{left:33.33333333%}.col-md-push-3{left:25%}.col-md-push-2{left:16.66666667%}.col-md-push-1{left:8.33333333%}.col-md-push-0{left:auto}.col-md-offset-12{margin-left:100%}.col-md-offset-11{margin-left:91.66666667%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-9{margin-left:75%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-6{margin-left:50%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-3{margin-left:25%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-0{margin-left:0}}@media (min-width:1200px){.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9{float:left}.col-lg-12{width:100%}.col-lg-11{width:91.66666667%}.col-lg-10{width:83.33333333%}.col-lg-9{width:75%}.col-lg-8{width:66.66666667%}.col-lg-7{width:58.33333333%}.col-lg-6{width:50%}.col-lg-5{width:41.66666667%}.col-lg-4{width:33.33333333%}.col-lg-3{width:25%}.col-lg-2{width:16.66666667%}.col-lg-1{width:8.33333333%}.col-lg-pull-12{right:100%}.col-lg-pull-11{right:91.66666667%}.col-lg-pull-10{right:83.33333333%}.col-lg-pull-9{right:75%}.col-lg-pull-8{right:66.66666667%}.col-lg-pull-7{right:58.33333333%}.col-lg-pull-6{right:50%}.col-lg-pull-5{right:41.66666667%}.col-lg-pull-4{right:33.33333333%}.col-lg-pull-3{right:25%}.col-lg-pull-2{right:16.66666667%}.col-lg-pull-1{right:8.33333333%}.col-lg-pull-0{right:auto}.col-lg-push-12{left:100%}.col-lg-push-11{left:91.66666667%}.col-lg-push-10{left:83.33333333%}.col-lg-push-9{left:75%}.col-lg-push-8{left:66.66666667%}.col-lg-push-7{left:58.33333333%}.col-lg-push-6{left:50%}.col-lg-push-5{left:41.66666667%}.col-lg-push-4{left:33.33333333%}.col-lg-push-3{left:25%}.col-lg-push-2{left:16.66666667%}.col-lg-push-1{left:8.33333333%}.col-lg-push-0{left:auto}.col-lg-offset-12{margin-left:100%}.col-lg-offset-11{margin-left:91.66666667%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-0{margin-left:0}}table{background-color:transparent}caption{padding-top:8px;padding-bottom:8px;color:#777;text-align:left}th{text-align:left}.table{width:100%;max-width:100%;margin-bottom:18px}.table>tbody>tr>td,.table>tbody>tr>th,.table>tfoot>tr>td,.table>tfoot>tr>th,.table>thead>tr>td,.table>thead>tr>th{padding:8px;line-height:1.42857143;vertical-align:top;border-top:1px solid #ddd}.table>thead>tr>th{vertical-align:bottom;border-bottom:2px solid #ddd}.table>caption+thead>tr:first-child>td,.table>caption+thead>tr:first-child>th,.table>colgroup+thead>tr:first-child>td,.table>colgroup+thead>tr:first-child>th,.table>thead:first-child>tr:first-child>td,.table>thead:first-child>tr:first-child>th{border-top:0}.table>tbody+tbody{border-top:2px solid #ddd}.table .table{background-color:#fff}.table-condensed>tbody>tr>td,.table-condensed>tbody>tr>th,.table-condensed>tfoot>tr>td,.table-condensed>tfoot>tr>th,.table-condensed>thead>tr>td,.table-condensed>thead>tr>th{padding:5px}.table-bordered{border:1px solid #ddd}.table-bordered>tbody>tr>td,.table-bordered>tbody>tr>th,.table-bordered>tfoot>tr>td,.table-bordered>tfoot>tr>th,.table-bordered>thead>tr>td,.table-bordered>thead>tr>th{border:1px solid #ddd}.table-bordered>thead>tr>td,.table-bordered>thead>tr>th{border-bottom-width:2px}.table-striped>tbody>tr:nth-of-type(odd){background-color:#f9f9f9}.table-hover>tbody>tr:hover{background-color:#f5f5f5}table col[class*=col-]{position:static;float:none;display:table-column}table td[class*=col-],table th[class*=col-]{position:static;float:none;display:table-cell}.table>tbody>tr.active>td,.table>tbody>tr.active>th,.table>tbody>tr>td.active,.table>tbody>tr>th.active,.table>tfoot>tr.active>td,.table>tfoot>tr.active>th,.table>tfoot>tr>td.active,.table>tfoot>tr>th.active,.table>thead>tr.active>td,.table>thead>tr.active>th,.table>thead>tr>td.active,.table>thead>tr>th.active{background-color:#f5f5f5}.table-hover>tbody>tr.active:hover>td,.table-hover>tbody>tr.active:hover>th,.table-hover>tbody>tr:hover>.active,.table-hover>tbody>tr>td.active:hover,.table-hover>tbody>tr>th.active:hover{background-color:#e8e8e8}.table>tbody>tr.success>td,.table>tbody>tr.success>th,.table>tbody>tr>td.success,.table>tbody>tr>th.success,.table>tfoot>tr.success>td,.table>tfoot>tr.success>th,.table>tfoot>tr>td.success,.table>tfoot>tr>th.success,.table>thead>tr.success>td,.table>thead>tr.success>th,.table>thead>tr>td.success,.table>thead>tr>th.success{background-color:#dff0d8}.table-hover>tbody>tr.success:hover>td,.table-hover>tbody>tr.success:hover>th,.table-hover>tbody>tr:hover>.success,.table-hover>tbody>tr>td.success:hover,.table-hover>tbody>tr>th.success:hover{background-color:#d0e9c6}.table>tbody>tr.info>td,.table>tbody>tr.info>th,.table>tbody>tr>td.info,.table>tbody>tr>th.info,.table>tfoot>tr.info>td,.table>tfoot>tr.info>th,.table>tfoot>tr>td.info,.table>tfoot>tr>th.info,.table>thead>tr.info>td,.table>thead>tr.info>th,.table>thead>tr>td.info,.table>thead>tr>th.info{background-color:#d9edf7}.table-hover>tbody>tr.info:hover>td,.table-hover>tbody>tr.info:hover>th,.table-hover>tbody>tr:hover>.info,.table-hover>tbody>tr>td.info:hover,.table-hover>tbody>tr>th.info:hover{background-color:#c4e3f3}.table>tbody>tr.warning>td,.table>tbody>tr.warning>th,.table>tbody>tr>td.warning,.table>tbody>tr>th.warning,.table>tfoot>tr.warning>td,.table>tfoot>tr.warning>th,.table>tfoot>tr>td.warning,.table>tfoot>tr>th.warning,.table>thead>tr.warning>td,.table>thead>tr.warning>th,.table>thead>tr>td.warning,.table>thead>tr>th.warning{background-color:#fcf8e3}.table-hover>tbody>tr.warning:hover>td,.table-hover>tbody>tr.warning:hover>th,.table-hover>tbody>tr:hover>.warning,.table-hover>tbody>tr>td.warning:hover,.table-hover>tbody>tr>th.warning:hover{background-color:#faf2cc}.table>tbody>tr.danger>td,.table>tbody>tr.danger>th,.table>tbody>tr>td.danger,.table>tbody>tr>th.danger,.table>tfoot>tr.danger>td,.table>tfoot>tr.danger>th,.table>tfoot>tr>td.danger,.table>tfoot>tr>th.danger,.table>thead>tr.danger>td,.table>thead>tr.danger>th,.table>thead>tr>td.danger,.table>thead>tr>th.danger{background-color:#f2dede}.table-hover>tbody>tr.danger:hover>td,.table-hover>tbody>tr.danger:hover>th,.table-hover>tbody>tr:hover>.danger,.table-hover>tbody>tr>td.danger:hover,.table-hover>tbody>tr>th.danger:hover{background-color:#ebcccc}.table-responsive{overflow-x:auto;min-height:.01%}@media screen and (max-width:767px){.table-responsive{width:100%;margin-bottom:13.5px;overflow-y:hidden;-ms-overflow-style:-ms-autohiding-scrollbar;border:1px solid #ddd}.table-responsive>.table{margin-bottom:0}.table-responsive>.table>tbody>tr>td,.table-responsive>.table>tbody>tr>th,.table-responsive>.table>tfoot>tr>td,.table-responsive>.table>tfoot>tr>th,.table-responsive>.table>thead>tr>td,.table-responsive>.table>thead>tr>th{white-space:nowrap}.table-responsive>.table-bordered{border:0}.table-responsive>.table-bordered>tbody>tr>td:first-child,.table-responsive>.table-bordered>tbody>tr>th:first-child,.table-responsive>.table-bordered>tfoot>tr>td:first-child,.table-responsive>.table-bordered>tfoot>tr>th:first-child,.table-responsive>.table-bordered>thead>tr>td:first-child,.table-responsive>.table-bordered>thead>tr>th:first-child{border-left:0}.table-responsive>.table-bordered>tbody>tr>td:last-child,.table-responsive>.table-bordered>tbody>tr>th:last-child,.table-responsive>.table-bordered>tfoot>tr>td:last-child,.table-responsive>.table-bordered>tfoot>tr>th:last-child,.table-responsive>.table-bordered>thead>tr>td:last-child,.table-responsive>.table-bordered>thead>tr>th:last-child{border-right:0}.table-responsive>.table-bordered>tbody>tr:last-child>td,.table-responsive>.table-bordered>tbody>tr:last-child>th,.table-responsive>.table-bordered>tfoot>tr:last-child>td,.table-responsive>.table-bordered>tfoot>tr:last-child>th{border-bottom:0}}fieldset{padding:0;margin:0;border:0;min-width:0}legend{display:block;width:100%;padding:0;margin-bottom:18px;font-size:19.5px;line-height:inherit;color:#333;border:0;border-bottom:1px solid #e5e5e5}label{display:inline-block;max-width:100%;margin-bottom:5px;font-weight:700}input[type=search]{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}input[type=checkbox],input[type=radio]{margin:4px 0 0;margin-top:1px\9;line-height:normal}input[type=file]{display:block}input[type=range]{display:block;width:100%}select[multiple],select[size]{height:auto}input[type=file]:focus,input[type=checkbox]:focus,input[type=radio]:focus{outline:thin dotted;outline:5px auto -webkit-focus-ring-color;outline-offset:-2px}output{display:block;padding-top:7px;font-size:13px;line-height:1.42857143;color:#555}.form-control{display:block;width:100%;height:32px;padding:6px 12px;font-size:13px;line-height:1.42857143;color:#555;background-color:#fff;background-image:none;border:1px solid #ccc;border-radius:2px;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075);-webkit-transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s;-o-transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s;transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s}.form-control:focus{border-color:#66afe9;outline:0;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 8px rgba(102,175,233,.6);box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 8px rgba(102,175,233,.6)}.form-control::-moz-placeholder{color:#999;opacity:1}.form-control:-ms-input-placeholder{color:#999}.form-control::-webkit-input-placeholder{color:#999}.form-control::-ms-expand{border:0;background-color:transparent}.form-control[disabled],.form-control[readonly],fieldset[disabled] .form-control{background-color:#eee;opacity:1}.form-control[disabled],fieldset[disabled] .form-control{cursor:not-allowed}textarea.form-control{height:auto}input[type=search]{-webkit-appearance:none}@media screen and (-webkit-min-device-pixel-ratio:0){input[type=date].form-control,input[type=time].form-control,input[type=datetime-local].form-control,input[type=month].form-control{line-height:32px}.input-group-sm input[type=date],.input-group-sm input[type=time],.input-group-sm input[type=datetime-local],.input-group-sm input[type=month],input[type=date].input-sm,input[type=time].input-sm,input[type=datetime-local].input-sm,input[type=month].input-sm{line-height:30px}.input-group-lg input[type=date],.input-group-lg input[type=time],.input-group-lg input[type=datetime-local],.input-group-lg input[type=month],input[type=date].input-lg,input[type=time].input-lg,input[type=datetime-local].input-lg,input[type=month].input-lg{line-height:45px}}.form-group{margin-bottom:15px}.checkbox,.radio{position:relative;display:block;margin-top:10px;margin-bottom:10px}.checkbox label,.radio label{min-height:18px;padding-left:20px;margin-bottom:0;font-weight:400;cursor:pointer}.checkbox input[type=checkbox],.checkbox-inline input[type=checkbox],.radio input[type=radio],.radio-inline input[type=radio]{position:absolute;margin-left:-20px;margin-top:4px\9}.checkbox+.checkbox,.radio+.radio{margin-top:-5px}.checkbox-inline,.radio-inline{position:relative;display:inline-block;padding-left:20px;margin-bottom:0;vertical-align:middle;font-weight:400;cursor:pointer}.checkbox-inline+.checkbox-inline,.radio-inline+.radio-inline{margin-top:0;margin-left:10px}fieldset[disabled] input[type=checkbox],fieldset[disabled] input[type=radio],input[type=checkbox].disabled,input[type=checkbox][disabled],input[type=radio].disabled,input[type=radio][disabled]{cursor:not-allowed}.checkbox-inline.disabled,.radio-inline.disabled,fieldset[disabled] .checkbox-inline,fieldset[disabled] .radio-inline{cursor:not-allowed}.checkbox.disabled label,.radio.disabled label,fieldset[disabled] .checkbox label,fieldset[disabled] .radio label{cursor:not-allowed}.form-control-static{padding-top:7px;padding-bottom:7px;margin-bottom:0;min-height:31px}.form-control-static.input-lg,.form-control-static.input-sm{padding-left:0;padding-right:0}.input-sm{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:1px}select.input-sm{height:30px;line-height:30px}select[multiple].input-sm,textarea.input-sm{height:auto}.form-group-sm .form-control{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:1px}.form-group-sm select.form-control{height:30px;line-height:30px}.form-group-sm select[multiple].form-control,.form-group-sm textarea.form-control{height:auto}.form-group-sm .form-control-static{height:30px;min-height:30px;padding:6px 10px;font-size:12px;line-height:1.5}.input-lg{height:45px;padding:10px 16px;font-size:17px;line-height:1.3333333;border-radius:3px}select.input-lg{height:45px;line-height:45px}select[multiple].input-lg,textarea.input-lg{height:auto}.form-group-lg .form-control{height:45px;padding:10px 16px;font-size:17px;line-height:1.3333333;border-radius:3px}.form-group-lg select.form-control{height:45px;line-height:45px}.form-group-lg select[multiple].form-control,.form-group-lg textarea.form-control{height:auto}.form-group-lg .form-control-static{height:45px;min-height:35px;padding:11px 16px;font-size:17px;line-height:1.3333333}.has-feedback{position:relative}.has-feedback .form-control{padding-right:40px}.form-control-feedback{position:absolute;top:0;right:0;z-index:2;display:block;width:32px;height:32px;line-height:32px;text-align:center;pointer-events:none}.form-group-lg .form-control+.form-control-feedback,.input-group-lg+.form-control-feedback,.input-lg+.form-control-feedback{width:45px;height:45px;line-height:45px}.form-group-sm .form-control+.form-control-feedback,.input-group-sm+.form-control-feedback,.input-sm+.form-control-feedback{width:30px;height:30px;line-height:30px}.has-success .checkbox,.has-success .checkbox-inline,.has-success .control-label,.has-success .help-block,.has-success .radio,.has-success .radio-inline,.has-success.checkbox label,.has-success.checkbox-inline label,.has-success.radio label,.has-success.radio-inline label{color:#3c763d}.has-success .form-control{border-color:#3c763d;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.has-success .form-control:focus{border-color:#2b542c;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #67b168;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #67b168}.has-success .input-group-addon{color:#3c763d;border-color:#3c763d;background-color:#dff0d8}.has-success .form-control-feedback{color:#3c763d}.has-warning .checkbox,.has-warning .checkbox-inline,.has-warning .control-label,.has-warning .help-block,.has-warning .radio,.has-warning .radio-inline,.has-warning.checkbox label,.has-warning.checkbox-inline label,.has-warning.radio label,.has-warning.radio-inline label{color:#8a6d3b}.has-warning .form-control{border-color:#8a6d3b;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.has-warning .form-control:focus{border-color:#66512c;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #c0a16b;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #c0a16b}.has-warning .input-group-addon{color:#8a6d3b;border-color:#8a6d3b;background-color:#fcf8e3}.has-warning .form-control-feedback{color:#8a6d3b}.has-error .checkbox,.has-error .checkbox-inline,.has-error .control-label,.has-error .help-block,.has-error .radio,.has-error .radio-inline,.has-error.checkbox label,.has-error.checkbox-inline label,.has-error.radio label,.has-error.radio-inline label{color:#a94442}.has-error .form-control{border-color:#a94442;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.has-error .form-control:focus{border-color:#843534;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #ce8483;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #ce8483}.has-error .input-group-addon{color:#a94442;border-color:#a94442;background-color:#f2dede}.has-error .form-control-feedback{color:#a94442}.has-feedback label~.form-control-feedback{top:23px}.has-feedback label.sr-only~.form-control-feedback{top:0}.help-block{display:block;margin-top:5px;margin-bottom:10px;color:#404040}@media (min-width:768px){.form-inline .form-group{display:inline-block;margin-bottom:0;vertical-align:middle}.form-inline .form-control{display:inline-block;width:auto;vertical-align:middle}.form-inline .form-control-static{display:inline-block}.form-inline .input-group{display:inline-table;vertical-align:middle}.form-inline .input-group .form-control,.form-inline .input-group .input-group-addon,.form-inline .input-group .input-group-btn{width:auto}.form-inline .input-group>.form-control{width:100%}.form-inline .control-label{margin-bottom:0;vertical-align:middle}.form-inline .checkbox,.form-inline .radio{display:inline-block;margin-top:0;margin-bottom:0;vertical-align:middle}.form-inline .checkbox label,.form-inline .radio label{padding-left:0}.form-inline .checkbox input[type=checkbox],.form-inline .radio input[type=radio]{position:relative;margin-left:0}.form-inline .has-feedback .form-control-feedback{top:0}}.form-horizontal .checkbox,.form-horizontal .checkbox-inline,.form-horizontal .radio,.form-horizontal .radio-inline{margin-top:0;margin-bottom:0;padding-top:7px}.form-horizontal .checkbox,.form-horizontal .radio{min-height:25px}.form-horizontal .form-group{margin-left:0;margin-right:0}@media (min-width:768px){.form-horizontal .control-label{text-align:right;margin-bottom:0;padding-top:7px}}.form-horizontal .has-feedback .form-control-feedback{right:0}@media (min-width:768px){.form-horizontal .form-group-lg .control-label{padding-top:11px;font-size:17px}}@media (min-width:768px){.form-horizontal .form-group-sm .control-label{padding-top:6px;font-size:12px}}.btn{display:inline-block;margin-bottom:0;font-weight:400;text-align:center;vertical-align:middle;touch-action:manipulation;cursor:pointer;background-image:none;border:1px solid transparent;white-space:nowrap;padding:6px 12px;font-size:13px;line-height:1.42857143;border-radius:2px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.btn.active.focus,.btn.active:focus,.btn.focus,.btn:active.focus,.btn:active:focus,.btn:focus{outline:thin dotted;outline:5px auto -webkit-focus-ring-color;outline-offset:-2px}.btn.focus,.btn:focus,.btn:hover{color:#333;text-decoration:none}.btn.active,.btn:active{outline:0;background-image:none;-webkit-box-shadow:inset 0 3px 5px rgba(0,0,0,.125);box-shadow:inset 0 3px 5px rgba(0,0,0,.125)}.btn.disabled,.btn[disabled],fieldset[disabled] .btn{cursor:not-allowed;opacity:.65;filter:alpha(opacity=65);-webkit-box-shadow:none;box-shadow:none}a.btn.disabled,fieldset[disabled] a.btn{pointer-events:none}.btn-default{color:#333;background-color:#fff;border-color:#ccc}.btn-default.focus,.btn-default:focus{color:#333;background-color:#e6e6e6;border-color:#8c8c8c}.btn-default:hover{color:#333;background-color:#e6e6e6;border-color:#adadad}.btn-default.active,.btn-default:active,.open>.dropdown-toggle.btn-default{color:#333;background-color:#e6e6e6;border-color:#adadad}.btn-default.active.focus,.btn-default.active:focus,.btn-default.active:hover,.btn-default:active.focus,.btn-default:active:focus,.btn-default:active:hover,.open>.dropdown-toggle.btn-default.focus,.open>.dropdown-toggle.btn-default:focus,.open>.dropdown-toggle.btn-default:hover{color:#333;background-color:#d4d4d4;border-color:#8c8c8c}.btn-default.active,.btn-default:active,.open>.dropdown-toggle.btn-default{background-image:none}.btn-default.disabled.focus,.btn-default.disabled:focus,.btn-default.disabled:hover,.btn-default[disabled].focus,.btn-default[disabled]:focus,.btn-default[disabled]:hover,fieldset[disabled] .btn-default.focus,fieldset[disabled] .btn-default:focus,fieldset[disabled] .btn-default:hover{background-color:#fff;border-color:#ccc}.btn-default .badge{color:#fff;background-color:#333}.btn-primary{color:#fff;background-color:#337ab7;border-color:#2e6da4}.btn-primary.focus,.btn-primary:focus{color:#fff;background-color:#286090;border-color:#122b40}.btn-primary:hover{color:#fff;background-color:#286090;border-color:#204d74}.btn-primary.active,.btn-primary:active,.open>.dropdown-toggle.btn-primary{color:#fff;background-color:#286090;border-color:#204d74}.btn-primary.active.focus,.btn-primary.active:focus,.btn-primary.active:hover,.btn-primary:active.focus,.btn-primary:active:focus,.btn-primary:active:hover,.open>.dropdown-toggle.btn-primary.focus,.open>.dropdown-toggle.btn-primary:focus,.open>.dropdown-toggle.btn-primary:hover{color:#fff;background-color:#204d74;border-color:#122b40}.btn-primary.active,.btn-primary:active,.open>.dropdown-toggle.btn-primary{background-image:none}.btn-primary.disabled.focus,.btn-primary.disabled:focus,.btn-primary.disabled:hover,.btn-primary[disabled].focus,.btn-primary[disabled]:focus,.btn-primary[disabled]:hover,fieldset[disabled] .btn-primary.focus,fieldset[disabled] .btn-primary:focus,fieldset[disabled] .btn-primary:hover{background-color:#337ab7;border-color:#2e6da4}.btn-primary .badge{color:#337ab7;background-color:#fff}.btn-success{color:#fff;background-color:#5cb85c;border-color:#4cae4c}.btn-success.focus,.btn-success:focus{color:#fff;background-color:#449d44;border-color:#255625}.btn-success:hover{color:#fff;background-color:#449d44;border-color:#398439}.btn-success.active,.btn-success:active,.open>.dropdown-toggle.btn-success{color:#fff;background-color:#449d44;border-color:#398439}.btn-success.active.focus,.btn-success.active:focus,.btn-success.active:hover,.btn-success:active.focus,.btn-success:active:focus,.btn-success:active:hover,.open>.dropdown-toggle.btn-success.focus,.open>.dropdown-toggle.btn-success:focus,.open>.dropdown-toggle.btn-success:hover{color:#fff;background-color:#398439;border-color:#255625}.btn-success.active,.btn-success:active,.open>.dropdown-toggle.btn-success{background-image:none}.btn-success.disabled.focus,.btn-success.disabled:focus,.btn-success.disabled:hover,.btn-success[disabled].focus,.btn-success[disabled]:focus,.btn-success[disabled]:hover,fieldset[disabled] .btn-success.focus,fieldset[disabled] .btn-success:focus,fieldset[disabled] .btn-success:hover{background-color:#5cb85c;border-color:#4cae4c}.btn-success .badge{color:#5cb85c;background-color:#fff}.btn-info{color:#fff;background-color:#5bc0de;border-color:#46b8da}.btn-info.focus,.btn-info:focus{color:#fff;background-color:#31b0d5;border-color:#1b6d85}.btn-info:hover{color:#fff;background-color:#31b0d5;border-color:#269abc}.btn-info.active,.btn-info:active,.open>.dropdown-toggle.btn-info{color:#fff;background-color:#31b0d5;border-color:#269abc}.btn-info.active.focus,.btn-info.active:focus,.btn-info.active:hover,.btn-info:active.focus,.btn-info:active:focus,.btn-info:active:hover,.open>.dropdown-toggle.btn-info.focus,.open>.dropdown-toggle.btn-info:focus,.open>.dropdown-toggle.btn-info:hover{color:#fff;background-color:#269abc;border-color:#1b6d85}.btn-info.active,.btn-info:active,.open>.dropdown-toggle.btn-info{background-image:none}.btn-info.disabled.focus,.btn-info.disabled:focus,.btn-info.disabled:hover,.btn-info[disabled].focus,.btn-info[disabled]:focus,.btn-info[disabled]:hover,fieldset[disabled] .btn-info.focus,fieldset[disabled] .btn-info:focus,fieldset[disabled] .btn-info:hover{background-color:#5bc0de;border-color:#46b8da}.btn-info .badge{color:#5bc0de;background-color:#fff}.btn-warning{color:#fff;background-color:#f0ad4e;border-color:#eea236}.btn-warning.focus,.btn-warning:focus{color:#fff;background-color:#ec971f;border-color:#985f0d}.btn-warning:hover{color:#fff;background-color:#ec971f;border-color:#d58512}.btn-warning.active,.btn-warning:active,.open>.dropdown-toggle.btn-warning{color:#fff;background-color:#ec971f;border-color:#d58512}.btn-warning.active.focus,.btn-warning.active:focus,.btn-warning.active:hover,.btn-warning:active.focus,.btn-warning:active:focus,.btn-warning:active:hover,.open>.dropdown-toggle.btn-warning.focus,.open>.dropdown-toggle.btn-warning:focus,.open>.dropdown-toggle.btn-warning:hover{color:#fff;background-color:#d58512;border-color:#985f0d}.btn-warning.active,.btn-warning:active,.open>.dropdown-toggle.btn-warning{background-image:none}.btn-warning.disabled.focus,.btn-warning.disabled:focus,.btn-warning.disabled:hover,.btn-warning[disabled].focus,.btn-warning[disabled]:focus,.btn-warning[disabled]:hover,fieldset[disabled] .btn-warning.focus,fieldset[disabled] .btn-warning:focus,fieldset[disabled] .btn-warning:hover{background-color:#f0ad4e;border-color:#eea236}.btn-warning .badge{color:#f0ad4e;background-color:#fff}.btn-danger{color:#fff;background-color:#d9534f;border-color:#d43f3a}.btn-danger.focus,.btn-danger:focus{color:#fff;background-color:#c9302c;border-color:#761c19}.btn-danger:hover{color:#fff;background-color:#c9302c;border-color:#ac2925}.btn-danger.active,.btn-danger:active,.open>.dropdown-toggle.btn-danger{color:#fff;background-color:#c9302c;border-color:#ac2925}.btn-danger.active.focus,.btn-danger.active:focus,.btn-danger.active:hover,.btn-danger:active.focus,.btn-danger:active:focus,.btn-danger:active:hover,.open>.dropdown-toggle.btn-danger.focus,.open>.dropdown-toggle.btn-danger:focus,.open>.dropdown-toggle.btn-danger:hover{color:#fff;background-color:#ac2925;border-color:#761c19}.btn-danger.active,.btn-danger:active,.open>.dropdown-toggle.btn-danger{background-image:none}.btn-danger.disabled.focus,.btn-danger.disabled:focus,.btn-danger.disabled:hover,.btn-danger[disabled].focus,.btn-danger[disabled]:focus,.btn-danger[disabled]:hover,fieldset[disabled] .btn-danger.focus,fieldset[disabled] .btn-danger:focus,fieldset[disabled] .btn-danger:hover{background-color:#d9534f;border-color:#d43f3a}.btn-danger .badge{color:#d9534f;background-color:#fff}.btn-link{color:#337ab7;font-weight:400;border-radius:0}.btn-link,.btn-link.active,.btn-link:active,.btn-link[disabled],fieldset[disabled] .btn-link{background-color:transparent;-webkit-box-shadow:none;box-shadow:none}.btn-link,.btn-link:active,.btn-link:focus,.btn-link:hover{border-color:transparent}.btn-link:focus,.btn-link:hover{color:#23527c;text-decoration:underline;background-color:transparent}.btn-link[disabled]:focus,.btn-link[disabled]:hover,fieldset[disabled] .btn-link:focus,fieldset[disabled] .btn-link:hover{color:#777;text-decoration:none}.btn-group-lg>.btn,.btn-lg{padding:10px 16px;font-size:17px;line-height:1.3333333;border-radius:3px}.btn-group-sm>.btn,.btn-sm{padding:5px 10px;font-size:12px;line-height:1.5;border-radius:1px}.btn-group-xs>.btn,.btn-xs{padding:1px 5px;font-size:12px;line-height:1.5;border-radius:1px}.btn-block{display:block;width:100%}.btn-block+.btn-block{margin-top:5px}input[type=button].btn-block,input[type=reset].btn-block,input[type=submit].btn-block{width:100%}.fade{opacity:0;-webkit-transition:opacity .15s linear;-o-transition:opacity .15s linear;transition:opacity .15s linear}.fade.in{opacity:1}.collapse{display:none}.collapse.in{display:block}tr.collapse.in{display:table-row}tbody.collapse.in{display:table-row-group}.collapsing{position:relative;height:0;overflow:hidden;-webkit-transition-property:height,visibility;transition-property:height,visibility;-webkit-transition-duration:.35s;transition-duration:.35s;-webkit-transition-timing-function:ease;transition-timing-function:ease}.caret{display:inline-block;width:0;height:0;margin-left:2px;vertical-align:middle;border-top:4px dashed;border-top:4px solid\9;border-right:4px solid transparent;border-left:4px solid transparent}.dropdown,.dropup{position:relative}.dropdown-toggle:focus{outline:0}.dropdown-menu{position:absolute;top:100%;left:0;z-index:1000;display:none;float:left;min-width:160px;padding:5px 0;margin:2px 0 0;list-style:none;font-size:13px;text-align:left;background-color:#fff;border:1px solid #ccc;border:1px solid rgba(0,0,0,.15);border-radius:2px;-webkit-box-shadow:0 6px 12px rgba(0,0,0,.175);box-shadow:0 6px 12px rgba(0,0,0,.175);background-clip:padding-box}.dropdown-menu.pull-right{right:0;left:auto}.dropdown-menu .divider{height:1px;margin:8px 0;overflow:hidden;background-color:#e5e5e5}.dropdown-menu>li>a{display:block;padding:3px 20px;clear:both;font-weight:400;line-height:1.42857143;color:#333;white-space:nowrap}.dropdown-menu>li>a:focus,.dropdown-menu>li>a:hover{text-decoration:none;color:#262626;background-color:#f5f5f5}.dropdown-menu>.active>a,.dropdown-menu>.active>a:focus,.dropdown-menu>.active>a:hover{color:#fff;text-decoration:none;outline:0;background-color:#337ab7}.dropdown-menu>.disabled>a,.dropdown-menu>.disabled>a:focus,.dropdown-menu>.disabled>a:hover{color:#777}.dropdown-menu>.disabled>a:focus,.dropdown-menu>.disabled>a:hover{text-decoration:none;background-color:transparent;background-image:none;filter:progid:DXImageTransform.Microsoft.gradient(enabled=false);cursor:not-allowed}.open>.dropdown-menu{display:block}.open>a{outline:0}.dropdown-menu-right{left:auto;right:0}.dropdown-menu-left{left:0;right:auto}.dropdown-header{display:block;padding:3px 20px;font-size:12px;line-height:1.42857143;color:#777;white-space:nowrap}.dropdown-backdrop{position:fixed;left:0;right:0;bottom:0;top:0;z-index:990}.pull-right>.dropdown-menu{right:0;left:auto}.dropup .caret,.navbar-fixed-bottom .dropdown .caret{border-top:0;border-bottom:4px dashed;border-bottom:4px solid\9;content:""}.dropup .dropdown-menu,.navbar-fixed-bottom .dropdown .dropdown-menu{top:auto;bottom:100%;margin-bottom:2px}@media (min-width:541px){.navbar-right .dropdown-menu{left:auto;right:0}.navbar-right .dropdown-menu-left{left:0;right:auto}}.btn-group,.btn-group-vertical{position:relative;display:inline-block;vertical-align:middle}.btn-group-vertical>.btn,.btn-group>.btn{position:relative;float:left}.btn-group-vertical>.btn.active,.btn-group-vertical>.btn:active,.btn-group-vertical>.btn:focus,.btn-group-vertical>.btn:hover,.btn-group>.btn.active,.btn-group>.btn:active,.btn-group>.btn:focus,.btn-group>.btn:hover{z-index:2}.btn-group .btn+.btn,.btn-group .btn+.btn-group,.btn-group .btn-group+.btn,.btn-group .btn-group+.btn-group{margin-left:-1px}.btn-toolbar{margin-left:-5px}.btn-toolbar .btn,.btn-toolbar .btn-group,.btn-toolbar .input-group{float:left}.btn-toolbar>.btn,.btn-toolbar>.btn-group,.btn-toolbar>.input-group{margin-left:5px}.btn-group>.btn:not(:first-child):not(:last-child):not(.dropdown-toggle){border-radius:0}.btn-group>.btn:first-child{margin-left:0}.btn-group>.btn:first-child:not(:last-child):not(.dropdown-toggle){border-bottom-right-radius:0;border-top-right-radius:0}.btn-group>.btn:last-child:not(:first-child),.btn-group>.dropdown-toggle:not(:first-child){border-bottom-left-radius:0;border-top-left-radius:0}.btn-group>.btn-group{float:left}.btn-group>.btn-group:not(:first-child):not(:last-child)>.btn{border-radius:0}.btn-group>.btn-group:first-child:not(:last-child)>.btn:last-child,.btn-group>.btn-group:first-child:not(:last-child)>.dropdown-toggle{border-bottom-right-radius:0;border-top-right-radius:0}.btn-group>.btn-group:last-child:not(:first-child)>.btn:first-child{border-bottom-left-radius:0;border-top-left-radius:0}.btn-group .dropdown-toggle:active,.btn-group.open .dropdown-toggle{outline:0}.btn-group>.btn+.dropdown-toggle{padding-left:8px;padding-right:8px}.btn-group>.btn-lg+.dropdown-toggle{padding-left:12px;padding-right:12px}.btn-group.open .dropdown-toggle{-webkit-box-shadow:inset 0 3px 5px rgba(0,0,0,.125);box-shadow:inset 0 3px 5px rgba(0,0,0,.125)}.btn-group.open .dropdown-toggle.btn-link{-webkit-box-shadow:none;box-shadow:none}.btn .caret{margin-left:0}.btn-lg .caret{border-width:5px 5px 0;border-bottom-width:0}.dropup .btn-lg .caret{border-width:0 5px 5px}.btn-group-vertical>.btn,.btn-group-vertical>.btn-group,.btn-group-vertical>.btn-group>.btn{display:block;float:none;width:100%;max-width:100%}.btn-group-vertical>.btn-group>.btn{float:none}.btn-group-vertical>.btn+.btn,.btn-group-vertical>.btn+.btn-group,.btn-group-vertical>.btn-group+.btn,.btn-group-vertical>.btn-group+.btn-group{margin-top:-1px;margin-left:0}.btn-group-vertical>.btn:not(:first-child):not(:last-child){border-radius:0}.btn-group-vertical>.btn:first-child:not(:last-child){border-top-right-radius:2px;border-top-left-radius:2px;border-bottom-right-radius:0;border-bottom-left-radius:0}.btn-group-vertical>.btn:last-child:not(:first-child){border-top-right-radius:0;border-top-left-radius:0;border-bottom-right-radius:2px;border-bottom-left-radius:2px}.btn-group-vertical>.btn-group:not(:first-child):not(:last-child)>.btn{border-radius:0}.btn-group-vertical>.btn-group:first-child:not(:last-child)>.btn:last-child,.btn-group-vertical>.btn-group:first-child:not(:last-child)>.dropdown-toggle{border-bottom-right-radius:0;border-bottom-left-radius:0}.btn-group-vertical>.btn-group:last-child:not(:first-child)>.btn:first-child{border-top-right-radius:0;border-top-left-radius:0}.btn-group-justified{display:table;width:100%;table-layout:fixed;border-collapse:separate}.btn-group-justified>.btn,.btn-group-justified>.btn-group{float:none;display:table-cell;width:1%}.btn-group-justified>.btn-group .btn{width:100%}.btn-group-justified>.btn-group .dropdown-menu{left:auto}[data-toggle=buttons]>.btn input[type=checkbox],[data-toggle=buttons]>.btn input[type=radio],[data-toggle=buttons]>.btn-group>.btn input[type=checkbox],[data-toggle=buttons]>.btn-group>.btn input[type=radio]{position:absolute;clip:rect(0,0,0,0);pointer-events:none}.input-group{position:relative;display:table;border-collapse:separate}.input-group[class*=col-]{float:none;padding-left:0;padding-right:0}.input-group .form-control{position:relative;z-index:2;float:left;width:100%;margin-bottom:0}.input-group .form-control:focus{z-index:3}.input-group-lg>.form-control,.input-group-lg>.input-group-addon,.input-group-lg>.input-group-btn>.btn{height:45px;padding:10px 16px;font-size:17px;line-height:1.3333333;border-radius:3px}select.input-group-lg>.form-control,select.input-group-lg>.input-group-addon,select.input-group-lg>.input-group-btn>.btn{height:45px;line-height:45px}select[multiple].input-group-lg>.form-control,select[multiple].input-group-lg>.input-group-addon,select[multiple].input-group-lg>.input-group-btn>.btn,textarea.input-group-lg>.form-control,textarea.input-group-lg>.input-group-addon,textarea.input-group-lg>.input-group-btn>.btn{height:auto}.input-group-sm>.form-control,.input-group-sm>.input-group-addon,.input-group-sm>.input-group-btn>.btn{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:1px}select.input-group-sm>.form-control,select.input-group-sm>.input-group-addon,select.input-group-sm>.input-group-btn>.btn{height:30px;line-height:30px}select[multiple].input-group-sm>.form-control,select[multiple].input-group-sm>.input-group-addon,select[multiple].input-group-sm>.input-group-btn>.btn,textarea.input-group-sm>.form-control,textarea.input-group-sm>.input-group-addon,textarea.input-group-sm>.input-group-btn>.btn{height:auto}.input-group .form-control,.input-group-addon,.input-group-btn{display:table-cell}.input-group .form-control:not(:first-child):not(:last-child),.input-group-addon:not(:first-child):not(:last-child),.input-group-btn:not(:first-child):not(:last-child){border-radius:0}.input-group-addon,.input-group-btn{width:1%;white-space:nowrap;vertical-align:middle}.input-group-addon{padding:6px 12px;font-size:13px;font-weight:400;line-height:1;color:#555;text-align:center;background-color:#eee;border:1px solid #ccc;border-radius:2px}.input-group-addon.input-sm{padding:5px 10px;font-size:12px;border-radius:1px}.input-group-addon.input-lg{padding:10px 16px;font-size:17px;border-radius:3px}.input-group-addon input[type=checkbox],.input-group-addon input[type=radio]{margin-top:0}.input-group .form-control:first-child,.input-group-addon:first-child,.input-group-btn:first-child>.btn,.input-group-btn:first-child>.btn-group>.btn,.input-group-btn:first-child>.dropdown-toggle,.input-group-btn:last-child>.btn-group:not(:last-child)>.btn,.input-group-btn:last-child>.btn:not(:last-child):not(.dropdown-toggle){border-bottom-right-radius:0;border-top-right-radius:0}.input-group-addon:first-child{border-right:0}.input-group .form-control:last-child,.input-group-addon:last-child,.input-group-btn:first-child>.btn-group:not(:first-child)>.btn,.input-group-btn:first-child>.btn:not(:first-child),.input-group-btn:last-child>.btn,.input-group-btn:last-child>.btn-group>.btn,.input-group-btn:last-child>.dropdown-toggle{border-bottom-left-radius:0;border-top-left-radius:0}.input-group-addon:last-child{border-left:0}.input-group-btn{position:relative;font-size:0;white-space:nowrap}.input-group-btn>.btn{position:relative}.input-group-btn>.btn+.btn{margin-left:-1px}.input-group-btn>.btn:active,.input-group-btn>.btn:focus,.input-group-btn>.btn:hover{z-index:2}.input-group-btn:first-child>.btn,.input-group-btn:first-child>.btn-group{margin-right:-1px}.input-group-btn:last-child>.btn,.input-group-btn:last-child>.btn-group{z-index:2;margin-left:-1px}.nav{margin-bottom:0;padding-left:0;list-style:none}.nav>li{position:relative;display:block}.nav>li>a{position:relative;display:block;padding:10px 15px}.nav>li>a:focus,.nav>li>a:hover{text-decoration:none;background-color:#eee}.nav>li.disabled>a{color:#777}.nav>li.disabled>a:focus,.nav>li.disabled>a:hover{color:#777;text-decoration:none;background-color:transparent;cursor:not-allowed}.nav .open>a,.nav .open>a:focus,.nav .open>a:hover{background-color:#eee;border-color:#337ab7}.nav .nav-divider{height:1px;margin:8px 0;overflow:hidden;background-color:#e5e5e5}.nav>li>a>img{max-width:none}.nav-tabs{border-bottom:1px solid #ddd}.nav-tabs>li{float:left;margin-bottom:-1px}.nav-tabs>li>a{margin-right:2px;line-height:1.42857143;border:1px solid transparent;border-radius:2px 2px 0 0}.nav-tabs>li>a:hover{border-color:#eee #eee #ddd}.nav-tabs>li.active>a,.nav-tabs>li.active>a:focus,.nav-tabs>li.active>a:hover{color:#555;background-color:#fff;border:1px solid #ddd;border-bottom-color:transparent;cursor:default}.nav-tabs.nav-justified{width:100%;border-bottom:0}.nav-tabs.nav-justified>li{float:none}.nav-tabs.nav-justified>li>a{text-align:center;margin-bottom:5px}.nav-tabs.nav-justified>.dropdown .dropdown-menu{top:auto;left:auto}@media (min-width:768px){.nav-tabs.nav-justified>li{display:table-cell;width:1%}.nav-tabs.nav-justified>li>a{margin-bottom:0}}.nav-tabs.nav-justified>li>a{margin-right:0;border-radius:2px}.nav-tabs.nav-justified>.active>a,.nav-tabs.nav-justified>.active>a:focus,.nav-tabs.nav-justified>.active>a:hover{border:1px solid #ddd}@media (min-width:768px){.nav-tabs.nav-justified>li>a{border-bottom:1px solid #ddd;border-radius:2px 2px 0 0}.nav-tabs.nav-justified>.active>a,.nav-tabs.nav-justified>.active>a:focus,.nav-tabs.nav-justified>.active>a:hover{border-bottom-color:#fff}}.nav-pills>li{float:left}.nav-pills>li>a{border-radius:2px}.nav-pills>li+li{margin-left:2px}.nav-pills>li.active>a,.nav-pills>li.active>a:focus,.nav-pills>li.active>a:hover{color:#fff;background-color:#337ab7}.nav-stacked>li{float:none}.nav-stacked>li+li{margin-top:2px;margin-left:0}.nav-justified{width:100%}.nav-justified>li{float:none}.nav-justified>li>a{text-align:center;margin-bottom:5px}.nav-justified>.dropdown .dropdown-menu{top:auto;left:auto}@media (min-width:768px){.nav-justified>li{display:table-cell;width:1%}.nav-justified>li>a{margin-bottom:0}}.nav-tabs-justified{border-bottom:0}.nav-tabs-justified>li>a{margin-right:0;border-radius:2px}.nav-tabs-justified>.active>a,.nav-tabs-justified>.active>a:focus,.nav-tabs-justified>.active>a:hover{border:1px solid #ddd}@media (min-width:768px){.nav-tabs-justified>li>a{border-bottom:1px solid #ddd;border-radius:2px 2px 0 0}.nav-tabs-justified>.active>a,.nav-tabs-justified>.active>a:focus,.nav-tabs-justified>.active>a:hover{border-bottom-color:#fff}}.tab-content>.tab-pane{display:none}.tab-content>.active{display:block}.nav-tabs .dropdown-menu{margin-top:-1px;border-top-right-radius:0;border-top-left-radius:0}.navbar{position:relative;min-height:30px;margin-bottom:18px;border:1px solid transparent}@media (min-width:541px){.navbar{border-radius:2px}}@media (min-width:541px){.navbar-header{float:left}}.navbar-collapse{overflow-x:visible;padding-right:0;padding-left:0;border-top:1px solid transparent;box-shadow:inset 0 1px 0 rgba(255,255,255,.1);-webkit-overflow-scrolling:touch}.navbar-collapse.in{overflow-y:auto}@media (min-width:541px){.navbar-collapse{width:auto;border-top:0;box-shadow:none}.navbar-collapse.collapse{display:block!important;height:auto!important;padding-bottom:0;overflow:visible!important}.navbar-collapse.in{overflow-y:visible}.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-collapse,.navbar-static-top .navbar-collapse{padding-left:0;padding-right:0}}.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-collapse{max-height:340px}@media (max-device-width:540px) and (orientation:landscape){.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-collapse{max-height:200px}}.container-fluid>.navbar-collapse,.container-fluid>.navbar-header,.container>.navbar-collapse,.container>.navbar-header{margin-right:0;margin-left:0}@media (min-width:541px){.container-fluid>.navbar-collapse,.container-fluid>.navbar-header,.container>.navbar-collapse,.container>.navbar-header{margin-right:0;margin-left:0}}.navbar-static-top{z-index:1000;border-width:0 0 1px}@media (min-width:541px){.navbar-static-top{border-radius:0}}.navbar-fixed-bottom,.navbar-fixed-top{position:fixed;right:0;left:0;z-index:1030}@media (min-width:541px){.navbar-fixed-bottom,.navbar-fixed-top{border-radius:0}}.navbar-fixed-top{top:0;border-width:0 0 1px}.navbar-fixed-bottom{bottom:0;margin-bottom:0;border-width:1px 0 0}.navbar-brand{float:left;padding:6px 0;font-size:17px;line-height:18px;height:30px}.navbar-brand:focus,.navbar-brand:hover{text-decoration:none}.navbar-brand>img{display:block}@media (min-width:541px){.navbar>.container .navbar-brand,.navbar>.container-fluid .navbar-brand{margin-left:0}}.navbar-toggle{position:relative;float:right;margin-right:0;padding:9px 10px;margin-top:-2px;margin-bottom:-2px;background-color:transparent;background-image:none;border:1px solid transparent;border-radius:2px}.navbar-toggle:focus{outline:0}.navbar-toggle .icon-bar{display:block;width:22px;height:2px;border-radius:1px}.navbar-toggle .icon-bar+.icon-bar{margin-top:4px}@media (min-width:541px){.navbar-toggle{display:none}}.navbar-nav{margin:3px 0}.navbar-nav>li>a{padding-top:10px;padding-bottom:10px;line-height:18px}@media (max-width:540px){.navbar-nav .open .dropdown-menu{position:static;float:none;width:auto;margin-top:0;background-color:transparent;border:0;box-shadow:none}.navbar-nav .open .dropdown-menu .dropdown-header,.navbar-nav .open .dropdown-menu>li>a{padding:5px 15px 5px 25px}.navbar-nav .open .dropdown-menu>li>a{line-height:18px}.navbar-nav .open .dropdown-menu>li>a:focus,.navbar-nav .open .dropdown-menu>li>a:hover{background-image:none}}@media (min-width:541px){.navbar-nav{float:left;margin:0}.navbar-nav>li{float:left}.navbar-nav>li>a{padding-top:6px;padding-bottom:6px}}.navbar-form{margin-left:0;margin-right:0;padding:10px 0;border-top:1px solid transparent;border-bottom:1px solid transparent;-webkit-box-shadow:inset 0 1px 0 rgba(255,255,255,.1),0 1px 0 rgba(255,255,255,.1);box-shadow:inset 0 1px 0 rgba(255,255,255,.1),0 1px 0 rgba(255,255,255,.1);margin-top:-1px;margin-bottom:-1px}@media (min-width:768px){.navbar-form .form-group{display:inline-block;margin-bottom:0;vertical-align:middle}.navbar-form .form-control{display:inline-block;width:auto;vertical-align:middle}.navbar-form .form-control-static{display:inline-block}.navbar-form .input-group{display:inline-table;vertical-align:middle}.navbar-form .input-group .form-control,.navbar-form .input-group .input-group-addon,.navbar-form .input-group .input-group-btn{width:auto}.navbar-form .input-group>.form-control{width:100%}.navbar-form .control-label{margin-bottom:0;vertical-align:middle}.navbar-form .checkbox,.navbar-form .radio{display:inline-block;margin-top:0;margin-bottom:0;vertical-align:middle}.navbar-form .checkbox label,.navbar-form .radio label{padding-left:0}.navbar-form .checkbox input[type=checkbox],.navbar-form .radio input[type=radio]{position:relative;margin-left:0}.navbar-form .has-feedback .form-control-feedback{top:0}}@media (max-width:540px){.navbar-form .form-group{margin-bottom:5px}.navbar-form .form-group:last-child{margin-bottom:0}}@media (min-width:541px){.navbar-form{width:auto;border:0;margin-left:0;margin-right:0;padding-top:0;padding-bottom:0;-webkit-box-shadow:none;box-shadow:none}}.navbar-nav>li>.dropdown-menu{margin-top:0;border-top-right-radius:0;border-top-left-radius:0}.navbar-fixed-bottom .navbar-nav>li>.dropdown-menu{margin-bottom:0;border-top-right-radius:2px;border-top-left-radius:2px;border-bottom-right-radius:0;border-bottom-left-radius:0}.navbar-btn{margin-top:-1px;margin-bottom:-1px}.navbar-btn.btn-sm{margin-top:0;margin-bottom:0}.navbar-btn.btn-xs{margin-top:4px;margin-bottom:4px}.navbar-text{margin-top:6px;margin-bottom:6px}@media (min-width:541px){.navbar-text{float:left;margin-left:0;margin-right:0}}@media (min-width:541px){.navbar-left{float:left!important;float:left}.navbar-right{float:right!important;float:right;margin-right:0}.navbar-right~.navbar-right{margin-right:0}}.navbar-default{background-color:#f8f8f8;border-color:#e7e7e7}.navbar-default .navbar-brand{color:#777}.navbar-default .navbar-brand:focus,.navbar-default .navbar-brand:hover{color:#5e5e5e;background-color:transparent}.navbar-default .navbar-text{color:#777}.navbar-default .navbar-nav>li>a{color:#777}.navbar-default .navbar-nav>li>a:focus,.navbar-default .navbar-nav>li>a:hover{color:#333;background-color:transparent}.navbar-default .navbar-nav>.active>a,.navbar-default .navbar-nav>.active>a:focus,.navbar-default .navbar-nav>.active>a:hover{color:#555;background-color:#e7e7e7}.navbar-default .navbar-nav>.disabled>a,.navbar-default .navbar-nav>.disabled>a:focus,.navbar-default .navbar-nav>.disabled>a:hover{color:#ccc;background-color:transparent}.navbar-default .navbar-toggle{border-color:#ddd}.navbar-default .navbar-toggle:focus,.navbar-default .navbar-toggle:hover{background-color:#ddd}.navbar-default .navbar-toggle .icon-bar{background-color:#888}.navbar-default .navbar-collapse,.navbar-default .navbar-form{border-color:#e7e7e7}.navbar-default .navbar-nav>.open>a,.navbar-default .navbar-nav>.open>a:focus,.navbar-default .navbar-nav>.open>a:hover{background-color:#e7e7e7;color:#555}@media (max-width:540px){.navbar-default .navbar-nav .open .dropdown-menu>li>a{color:#777}.navbar-default .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-default .navbar-nav .open .dropdown-menu>li>a:hover{color:#333;background-color:transparent}.navbar-default .navbar-nav .open .dropdown-menu>.active>a,.navbar-default .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-default .navbar-nav .open .dropdown-menu>.active>a:hover{color:#555;background-color:#e7e7e7}.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:hover{color:#ccc;background-color:transparent}}.navbar-default .navbar-link{color:#777}.navbar-default .navbar-link:hover{color:#333}.navbar-default .btn-link{color:#777}.navbar-default .btn-link:focus,.navbar-default .btn-link:hover{color:#333}.navbar-default .btn-link[disabled]:focus,.navbar-default .btn-link[disabled]:hover,fieldset[disabled] .navbar-default .btn-link:focus,fieldset[disabled] .navbar-default .btn-link:hover{color:#ccc}.navbar-inverse{background-color:#222;border-color:#080808}.navbar-inverse .navbar-brand{color:#9d9d9d}.navbar-inverse .navbar-brand:focus,.navbar-inverse .navbar-brand:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-text{color:#9d9d9d}.navbar-inverse .navbar-nav>li>a{color:#9d9d9d}.navbar-inverse .navbar-nav>li>a:focus,.navbar-inverse .navbar-nav>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav>.active>a,.navbar-inverse .navbar-nav>.active>a:focus,.navbar-inverse .navbar-nav>.active>a:hover{color:#fff;background-color:#080808}.navbar-inverse .navbar-nav>.disabled>a,.navbar-inverse .navbar-nav>.disabled>a:focus,.navbar-inverse .navbar-nav>.disabled>a:hover{color:#444;background-color:transparent}.navbar-inverse .navbar-toggle{border-color:#333}.navbar-inverse .navbar-toggle:focus,.navbar-inverse .navbar-toggle:hover{background-color:#333}.navbar-inverse .navbar-toggle .icon-bar{background-color:#fff}.navbar-inverse .navbar-collapse,.navbar-inverse .navbar-form{border-color:#101010}.navbar-inverse .navbar-nav>.open>a,.navbar-inverse .navbar-nav>.open>a:focus,.navbar-inverse .navbar-nav>.open>a:hover{background-color:#080808;color:#fff}@media (max-width:540px){.navbar-inverse .navbar-nav .open .dropdown-menu>.dropdown-header{border-color:#080808}.navbar-inverse .navbar-nav .open .dropdown-menu .divider{background-color:#080808}.navbar-inverse .navbar-nav .open .dropdown-menu>li>a{color:#9d9d9d}.navbar-inverse .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a:hover{color:#fff;background-color:#080808}.navbar-inverse .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu>.disabled>a:hover{color:#444;background-color:transparent}}.navbar-inverse .navbar-link{color:#9d9d9d}.navbar-inverse .navbar-link:hover{color:#fff}.navbar-inverse .btn-link{color:#9d9d9d}.navbar-inverse .btn-link:focus,.navbar-inverse .btn-link:hover{color:#fff}.navbar-inverse .btn-link[disabled]:focus,.navbar-inverse .btn-link[disabled]:hover,fieldset[disabled] .navbar-inverse .btn-link:focus,fieldset[disabled] .navbar-inverse .btn-link:hover{color:#444}.breadcrumb{padding:8px 15px;margin-bottom:18px;list-style:none;background-color:#f5f5f5;border-radius:2px}.breadcrumb>li{display:inline-block}.breadcrumb>li+li:before{content:"/\00a0";padding:0 5px;color:#5e5e5e}.breadcrumb>.active{color:#777}.pagination{display:inline-block;padding-left:0;margin:18px 0;border-radius:2px}.pagination>li{display:inline}.pagination>li>a,.pagination>li>span{position:relative;float:left;padding:6px 12px;line-height:1.42857143;text-decoration:none;color:#337ab7;background-color:#fff;border:1px solid #ddd;margin-left:-1px}.pagination>li:first-child>a,.pagination>li:first-child>span{margin-left:0;border-bottom-left-radius:2px;border-top-left-radius:2px}.pagination>li:last-child>a,.pagination>li:last-child>span{border-bottom-right-radius:2px;border-top-right-radius:2px}.pagination>li>a:focus,.pagination>li>a:hover,.pagination>li>span:focus,.pagination>li>span:hover{z-index:2;color:#23527c;background-color:#eee;border-color:#ddd}.pagination>.active>a,.pagination>.active>a:focus,.pagination>.active>a:hover,.pagination>.active>span,.pagination>.active>span:focus,.pagination>.active>span:hover{z-index:3;color:#fff;background-color:#337ab7;border-color:#337ab7;cursor:default}.pagination>.disabled>a,.pagination>.disabled>a:focus,.pagination>.disabled>a:hover,.pagination>.disabled>span,.pagination>.disabled>span:focus,.pagination>.disabled>span:hover{color:#777;background-color:#fff;border-color:#ddd;cursor:not-allowed}.pagination-lg>li>a,.pagination-lg>li>span{padding:10px 16px;font-size:17px;line-height:1.3333333}.pagination-lg>li:first-child>a,.pagination-lg>li:first-child>span{border-bottom-left-radius:3px;border-top-left-radius:3px}.pagination-lg>li:last-child>a,.pagination-lg>li:last-child>span{border-bottom-right-radius:3px;border-top-right-radius:3px}.pagination-sm>li>a,.pagination-sm>li>span{padding:5px 10px;font-size:12px;line-height:1.5}.pagination-sm>li:first-child>a,.pagination-sm>li:first-child>span{border-bottom-left-radius:1px;border-top-left-radius:1px}.pagination-sm>li:last-child>a,.pagination-sm>li:last-child>span{border-bottom-right-radius:1px;border-top-right-radius:1px}.pager{padding-left:0;margin:18px 0;list-style:none;text-align:center}.pager li{display:inline}.pager li>a,.pager li>span{display:inline-block;padding:5px 14px;background-color:#fff;border:1px solid #ddd;border-radius:15px}.pager li>a:focus,.pager li>a:hover{text-decoration:none;background-color:#eee}.pager .next>a,.pager .next>span{float:right}.pager .previous>a,.pager .previous>span{float:left}.pager .disabled>a,.pager .disabled>a:focus,.pager .disabled>a:hover,.pager .disabled>span{color:#777;background-color:#fff;cursor:not-allowed}.label{display:inline;padding:.2em .6em .3em;font-size:75%;font-weight:700;line-height:1;color:#fff;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:.25em}a.label:focus,a.label:hover{color:#fff;text-decoration:none;cursor:pointer}.label:empty{display:none}.btn .label{position:relative;top:-1px}.label-default{background-color:#777}.label-default[href]:focus,.label-default[href]:hover{background-color:#5e5e5e}.label-primary{background-color:#337ab7}.label-primary[href]:focus,.label-primary[href]:hover{background-color:#286090}.label-success{background-color:#5cb85c}.label-success[href]:focus,.label-success[href]:hover{background-color:#449d44}.label-info{background-color:#5bc0de}.label-info[href]:focus,.label-info[href]:hover{background-color:#31b0d5}.label-warning{background-color:#f0ad4e}.label-warning[href]:focus,.label-warning[href]:hover{background-color:#ec971f}.label-danger{background-color:#d9534f}.label-danger[href]:focus,.label-danger[href]:hover{background-color:#c9302c}.badge{display:inline-block;min-width:10px;padding:3px 7px;font-size:12px;font-weight:700;color:#fff;line-height:1;vertical-align:middle;white-space:nowrap;text-align:center;background-color:#777;border-radius:10px}.badge:empty{display:none}.btn .badge{position:relative;top:-1px}.btn-group-xs>.btn .badge,.btn-xs .badge{top:0;padding:1px 5px}a.badge:focus,a.badge:hover{color:#fff;text-decoration:none;cursor:pointer}.list-group-item.active>.badge,.nav-pills>.active>a>.badge{color:#337ab7;background-color:#fff}.list-group-item>.badge{float:right}.list-group-item>.badge+.badge{margin-right:5px}.nav-pills>li>a>.badge{margin-left:3px}.jumbotron{padding-top:30px;padding-bottom:30px;margin-bottom:30px;color:inherit;background-color:#eee}.jumbotron .h1,.jumbotron h1{color:inherit}.jumbotron p{margin-bottom:15px;font-size:20px;font-weight:200}.jumbotron>hr{border-top-color:#d5d5d5}.container .jumbotron,.container-fluid .jumbotron{border-radius:3px;padding-left:0;padding-right:0}.jumbotron .container{max-width:100%}@media screen and (min-width:768px){.jumbotron{padding-top:48px;padding-bottom:48px}.container .jumbotron,.container-fluid .jumbotron{padding-left:60px;padding-right:60px}.jumbotron .h1,.jumbotron h1{font-size:59px}}.thumbnail{display:block;padding:4px;margin-bottom:18px;line-height:1.42857143;background-color:#fff;border:1px solid #ddd;border-radius:2px;-webkit-transition:border .2s ease-in-out;-o-transition:border .2s ease-in-out;transition:border .2s ease-in-out}.thumbnail a>img,.thumbnail>img{margin-left:auto;margin-right:auto}a.thumbnail.active,a.thumbnail:focus,a.thumbnail:hover{border-color:#337ab7}.thumbnail .caption{padding:9px;color:#000}.alert{padding:15px;margin-bottom:18px;border:1px solid transparent;border-radius:2px}.alert h4{margin-top:0;color:inherit}.alert .alert-link{font-weight:700}.alert>p,.alert>ul{margin-bottom:0}.alert>p+p{margin-top:5px}.alert-dismissable,.alert-dismissible{padding-right:35px}.alert-dismissable .close,.alert-dismissible .close{position:relative;top:-2px;right:-21px;color:inherit}.alert-success{background-color:#dff0d8;border-color:#d6e9c6;color:#3c763d}.alert-success hr{border-top-color:#c9e2b3}.alert-success .alert-link{color:#2b542c}.alert-info{background-color:#d9edf7;border-color:#bce8f1;color:#31708f}.alert-info hr{border-top-color:#a6e1ec}.alert-info .alert-link{color:#245269}.alert-warning{background-color:#fcf8e3;border-color:#faebcc;color:#8a6d3b}.alert-warning hr{border-top-color:#f7e1b5}.alert-warning .alert-link{color:#66512c}.alert-danger{background-color:#f2dede;border-color:#ebccd1;color:#a94442}.alert-danger hr{border-top-color:#e4b9c0}.alert-danger .alert-link{color:#843534}@-webkit-keyframes progress-bar-stripes{from{background-position:40px 0}to{background-position:0 0}}@keyframes progress-bar-stripes{from{background-position:40px 0}to{background-position:0 0}}.progress{overflow:hidden;height:18px;margin-bottom:18px;background-color:#f5f5f5;border-radius:2px;-webkit-box-shadow:inset 0 1px 2px rgba(0,0,0,.1);box-shadow:inset 0 1px 2px rgba(0,0,0,.1)}.progress-bar{float:left;width:0;height:100%;font-size:12px;line-height:18px;color:#fff;text-align:center;background-color:#337ab7;-webkit-box-shadow:inset 0 -1px 0 rgba(0,0,0,.15);box-shadow:inset 0 -1px 0 rgba(0,0,0,.15);-webkit-transition:width .6s ease;-o-transition:width .6s ease;transition:width .6s ease}.progress-bar-striped,.progress-striped .progress-bar{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-size:40px 40px}.progress-bar.active,.progress.active .progress-bar{-webkit-animation:progress-bar-stripes 2s linear infinite;-o-animation:progress-bar-stripes 2s linear infinite;animation:progress-bar-stripes 2s linear infinite}.progress-bar-success{background-color:#5cb85c}.progress-striped .progress-bar-success{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-bar-info{background-color:#5bc0de}.progress-striped .progress-bar-info{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-bar-warning{background-color:#f0ad4e}.progress-striped .progress-bar-warning{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-bar-danger{background-color:#d9534f}.progress-striped .progress-bar-danger{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.media{margin-top:15px}.media:first-child{margin-top:0}.media,.media-body{zoom:1;overflow:hidden}.media-body{width:10000px}.media-object{display:block}.media-object.img-thumbnail{max-width:none}.media-right,.media>.pull-right{padding-left:10px}.media-left,.media>.pull-left{padding-right:10px}.media-body,.media-left,.media-right{display:table-cell;vertical-align:top}.media-middle{vertical-align:middle}.media-bottom{vertical-align:bottom}.media-heading{margin-top:0;margin-bottom:5px}.media-list{padding-left:0;list-style:none}.list-group{margin-bottom:20px;padding-left:0}.list-group-item{position:relative;display:block;padding:10px 15px;margin-bottom:-1px;background-color:#fff;border:1px solid #ddd}.list-group-item:first-child{border-top-right-radius:2px;border-top-left-radius:2px}.list-group-item:last-child{margin-bottom:0;border-bottom-right-radius:2px;border-bottom-left-radius:2px}a.list-group-item,button.list-group-item{color:#555}a.list-group-item .list-group-item-heading,button.list-group-item .list-group-item-heading{color:#333}a.list-group-item:focus,a.list-group-item:hover,button.list-group-item:focus,button.list-group-item:hover{text-decoration:none;color:#555;background-color:#f5f5f5}button.list-group-item{width:100%;text-align:left}.list-group-item.disabled,.list-group-item.disabled:focus,.list-group-item.disabled:hover{background-color:#eee;color:#777;cursor:not-allowed}.list-group-item.disabled .list-group-item-heading,.list-group-item.disabled:focus .list-group-item-heading,.list-group-item.disabled:hover .list-group-item-heading{color:inherit}.list-group-item.disabled .list-group-item-text,.list-group-item.disabled:focus .list-group-item-text,.list-group-item.disabled:hover .list-group-item-text{color:#777}.list-group-item.active,.list-group-item.active:focus,.list-group-item.active:hover{z-index:2;color:#fff;background-color:#337ab7;border-color:#337ab7}.list-group-item.active .list-group-item-heading,.list-group-item.active .list-group-item-heading>.small,.list-group-item.active .list-group-item-heading>small,.list-group-item.active:focus .list-group-item-heading,.list-group-item.active:focus .list-group-item-heading>.small,.list-group-item.active:focus .list-group-item-heading>small,.list-group-item.active:hover .list-group-item-heading,.list-group-item.active:hover .list-group-item-heading>.small,.list-group-item.active:hover .list-group-item-heading>small{color:inherit}.list-group-item.active .list-group-item-text,.list-group-item.active:focus .list-group-item-text,.list-group-item.active:hover .list-group-item-text{color:#c7ddef}.list-group-item-success{color:#3c763d;background-color:#dff0d8}a.list-group-item-success,button.list-group-item-success{color:#3c763d}a.list-group-item-success .list-group-item-heading,button.list-group-item-success .list-group-item-heading{color:inherit}a.list-group-item-success:focus,a.list-group-item-success:hover,button.list-group-item-success:focus,button.list-group-item-success:hover{color:#3c763d;background-color:#d0e9c6}a.list-group-item-success.active,a.list-group-item-success.active:focus,a.list-group-item-success.active:hover,button.list-group-item-success.active,button.list-group-item-success.active:focus,button.list-group-item-success.active:hover{color:#fff;background-color:#3c763d;border-color:#3c763d}.list-group-item-info{color:#31708f;background-color:#d9edf7}a.list-group-item-info,button.list-group-item-info{color:#31708f}a.list-group-item-info .list-group-item-heading,button.list-group-item-info .list-group-item-heading{color:inherit}a.list-group-item-info:focus,a.list-group-item-info:hover,button.list-group-item-info:focus,button.list-group-item-info:hover{color:#31708f;background-color:#c4e3f3}a.list-group-item-info.active,a.list-group-item-info.active:focus,a.list-group-item-info.active:hover,button.list-group-item-info.active,button.list-group-item-info.active:focus,button.list-group-item-info.active:hover{color:#fff;background-color:#31708f;border-color:#31708f}.list-group-item-warning{color:#8a6d3b;background-color:#fcf8e3}a.list-group-item-warning,button.list-group-item-warning{color:#8a6d3b}a.list-group-item-warning .list-group-item-heading,button.list-group-item-warning .list-group-item-heading{color:inherit}a.list-group-item-warning:focus,a.list-group-item-warning:hover,button.list-group-item-warning:focus,button.list-group-item-warning:hover{color:#8a6d3b;background-color:#faf2cc}a.list-group-item-warning.active,a.list-group-item-warning.active:focus,a.list-group-item-warning.active:hover,button.list-group-item-warning.active,button.list-group-item-warning.active:focus,button.list-group-item-warning.active:hover{color:#fff;background-color:#8a6d3b;border-color:#8a6d3b}.list-group-item-danger{color:#a94442;background-color:#f2dede}a.list-group-item-danger,button.list-group-item-danger{color:#a94442}a.list-group-item-danger .list-group-item-heading,button.list-group-item-danger .list-group-item-heading{color:inherit}a.list-group-item-danger:focus,a.list-group-item-danger:hover,button.list-group-item-danger:focus,button.list-group-item-danger:hover{color:#a94442;background-color:#ebcccc}a.list-group-item-danger.active,a.list-group-item-danger.active:focus,a.list-group-item-danger.active:hover,button.list-group-item-danger.active,button.list-group-item-danger.active:focus,button.list-group-item-danger.active:hover{color:#fff;background-color:#a94442;border-color:#a94442}.list-group-item-heading{margin-top:0;margin-bottom:5px}.list-group-item-text{margin-bottom:0;line-height:1.3}.panel{margin-bottom:18px;background-color:#fff;border:1px solid transparent;border-radius:2px;-webkit-box-shadow:0 1px 1px rgba(0,0,0,.05);box-shadow:0 1px 1px rgba(0,0,0,.05)}.panel-body{padding:15px}.panel-heading{padding:10px 15px;border-bottom:1px solid transparent;border-top-right-radius:1px;border-top-left-radius:1px}.panel-heading>.dropdown .dropdown-toggle{color:inherit}.panel-title{margin-top:0;margin-bottom:0;font-size:15px;color:inherit}.panel-title>.small,.panel-title>.small>a,.panel-title>a,.panel-title>small,.panel-title>small>a{color:inherit}.panel-footer{padding:10px 15px;background-color:#f5f5f5;border-top:1px solid #ddd;border-bottom-right-radius:1px;border-bottom-left-radius:1px}.panel>.list-group,.panel>.panel-collapse>.list-group{margin-bottom:0}.panel>.list-group .list-group-item,.panel>.panel-collapse>.list-group .list-group-item{border-width:1px 0;border-radius:0}.panel>.list-group:first-child .list-group-item:first-child,.panel>.panel-collapse>.list-group:first-child .list-group-item:first-child{border-top:0;border-top-right-radius:1px;border-top-left-radius:1px}.panel>.list-group:last-child .list-group-item:last-child,.panel>.panel-collapse>.list-group:last-child .list-group-item:last-child{border-bottom:0;border-bottom-right-radius:1px;border-bottom-left-radius:1px}.panel>.panel-heading+.panel-collapse>.list-group .list-group-item:first-child{border-top-right-radius:0;border-top-left-radius:0}.panel-heading+.list-group .list-group-item:first-child{border-top-width:0}.list-group+.panel-footer{border-top-width:0}.panel>.panel-collapse>.table,.panel>.table,.panel>.table-responsive>.table{margin-bottom:0}.panel>.panel-collapse>.table caption,.panel>.table caption,.panel>.table-responsive>.table caption{padding-left:15px;padding-right:15px}.panel>.table-responsive:first-child>.table:first-child,.panel>.table:first-child{border-top-right-radius:1px;border-top-left-radius:1px}.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child,.panel>.table:first-child>thead:first-child>tr:first-child{border-top-left-radius:1px;border-top-right-radius:1px}.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child td:first-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table:first-child>thead:first-child>tr:first-child th:first-child{border-top-left-radius:1px}.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table:first-child>thead:first-child>tr:first-child th:last-child{border-top-right-radius:1px}.panel>.table-responsive:last-child>.table:last-child,.panel>.table:last-child{border-bottom-right-radius:1px;border-bottom-left-radius:1px}.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child{border-bottom-left-radius:1px;border-bottom-right-radius:1px}.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child th:first-child{border-bottom-left-radius:1px}.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child th:last-child{border-bottom-right-radius:1px}.panel>.panel-body+.table,.panel>.panel-body+.table-responsive,.panel>.table+.panel-body,.panel>.table-responsive+.panel-body{border-top:1px solid #ddd}.panel>.table>tbody:first-child>tr:first-child td,.panel>.table>tbody:first-child>tr:first-child th{border-top:0}.panel>.table-bordered,.panel>.table-responsive>.table-bordered{border:0}.panel>.table-bordered>tbody>tr>td:first-child,.panel>.table-bordered>tbody>tr>th:first-child,.panel>.table-bordered>tfoot>tr>td:first-child,.panel>.table-bordered>tfoot>tr>th:first-child,.panel>.table-bordered>thead>tr>td:first-child,.panel>.table-bordered>thead>tr>th:first-child,.panel>.table-responsive>.table-bordered>tbody>tr>td:first-child,.panel>.table-responsive>.table-bordered>tbody>tr>th:first-child,.panel>.table-responsive>.table-bordered>tfoot>tr>td:first-child,.panel>.table-responsive>.table-bordered>tfoot>tr>th:first-child,.panel>.table-responsive>.table-bordered>thead>tr>td:first-child,.panel>.table-responsive>.table-bordered>thead>tr>th:first-child{border-left:0}.panel>.table-bordered>tbody>tr>td:last-child,.panel>.table-bordered>tbody>tr>th:last-child,.panel>.table-bordered>tfoot>tr>td:last-child,.panel>.table-bordered>tfoot>tr>th:last-child,.panel>.table-bordered>thead>tr>td:last-child,.panel>.table-bordered>thead>tr>th:last-child,.panel>.table-responsive>.table-bordered>tbody>tr>td:last-child,.panel>.table-responsive>.table-bordered>tbody>tr>th:last-child,.panel>.table-responsive>.table-bordered>tfoot>tr>td:last-child,.panel>.table-responsive>.table-bordered>tfoot>tr>th:last-child,.panel>.table-responsive>.table-bordered>thead>tr>td:last-child,.panel>.table-responsive>.table-bordered>thead>tr>th:last-child{border-right:0}.panel>.table-bordered>tbody>tr:first-child>td,.panel>.table-bordered>tbody>tr:first-child>th,.panel>.table-bordered>thead>tr:first-child>td,.panel>.table-bordered>thead>tr:first-child>th,.panel>.table-responsive>.table-bordered>tbody>tr:first-child>td,.panel>.table-responsive>.table-bordered>tbody>tr:first-child>th,.panel>.table-responsive>.table-bordered>thead>tr:first-child>td,.panel>.table-responsive>.table-bordered>thead>tr:first-child>th{border-bottom:0}.panel>.table-bordered>tbody>tr:last-child>td,.panel>.table-bordered>tbody>tr:last-child>th,.panel>.table-bordered>tfoot>tr:last-child>td,.panel>.table-bordered>tfoot>tr:last-child>th,.panel>.table-responsive>.table-bordered>tbody>tr:last-child>td,.panel>.table-responsive>.table-bordered>tbody>tr:last-child>th,.panel>.table-responsive>.table-bordered>tfoot>tr:last-child>td,.panel>.table-responsive>.table-bordered>tfoot>tr:last-child>th{border-bottom:0}.panel>.table-responsive{border:0;margin-bottom:0}.panel-group{margin-bottom:18px}.panel-group .panel{margin-bottom:0;border-radius:2px}.panel-group .panel+.panel{margin-top:5px}.panel-group .panel-heading{border-bottom:0}.panel-group .panel-heading+.panel-collapse>.list-group,.panel-group .panel-heading+.panel-collapse>.panel-body{border-top:1px solid #ddd}.panel-group .panel-footer{border-top:0}.panel-group .panel-footer+.panel-collapse .panel-body{border-bottom:1px solid #ddd}.panel-default{border-color:#ddd}.panel-default>.panel-heading{color:#333;background-color:#f5f5f5;border-color:#ddd}.panel-default>.panel-heading+.panel-collapse>.panel-body{border-top-color:#ddd}.panel-default>.panel-heading .badge{color:#f5f5f5;background-color:#333}.panel-default>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#ddd}.panel-primary{border-color:#337ab7}.panel-primary>.panel-heading{color:#fff;background-color:#337ab7;border-color:#337ab7}.panel-primary>.panel-heading+.panel-collapse>.panel-body{border-top-color:#337ab7}.panel-primary>.panel-heading .badge{color:#337ab7;background-color:#fff}.panel-primary>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#337ab7}.panel-success{border-color:#d6e9c6}.panel-success>.panel-heading{color:#3c763d;background-color:#dff0d8;border-color:#d6e9c6}.panel-success>.panel-heading+.panel-collapse>.panel-body{border-top-color:#d6e9c6}.panel-success>.panel-heading .badge{color:#dff0d8;background-color:#3c763d}.panel-success>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#d6e9c6}.panel-info{border-color:#bce8f1}.panel-info>.panel-heading{color:#31708f;background-color:#d9edf7;border-color:#bce8f1}.panel-info>.panel-heading+.panel-collapse>.panel-body{border-top-color:#bce8f1}.panel-info>.panel-heading .badge{color:#d9edf7;background-color:#31708f}.panel-info>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#bce8f1}.panel-warning{border-color:#faebcc}.panel-warning>.panel-heading{color:#8a6d3b;background-color:#fcf8e3;border-color:#faebcc}.panel-warning>.panel-heading+.panel-collapse>.panel-body{border-top-color:#faebcc}.panel-warning>.panel-heading .badge{color:#fcf8e3;background-color:#8a6d3b}.panel-warning>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#faebcc}.panel-danger{border-color:#ebccd1}.panel-danger>.panel-heading{color:#a94442;background-color:#f2dede;border-color:#ebccd1}.panel-danger>.panel-heading+.panel-collapse>.panel-body{border-top-color:#ebccd1}.panel-danger>.panel-heading .badge{color:#f2dede;background-color:#a94442}.panel-danger>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#ebccd1}.embed-responsive{position:relative;display:block;height:0;padding:0;overflow:hidden}.embed-responsive .embed-responsive-item,.embed-responsive embed,.embed-responsive iframe,.embed-responsive object,.embed-responsive video{position:absolute;top:0;left:0;bottom:0;height:100%;width:100%;border:0}.embed-responsive-16by9{padding-bottom:56.25%}.embed-responsive-4by3{padding-bottom:75%}.well{min-height:20px;padding:19px;margin-bottom:20px;background-color:#f5f5f5;border:1px solid #e3e3e3;border-radius:2px;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.05);box-shadow:inset 0 1px 1px rgba(0,0,0,.05)}.well blockquote{border-color:#ddd;border-color:rgba(0,0,0,.15)}.well-lg{padding:24px;border-radius:3px}.well-sm{padding:9px;border-radius:1px}.close{float:right;font-size:19.5px;font-weight:700;line-height:1;color:#000;text-shadow:0 1px 0 #fff;opacity:.2;filter:alpha(opacity=20)}.close:focus,.close:hover{color:#000;text-decoration:none;cursor:pointer;opacity:.5;filter:alpha(opacity=50)}button.close{padding:0;cursor:pointer;background:0 0;border:0;-webkit-appearance:none}.modal-open{overflow:hidden}.modal{display:none;overflow:hidden;position:fixed;top:0;right:0;bottom:0;left:0;z-index:1050;-webkit-overflow-scrolling:touch;outline:0}.modal.fade .modal-dialog{-webkit-transform:translate(0,-25%);-ms-transform:translate(0,-25%);-o-transform:translate(0,-25%);transform:translate(0,-25%);-webkit-transition:-webkit-transform .3s ease-out;-moz-transition:-moz-transform .3s ease-out;-o-transition:-o-transform .3s ease-out;transition:transform .3s ease-out}.modal.in .modal-dialog{-webkit-transform:translate(0,0);-ms-transform:translate(0,0);-o-transform:translate(0,0);transform:translate(0,0)}.modal-open .modal{overflow-x:hidden;overflow-y:auto}.modal-dialog{position:relative;width:auto;margin:10px}.modal-content{position:relative;background-color:#fff;border:1px solid #999;border:1px solid rgba(0,0,0,.2);border-radius:3px;-webkit-box-shadow:0 3px 9px rgba(0,0,0,.5);box-shadow:0 3px 9px rgba(0,0,0,.5);background-clip:padding-box;outline:0}.modal-backdrop{position:fixed;top:0;right:0;bottom:0;left:0;z-index:1040;background-color:#000}.modal-backdrop.fade{opacity:0;filter:alpha(opacity=0)}.modal-backdrop.in{opacity:.5;filter:alpha(opacity=50)}.modal-header{padding:15px;border-bottom:1px solid #e5e5e5}.modal-header .close{margin-top:-2px}.modal-title{margin:0;line-height:1.42857143}.modal-body{position:relative;padding:15px}.modal-footer{padding:15px;text-align:right;border-top:1px solid #e5e5e5}.modal-footer .btn+.btn{margin-left:5px;margin-bottom:0}.modal-footer .btn-group .btn+.btn{margin-left:-1px}.modal-footer .btn-block+.btn-block{margin-left:0}.modal-scrollbar-measure{position:absolute;top:-9999px;width:50px;height:50px;overflow:scroll}@media (min-width:768px){.modal-dialog{width:600px;margin:30px auto}.modal-content{-webkit-box-shadow:0 5px 15px rgba(0,0,0,.5);box-shadow:0 5px 15px rgba(0,0,0,.5)}.modal-sm{width:300px}}@media (min-width:992px){.modal-lg{width:900px}}.tooltip{position:absolute;z-index:1070;display:block;font-family:"Helvetica Neue",Helvetica,Arial,sans-serif;font-style:normal;font-weight:400;letter-spacing:normal;line-break:auto;line-height:1.42857143;text-align:left;text-align:start;text-decoration:none;text-shadow:none;text-transform:none;white-space:normal;word-break:normal;word-spacing:normal;word-wrap:normal;font-size:12px;opacity:0;filter:alpha(opacity=0)}.tooltip.in{opacity:.9;filter:alpha(opacity=90)}.tooltip.top{margin-top:-3px;padding:5px 0}.tooltip.right{margin-left:3px;padding:0 5px}.tooltip.bottom{margin-top:3px;padding:5px 0}.tooltip.left{margin-left:-3px;padding:0 5px}.tooltip-inner{max-width:200px;padding:3px 8px;color:#fff;text-align:center;background-color:#000;border-radius:2px}.tooltip-arrow{position:absolute;width:0;height:0;border-color:transparent;border-style:solid}.tooltip.top .tooltip-arrow{bottom:0;left:50%;margin-left:-5px;border-width:5px 5px 0;border-top-color:#000}.tooltip.top-left .tooltip-arrow{bottom:0;right:5px;margin-bottom:-5px;border-width:5px 5px 0;border-top-color:#000}.tooltip.top-right .tooltip-arrow{bottom:0;left:5px;margin-bottom:-5px;border-width:5px 5px 0;border-top-color:#000}.tooltip.right .tooltip-arrow{top:50%;left:0;margin-top:-5px;border-width:5px 5px 5px 0;border-right-color:#000}.tooltip.left .tooltip-arrow{top:50%;right:0;margin-top:-5px;border-width:5px 0 5px 5px;border-left-color:#000}.tooltip.bottom .tooltip-arrow{top:0;left:50%;margin-left:-5px;border-width:0 5px 5px;border-bottom-color:#000}.tooltip.bottom-left .tooltip-arrow{top:0;right:5px;margin-top:-5px;border-width:0 5px 5px;border-bottom-color:#000}.tooltip.bottom-right .tooltip-arrow{top:0;left:5px;margin-top:-5px;border-width:0 5px 5px;border-bottom-color:#000}.popover{position:absolute;top:0;left:0;z-index:1060;display:none;max-width:276px;padding:1px;font-family:"Helvetica Neue",Helvetica,Arial,sans-serif;font-style:normal;font-weight:400;letter-spacing:normal;line-break:auto;line-height:1.42857143;text-align:left;text-align:start;text-decoration:none;text-shadow:none;text-transform:none;white-space:normal;word-break:normal;word-spacing:normal;word-wrap:normal;font-size:13px;background-color:#fff;background-clip:padding-box;border:1px solid #ccc;border:1px solid rgba(0,0,0,.2);border-radius:3px;-webkit-box-shadow:0 5px 10px rgba(0,0,0,.2);box-shadow:0 5px 10px rgba(0,0,0,.2)}.popover.top{margin-top:-10px}.popover.right{margin-left:10px}.popover.bottom{margin-top:10px}.popover.left{margin-left:-10px}.popover-title{margin:0;padding:8px 14px;font-size:13px;background-color:#f7f7f7;border-bottom:1px solid #ebebeb;border-radius:2px 2px 0 0}.popover-content{padding:9px 14px}.popover>.arrow,.popover>.arrow:after{position:absolute;display:block;width:0;height:0;border-color:transparent;border-style:solid}.popover>.arrow{border-width:11px}.popover>.arrow:after{border-width:10px;content:""}.popover.top>.arrow{left:50%;margin-left:-11px;border-bottom-width:0;border-top-color:#999;border-top-color:rgba(0,0,0,.25);bottom:-11px}.popover.top>.arrow:after{content:" ";bottom:1px;margin-left:-10px;border-bottom-width:0;border-top-color:#fff}.popover.right>.arrow{top:50%;left:-11px;margin-top:-11px;border-left-width:0;border-right-color:#999;border-right-color:rgba(0,0,0,.25)}.popover.right>.arrow:after{content:" ";left:1px;bottom:-10px;border-left-width:0;border-right-color:#fff}.popover.bottom>.arrow{left:50%;margin-left:-11px;border-top-width:0;border-bottom-color:#999;border-bottom-color:rgba(0,0,0,.25);top:-11px}.popover.bottom>.arrow:after{content:" ";top:1px;margin-left:-10px;border-top-width:0;border-bottom-color:#fff}.popover.left>.arrow{top:50%;right:-11px;margin-top:-11px;border-right-width:0;border-left-color:#999;border-left-color:rgba(0,0,0,.25)}.popover.left>.arrow:after{content:" ";right:1px;border-right-width:0;border-left-color:#fff;bottom:-10px}.carousel{position:relative}.carousel-inner{position:relative;overflow:hidden;width:100%}.carousel-inner>.item{display:none;position:relative;-webkit-transition:.6s ease-in-out left;-o-transition:.6s ease-in-out left;transition:.6s ease-in-out left}.carousel-inner>.item>a>img,.carousel-inner>.item>img{line-height:1}@media all and (transform-3d),(-webkit-transform-3d){.carousel-inner>.item{-webkit-transition:-webkit-transform .6s ease-in-out;-moz-transition:-moz-transform .6s ease-in-out;-o-transition:-o-transform .6s ease-in-out;transition:transform .6s ease-in-out;-webkit-backface-visibility:hidden;-moz-backface-visibility:hidden;backface-visibility:hidden;-webkit-perspective:1000px;-moz-perspective:1000px;perspective:1000px}.carousel-inner>.item.active.right,.carousel-inner>.item.next{-webkit-transform:translate3d(100%,0,0);transform:translate3d(100%,0,0);left:0}.carousel-inner>.item.active.left,.carousel-inner>.item.prev{-webkit-transform:translate3d(-100%,0,0);transform:translate3d(-100%,0,0);left:0}.carousel-inner>.item.active,.carousel-inner>.item.next.left,.carousel-inner>.item.prev.right{-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0);left:0}}.carousel-inner>.active,.carousel-inner>.next,.carousel-inner>.prev{display:block}.carousel-inner>.active{left:0}.carousel-inner>.next,.carousel-inner>.prev{position:absolute;top:0;width:100%}.carousel-inner>.next{left:100%}.carousel-inner>.prev{left:-100%}.carousel-inner>.next.left,.carousel-inner>.prev.right{left:0}.carousel-inner>.active.left{left:-100%}.carousel-inner>.active.right{left:100%}.carousel-control{position:absolute;top:0;left:0;bottom:0;width:15%;opacity:.5;filter:alpha(opacity=50);font-size:20px;color:#fff;text-align:center;text-shadow:0 1px 2px rgba(0,0,0,.6);background-color:rgba(0,0,0,0)}.carousel-control.left{background-image:-webkit-linear-gradient(left,rgba(0,0,0,.5) 0,rgba(0,0,0,.0001) 100%);background-image:-o-linear-gradient(left,rgba(0,0,0,.5) 0,rgba(0,0,0,.0001) 100%);background-image:linear-gradient(to right,rgba(0,0,0,.5) 0,rgba(0,0,0,.0001) 100%);background-repeat:repeat-x;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1)}.carousel-control.right{left:auto;right:0;background-image:-webkit-linear-gradient(left,rgba(0,0,0,.0001) 0,rgba(0,0,0,.5) 100%);background-image:-o-linear-gradient(left,rgba(0,0,0,.0001) 0,rgba(0,0,0,.5) 100%);background-image:linear-gradient(to right,rgba(0,0,0,.0001) 0,rgba(0,0,0,.5) 100%);background-repeat:repeat-x;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1)}.carousel-control:focus,.carousel-control:hover{outline:0;color:#fff;text-decoration:none;opacity:.9;filter:alpha(opacity=90)}.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .icon-prev{position:absolute;top:50%;margin-top:-10px;z-index:5;display:inline-block}.carousel-control .glyphicon-chevron-left,.carousel-control .icon-prev{left:50%;margin-left:-10px}.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next{right:50%;margin-right:-10px}.carousel-control .icon-next,.carousel-control .icon-prev{width:20px;height:20px;line-height:1;font-family:serif}.carousel-control .icon-prev:before{content:'\2039'}.carousel-control .icon-next:before{content:'\203a'}.carousel-indicators{position:absolute;bottom:10px;left:50%;z-index:15;width:60%;margin-left:-30%;padding-left:0;list-style:none;text-align:center}.carousel-indicators li{display:inline-block;width:10px;height:10px;margin:1px;text-indent:-999px;border:1px solid #fff;border-radius:10px;cursor:pointer;background-color:#000\9;background-color:rgba(0,0,0,0)}.carousel-indicators .active{margin:0;width:12px;height:12px;background-color:#fff}.carousel-caption{position:absolute;left:15%;right:15%;bottom:20px;z-index:10;padding-top:20px;padding-bottom:20px;color:#fff;text-align:center;text-shadow:0 1px 2px rgba(0,0,0,.6)}.carousel-caption .btn{text-shadow:none}@media screen and (min-width:768px){.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .icon-prev{width:30px;height:30px;margin-top:-10px;font-size:30px}.carousel-control .glyphicon-chevron-left,.carousel-control .icon-prev{margin-left:-10px}.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next{margin-right:-10px}.carousel-caption{left:20%;right:20%;padding-bottom:30px}.carousel-indicators{bottom:20px}}.btn-group-vertical>.btn-group:after,.btn-group-vertical>.btn-group:before,.btn-toolbar:after,.btn-toolbar:before,.clearfix:after,.clearfix:before,.container-fluid:after,.container-fluid:before,.container:after,.container:before,.dl-horizontal dd:after,.dl-horizontal dd:before,.form-horizontal .form-group:after,.form-horizontal .form-group:before,.item_buttons:after,.item_buttons:before,.modal-footer:after,.modal-footer:before,.modal-header:after,.modal-header:before,.nav:after,.nav:before,.navbar-collapse:after,.navbar-collapse:before,.navbar-header:after,.navbar-header:before,.navbar:after,.navbar:before,.pager:after,.pager:before,.panel-body:after,.panel-body:before,.row:after,.row:before{content:" ";display:table}.btn-group-vertical>.btn-group:after,.btn-toolbar:after,.clearfix:after,.container-fluid:after,.container:after,.dl-horizontal dd:after,.form-horizontal .form-group:after,.item_buttons:after,.modal-footer:after,.modal-header:after,.nav:after,.navbar-collapse:after,.navbar-header:after,.navbar:after,.pager:after,.panel-body:after,.row:after{clear:both}.center-block{display:block;margin-left:auto;margin-right:auto}.pull-right{float:right!important}.pull-left{float:left!important}.hide{display:none!important}.show{display:block!important}.invisible{visibility:hidden}.text-hide{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;border:0}.hidden{display:none!important}.affix{position:fixed}@-ms-viewport{width:device-width}.visible-lg,.visible-md,.visible-sm,.visible-xs{display:none!important}.visible-lg-block,.visible-lg-inline,.visible-lg-inline-block,.visible-md-block,.visible-md-inline,.visible-md-inline-block,.visible-sm-block,.visible-sm-inline,.visible-sm-inline-block,.visible-xs-block,.visible-xs-inline,.visible-xs-inline-block{display:none!important}@media (max-width:767px){.visible-xs{display:block!important}table.visible-xs{display:table!important}tr.visible-xs{display:table-row!important}td.visible-xs,th.visible-xs{display:table-cell!important}}@media (max-width:767px){.visible-xs-block{display:block!important}}@media (max-width:767px){.visible-xs-inline{display:inline!important}}@media (max-width:767px){.visible-xs-inline-block{display:inline-block!important}}@media (min-width:768px) and (max-width:991px){.visible-sm{display:block!important}table.visible-sm{display:table!important}tr.visible-sm{display:table-row!important}td.visible-sm,th.visible-sm{display:table-cell!important}}@media (min-width:768px) and (max-width:991px){.visible-sm-block{display:block!important}}@media (min-width:768px) and (max-width:991px){.visible-sm-inline{display:inline!important}}@media (min-width:768px) and (max-width:991px){.visible-sm-inline-block{display:inline-block!important}}@media (min-width:992px) and (max-width:1199px){.visible-md{display:block!important}table.visible-md{display:table!important}tr.visible-md{display:table-row!important}td.visible-md,th.visible-md{display:table-cell!important}}@media (min-width:992px) and (max-width:1199px){.visible-md-block{display:block!important}}@media (min-width:992px) and (max-width:1199px){.visible-md-inline{display:inline!important}}@media (min-width:992px) and (max-width:1199px){.visible-md-inline-block{display:inline-block!important}}@media (min-width:1200px){.visible-lg{display:block!important}table.visible-lg{display:table!important}tr.visible-lg{display:table-row!important}td.visible-lg,th.visible-lg{display:table-cell!important}}@media (min-width:1200px){.visible-lg-block{display:block!important}}@media (min-width:1200px){.visible-lg-inline{display:inline!important}}@media (min-width:1200px){.visible-lg-inline-block{display:inline-block!important}}@media (max-width:767px){.hidden-xs{display:none!important}}@media (min-width:768px) and (max-width:991px){.hidden-sm{display:none!important}}@media (min-width:992px) and (max-width:1199px){.hidden-md{display:none!important}}@media (min-width:1200px){.hidden-lg{display:none!important}}.visible-print{display:none!important}@media print{.visible-print{display:block!important}table.visible-print{display:table!important}tr.visible-print{display:table-row!important}td.visible-print,th.visible-print{display:table-cell!important}}.visible-print-block{display:none!important}@media print{.visible-print-block{display:block!important}}.visible-print-inline{display:none!important}@media print{.visible-print-inline{display:inline!important}}.visible-print-inline-block{display:none!important}@media print{.visible-print-inline-block{display:inline-block!important}}@media print{.hidden-print{display:none!important}}/*! * * Font Awesome * *//*! * Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome * License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License) */@font-face{font-family:FontAwesome;src:url(../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0);src:url(../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0) format('embedded-opentype'),url(../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0) format('woff'),url(../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0) format('truetype'),url(../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular) format('svg');font-weight:400;font-style:normal}.fa{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.fa-lg{font-size:1.33333333em;line-height:.75em;vertical-align:-15%}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-fw{width:1.28571429em;text-align:center}.fa-ul{padding-left:0;margin-left:2.14285714em;list-style-type:none}.fa-ul>li{position:relative}.fa-li{position:absolute;left:-2.14285714em;width:2.14285714em;top:.14285714em;text-align:center}.fa-li.fa-lg{left:-1.85714286em}.fa-border{padding:.2em .25em .15em;border:solid .08em #eee;border-radius:.1em}.pull-right{float:right}.pull-left{float:left}.fa.pull-left{margin-right:.3em}.fa.pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(359deg);transform:rotate(359deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(359deg);transform:rotate(359deg)}}.fa-rotate-90{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=1);-webkit-transform:rotate(90deg);-ms-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=2);-webkit-transform:rotate(180deg);-ms-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=3);-webkit-transform:rotate(270deg);-ms-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);-webkit-transform:scale(-1,1);-ms-transform:scale(-1,1);transform:scale(-1,1)}.fa-flip-vertical{filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);-webkit-transform:scale(1,-1);-ms-transform:scale(1,-1);transform:scale(1,-1)}:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-rotate-90{filter:none}.fa-stack{position:relative;display:inline-block;width:2em;height:2em;line-height:2em;vertical-align:middle}.fa-stack-1x,.fa-stack-2x{position:absolute;left:0;width:100%;text-align:center}.fa-stack-1x{line-height:inherit}.fa-stack-2x{font-size:2em}.fa-inverse{color:#fff}.fa-glass:before{content:"\f000"}.fa-music:before{content:"\f001"}.fa-search:before{content:"\f002"}.fa-envelope-o:before{content:"\f003"}.fa-heart:before{content:"\f004"}.fa-star:before{content:"\f005"}.fa-star-o:before{content:"\f006"}.fa-user:before{content:"\f007"}.fa-film:before{content:"\f008"}.fa-th-large:before{content:"\f009"}.fa-th:before{content:"\f00a"}.fa-th-list:before{content:"\f00b"}.fa-check:before{content:"\f00c"}.fa-close:before,.fa-remove:before,.fa-times:before{content:"\f00d"}.fa-search-plus:before{content:"\f00e"}.fa-search-minus:before{content:"\f010"}.fa-power-off:before{content:"\f011"}.fa-signal:before{content:"\f012"}.fa-cog:before,.fa-gear:before{content:"\f013"}.fa-trash-o:before{content:"\f014"}.fa-home:before{content:"\f015"}.fa-file-o:before{content:"\f016"}.fa-clock-o:before{content:"\f017"}.fa-road:before{content:"\f018"}.fa-download:before{content:"\f019"}.fa-arrow-circle-o-down:before{content:"\f01a"}.fa-arrow-circle-o-up:before{content:"\f01b"}.fa-inbox:before{content:"\f01c"}.fa-play-circle-o:before{content:"\f01d"}.fa-repeat:before,.fa-rotate-right:before{content:"\f01e"}.fa-refresh:before{content:"\f021"}.fa-list-alt:before{content:"\f022"}.fa-lock:before{content:"\f023"}.fa-flag:before{content:"\f024"}.fa-headphones:before{content:"\f025"}.fa-volume-off:before{content:"\f026"}.fa-volume-down:before{content:"\f027"}.fa-volume-up:before{content:"\f028"}.fa-qrcode:before{content:"\f029"}.fa-barcode:before{content:"\f02a"}.fa-tag:before{content:"\f02b"}.fa-tags:before{content:"\f02c"}.fa-book:before{content:"\f02d"}.fa-bookmark:before{content:"\f02e"}.fa-print:before{content:"\f02f"}.fa-camera:before{content:"\f030"}.fa-font:before{content:"\f031"}.fa-bold:before{content:"\f032"}.fa-italic:before{content:"\f033"}.fa-text-height:before{content:"\f034"}.fa-text-width:before{content:"\f035"}.fa-align-left:before{content:"\f036"}.fa-align-center:before{content:"\f037"}.fa-align-right:before{content:"\f038"}.fa-align-justify:before{content:"\f039"}.fa-list:before{content:"\f03a"}.fa-dedent:before,.fa-outdent:before{content:"\f03b"}.fa-indent:before{content:"\f03c"}.fa-video-camera:before{content:"\f03d"}.fa-image:before,.fa-photo:before,.fa-picture-o:before{content:"\f03e"}.fa-pencil:before{content:"\f040"}.fa-map-marker:before{content:"\f041"}.fa-adjust:before{content:"\f042"}.fa-tint:before{content:"\f043"}.fa-edit:before,.fa-pencil-square-o:before{content:"\f044"}.fa-share-square-o:before{content:"\f045"}.fa-check-square-o:before{content:"\f046"}.fa-arrows:before{content:"\f047"}.fa-step-backward:before{content:"\f048"}.fa-fast-backward:before{content:"\f049"}.fa-backward:before{content:"\f04a"}.fa-play:before{content:"\f04b"}.fa-pause:before{content:"\f04c"}.fa-stop:before{content:"\f04d"}.fa-forward:before{content:"\f04e"}.fa-fast-forward:before{content:"\f050"}.fa-step-forward:before{content:"\f051"}.fa-eject:before{content:"\f052"}.fa-chevron-left:before{content:"\f053"}.fa-chevron-right:before{content:"\f054"}.fa-plus-circle:before{content:"\f055"}.fa-minus-circle:before{content:"\f056"}.fa-times-circle:before{content:"\f057"}.fa-check-circle:before{content:"\f058"}.fa-question-circle:before{content:"\f059"}.fa-info-circle:before{content:"\f05a"}.fa-crosshairs:before{content:"\f05b"}.fa-times-circle-o:before{content:"\f05c"}.fa-check-circle-o:before{content:"\f05d"}.fa-ban:before{content:"\f05e"}.fa-arrow-left:before{content:"\f060"}.fa-arrow-right:before{content:"\f061"}.fa-arrow-up:before{content:"\f062"}.fa-arrow-down:before{content:"\f063"}.fa-mail-forward:before,.fa-share:before{content:"\f064"}.fa-expand:before{content:"\f065"}.fa-compress:before{content:"\f066"}.fa-plus:before{content:"\f067"}.fa-minus:before{content:"\f068"}.fa-asterisk:before{content:"\f069"}.fa-exclamation-circle:before{content:"\f06a"}.fa-gift:before{content:"\f06b"}.fa-leaf:before{content:"\f06c"}.fa-fire:before{content:"\f06d"}.fa-eye:before{content:"\f06e"}.fa-eye-slash:before{content:"\f070"}.fa-exclamation-triangle:before,.fa-warning:before{content:"\f071"}.fa-plane:before{content:"\f072"}.fa-calendar:before{content:"\f073"}.fa-random:before{content:"\f074"}.fa-comment:before{content:"\f075"}.fa-magnet:before{content:"\f076"}.fa-chevron-up:before{content:"\f077"}.fa-chevron-down:before{content:"\f078"}.fa-retweet:before{content:"\f079"}.fa-shopping-cart:before{content:"\f07a"}.fa-folder:before{content:"\f07b"}.fa-folder-open:before{content:"\f07c"}.fa-arrows-v:before{content:"\f07d"}.fa-arrows-h:before{content:"\f07e"}.fa-bar-chart-o:before,.fa-bar-chart:before{content:"\f080"}.fa-twitter-square:before{content:"\f081"}.fa-facebook-square:before{content:"\f082"}.fa-camera-retro:before{content:"\f083"}.fa-key:before{content:"\f084"}.fa-cogs:before,.fa-gears:before{content:"\f085"}.fa-comments:before{content:"\f086"}.fa-thumbs-o-up:before{content:"\f087"}.fa-thumbs-o-down:before{content:"\f088"}.fa-star-half:before{content:"\f089"}.fa-heart-o:before{content:"\f08a"}.fa-sign-out:before{content:"\f08b"}.fa-linkedin-square:before{content:"\f08c"}.fa-thumb-tack:before{content:"\f08d"}.fa-external-link:before{content:"\f08e"}.fa-sign-in:before{content:"\f090"}.fa-trophy:before{content:"\f091"}.fa-github-square:before{content:"\f092"}.fa-upload:before{content:"\f093"}.fa-lemon-o:before{content:"\f094"}.fa-phone:before{content:"\f095"}.fa-square-o:before{content:"\f096"}.fa-bookmark-o:before{content:"\f097"}.fa-phone-square:before{content:"\f098"}.fa-twitter:before{content:"\f099"}.fa-facebook:before{content:"\f09a"}.fa-github:before{content:"\f09b"}.fa-unlock:before{content:"\f09c"}.fa-credit-card:before{content:"\f09d"}.fa-rss:before{content:"\f09e"}.fa-hdd-o:before{content:"\f0a0"}.fa-bullhorn:before{content:"\f0a1"}.fa-bell:before{content:"\f0f3"}.fa-certificate:before{content:"\f0a3"}.fa-hand-o-right:before{content:"\f0a4"}.fa-hand-o-left:before{content:"\f0a5"}.fa-hand-o-up:before{content:"\f0a6"}.fa-hand-o-down:before{content:"\f0a7"}.fa-arrow-circle-left:before{content:"\f0a8"}.fa-arrow-circle-right:before{content:"\f0a9"}.fa-arrow-circle-up:before{content:"\f0aa"}.fa-arrow-circle-down:before{content:"\f0ab"}.fa-globe:before{content:"\f0ac"}.fa-wrench:before{content:"\f0ad"}.fa-tasks:before{content:"\f0ae"}.fa-filter:before{content:"\f0b0"}.fa-briefcase:before{content:"\f0b1"}.fa-arrows-alt:before{content:"\f0b2"}.fa-group:before,.fa-users:before{content:"\f0c0"}.fa-chain:before,.fa-link:before{content:"\f0c1"}.fa-cloud:before{content:"\f0c2"}.fa-flask:before{content:"\f0c3"}.fa-cut:before,.fa-scissors:before{content:"\f0c4"}.fa-copy:before,.fa-files-o:before{content:"\f0c5"}.fa-paperclip:before{content:"\f0c6"}.fa-floppy-o:before,.fa-save:before{content:"\f0c7"}.fa-square:before{content:"\f0c8"}.fa-bars:before,.fa-navicon:before,.fa-reorder:before{content:"\f0c9"}.fa-list-ul:before{content:"\f0ca"}.fa-list-ol:before{content:"\f0cb"}.fa-strikethrough:before{content:"\f0cc"}.fa-underline:before{content:"\f0cd"}.fa-table:before{content:"\f0ce"}.fa-magic:before{content:"\f0d0"}.fa-truck:before{content:"\f0d1"}.fa-pinterest:before{content:"\f0d2"}.fa-pinterest-square:before{content:"\f0d3"}.fa-google-plus-square:before{content:"\f0d4"}.fa-google-plus:before{content:"\f0d5"}.fa-money:before{content:"\f0d6"}.fa-caret-down:before{content:"\f0d7"}.fa-caret-up:before{content:"\f0d8"}.fa-caret-left:before{content:"\f0d9"}.fa-caret-right:before{content:"\f0da"}.fa-columns:before{content:"\f0db"}.fa-sort:before,.fa-unsorted:before{content:"\f0dc"}.fa-sort-desc:before,.fa-sort-down:before{content:"\f0dd"}.fa-sort-asc:before,.fa-sort-up:before{content:"\f0de"}.fa-envelope:before{content:"\f0e0"}.fa-linkedin:before{content:"\f0e1"}.fa-rotate-left:before,.fa-undo:before{content:"\f0e2"}.fa-gavel:before,.fa-legal:before{content:"\f0e3"}.fa-dashboard:before,.fa-tachometer:before{content:"\f0e4"}.fa-comment-o:before{content:"\f0e5"}.fa-comments-o:before{content:"\f0e6"}.fa-bolt:before,.fa-flash:before{content:"\f0e7"}.fa-sitemap:before{content:"\f0e8"}.fa-umbrella:before{content:"\f0e9"}.fa-clipboard:before,.fa-paste:before{content:"\f0ea"}.fa-lightbulb-o:before{content:"\f0eb"}.fa-exchange:before{content:"\f0ec"}.fa-cloud-download:before{content:"\f0ed"}.fa-cloud-upload:before{content:"\f0ee"}.fa-user-md:before{content:"\f0f0"}.fa-stethoscope:before{content:"\f0f1"}.fa-suitcase:before{content:"\f0f2"}.fa-bell-o:before{content:"\f0a2"}.fa-coffee:before{content:"\f0f4"}.fa-cutlery:before{content:"\f0f5"}.fa-file-text-o:before{content:"\f0f6"}.fa-building-o:before{content:"\f0f7"}.fa-hospital-o:before{content:"\f0f8"}.fa-ambulance:before{content:"\f0f9"}.fa-medkit:before{content:"\f0fa"}.fa-fighter-jet:before{content:"\f0fb"}.fa-beer:before{content:"\f0fc"}.fa-h-square:before{content:"\f0fd"}.fa-plus-square:before{content:"\f0fe"}.fa-angle-double-left:before{content:"\f100"}.fa-angle-double-right:before{content:"\f101"}.fa-angle-double-up:before{content:"\f102"}.fa-angle-double-down:before{content:"\f103"}.fa-angle-left:before{content:"\f104"}.fa-angle-right:before{content:"\f105"}.fa-angle-up:before{content:"\f106"}.fa-angle-down:before{content:"\f107"}.fa-desktop:before{content:"\f108"}.fa-laptop:before{content:"\f109"}.fa-tablet:before{content:"\f10a"}.fa-mobile-phone:before,.fa-mobile:before{content:"\f10b"}.fa-circle-o:before{content:"\f10c"}.fa-quote-left:before{content:"\f10d"}.fa-quote-right:before{content:"\f10e"}.fa-spinner:before{content:"\f110"}.fa-circle:before{content:"\f111"}.fa-mail-reply:before,.fa-reply:before{content:"\f112"}.fa-github-alt:before{content:"\f113"}.fa-folder-o:before{content:"\f114"}.fa-folder-open-o:before{content:"\f115"}.fa-smile-o:before{content:"\f118"}.fa-frown-o:before{content:"\f119"}.fa-meh-o:before{content:"\f11a"}.fa-gamepad:before{content:"\f11b"}.fa-keyboard-o:before{content:"\f11c"}.fa-flag-o:before{content:"\f11d"}.fa-flag-checkered:before{content:"\f11e"}.fa-terminal:before{content:"\f120"}.fa-code:before{content:"\f121"}.fa-mail-reply-all:before,.fa-reply-all:before{content:"\f122"}.fa-star-half-empty:before,.fa-star-half-full:before,.fa-star-half-o:before{content:"\f123"}.fa-location-arrow:before{content:"\f124"}.fa-crop:before{content:"\f125"}.fa-code-fork:before{content:"\f126"}.fa-chain-broken:before,.fa-unlink:before{content:"\f127"}.fa-question:before{content:"\f128"}.fa-info:before{content:"\f129"}.fa-exclamation:before{content:"\f12a"}.fa-superscript:before{content:"\f12b"}.fa-subscript:before{content:"\f12c"}.fa-eraser:before{content:"\f12d"}.fa-puzzle-piece:before{content:"\f12e"}.fa-microphone:before{content:"\f130"}.fa-microphone-slash:before{content:"\f131"}.fa-shield:before{content:"\f132"}.fa-calendar-o:before{content:"\f133"}.fa-fire-extinguisher:before{content:"\f134"}.fa-rocket:before{content:"\f135"}.fa-maxcdn:before{content:"\f136"}.fa-chevron-circle-left:before{content:"\f137"}.fa-chevron-circle-right:before{content:"\f138"}.fa-chevron-circle-up:before{content:"\f139"}.fa-chevron-circle-down:before{content:"\f13a"}.fa-html5:before{content:"\f13b"}.fa-css3:before{content:"\f13c"}.fa-anchor:before{content:"\f13d"}.fa-unlock-alt:before{content:"\f13e"}.fa-bullseye:before{content:"\f140"}.fa-ellipsis-h:before{content:"\f141"}.fa-ellipsis-v:before{content:"\f142"}.fa-rss-square:before{content:"\f143"}.fa-play-circle:before{content:"\f144"}.fa-ticket:before{content:"\f145"}.fa-minus-square:before{content:"\f146"}.fa-minus-square-o:before{content:"\f147"}.fa-level-up:before{content:"\f148"}.fa-level-down:before{content:"\f149"}.fa-check-square:before{content:"\f14a"}.fa-pencil-square:before{content:"\f14b"}.fa-external-link-square:before{content:"\f14c"}.fa-share-square:before{content:"\f14d"}.fa-compass:before{content:"\f14e"}.fa-caret-square-o-down:before,.fa-toggle-down:before{content:"\f150"}.fa-caret-square-o-up:before,.fa-toggle-up:before{content:"\f151"}.fa-caret-square-o-right:before,.fa-toggle-right:before{content:"\f152"}.fa-eur:before,.fa-euro:before{content:"\f153"}.fa-gbp:before{content:"\f154"}.fa-dollar:before,.fa-usd:before{content:"\f155"}.fa-inr:before,.fa-rupee:before{content:"\f156"}.fa-cny:before,.fa-jpy:before,.fa-rmb:before,.fa-yen:before{content:"\f157"}.fa-rouble:before,.fa-rub:before,.fa-ruble:before{content:"\f158"}.fa-krw:before,.fa-won:before{content:"\f159"}.fa-bitcoin:before,.fa-btc:before{content:"\f15a"}.fa-file:before{content:"\f15b"}.fa-file-text:before{content:"\f15c"}.fa-sort-alpha-asc:before{content:"\f15d"}.fa-sort-alpha-desc:before{content:"\f15e"}.fa-sort-amount-asc:before{content:"\f160"}.fa-sort-amount-desc:before{content:"\f161"}.fa-sort-numeric-asc:before{content:"\f162"}.fa-sort-numeric-desc:before{content:"\f163"}.fa-thumbs-up:before{content:"\f164"}.fa-thumbs-down:before{content:"\f165"}.fa-youtube-square:before{content:"\f166"}.fa-youtube:before{content:"\f167"}.fa-xing:before{content:"\f168"}.fa-xing-square:before{content:"\f169"}.fa-youtube-play:before{content:"\f16a"}.fa-dropbox:before{content:"\f16b"}.fa-stack-overflow:before{content:"\f16c"}.fa-instagram:before{content:"\f16d"}.fa-flickr:before{content:"\f16e"}.fa-adn:before{content:"\f170"}.fa-bitbucket:before{content:"\f171"}.fa-bitbucket-square:before{content:"\f172"}.fa-tumblr:before{content:"\f173"}.fa-tumblr-square:before{content:"\f174"}.fa-long-arrow-down:before{content:"\f175"}.fa-long-arrow-up:before{content:"\f176"}.fa-long-arrow-left:before{content:"\f177"}.fa-long-arrow-right:before{content:"\f178"}.fa-apple:before{content:"\f179"}.fa-windows:before{content:"\f17a"}.fa-android:before{content:"\f17b"}.fa-linux:before{content:"\f17c"}.fa-dribbble:before{content:"\f17d"}.fa-skype:before{content:"\f17e"}.fa-foursquare:before{content:"\f180"}.fa-trello:before{content:"\f181"}.fa-female:before{content:"\f182"}.fa-male:before{content:"\f183"}.fa-gittip:before{content:"\f184"}.fa-sun-o:before{content:"\f185"}.fa-moon-o:before{content:"\f186"}.fa-archive:before{content:"\f187"}.fa-bug:before{content:"\f188"}.fa-vk:before{content:"\f189"}.fa-weibo:before{content:"\f18a"}.fa-renren:before{content:"\f18b"}.fa-pagelines:before{content:"\f18c"}.fa-stack-exchange:before{content:"\f18d"}.fa-arrow-circle-o-right:before{content:"\f18e"}.fa-arrow-circle-o-left:before{content:"\f190"}.fa-caret-square-o-left:before,.fa-toggle-left:before{content:"\f191"}.fa-dot-circle-o:before{content:"\f192"}.fa-wheelchair:before{content:"\f193"}.fa-vimeo-square:before{content:"\f194"}.fa-try:before,.fa-turkish-lira:before{content:"\f195"}.fa-plus-square-o:before{content:"\f196"}.fa-space-shuttle:before{content:"\f197"}.fa-slack:before{content:"\f198"}.fa-envelope-square:before{content:"\f199"}.fa-wordpress:before{content:"\f19a"}.fa-openid:before{content:"\f19b"}.fa-bank:before,.fa-institution:before,.fa-university:before{content:"\f19c"}.fa-graduation-cap:before,.fa-mortar-board:before{content:"\f19d"}.fa-yahoo:before{content:"\f19e"}.fa-google:before{content:"\f1a0"}.fa-reddit:before{content:"\f1a1"}.fa-reddit-square:before{content:"\f1a2"}.fa-stumbleupon-circle:before{content:"\f1a3"}.fa-stumbleupon:before{content:"\f1a4"}.fa-delicious:before{content:"\f1a5"}.fa-digg:before{content:"\f1a6"}.fa-pied-piper:before{content:"\f1a7"}.fa-pied-piper-alt:before{content:"\f1a8"}.fa-drupal:before{content:"\f1a9"}.fa-joomla:before{content:"\f1aa"}.fa-language:before{content:"\f1ab"}.fa-fax:before{content:"\f1ac"}.fa-building:before{content:"\f1ad"}.fa-child:before{content:"\f1ae"}.fa-paw:before{content:"\f1b0"}.fa-spoon:before{content:"\f1b1"}.fa-cube:before{content:"\f1b2"}.fa-cubes:before{content:"\f1b3"}.fa-behance:before{content:"\f1b4"}.fa-behance-square:before{content:"\f1b5"}.fa-steam:before{content:"\f1b6"}.fa-steam-square:before{content:"\f1b7"}.fa-recycle:before{content:"\f1b8"}.fa-automobile:before,.fa-car:before{content:"\f1b9"}.fa-cab:before,.fa-taxi:before{content:"\f1ba"}.fa-tree:before{content:"\f1bb"}.fa-spotify:before{content:"\f1bc"}.fa-deviantart:before{content:"\f1bd"}.fa-soundcloud:before{content:"\f1be"}.fa-database:before{content:"\f1c0"}.fa-file-pdf-o:before{content:"\f1c1"}.fa-file-word-o:before{content:"\f1c2"}.fa-file-excel-o:before{content:"\f1c3"}.fa-file-powerpoint-o:before{content:"\f1c4"}.fa-file-image-o:before,.fa-file-photo-o:before,.fa-file-picture-o:before{content:"\f1c5"}.fa-file-archive-o:before,.fa-file-zip-o:before{content:"\f1c6"}.fa-file-audio-o:before,.fa-file-sound-o:before{content:"\f1c7"}.fa-file-movie-o:before,.fa-file-video-o:before{content:"\f1c8"}.fa-file-code-o:before{content:"\f1c9"}.fa-vine:before{content:"\f1ca"}.fa-codepen:before{content:"\f1cb"}.fa-jsfiddle:before{content:"\f1cc"}.fa-life-bouy:before,.fa-life-buoy:before,.fa-life-ring:before,.fa-life-saver:before,.fa-support:before{content:"\f1cd"}.fa-circle-o-notch:before{content:"\f1ce"}.fa-ra:before,.fa-rebel:before{content:"\f1d0"}.fa-empire:before,.fa-ge:before{content:"\f1d1"}.fa-git-square:before{content:"\f1d2"}.fa-git:before{content:"\f1d3"}.fa-hacker-news:before{content:"\f1d4"}.fa-tencent-weibo:before{content:"\f1d5"}.fa-qq:before{content:"\f1d6"}.fa-wechat:before,.fa-weixin:before{content:"\f1d7"}.fa-paper-plane:before,.fa-send:before{content:"\f1d8"}.fa-paper-plane-o:before,.fa-send-o:before{content:"\f1d9"}.fa-history:before{content:"\f1da"}.fa-circle-thin:before{content:"\f1db"}.fa-header:before{content:"\f1dc"}.fa-paragraph:before{content:"\f1dd"}.fa-sliders:before{content:"\f1de"}.fa-share-alt:before{content:"\f1e0"}.fa-share-alt-square:before{content:"\f1e1"}.fa-bomb:before{content:"\f1e2"}.fa-futbol-o:before,.fa-soccer-ball-o:before{content:"\f1e3"}.fa-tty:before{content:"\f1e4"}.fa-binoculars:before{content:"\f1e5"}.fa-plug:before{content:"\f1e6"}.fa-slideshare:before{content:"\f1e7"}.fa-twitch:before{content:"\f1e8"}.fa-yelp:before{content:"\f1e9"}.fa-newspaper-o:before{content:"\f1ea"}.fa-wifi:before{content:"\f1eb"}.fa-calculator:before{content:"\f1ec"}.fa-paypal:before{content:"\f1ed"}.fa-google-wallet:before{content:"\f1ee"}.fa-cc-visa:before{content:"\f1f0"}.fa-cc-mastercard:before{content:"\f1f1"}.fa-cc-discover:before{content:"\f1f2"}.fa-cc-amex:before{content:"\f1f3"}.fa-cc-paypal:before{content:"\f1f4"}.fa-cc-stripe:before{content:"\f1f5"}.fa-bell-slash:before{content:"\f1f6"}.fa-bell-slash-o:before{content:"\f1f7"}.fa-trash:before{content:"\f1f8"}.fa-copyright:before{content:"\f1f9"}.fa-at:before{content:"\f1fa"}.fa-eyedropper:before{content:"\f1fb"}.fa-paint-brush:before{content:"\f1fc"}.fa-birthday-cake:before{content:"\f1fd"}.fa-area-chart:before{content:"\f1fe"}.fa-pie-chart:before{content:"\f200"}.fa-line-chart:before{content:"\f201"}.fa-lastfm:before{content:"\f202"}.fa-lastfm-square:before{content:"\f203"}.fa-toggle-off:before{content:"\f204"}.fa-toggle-on:before{content:"\f205"}.fa-bicycle:before{content:"\f206"}.fa-bus:before{content:"\f207"}.fa-ioxhost:before{content:"\f208"}.fa-angellist:before{content:"\f209"}.fa-cc:before{content:"\f20a"}.fa-ils:before,.fa-shekel:before,.fa-sheqel:before{content:"\f20b"}.fa-meanpath:before{content:"\f20c"}/*! * * IPython base * */.modal.fade .modal-dialog{-webkit-transform:translate(0,0);-ms-transform:translate(0,0);-o-transform:translate(0,0);transform:translate(0,0)}code{color:#000}pre{font-size:inherit;line-height:inherit}label{font-weight:400}.border-box-sizing{box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box}.corner-all{border-radius:2px}.no-padding{padding:0}.hbox{display:-webkit-box;-webkit-box-orient:horizontal;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:horizontal;-moz-box-align:stretch;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}.hbox>*{-webkit-box-flex:0;-moz-box-flex:0;box-flex:0;flex:none}.vbox{display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}.vbox>*{-webkit-box-flex:0;-moz-box-flex:0;box-flex:0;flex:none}.hbox.reverse,.reverse,.vbox.reverse{-webkit-box-direction:reverse;-moz-box-direction:reverse;box-direction:reverse;flex-direction:row-reverse}.box-flex0,.hbox.box-flex0,.vbox.box-flex0{-webkit-box-flex:0;-moz-box-flex:0;box-flex:0;flex:none;width:auto}.box-flex1,.hbox.box-flex1,.vbox.box-flex1{-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1}.box-flex,.hbox.box-flex,.vbox.box-flex{-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1}.box-flex2,.hbox.box-flex2,.vbox.box-flex2{-webkit-box-flex:2;-moz-box-flex:2;box-flex:2;flex:2}.box-group1{-webkit-box-flex-group:1;-moz-box-flex-group:1;box-flex-group:1}.box-group2{-webkit-box-flex-group:2;-moz-box-flex-group:2;box-flex-group:2}.hbox.start,.start,.vbox.start{-webkit-box-pack:start;-moz-box-pack:start;box-pack:start;justify-content:flex-start}.end,.hbox.end,.vbox.end{-webkit-box-pack:end;-moz-box-pack:end;box-pack:end;justify-content:flex-end}.center,.hbox.center,.vbox.center{-webkit-box-pack:center;-moz-box-pack:center;box-pack:center;justify-content:center}.baseline,.hbox.baseline,.vbox.baseline{-webkit-box-pack:baseline;-moz-box-pack:baseline;box-pack:baseline;justify-content:baseline}.hbox.stretch,.stretch,.vbox.stretch{-webkit-box-pack:stretch;-moz-box-pack:stretch;box-pack:stretch;justify-content:stretch}.align-start,.hbox.align-start,.vbox.align-start{-webkit-box-align:start;-moz-box-align:start;box-align:start;align-items:flex-start}.align-end,.hbox.align-end,.vbox.align-end{-webkit-box-align:end;-moz-box-align:end;box-align:end;align-items:flex-end}.align-center,.hbox.align-center,.vbox.align-center{-webkit-box-align:center;-moz-box-align:center;box-align:center;align-items:center}.align-baseline,.hbox.align-baseline,.vbox.align-baseline{-webkit-box-align:baseline;-moz-box-align:baseline;box-align:baseline;align-items:baseline}.align-stretch,.hbox.align-stretch,.vbox.align-stretch{-webkit-box-align:stretch;-moz-box-align:stretch;box-align:stretch;align-items:stretch}div.error{margin:2em;text-align:center}div.error>h1{font-size:500%;line-height:normal}div.error>p{font-size:200%;line-height:normal}div.traceback-wrapper{text-align:left;max-width:800px;margin:auto}body{background-color:#fff;position:absolute;left:0;right:0;top:0;bottom:0;overflow:visible}body>#header{display:none;background-color:#fff;position:relative;z-index:100}body>#header #header-container{padding-bottom:5px;padding-top:5px;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box}body>#header .header-bar{width:100%;height:1px;background:#e7e7e7;margin-bottom:-1px}@media print{body>#header{display:none!important}}#header-spacer{width:100%;visibility:hidden}@media print{#header-spacer{display:none}}#ipython_notebook{padding-left:0;padding-top:1px;padding-bottom:1px}@media (max-width:991px){#ipython_notebook{margin-left:10px}}#noscript{width:auto;padding-top:16px;padding-bottom:16px;text-align:center;font-size:22px;color:red;font-weight:700}#ipython_notebook img{height:28px}#site{width:100%;display:none;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;overflow:auto}@media print{#site{height:auto!important}}.ui-button .ui-button-text{padding:.2em .8em;font-size:77%}input.ui-button{padding:.3em .9em}span#login_widget{float:right}#logout,span#login_widget>.button{color:#333;background-color:#fff;border-color:#ccc}#logout.focus,#logout:focus,span#login_widget>.button.focus,span#login_widget>.button:focus{color:#333;background-color:#e6e6e6;border-color:#8c8c8c}#logout:hover,span#login_widget>.button:hover{color:#333;background-color:#e6e6e6;border-color:#adadad}#logout.active,#logout:active,.open>.dropdown-toggle#logout,.open>.dropdown-togglespan#login_widget>.button,span#login_widget>.button.active,span#login_widget>.button:active{color:#333;background-color:#e6e6e6;border-color:#adadad}#logout.active.focus,#logout.active:focus,#logout.active:hover,#logout:active.focus,#logout:active:focus,#logout:active:hover,.open>.dropdown-toggle#logout.focus,.open>.dropdown-toggle#logout:focus,.open>.dropdown-toggle#logout:hover,.open>.dropdown-togglespan#login_widget>.button.focus,.open>.dropdown-togglespan#login_widget>.button:focus,.open>.dropdown-togglespan#login_widget>.button:hover,span#login_widget>.button.active.focus,span#login_widget>.button.active:focus,span#login_widget>.button.active:hover,span#login_widget>.button:active.focus,span#login_widget>.button:active:focus,span#login_widget>.button:active:hover{color:#333;background-color:#d4d4d4;border-color:#8c8c8c}#logout.active,#logout:active,.open>.dropdown-toggle#logout,.open>.dropdown-togglespan#login_widget>.button,span#login_widget>.button.active,span#login_widget>.button:active{background-image:none}#logout.disabled.focus,#logout.disabled:focus,#logout.disabled:hover,#logout[disabled].focus,#logout[disabled]:focus,#logout[disabled]:hover,fieldset[disabled] #logout.focus,fieldset[disabled] #logout:focus,fieldset[disabled] #logout:hover,fieldset[disabled] span#login_widget>.button.focus,fieldset[disabled] span#login_widget>.button:focus,fieldset[disabled] span#login_widget>.button:hover,span#login_widget>.button.disabled.focus,span#login_widget>.button.disabled:focus,span#login_widget>.button.disabled:hover,span#login_widget>.button[disabled].focus,span#login_widget>.button[disabled]:focus,span#login_widget>.button[disabled]:hover{background-color:#fff;border-color:#ccc}#logout .badge,span#login_widget>.button .badge{color:#fff;background-color:#333}.nav-header{text-transform:none}#header>span{margin-top:10px}.modal_stretch .modal-dialog{display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;min-height:80vh}.modal_stretch .modal-dialog .modal-body{max-height:calc(100vh - 200px);overflow:auto;flex:1}@media (min-width:768px){.modal .modal-dialog{width:700px}}@media (min-width:768px){select.form-control{margin-left:12px;margin-right:12px}}/*! * * IPython auth * */.center-nav{display:inline-block;margin-bottom:-4px}/*! * * IPython tree view * */.alternate_upload{background-color:none;display:inline}.alternate_upload.form{padding:0;margin:0}.alternate_upload input.fileinput{text-align:center;vertical-align:middle;display:inline;opacity:0;z-index:2;width:12ex;margin-right:-12ex}.alternate_upload .btn-upload{height:22px}ul#tabs{margin-bottom:4px}ul#tabs a{padding-top:6px;padding-bottom:4px}ul.breadcrumb a:focus,ul.breadcrumb a:hover{text-decoration:none}ul.breadcrumb i.icon-home{font-size:16px;margin-right:4px}ul.breadcrumb span{color:#5e5e5e}.list_toolbar{padding:4px 0 4px 0;vertical-align:middle}.list_toolbar .tree-buttons{padding-top:1px}.dynamic-buttons{padding-top:3px;display:inline-block}.list_toolbar [class*=span]{min-height:24px}.list_header{font-weight:700;background-color:#EEE}.list_placeholder{font-weight:700;padding-top:4px;padding-bottom:4px;padding-left:7px;padding-right:7px}.list_container{margin-top:4px;margin-bottom:20px;border:1px solid #ddd;border-radius:2px}.list_container>div{border-bottom:1px solid #ddd}.list_container>div:hover .list-item{background-color:red}.list_container>div:last-child{border:none}.list_item:hover .list_item{background-color:#ddd}.list_item a{text-decoration:none}.list_item:hover{background-color:#fafafa}.list_header>div,.list_item>div{padding-top:4px;padding-bottom:4px;padding-left:7px;padding-right:7px;line-height:22px}.list_header>div input,.list_item>div input{margin-right:7px;margin-left:14px;vertical-align:baseline;line-height:22px;position:relative;top:-1px}.list_header>div .item_link,.list_item>div .item_link{margin-left:-1px;vertical-align:baseline;line-height:22px}.new-file input[type=checkbox]{visibility:hidden}.item_name{line-height:22px;height:24px}.item_icon{font-size:14px;color:#5e5e5e;margin-right:7px;margin-left:7px;line-height:22px;vertical-align:baseline}.item_buttons{line-height:1em;margin-left:-5px}.item_buttons .btn,.item_buttons .btn-group,.item_buttons .input-group{float:left}.item_buttons>.btn,.item_buttons>.btn-group,.item_buttons>.input-group{margin-left:5px}.item_buttons .btn{min-width:13ex}.item_buttons .running-indicator{padding-top:4px;color:#5cb85c}.item_buttons .kernel-name{padding-top:4px;color:#5bc0de;margin-right:7px;float:left}.toolbar_info{height:24px;line-height:24px}.list_item input:not([type=checkbox]){padding-top:3px;padding-bottom:3px;height:22px;line-height:14px;margin:0}.highlight_text{color:#00f}#project_name{display:inline-block;padding-left:7px;margin-left:-2px}#project_name>.breadcrumb{padding:0;margin-bottom:0;background-color:transparent;font-weight:700}#tree-selector{padding-right:0}#button-select-all{min-width:50px}#select-all{margin-left:7px;margin-right:2px}.menu_icon{margin-right:2px}.tab-content .row{margin-left:0;margin-right:0}.folder_icon:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f114"}.folder_icon:before.pull-left{margin-right:.3em}.folder_icon:before.pull-right{margin-left:.3em}.notebook_icon:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f02d";position:relative;top:-1px}.notebook_icon:before.pull-left{margin-right:.3em}.notebook_icon:before.pull-right{margin-left:.3em}.running_notebook_icon:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f02d";position:relative;top:-1px;color:#5cb85c}.running_notebook_icon:before.pull-left{margin-right:.3em}.running_notebook_icon:before.pull-right{margin-left:.3em}.file_icon:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f016";position:relative;top:-2px}.file_icon:before.pull-left{margin-right:.3em}.file_icon:before.pull-right{margin-left:.3em}#notebook_toolbar .pull-right{padding-top:0;margin-right:-1px}ul#new-menu{left:auto;right:0}.kernel-menu-icon{padding-right:12px;width:24px;content:"\f096"}.kernel-menu-icon:before{content:"\f096"}.kernel-menu-icon-current:before{content:"\f00c"}#tab_content{padding-top:20px}#running .panel-group .panel{margin-top:3px;margin-bottom:1em}#running .panel-group .panel .panel-heading{background-color:#EEE;padding-top:4px;padding-bottom:4px;padding-left:7px;padding-right:7px;line-height:22px}#running .panel-group .panel .panel-heading a:focus,#running .panel-group .panel .panel-heading a:hover{text-decoration:none}#running .panel-group .panel .panel-body{padding:0}#running .panel-group .panel .panel-body .list_container{margin-top:0;margin-bottom:0;border:0;border-radius:0}#running .panel-group .panel .panel-body .list_container .list_item{border-bottom:1px solid #ddd}#running .panel-group .panel .panel-body .list_container .list_item:last-child{border-bottom:0}.delete-button{display:none}.duplicate-button{display:none}.rename-button{display:none}.shutdown-button{display:none}.dynamic-instructions{display:inline-block;padding-top:4px}/*! * * IPython text editor webapp * */.selected-keymap i.fa{padding:0 5px}.selected-keymap i.fa:before{content:"\f00c"}#mode-menu{overflow:auto;max-height:20em}.edit_app #header{-webkit-box-shadow:0 0 12px 1px rgba(87,87,87,.2);box-shadow:0 0 12px 1px rgba(87,87,87,.2)}.edit_app #menubar .navbar{margin-bottom:-1px}.dirty-indicator{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;width:20px}.dirty-indicator.pull-left{margin-right:.3em}.dirty-indicator.pull-right{margin-left:.3em}.dirty-indicator-dirty{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;width:20px}.dirty-indicator-dirty.pull-left{margin-right:.3em}.dirty-indicator-dirty.pull-right{margin-left:.3em}.dirty-indicator-clean{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;width:20px}.dirty-indicator-clean.pull-left{margin-right:.3em}.dirty-indicator-clean.pull-right{margin-left:.3em}.dirty-indicator-clean:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f00c"}.dirty-indicator-clean:before.pull-left{margin-right:.3em}.dirty-indicator-clean:before.pull-right{margin-left:.3em}#filename{font-size:16pt;display:table;padding:0 5px}#current-mode{padding-left:5px;padding-right:5px}#texteditor-backdrop{padding-top:20px;padding-bottom:20px}@media not print{#texteditor-backdrop{background-color:#EEE}}@media print{#texteditor-backdrop #texteditor-container .CodeMirror-gutter,#texteditor-backdrop #texteditor-container .CodeMirror-gutters{background-color:#fff}}@media not print{#texteditor-backdrop #texteditor-container .CodeMirror-gutter,#texteditor-backdrop #texteditor-container .CodeMirror-gutters{background-color:#fff}}@media not print{#texteditor-backdrop #texteditor-container{padding:0;background-color:#fff;-webkit-box-shadow:0 0 12px 1px rgba(87,87,87,.2);box-shadow:0 0 12px 1px rgba(87,87,87,.2)}}/*! * * IPython notebook * */.ansibold{font-weight:700}.ansiblack{color:#000}.ansired{color:#8b0000}.ansigreen{color:#006400}.ansiyellow{color:#c4a000}.ansiblue{color:#00008b}.ansipurple{color:#9400d3}.ansicyan{color:#4682b4}.ansigray{color:gray}.ansibgblack{background-color:#000}.ansibgred{background-color:red}.ansibggreen{background-color:green}.ansibgyellow{background-color:#ff0}.ansibgblue{background-color:#00f}.ansibgpurple{background-color:#ff00ff}.ansibgcyan{background-color:#0ff}.ansibggray{background-color:gray}div.cell{display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;border-radius:2px;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;border-width:1px;border-style:solid;border-color:transparent;width:100%;padding:5px;margin:0;outline:0;border-left-width:1px;padding-left:5px;background:linear-gradient(to right,transparent -40px,transparent 1px,transparent 1px,transparent 100%)}div.cell.jupyter-soft-selected{border-left-color:#90CAF9;border-left-color:#E3F2FD;border-left-width:1px;padding-left:5px;border-right-color:#E3F2FD;border-right-width:1px;background:#E3F2FD}@media print{div.cell.jupyter-soft-selected{border-color:transparent}}div.cell.selected{border-color:#ababab;border-left-width:0;padding-left:6px;background:linear-gradient(to right,#42A5F5 -40px,#42A5F5 5px,transparent 5px,transparent 100%)}@media print{div.cell.selected{border-color:transparent}}div.cell.selected.jupyter-soft-selected{border-left-width:0;padding-left:6px;background:linear-gradient(to right,#42A5F5 -40px,#42A5F5 7px,#E3F2FD 7px,#E3F2FD 100%)}.edit_mode div.cell.selected{border-color:#66BB6A;border-left-width:0;padding-left:6px;background:linear-gradient(to right,#66BB6A -40px,#66BB6A 5px,transparent 5px,transparent 100%)}@media print{.edit_mode div.cell.selected{border-color:transparent}}.prompt{min-width:14ex;padding:.4em;margin:0;font-family:monospace;text-align:right;line-height:1.21429em;-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default}@media (max-width:540px){.prompt{text-align:left}}div.inner_cell{display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1}@-moz-document url-prefix(){div.inner_cell{overflow-x:hidden}}div.input_area{border:1px solid #cfcfcf;border-radius:2px;background:#f7f7f7;line-height:1.21429em}div.prompt:empty{padding-top:0;padding-bottom:0}div.unrecognized_cell{padding:5px 5px 5px 0;display:-webkit-box;-webkit-box-orient:horizontal;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:horizontal;-moz-box-align:stretch;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}div.unrecognized_cell .inner_cell{border-radius:2px;padding:5px;font-weight:700;color:red;border:1px solid #cfcfcf;background:#eaeaea}div.unrecognized_cell .inner_cell a{color:inherit;text-decoration:none}div.unrecognized_cell .inner_cell a:hover{color:inherit;text-decoration:none}@media (max-width:540px){div.unrecognized_cell>div.prompt{display:none}}@media print{div.code_cell{page-break-inside:avoid}}div.input{page-break-inside:avoid;display:-webkit-box;-webkit-box-orient:horizontal;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:horizontal;-moz-box-align:stretch;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}@media (max-width:540px){div.input{display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}}div.input_prompt{color:#303F9F;border-top:1px solid transparent}div.input_area>div.highlight{margin:.4em;border:none;padding:0;background-color:transparent}div.input_area>div.highlight>pre{margin:0;border:none;padding:0;background-color:transparent}.CodeMirror{line-height:1.21429em;font-size:14px;height:auto;background:0 0}.CodeMirror-scroll{overflow-y:hidden;overflow-x:auto}.CodeMirror-lines{padding:.4em}.CodeMirror-linenumber{padding:0 8px 0 4px}.CodeMirror-gutters{border-bottom-left-radius:2px;border-top-left-radius:2px}.CodeMirror pre{padding:0;border:0;border-radius:0}.highlight-base{color:#000}.highlight-variable{color:#000}.highlight-variable-2{color:#1a1a1a}.highlight-variable-3{color:#333}.highlight-string{color:#BA2121}.highlight-comment{color:#408080;font-style:italic}.highlight-number{color:#080}.highlight-atom{color:#88F}.highlight-keyword{color:green;font-weight:700}.highlight-builtin{color:green}.highlight-error{color:red}.highlight-operator{color:#A2F;font-weight:700}.highlight-meta{color:#A2F}.highlight-def{color:#00f}.highlight-string-2{color:#f50}.highlight-qualifier{color:#555}.highlight-bracket{color:#997}.highlight-tag{color:#170}.highlight-attribute{color:#00c}.highlight-header{color:#00f}.highlight-quote{color:#090}.highlight-link{color:#00c}.cm-s-ipython span.cm-keyword{color:green;font-weight:700}.cm-s-ipython span.cm-atom{color:#88F}.cm-s-ipython span.cm-number{color:#080}.cm-s-ipython span.cm-def{color:#00f}.cm-s-ipython span.cm-variable{color:#000}.cm-s-ipython span.cm-operator{color:#A2F;font-weight:700}.cm-s-ipython span.cm-variable-2{color:#1a1a1a}.cm-s-ipython span.cm-variable-3{color:#333}.cm-s-ipython span.cm-comment{color:#408080;font-style:italic}.cm-s-ipython span.cm-string{color:#BA2121}.cm-s-ipython span.cm-string-2{color:#f50}.cm-s-ipython span.cm-meta{color:#A2F}.cm-s-ipython span.cm-qualifier{color:#555}.cm-s-ipython span.cm-builtin{color:green}.cm-s-ipython span.cm-bracket{color:#997}.cm-s-ipython span.cm-tag{color:#170}.cm-s-ipython span.cm-attribute{color:#00c}.cm-s-ipython span.cm-header{color:#00f}.cm-s-ipython span.cm-quote{color:#090}.cm-s-ipython span.cm-link{color:#00c}.cm-s-ipython span.cm-error{color:red}.cm-s-ipython span.cm-tab{background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);background-position:right;background-repeat:no-repeat}div.output_wrapper{position:relative;display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch;z-index:1}div.output_scroll{height:24em;width:100%;overflow:auto;border-radius:2px;-webkit-box-shadow:inset 0 2px 8px rgba(0,0,0,.8);box-shadow:inset 0 2px 8px rgba(0,0,0,.8);display:block}div.output_collapsed{margin:0;padding:0;display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}div.out_prompt_overlay{height:100%;padding:0 .4em;position:absolute;border-radius:2px}div.out_prompt_overlay:hover{-webkit-box-shadow:inset 0 0 1px #000;box-shadow:inset 0 0 1px #000;background:rgba(240,240,240,.5)}div.output_prompt{color:#D84315}div.output_area{padding:0;page-break-inside:avoid;display:-webkit-box;-webkit-box-orient:horizontal;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:horizontal;-moz-box-align:stretch;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}div.output_area .MathJax_Display{text-align:left!important}div.output_area .rendered_html table{margin-left:0;margin-right:0}div.output_area .rendered_html img{margin-left:0;margin-right:0}div.output_area img,div.output_area svg{max-width:100%;height:auto}div.output_area img.unconfined,div.output_area svg.unconfined{max-width:none}.output{display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}@media (max-width:540px){div.output_area{display:-webkit-box;-webkit-box-orient:vertical;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:vertical;-moz-box-align:stretch;display:box;box-orient:vertical;box-align:stretch;display:flex;flex-direction:column;align-items:stretch}}div.output_area pre{margin:0;padding:0;border:0;vertical-align:baseline;color:#000;background-color:transparent;border-radius:0}div.output_subarea{overflow-x:auto;padding:.4em;-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1;max-width:calc(100% - 14ex)}div.output_scroll div.output_subarea{overflow-x:visible}div.output_text{text-align:left;color:#000;line-height:1.21429em}div.output_stderr{background:#fdd}div.output_latex{text-align:left}div.output_javascript:empty{padding:0}.js-error{color:#8b0000}div.raw_input_container{line-height:1.21429em;padding-top:5px}input.raw_input{font-family:monospace;font-size:inherit;color:inherit;width:auto;vertical-align:baseline;padding:0 .25em;margin:0 .25em}input.raw_input:focus{box-shadow:none}p.p-space{margin-bottom:10px}div.output_unrecognized{padding:5px;font-weight:700;color:red}div.output_unrecognized a{color:inherit;text-decoration:none}div.output_unrecognized a:hover{color:inherit;text-decoration:none}.rendered_html{color:#000}.rendered_html em{font-style:italic}.rendered_html strong{font-weight:700}.rendered_html u{text-decoration:underline}.rendered_html :link{text-decoration:underline}.rendered_html :visited{text-decoration:underline}.rendered_html h1{font-size:185.7%;margin:1.08em 0 0 0;font-weight:700;line-height:1}.rendered_html h2{font-size:157.1%;margin:1.27em 0 0 0;font-weight:700;line-height:1}.rendered_html h3{font-size:128.6%;margin:1.55em 0 0 0;font-weight:700;line-height:1}.rendered_html h4{font-size:100%;margin:2em 0 0 0;font-weight:700;line-height:1}.rendered_html h5{font-size:100%;margin:2em 0 0 0;font-weight:700;line-height:1;font-style:italic}.rendered_html h6{font-size:100%;margin:2em 0 0 0;font-weight:700;line-height:1;font-style:italic}.rendered_html h1:first-child{margin-top:.538em}.rendered_html h2:first-child{margin-top:.636em}.rendered_html h3:first-child{margin-top:.777em}.rendered_html h4:first-child{margin-top:1em}.rendered_html h5:first-child{margin-top:1em}.rendered_html h6:first-child{margin-top:1em}.rendered_html ul{list-style:disc;margin:0 2em;padding-left:0}.rendered_html ul ul{list-style:square;margin:0 2em}.rendered_html ul ul ul{list-style:circle;margin:0 2em}.rendered_html ol{list-style:decimal;margin:0 2em;padding-left:0}.rendered_html ol ol{list-style:upper-alpha;margin:0 2em}.rendered_html ol ol ol{list-style:lower-alpha;margin:0 2em}.rendered_html ol ol ol ol{list-style:lower-roman;margin:0 2em}.rendered_html ol ol ol ol ol{list-style:decimal;margin:0 2em}.rendered_html *+ul{margin-top:1em}.rendered_html *+ol{margin-top:1em}.rendered_html hr{color:#000;background-color:#000}.rendered_html pre{margin:1em 2em}.rendered_html code,.rendered_html pre{border:0;background-color:#fff;color:#000;font-size:100%;padding:0}.rendered_html blockquote{margin:1em 2em}.rendered_html table{margin-left:auto;margin-right:auto;border:1px solid #000;border-collapse:collapse}.rendered_html td,.rendered_html th,.rendered_html tr{border:1px solid #000;border-collapse:collapse;margin:1em 2em}.rendered_html td,.rendered_html th{text-align:left;vertical-align:middle;padding:4px}.rendered_html th{font-weight:700}.rendered_html *+table{margin-top:1em}.rendered_html p{text-align:left}.rendered_html *+p{margin-top:1em}.rendered_html img{display:block;margin-left:auto;margin-right:auto}.rendered_html *+img{margin-top:1em}.rendered_html img,.rendered_html svg{max-width:100%;height:auto}.rendered_html img.unconfined,.rendered_html svg.unconfined{max-width:none}div.text_cell{display:-webkit-box;-webkit-box-orient:horizontal;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:horizontal;-moz-box-align:stretch;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch}@media (max-width:540px){div.text_cell>div.prompt{display:none}}div.text_cell_render{outline:0;resize:none;width:inherit;border-style:none;padding:.5em .5em .5em .4em;color:#000;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box}a.anchor-link:link{text-decoration:none;padding:0 20px;visibility:hidden}h1:hover .anchor-link,h2:hover .anchor-link,h3:hover .anchor-link,h4:hover .anchor-link,h5:hover .anchor-link,h6:hover .anchor-link{visibility:visible}.text_cell.rendered .input_area{display:none}.text_cell.rendered .rendered_html{overflow-x:auto;overflow-y:hidden}.text_cell.unrendered .text_cell_render{display:none}.cm-header-1,.cm-header-2,.cm-header-3,.cm-header-4,.cm-header-5,.cm-header-6{font-weight:700;font-family:"Helvetica Neue",Helvetica,Arial,sans-serif}.cm-header-1{font-size:185.7%}.cm-header-2{font-size:157.1%}.cm-header-3{font-size:128.6%}.cm-header-4{font-size:110%}.cm-header-5{font-size:100%;font-style:italic}.cm-header-6{font-size:100%;font-style:italic}/*! * * IPython notebook webapp * */@media (max-width:767px){.notebook_app{padding-left:0;padding-right:0}}#ipython-main-app{box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;height:100%}div#notebook_panel{margin:0;padding:0;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;height:100%}div#notebook{font-size:14px;line-height:20px;overflow-y:hidden;overflow-x:auto;width:100%;padding-top:20px;margin:0;outline:0;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;min-height:100%}@media not print{#notebook-container{padding:15px;background-color:#fff;min-height:0;-webkit-box-shadow:0 0 12px 1px rgba(87,87,87,.2);box-shadow:0 0 12px 1px rgba(87,87,87,.2)}}@media print{#notebook-container{width:100%}}div.ui-widget-content{border:1px solid #ababab;outline:0}pre.dialog{background-color:#f7f7f7;border:1px solid #ddd;border-radius:2px;padding:.4em;padding-left:2em}p.dialog{padding:.2em}code,kbd,pre,samp{white-space:pre-wrap}#fonttest{font-family:monospace}p{margin-bottom:0}.end_space{min-height:100px;transition:height .2s ease}.notebook_app>#header{-webkit-box-shadow:0 0 12px 1px rgba(87,87,87,.2);box-shadow:0 0 12px 1px rgba(87,87,87,.2)}@media not print{.notebook_app{background-color:#EEE}}kbd{border-style:solid;border-width:1px;box-shadow:none;margin:2px;padding-left:2px;padding-right:2px;padding-top:1px;padding-bottom:1px}.celltoolbar{border:thin solid #CFCFCF;border-bottom:none;background:#EEE;border-radius:2px 2px 0 0;width:100%;height:29px;padding-right:4px;display:-webkit-box;-webkit-box-orient:horizontal;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:horizontal;-moz-box-align:stretch;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch;-webkit-box-pack:end;-moz-box-pack:end;box-pack:end;justify-content:flex-end;display:-webkit-flex}@media print{.celltoolbar{display:none}}.ctb_hideshow{display:none;vertical-align:bottom}.ctb_global_show .ctb_show.ctb_hideshow{display:block}.ctb_global_show .ctb_show+.input_area,.ctb_global_show .ctb_show+div.text_cell_input,.ctb_global_show .ctb_show~div.text_cell_render{border-top-right-radius:0;border-top-left-radius:0}.ctb_global_show .ctb_show~div.text_cell_render{border:1px solid #cfcfcf}.celltoolbar{font-size:87%;padding-top:3px}.celltoolbar select{display:block;width:100%;height:32px;padding:6px 12px;font-size:13px;line-height:1.42857143;color:#555;background-color:#fff;background-image:none;border:1px solid #ccc;border-radius:2px;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075);-webkit-transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s;-o-transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s;transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s;height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:1px;width:inherit;font-size:inherit;height:22px;padding:0;display:inline-block}.celltoolbar select:focus{border-color:#66afe9;outline:0;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 8px rgba(102,175,233,.6);box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 8px rgba(102,175,233,.6)}.celltoolbar select::-moz-placeholder{color:#999;opacity:1}.celltoolbar select:-ms-input-placeholder{color:#999}.celltoolbar select::-webkit-input-placeholder{color:#999}.celltoolbar select::-ms-expand{border:0;background-color:transparent}.celltoolbar select[disabled],.celltoolbar select[readonly],fieldset[disabled] .celltoolbar select{background-color:#eee;opacity:1}.celltoolbar select[disabled],fieldset[disabled] .celltoolbar select{cursor:not-allowed}textarea.celltoolbar select{height:auto}select.celltoolbar select{height:30px;line-height:30px}select[multiple].celltoolbar select,textarea.celltoolbar select{height:auto}.celltoolbar label{margin-left:5px;margin-right:5px}.completions{position:absolute;z-index:110;overflow:hidden;border:1px solid #ababab;border-radius:2px;-webkit-box-shadow:0 6px 10px -1px #adadad;box-shadow:0 6px 10px -1px #adadad;line-height:1}.completions select{background:#fff;outline:0;border:none;padding:0;margin:0;overflow:auto;font-family:monospace;font-size:110%;color:#000;width:auto}.completions select option.context{color:#286090}#kernel_logo_widget{float:right!important;float:right}#kernel_logo_widget .current_kernel_logo{display:none;margin-top:-1px;margin-bottom:-1px;width:32px;height:32px}#menubar{box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;margin-top:1px}#menubar .navbar{border-top:1px;border-radius:0 0 2px 2px;margin-bottom:0}#menubar .navbar-toggle{float:left;padding-top:7px;padding-bottom:7px;border:none}#menubar .navbar-collapse{clear:left}.nav-wrapper{border-bottom:1px solid #e7e7e7}i.menu-icon{padding-top:4px}ul#help_menu li a{overflow:hidden;padding-right:2.2em}ul#help_menu li a i{margin-right:-1.2em}.dropdown-submenu{position:relative}.dropdown-submenu>.dropdown-menu{top:0;left:100%;margin-top:-6px;margin-left:-1px}.dropdown-submenu:hover>.dropdown-menu{display:block}.dropdown-submenu>a:after{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;display:block;content:"\f0da";float:right;color:#333;margin-top:2px;margin-right:-10px}.dropdown-submenu>a:after.pull-left{margin-right:.3em}.dropdown-submenu>a:after.pull-right{margin-left:.3em}.dropdown-submenu:hover>a:after{color:#262626}.dropdown-submenu.pull-left{float:none}.dropdown-submenu.pull-left>.dropdown-menu{left:-100%;margin-left:10px}#notification_area{float:right!important;float:right;z-index:10}.indicator_area{float:right!important;float:right;color:#777;margin-left:5px;margin-right:5px;width:11px;z-index:10;text-align:center;width:auto}#kernel_indicator{float:right!important;float:right;color:#777;margin-left:5px;margin-right:5px;width:11px;z-index:10;text-align:center;width:auto;border-left:1px solid}#kernel_indicator .kernel_indicator_name{padding-left:5px;padding-right:5px}#modal_indicator{float:right!important;float:right;color:#777;margin-left:5px;margin-right:5px;width:11px;z-index:10;text-align:center;width:auto}#readonly-indicator{float:right!important;float:right;color:#777;margin-left:5px;margin-right:5px;width:11px;z-index:10;text-align:center;width:auto;margin-top:2px;margin-bottom:0;margin-left:0;margin-right:0;display:none}.modal_indicator:before{width:1.28571429em;text-align:center}.edit_mode .modal_indicator:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f040"}.edit_mode .modal_indicator:before.pull-left{margin-right:.3em}.edit_mode .modal_indicator:before.pull-right{margin-left:.3em}.command_mode .modal_indicator:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:' '}.command_mode .modal_indicator:before.pull-left{margin-right:.3em}.command_mode .modal_indicator:before.pull-right{margin-left:.3em}.kernel_idle_icon:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f10c"}.kernel_idle_icon:before.pull-left{margin-right:.3em}.kernel_idle_icon:before.pull-right{margin-left:.3em}.kernel_busy_icon:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f111"}.kernel_busy_icon:before.pull-left{margin-right:.3em}.kernel_busy_icon:before.pull-right{margin-left:.3em}.kernel_dead_icon:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f1e2"}.kernel_dead_icon:before.pull-left{margin-right:.3em}.kernel_dead_icon:before.pull-right{margin-left:.3em}.kernel_disconnected_icon:before{display:inline-block;font:normal normal normal 14px/1 FontAwesome;font-size:inherit;text-rendering:auto;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;content:"\f127"}.kernel_disconnected_icon:before.pull-left{margin-right:.3em}.kernel_disconnected_icon:before.pull-right{margin-left:.3em}.notification_widget{color:#777;z-index:10;background:rgba(240,240,240,.5);margin-right:4px;color:#333;background-color:#fff;border-color:#ccc}.notification_widget.focus,.notification_widget:focus{color:#333;background-color:#e6e6e6;border-color:#8c8c8c}.notification_widget:hover{color:#333;background-color:#e6e6e6;border-color:#adadad}.notification_widget.active,.notification_widget:active,.open>.dropdown-toggle.notification_widget{color:#333;background-color:#e6e6e6;border-color:#adadad}.notification_widget.active.focus,.notification_widget.active:focus,.notification_widget.active:hover,.notification_widget:active.focus,.notification_widget:active:focus,.notification_widget:active:hover,.open>.dropdown-toggle.notification_widget.focus,.open>.dropdown-toggle.notification_widget:focus,.open>.dropdown-toggle.notification_widget:hover{color:#333;background-color:#d4d4d4;border-color:#8c8c8c}.notification_widget.active,.notification_widget:active,.open>.dropdown-toggle.notification_widget{background-image:none}.notification_widget.disabled.focus,.notification_widget.disabled:focus,.notification_widget.disabled:hover,.notification_widget[disabled].focus,.notification_widget[disabled]:focus,.notification_widget[disabled]:hover,fieldset[disabled] .notification_widget.focus,fieldset[disabled] .notification_widget:focus,fieldset[disabled] .notification_widget:hover{background-color:#fff;border-color:#ccc}.notification_widget .badge{color:#fff;background-color:#333}.notification_widget.warning{color:#fff;background-color:#f0ad4e;border-color:#eea236}.notification_widget.warning.focus,.notification_widget.warning:focus{color:#fff;background-color:#ec971f;border-color:#985f0d}.notification_widget.warning:hover{color:#fff;background-color:#ec971f;border-color:#d58512}.notification_widget.warning.active,.notification_widget.warning:active,.open>.dropdown-toggle.notification_widget.warning{color:#fff;background-color:#ec971f;border-color:#d58512}.notification_widget.warning.active.focus,.notification_widget.warning.active:focus,.notification_widget.warning.active:hover,.notification_widget.warning:active.focus,.notification_widget.warning:active:focus,.notification_widget.warning:active:hover,.open>.dropdown-toggle.notification_widget.warning.focus,.open>.dropdown-toggle.notification_widget.warning:focus,.open>.dropdown-toggle.notification_widget.warning:hover{color:#fff;background-color:#d58512;border-color:#985f0d}.notification_widget.warning.active,.notification_widget.warning:active,.open>.dropdown-toggle.notification_widget.warning{background-image:none}.notification_widget.warning.disabled.focus,.notification_widget.warning.disabled:focus,.notification_widget.warning.disabled:hover,.notification_widget.warning[disabled].focus,.notification_widget.warning[disabled]:focus,.notification_widget.warning[disabled]:hover,fieldset[disabled] .notification_widget.warning.focus,fieldset[disabled] .notification_widget.warning:focus,fieldset[disabled] .notification_widget.warning:hover{background-color:#f0ad4e;border-color:#eea236}.notification_widget.warning .badge{color:#f0ad4e;background-color:#fff}.notification_widget.success{color:#fff;background-color:#5cb85c;border-color:#4cae4c}.notification_widget.success.focus,.notification_widget.success:focus{color:#fff;background-color:#449d44;border-color:#255625}.notification_widget.success:hover{color:#fff;background-color:#449d44;border-color:#398439}.notification_widget.success.active,.notification_widget.success:active,.open>.dropdown-toggle.notification_widget.success{color:#fff;background-color:#449d44;border-color:#398439}.notification_widget.success.active.focus,.notification_widget.success.active:focus,.notification_widget.success.active:hover,.notification_widget.success:active.focus,.notification_widget.success:active:focus,.notification_widget.success:active:hover,.open>.dropdown-toggle.notification_widget.success.focus,.open>.dropdown-toggle.notification_widget.success:focus,.open>.dropdown-toggle.notification_widget.success:hover{color:#fff;background-color:#398439;border-color:#255625}.notification_widget.success.active,.notification_widget.success:active,.open>.dropdown-toggle.notification_widget.success{background-image:none}.notification_widget.success.disabled.focus,.notification_widget.success.disabled:focus,.notification_widget.success.disabled:hover,.notification_widget.success[disabled].focus,.notification_widget.success[disabled]:focus,.notification_widget.success[disabled]:hover,fieldset[disabled] .notification_widget.success.focus,fieldset[disabled] .notification_widget.success:focus,fieldset[disabled] .notification_widget.success:hover{background-color:#5cb85c;border-color:#4cae4c}.notification_widget.success .badge{color:#5cb85c;background-color:#fff}.notification_widget.info{color:#fff;background-color:#5bc0de;border-color:#46b8da}.notification_widget.info.focus,.notification_widget.info:focus{color:#fff;background-color:#31b0d5;border-color:#1b6d85}.notification_widget.info:hover{color:#fff;background-color:#31b0d5;border-color:#269abc}.notification_widget.info.active,.notification_widget.info:active,.open>.dropdown-toggle.notification_widget.info{color:#fff;background-color:#31b0d5;border-color:#269abc}.notification_widget.info.active.focus,.notification_widget.info.active:focus,.notification_widget.info.active:hover,.notification_widget.info:active.focus,.notification_widget.info:active:focus,.notification_widget.info:active:hover,.open>.dropdown-toggle.notification_widget.info.focus,.open>.dropdown-toggle.notification_widget.info:focus,.open>.dropdown-toggle.notification_widget.info:hover{color:#fff;background-color:#269abc;border-color:#1b6d85}.notification_widget.info.active,.notification_widget.info:active,.open>.dropdown-toggle.notification_widget.info{background-image:none}.notification_widget.info.disabled.focus,.notification_widget.info.disabled:focus,.notification_widget.info.disabled:hover,.notification_widget.info[disabled].focus,.notification_widget.info[disabled]:focus,.notification_widget.info[disabled]:hover,fieldset[disabled] .notification_widget.info.focus,fieldset[disabled] .notification_widget.info:focus,fieldset[disabled] .notification_widget.info:hover{background-color:#5bc0de;border-color:#46b8da}.notification_widget.info .badge{color:#5bc0de;background-color:#fff}.notification_widget.danger{color:#fff;background-color:#d9534f;border-color:#d43f3a}.notification_widget.danger.focus,.notification_widget.danger:focus{color:#fff;background-color:#c9302c;border-color:#761c19}.notification_widget.danger:hover{color:#fff;background-color:#c9302c;border-color:#ac2925}.notification_widget.danger.active,.notification_widget.danger:active,.open>.dropdown-toggle.notification_widget.danger{color:#fff;background-color:#c9302c;border-color:#ac2925}.notification_widget.danger.active.focus,.notification_widget.danger.active:focus,.notification_widget.danger.active:hover,.notification_widget.danger:active.focus,.notification_widget.danger:active:focus,.notification_widget.danger:active:hover,.open>.dropdown-toggle.notification_widget.danger.focus,.open>.dropdown-toggle.notification_widget.danger:focus,.open>.dropdown-toggle.notification_widget.danger:hover{color:#fff;background-color:#ac2925;border-color:#761c19}.notification_widget.danger.active,.notification_widget.danger:active,.open>.dropdown-toggle.notification_widget.danger{background-image:none}.notification_widget.danger.disabled.focus,.notification_widget.danger.disabled:focus,.notification_widget.danger.disabled:hover,.notification_widget.danger[disabled].focus,.notification_widget.danger[disabled]:focus,.notification_widget.danger[disabled]:hover,fieldset[disabled] .notification_widget.danger.focus,fieldset[disabled] .notification_widget.danger:focus,fieldset[disabled] .notification_widget.danger:hover{background-color:#d9534f;border-color:#d43f3a}.notification_widget.danger .badge{color:#d9534f;background-color:#fff}div#pager{background-color:#fff;font-size:14px;line-height:20px;overflow:hidden;display:none;position:fixed;bottom:0;width:100%;max-height:50%;padding-top:8px;-webkit-box-shadow:0 0 12px 1px rgba(87,87,87,.2);box-shadow:0 0 12px 1px rgba(87,87,87,.2);z-index:100;top:auto!important}div#pager pre{line-height:1.21429em;color:#000;background-color:#f7f7f7;padding:.4em}div#pager #pager-button-area{position:absolute;top:8px;right:20px}div#pager #pager-contents{position:relative;overflow:auto;width:100%;height:100%}div#pager #pager-contents #pager-container{position:relative;padding:15px 0;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box}div#pager .ui-resizable-handle{top:0;height:8px;background:#f7f7f7;border-top:1px solid #cfcfcf;border-bottom:1px solid #cfcfcf}div#pager .ui-resizable-handle::after{content:'';top:2px;left:50%;height:3px;width:30px;margin-left:-15px;position:absolute;border-top:1px solid #cfcfcf}.quickhelp{display:-webkit-box;-webkit-box-orient:horizontal;-webkit-box-align:stretch;display:-moz-box;-moz-box-orient:horizontal;-moz-box-align:stretch;display:box;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch;line-height:1.8em}.shortcut_key{display:inline-block;width:20ex;text-align:right;font-family:monospace}.shortcut_descr{display:inline-block;-webkit-box-flex:1;-moz-box-flex:1;box-flex:1;flex:1}span.save_widget{margin-top:6px}span.save_widget span.filename{height:1em;line-height:1em;padding:3px;margin-left:16px;border:none;font-size:146.5%;border-radius:2px}span.save_widget span.filename:hover{background-color:#e6e6e6}span.autosave_status,span.checkpoint_status{font-size:small}@media (max-width:767px){span.save_widget{font-size:small}span.autosave_status,span.checkpoint_status{display:none}}@media (min-width:768px) and (max-width:991px){span.checkpoint_status{display:none}span.autosave_status{font-size:x-small}}.toolbar{padding:0;margin-left:-5px;margin-top:2px;margin-bottom:5px;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box}.toolbar label,.toolbar select{width:auto;vertical-align:middle;margin-right:2px;margin-bottom:0;display:inline;font-size:92%;margin-left:.3em;margin-right:.3em;padding:0;padding-top:3px}.toolbar .btn{padding:2px 8px}.toolbar .btn-group{margin-top:0;margin-left:5px}#maintoolbar{margin-bottom:-3px;margin-top:-8px;border:0;min-height:27px;margin-left:0;padding-top:11px;padding-bottom:3px}#maintoolbar .navbar-text{float:none;vertical-align:middle;text-align:right;margin-left:5px;margin-right:0;margin-top:0}.select-xs{height:24px}.dropdown-menu>li>a.pulse,.pulse,li.pulse.open>a.dropdown-toggle,li.pulse>a.dropdown-toggle{background-color:#F37626;color:#fff}@-moz-keyframes fadeOut{from{opacity:1}to{opacity:0}}@-webkit-keyframes fadeOut{from{opacity:1}to{opacity:0}}@-moz-keyframes fadeIn{from{opacity:0}to{opacity:1}}@-webkit-keyframes fadeIn{from{opacity:0}to{opacity:1}}.bigtooltip{overflow:auto;height:200px;-webkit-transition-property:height;-webkit-transition-duration:.5s;-moz-transition-property:height;-moz-transition-duration:.5s;transition-property:height;transition-duration:.5s}.smalltooltip{-webkit-transition-property:height;-webkit-transition-duration:.5s;-moz-transition-property:height;-moz-transition-duration:.5s;transition-property:height;transition-duration:.5s;text-overflow:ellipsis;overflow:hidden;height:80px}.tooltipbuttons{position:absolute;padding-right:15px;top:0;right:0}.tooltiptext{padding-right:30px}.ipython_tooltip{max-width:700px;-webkit-animation:fadeOut .4s;-moz-animation:fadeOut .4s;animation:fadeOut .4s;-webkit-animation:fadeIn .4s;-moz-animation:fadeIn .4s;animation:fadeIn .4s;vertical-align:middle;background-color:#f7f7f7;overflow:visible;border:#ababab 1px solid;outline:0;padding:3px;margin:0;padding-left:7px;font-family:monospace;min-height:50px;-moz-box-shadow:0 6px 10px -1px #adadad;-webkit-box-shadow:0 6px 10px -1px #adadad;box-shadow:0 6px 10px -1px #adadad;border-radius:2px;position:absolute;z-index:1000}.ipython_tooltip a{float:right}.ipython_tooltip .tooltiptext pre{border:0;border-radius:0;font-size:100%;background-color:#f7f7f7}.pretooltiparrow{left:0;margin:0;top:-16px;width:40px;height:16px;overflow:hidden;position:absolute}.pretooltiparrow:before{background-color:#f7f7f7;border:1px #ababab solid;z-index:11;content:"";position:absolute;left:15px;top:10px;width:25px;height:25px;-webkit-transform:rotate(45deg);-moz-transform:rotate(45deg);-ms-transform:rotate(45deg);-o-transform:rotate(45deg)}ul.typeahead-list i{margin-left:-10px;width:18px}ul.typeahead-list{max-height:80vh;overflow:auto}ul.typeahead-list>li>a{white-space:normal}.cmd-palette .modal-body{padding:7px}.cmd-palette form{background:#fff}.cmd-palette input{outline:0}.no-shortcut{display:none}.command-shortcut:before{content:"(command)";padding-right:3px;color:#777}.edit-shortcut:before{content:"(edit)";padding-right:3px;color:#777}#find-and-replace #replace-preview .insert,#find-and-replace #replace-preview .match{background-color:#BBDEFB;border-color:#90CAF9;border-style:solid;border-width:1px;border-radius:0}#find-and-replace #replace-preview .replace .match{background-color:#FFCDD2;border-color:#EF9A9A;border-radius:0}#find-and-replace #replace-preview .replace .insert{background-color:#C8E6C9;border-color:#A5D6A7;border-radius:0}#find-and-replace #replace-preview{max-height:60vh;overflow:auto}#find-and-replace #replace-preview pre{padding:5px 10px}.terminal-app{background:#EEE}.terminal-app #header{background:#fff;-webkit-box-shadow:0 0 12px 1px rgba(87,87,87,.2);box-shadow:0 0 12px 1px rgba(87,87,87,.2)}.terminal-app .terminal{float:left;font-family:monospace;color:#fff;background:#000;padding:.4em;border-radius:2px;-webkit-box-shadow:0 0 12px 1px rgba(87,87,87,.4);box-shadow:0 0 12px 1px rgba(87,87,87,.4)}.terminal-app .terminal,.terminal-app .terminal dummy-screen{line-height:1em;font-size:14px}.terminal-app .terminal-cursor{color:#000;background:#fff}.terminal-app #terminado-container{margin-top:20px}.highlight .hll{background-color:#ffc}.highlight{background:#f8f8f8}.highlight .c{color:#408080;font-style:italic}.highlight .err{border:1px solid red}.highlight .k{color:green;font-weight:700}.highlight .o{color:#666}.highlight .ch{color:#408080;font-style:italic}.highlight .cm{color:#408080;font-style:italic}.highlight .cp{color:#BC7A00}.highlight .cpf{color:#408080;font-style:italic}.highlight .c1{color:#408080;font-style:italic}.highlight .cs{color:#408080;font-style:italic}.highlight .gd{color:#A00000}.highlight .ge{font-style:italic}.highlight .gr{color:red}.highlight .gh{color:navy;font-weight:700}.highlight .gi{color:#00A000}.highlight .go{color:#888}.highlight .gp{color:navy;font-weight:700}.highlight .gs{font-weight:700}.highlight .gu{color:purple;font-weight:700}.highlight .gt{color:#04D}.highlight .kc{color:green;font-weight:700}.highlight .kd{color:green;font-weight:700}.highlight .kn{color:green;font-weight:700}.highlight .kp{color:green}.highlight .kr{color:green;font-weight:700}.highlight .kt{color:#B00040}.highlight .m{color:#666}.highlight .s{color:#BA2121}.highlight .na{color:#7D9029}.highlight .nb{color:green}.highlight .nc{color:#00F;font-weight:700}.highlight .no{color:#800}.highlight .nd{color:#A2F}.highlight .ni{color:#999;font-weight:700}.highlight .ne{color:#D2413A;font-weight:700}.highlight .nf{color:#00F}.highlight .nl{color:#A0A000}.highlight .nn{color:#00F;font-weight:700}.highlight .nt{color:green;font-weight:700}.highlight .nv{color:#19177C}.highlight .ow{color:#A2F;font-weight:700}.highlight .w{color:#bbb}.highlight .mb{color:#666}.highlight .mf{color:#666}.highlight .mh{color:#666}.highlight .mi{color:#666}.highlight .mo{color:#666}.highlight .sb{color:#BA2121}.highlight .sc{color:#BA2121}.highlight .sd{color:#BA2121;font-style:italic}.highlight .s2{color:#BA2121}.highlight .se{color:#B62;font-weight:700}.highlight .sh{color:#BA2121}.highlight .si{color:#B68;font-weight:700}.highlight .sx{color:green}.highlight .sr{color:#B68}.highlight .s1{color:#BA2121}.highlight .ss{color:#19177C}.highlight .bp{color:green}.highlight .vc{color:#19177C}.highlight .vg{color:#19177C}.highlight .vi{color:#19177C}.highlight .il{color:#666}.ansi-black-fg{color:#3E424D}.ansi-black-bg{background-color:#3E424D}.ansi-black-intense-fg{color:#282C36}.ansi-black-intense-bg{background-color:#282C36}.ansi-red-fg{color:#E75C58}.ansi-red-bg{background-color:#E75C58}.ansi-red-intense-fg{color:#B22B31}.ansi-red-intense-bg{background-color:#B22B31}.ansi-green-fg{color:#00A250}.ansi-green-bg{background-color:#00A250}.ansi-green-intense-fg{color:#007427}.ansi-green-intense-bg{background-color:#007427}.ansi-yellow-fg{color:#DDB62B}.ansi-yellow-bg{background-color:#DDB62B}.ansi-yellow-intense-fg{color:#B27D12}.ansi-yellow-intense-bg{background-color:#B27D12}.ansi-blue-fg{color:#208FFB}.ansi-blue-bg{background-color:#208FFB}.ansi-blue-intense-fg{color:#0065CA}.ansi-blue-intense-bg{background-color:#0065CA}.ansi-magenta-fg{color:#D160C4}.ansi-magenta-bg{background-color:#D160C4}.ansi-magenta-intense-fg{color:#A03196}.ansi-magenta-intense-bg{background-color:#A03196}.ansi-cyan-fg{color:#60C6C8}.ansi-cyan-bg{background-color:#60C6C8}.ansi-cyan-intense-fg{color:#258F8F}.ansi-cyan-intense-bg{background-color:#258F8F}.ansi-white-fg{color:#C5C1B4}.ansi-white-bg{background-color:#C5C1B4}.ansi-white-intense-fg{color:#A1A6B2}.ansi-white-intense-bg{background-color:#A1A6B2}.ansi-bold{font-weight:700}body{overflow:visible;padding:8px}div#notebook{overflow:visible;border-top:none}@media print{div.cell{display:block;page-break-inside:avoid}div.output_wrapper{display:block;page-break-inside:avoid}div.output{display:block;page-break-inside:avoid}}MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true, processEnvironments: true }, // Center justify equations in code and markdown cells. Elsewhere // we use CSS to left justify single line equations in code cells. displayAlign: 'center', "HTML-CSS": { styles: {'.MathJax_Display': {"margin": 0}}, linebreaks: { automatic: true } } });&#25968;&#25454;&#32858;&#21512;&#19982;&#20998;&#32452;&#36816;&#31639;&#182;In&nbsp;[236]:from __future__ import division from numpy.random import randn import numpy as np import os import matplotlib.pyplot as plt np.random.seed(12345) plt.rc(&#39;figure&#39;, figsize=(10, 6)) from pandas import Series, DataFrame import pandas as pd np.set_printoptions(precision=4) In&nbsp;[237]:pd.options.display.notebook_repr_html = False from IPython.core.interactiveshell import InteractiveShell InteractiveShell.ast_node_interactivity = &quot;all&quot; In&nbsp;[238]:%matplotlib inline GroupBy &#26426;&#21046;&#182;In&nbsp;[239]:df = DataFrame({&#39;key1&#39; : [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;a&#39;], &#39;key2&#39; : [&#39;one&#39;, &#39;two&#39;, &#39;one&#39;, &#39;two&#39;, &#39;one&#39;], &#39;data1&#39; : np.random.randn(5), &#39;data2&#39; : np.random.randn(5)}) df Out[239]: data1 data2 key1 key2 0 -0.204708 1.393406 a one 1 0.478943 0.092908 a two 2 -0.519439 0.281746 b one 3 -0.555730 0.769023 b two 4 1.965781 1.246435 a oneIn&nbsp;[240]:grouped = df[&#39;data1&#39;].groupby(df[&#39;key1&#39;]) grouped Out[240]:&lt;pandas.core.groupby.SeriesGroupBy object at 0x0000000008BAFA90&gt;groupbyGroupByIn&nbsp;[241]:grouped.mean() Out[241]:key1 a 0.746672 b -0.537585 Name: data1, dtype: float64In&nbsp;[242]:means = df[&#39;data1&#39;].groupby([df[&#39;key1&#39;], df[&#39;key2&#39;]]).mean() means Out[242]:key1 key2 a one 0.880536 two 0.478943 b one -0.519439 two -0.555730 Name: data1, dtype: float64In&nbsp;[243]:means.unstack() Out[243]:key2 one two key1 a 0.880536 0.478943 b -0.519439 -0.555730In&nbsp;[244]:states = np.array([&#39;Ohio&#39;, &#39;California&#39;, &#39;California&#39;, &#39;Ohio&#39;, &#39;Ohio&#39;]) years = np.array([2005, 2005, 2006, 2005, 2006]) df[&#39;data1&#39;].groupby([states, years]).mean() Out[244]:California 2005 0.478943 2006 -0.519439 Ohio 2005 -0.380219 2006 1.965781 Name: data1, dtype: float64In&nbsp;[245]:df.groupby(&#39;key1&#39;).mean() Out[245]: data1 data2 key1 a 0.746672 0.910916 b -0.537585 0.525384In&nbsp;[246]:df.groupby([&#39;key1&#39;, &#39;key2&#39;]).mean() Out[246]: data1 data2 key1 key2 a one 0.880536 1.319920 two 0.478943 0.092908 b one -0.519439 0.281746 two -0.555730 0.769023In&nbsp;[247]:df.groupby([&#39;key1&#39;, &#39;key2&#39;]).size() Out[247]:key1 key2 a one 2 two 1 b one 1 two 1 dtype: int64&#23545;&#20998;&#32452;&#36827;&#34892;&#36845;&#20195;&#182;In&nbsp;[248]:df.groupby(&#39;key1&#39;) Out[248]:&lt;pandas.core.groupby.DataFrameGroupBy object at 0x0000000034BC8CF8&gt;In&nbsp;[249]:df for name, group in df.groupby(&#39;key1&#39;): print(name) print(group) Out[249]: data1 data2 key1 key2 0 -0.204708 1.393406 a one 1 0.478943 0.092908 a two 2 -0.519439 0.281746 b one 3 -0.555730 0.769023 b two 4 1.965781 1.246435 a onea data1 data2 key1 key2 0 -0.204708 1.393406 a one 1 0.478943 0.092908 a two 4 1.965781 1.246435 a one b data1 data2 key1 key2 2 -0.519439 0.281746 b one 3 -0.555730 0.769023 b two In&nbsp;[250]:for (k1, k2), group in df.groupby([&#39;key1&#39;, &#39;key2&#39;]): print((k1, k2)) print(group) (&#39;a&#39;, &#39;one&#39;) data1 data2 key1 key2 0 -0.204708 1.393406 a one 4 1.965781 1.246435 a one (&#39;a&#39;, &#39;two&#39;) data1 data2 key1 key2 1 0.478943 0.092908 a two (&#39;b&#39;, &#39;one&#39;) data1 data2 key1 key2 2 -0.519439 0.281746 b one (&#39;b&#39;, &#39;two&#39;) data1 data2 key1 key2 3 -0.55573 0.769023 b two In&nbsp;[251]:pieces = dict(list(df.groupby(&#39;key1&#39;))) pieces[&#39;b&#39;] Out[251]: data1 data2 key1 key2 2 -0.519439 0.281746 b one 3 -0.555730 0.769023 b twoIn&nbsp;[252]:df.dtypes Out[252]:data1 float64 data2 float64 key1 object key2 object dtype: object...In&nbsp;[253]:grouped = df.groupby(df.dtypes, axis=1) dict(list(grouped)) Out[253]:{dtype(&#39;float64&#39;): data1 data2 0 -0.204708 1.393406 1 0.478943 0.092908 2 -0.519439 0.281746 3 -0.555730 0.769023 4 1.965781 1.246435, dtype(&#39;O&#39;): key1 key2 0 a one 1 a two 2 b one 3 b two 4 a one}&#36873;&#25321;&#19968;&#21015;&#25110;&#19968;&#32452;&#21015;&#182;In&nbsp;[254]:df.groupby(&#39;key1&#39;)[&#39;data1&#39;] df.groupby(&#39;key1&#39;)[[&#39;data2&#39;]] Out[254]:&lt;pandas.core.groupby.SeriesGroupBy object at 0x0000000034BDC2E8&gt;Out[254]:&lt;pandas.core.groupby.DataFrameGroupBy object at 0x0000000015EDF2B0&gt;In&nbsp;[255]:df[&#39;data1&#39;].groupby(df[&#39;key1&#39;]) df[[&#39;data2&#39;]].groupby(df[&#39;key1&#39;]) Out[255]:&lt;pandas.core.groupby.SeriesGroupBy object at 0x0000000034BDC8D0&gt;Out[255]:&lt;pandas.core.groupby.DataFrameGroupBy object at 0x0000000034BDC898&gt;In&nbsp;[256]:df.groupby([&#39;key1&#39;, &#39;key2&#39;])[[&#39;data2&#39;]].mean() Out[256]: data2 key1 key2 a one 1.319920 two 0.092908 b one 0.281746 two 0.769023In&nbsp;[257]:s_grouped = df.groupby([&#39;key1&#39;, &#39;key2&#39;])[&#39;data2&#39;] s_grouped Out[257]:&lt;pandas.core.groupby.SeriesGroupBy object at 0x0000000034BDC6A0&gt;In&nbsp;[258]:s_grouped.mean() Out[258]:key1 key2 a one 1.319920 two 0.092908 b one 0.281746 two 0.769023 Name: data2, dtype: float64&#36890;&#36807;&#23383;&#20856;&#25110;Series&#36827;&#34892;&#20998;&#32452;&#182;In&nbsp;[259]:people = DataFrame(np.random.randn(5, 5), columns=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;], index=[&#39;Joe&#39;, &#39;Steve&#39;, &#39;Wes&#39;, &#39;Jim&#39;, &#39;Travis&#39;]) people.ix[2:3, [&#39;b&#39;, &#39;c&#39;]] = np.nan # Add a few NA values people Out[259]: a b c d e Joe 1.007189 -1.296221 0.274992 0.228913 1.352917 Steve 0.886429 -2.001637 -0.371843 1.669025 -0.438570 Wes -0.539741 NaN NaN -1.021228 -0.577087 Jim 0.124121 0.302614 0.523772 0.000940 1.343810 Travis -0.713544 -0.831154 -2.370232 -1.860761 -0.860757In&nbsp;[260]:mapping = {&#39;a&#39;: &#39;red&#39;, &#39;b&#39;: &#39;red&#39;, &#39;c&#39;: &#39;blue&#39;, &#39;d&#39;: &#39;blue&#39;, &#39;e&#39;: &#39;red&#39;, &#39;f&#39; : &#39;orange&#39;} NAIn&nbsp;[261]:by_column = people.groupby(mapping, axis=1) by_column.sum() Out[261]: blue red Joe 0.503905 1.063885 Steve 1.297183 -1.553778 Wes -1.021228 -1.116829 Jim 0.524712 1.770545 Travis -4.230992 -2.405455SeriesIn&nbsp;[262]:map_series = Series(mapping) map_series Out[262]:a red b red c blue d blue e red f orange dtype: objectIn&nbsp;[263]:people.groupby(map_series, axis=1).count() Out[263]: blue red Joe 2 3 Steve 2 3 Wes 1 2 Jim 2 3 Travis 2 3&#36890;&#36807;&#20989;&#25968;&#36827;&#34892;&#20998;&#32452;&#182;In&nbsp;[264]:people.groupby(len).sum() Out[264]: a b c d e 3 0.591569 -0.993608 0.798764 -0.791374 2.119639 5 0.886429 -2.001637 -0.371843 1.669025 -0.438570 6 -0.713544 -0.831154 -2.370232 -1.860761 -0.860757In&nbsp;[265]:key_list = [&#39;one&#39;, &#39;one&#39;, &#39;one&#39;, &#39;two&#39;, &#39;two&#39;] people.groupby([len, key_list]).min() Out[265]: a b c d e 3 one -0.539741 -1.296221 0.274992 -1.021228 -0.577087 two 0.124121 0.302614 0.523772 0.000940 1.343810 5 one 0.886429 -2.001637 -0.371843 1.669025 -0.438570 6 two -0.713544 -0.831154 -2.370232 -1.860761 -0.860757&#26681;&#25454;&#32034;&#24341;&#32423;&#21035;&#20998;&#32452;&#182;In&nbsp;[266]:columns = pd.MultiIndex.from_arrays([[&#39;US&#39;, &#39;US&#39;, &#39;US&#39;, &#39;JP&#39;, &#39;JP&#39;], [1, 3, 5, 1, 3]], names=[&#39;cty&#39;, &#39;tenor&#39;]) hier_df = DataFrame(np.random.randn(4, 5), columns=columns) hier_df Out[266]:cty US JP tenor 1 3 5 1 3 0 0.560145 -1.265934 0.119827 -1.063512 0.332883 1 -2.359419 -0.199543 -1.541996 -0.970736 -1.307030 2 0.286350 0.377984 -0.753887 0.331286 1.349742 3 0.069877 0.246674 -0.011862 1.004812 1.327195In&nbsp;[267]:hier_df.groupby(level=&#39;cty&#39;, axis=1).count() Out[267]:cty JP US 0 2 3 1 2 3 2 2 3 3 2 3&#25968;&#25454;&#32858;&#21512;&#182;In&nbsp;[268]:df Out[268]: data1 data2 key1 key2 0 -0.204708 1.393406 a one 1 0.478943 0.092908 a two 2 -0.519439 0.281746 b one 3 -0.555730 0.769023 b two 4 1.965781 1.246435 a oneIn&nbsp;[269]:grouped = df.groupby(&#39;key1&#39;) grouped[&#39;data1&#39;].quantile(0.9) Out[269]:key1 a 1.668413 b -0.523068 Name: data1, dtype: float64In&nbsp;[270]:def peak_to_peak(arr): return arr.max() - arr.min() grouped.agg(peak_to_peak) Out[270]: data1 data2 key1 a 2.170488 1.300498 b 0.036292 0.487276In&nbsp;[271]:grouped.describe() Out[271]: data1 data2 key1 a count 3.000000 3.000000 mean 0.746672 0.910916 std 1.109736 0.712217 min -0.204708 0.092908 25% 0.137118 0.669671 50% 0.478943 1.246435 75% 1.222362 1.319920 max 1.965781 1.393406 b count 2.000000 2.000000 mean -0.537585 0.525384 std 0.025662 0.344556 min -0.555730 0.281746 25% -0.546657 0.403565 50% -0.537585 0.525384 75% -0.528512 0.647203 max -0.519439 0.769023In&nbsp;[272]:tips = pd.read_csv(&#39;ch08/tips.csv&#39;) # Add tip percentage of total bill tips[&#39;tip_pct&#39;] = tips[&#39;tip&#39;] / tips[&#39;total_bill&#39;] tips[:6] Out[272]: total_bill tip sex smoker day time size_ tip_pct 0 16.99 1.01 Female No Sun Dinner 2 0.059447 1 10.34 1.66 Male No Sun Dinner 3 0.160542 2 21.01 3.50 Male No Sun Dinner 3 0.166587 3 23.68 3.31 Male No Sun Dinner 2 0.139780 4 24.59 3.61 Female No Sun Dinner 4 0.146808 5 25.29 4.71 Male No Sun Dinner 4 0.186240&#38754;&#21521;&#21015;&#30340;&#22810;&#20989;&#25968;&#24212;&#29992;&#182;In&nbsp;[273]:grouped = tips.groupby([&#39;sex&#39;, &#39;smoker&#39;]) In&nbsp;[274]:grouped_pct = grouped[&#39;tip_pct&#39;] grouped_pct.agg(&#39;mean&#39;) Out[274]:sex smoker Female No 0.156921 Yes 0.182150 Male No 0.160669 Yes 0.152771 Name: tip_pct, dtype: float64In&nbsp;[275]:grouped_pct.agg([&#39;mean&#39;, &#39;std&#39;, peak_to_peak]) Out[275]: mean std peak_to_peak sex smoker Female No 0.156921 0.036421 0.195876 Yes 0.182150 0.071595 0.360233 Male No 0.160669 0.041849 0.220186 Yes 0.152771 0.090588 0.674707In&nbsp;[276]:grouped_pct.agg([(&#39;foo&#39;, &#39;mean&#39;), (&#39;bar&#39;, np.std)]) Out[276]: foo bar sex smoker Female No 0.156921 0.036421 Yes 0.182150 0.071595 Male No 0.160669 0.041849 Yes 0.152771 0.090588In&nbsp;[277]:functions = [&#39;count&#39;, &#39;mean&#39;, &#39;max&#39;] result = grouped[&#39;tip_pct&#39;, &#39;total_bill&#39;].agg(functions) result Out[277]: tip_pct total_bill count mean max count mean max sex smoker Female No 54 0.156921 0.252672 54 18.105185 35.83 Yes 33 0.182150 0.416667 33 17.977879 44.30 Male No 97 0.160669 0.291990 97 19.791237 48.33 Yes 60 0.152771 0.710345 60 22.284500 50.81In&nbsp;[278]:result[&#39;tip_pct&#39;] Out[278]: count mean max sex smoker Female No 54 0.156921 0.252672 Yes 33 0.182150 0.416667 Male No 97 0.160669 0.291990 Yes 60 0.152771 0.710345In&nbsp;[279]:ftuples = [(&#39;Durchschnitt&#39;, &#39;mean&#39;), (&#39;Abweichung&#39;, np.var)] grouped[&#39;tip_pct&#39;, &#39;total_bill&#39;].agg(ftuples) Out[279]: tip_pct total_bill Durchschnitt Abweichung Durchschnitt Abweichung sex smoker Female No 0.156921 0.001327 18.105185 53.092422 Yes 0.182150 0.005126 17.977879 84.451517 Male No 0.160669 0.001751 19.791237 76.152961 Yes 0.152771 0.008206 22.284500 98.244673In&nbsp;[280]:grouped.agg({&#39;tip&#39; : np.max, &#39;size_&#39; : &#39;sum&#39;}) Out[280]: size_ tip sex smoker Female No 140 5.2 Yes 74 6.5 Male No 263 9.0 Yes 150 10.0In&nbsp;[281]:grouped.agg({&#39;tip_pct&#39; : [&#39;min&#39;, &#39;max&#39;, &#39;mean&#39;, &#39;std&#39;], &#39;size_&#39; : &#39;sum&#39;}) Out[281]: tip_pct size_ min max mean std sum sex smoker Female No 0.056797 0.252672 0.156921 0.036421 140 Yes 0.056433 0.416667 0.182150 0.071595 74 Male No 0.071804 0.291990 0.160669 0.041849 263 Yes 0.035638 0.710345 0.152771 0.090588 150&#20197;&#26080;&#32034;&#24341;&#30340;&#24418;&#24335;&#36820;&#22238;&#32858;&#21512;&#25968;&#25454;&#182;In&nbsp;[282]:tips.groupby([&#39;sex&#39;, &#39;smoker&#39;], as_index=False).mean() Out[282]: sex smoker total_bill tip size_ tip_pct 0 Female No 18.105185 2.773519 2.592593 0.156921 1 Female Yes 17.977879 2.931515 2.242424 0.182150 2 Male No 19.791237 3.113402 2.711340 0.160669 3 Male Yes 22.284500 3.051167 2.500000 0.152771In&nbsp;[283]:tips.groupby([&#39;sex&#39;, &#39;smoker&#39;], as_index=True).mean() Out[283]: total_bill tip size_ tip_pct sex smoker Female No 18.105185 2.773519 2.592593 0.156921 Yes 17.977879 2.931515 2.242424 0.182150 Male No 19.791237 3.113402 2.711340 0.160669 Yes 22.284500 3.051167 2.500000 0.152771&#20998;&#32452;&#32423;&#36816;&#31639;&#21644;&#36716;&#25442;&#182;In&nbsp;[284]:df Out[284]: data1 data2 key1 key2 0 -0.204708 1.393406 a one 1 0.478943 0.092908 a two 2 -0.519439 0.281746 b one 3 -0.555730 0.769023 b two 4 1.965781 1.246435 a oneIn&nbsp;[285]:k1_means = df.groupby(&#39;key1&#39;).mean().add_prefix(&#39;mean_&#39;) k1_means Out[285]: mean_data1 mean_data2 key1 a 0.746672 0.910916 b -0.537585 0.525384In&nbsp;[286]:pd.merge(df, k1_means, left_on=&#39;key1&#39;, right_index=True) Out[286]: data1 data2 key1 key2 mean_data1 mean_data2 0 -0.204708 1.393406 a one 0.746672 0.910916 1 0.478943 0.092908 a two 0.746672 0.910916 4 1.965781 1.246435 a one 0.746672 0.910916 2 -0.519439 0.281746 b one -0.537585 0.525384 3 -0.555730 0.769023 b two -0.537585 0.525384In&nbsp;[287]:people Out[287]: a b c d e Joe 1.007189 -1.296221 0.274992 0.228913 1.352917 Steve 0.886429 -2.001637 -0.371843 1.669025 -0.438570 Wes -0.539741 NaN NaN -1.021228 -0.577087 Jim 0.124121 0.302614 0.523772 0.000940 1.343810 Travis -0.713544 -0.831154 -2.370232 -1.860761 -0.860757In&nbsp;[288]:key = [&#39;one&#39;, &#39;two&#39;, &#39;one&#39;, &#39;two&#39;, &#39;one&#39;] people.groupby(key).mean() Out[288]: a b c d e one -0.082032 -1.063687 -1.047620 -0.884358 -0.028309 two 0.505275 -0.849512 0.075965 0.834983 0.452620In&nbsp;[289]:people.groupby(key).transform(np.mean) Out[289]: a b c d e Joe -0.082032 -1.063687 -1.047620 -0.884358 -0.028309 Steve 0.505275 -0.849512 0.075965 0.834983 0.452620 Wes -0.082032 -1.063687 -1.047620 -0.884358 -0.028309 Jim 0.505275 -0.849512 0.075965 0.834983 0.452620 Travis -0.082032 -1.063687 -1.047620 -0.884358 -0.028309In&nbsp;[290]:def demean(arr): return arr - arr.mean() demeaned = people.groupby(key).transform(demean) demeaned Out[290]: a b c d e Joe 1.089221 -0.232534 1.322612 1.113271 1.381226 Steve 0.381154 -1.152125 -0.447807 0.834043 -0.891190 Wes -0.457709 NaN NaN -0.136869 -0.548778 Jim -0.381154 1.152125 0.447807 -0.834043 0.891190 Travis -0.631512 0.232534 -1.322612 -0.976402 -0.832448In&nbsp;[291]:demeaned.groupby(key).mean() Out[291]: a b c d e one 0.000000e+00 -1.110223e-16 0.0 7.401487e-17 0.0 two -2.775558e-17 0.000000e+00 0.0 0.000000e+00 0.0Apply: &#19968;&#33324;&#24615;&#30340; &#8220;&#25286;&#20998;-&#24212;&#29992;-&#21512;&#24182;&#8221;&#182;In&nbsp;[292]:def top(df, n=5, column=&#39;tip_pct&#39;): return df.sort_values(by=column)[-n:] top(tips, n=6) Out[292]: total_bill tip sex smoker day time size_ tip_pct 109 14.31 4.00 Female Yes Sat Dinner 2 0.279525 183 23.17 6.50 Male Yes Sun Dinner 4 0.280535 232 11.61 3.39 Male No Sat Dinner 2 0.291990 67 3.07 1.00 Female Yes Sat Dinner 1 0.325733 178 9.60 4.00 Female Yes Sun Dinner 2 0.416667 172 7.25 5.15 Male Yes Sun Dinner 2 0.710345DataFrameIn&nbsp;[293]:tips.groupby(&#39;smoker&#39;).apply(top) Out[293]: total_bill tip sex smoker day time size_ tip_pct smoker No 88 24.71 5.85 Male No Thur Lunch 2 0.236746 185 20.69 5.00 Male No Sun Dinner 5 0.241663 51 10.29 2.60 Female No Sun Dinner 2 0.252672 149 7.51 2.00 Male No Thur Lunch 2 0.266312 232 11.61 3.39 Male No Sat Dinner 2 0.291990 Yes 109 14.31 4.00 Female Yes Sat Dinner 2 0.279525 183 23.17 6.50 Male Yes Sun Dinner 4 0.280535 67 3.07 1.00 Female Yes Sat Dinner 1 0.325733 178 9.60 4.00 Female Yes Sun Dinner 2 0.416667 172 7.25 5.15 Male Yes Sun Dinner 2 0.710345In&nbsp;[294]:tips.groupby([&#39;smoker&#39;, &#39;day&#39;]).apply(top, n=1, column=&#39;total_bill&#39;) Out[294]: total_bill tip sex smoker day time size_ \ smoker day No Fri 94 22.75 3.25 Female No Fri Dinner 2 Sat 212 48.33 9.00 Male No Sat Dinner 4 Sun 156 48.17 5.00 Male No Sun Dinner 6 Thur 142 41.19 5.00 Male No Thur Lunch 5 Yes Fri 95 40.17 4.73 Male Yes Fri Dinner 4 Sat 170 50.81 10.00 Male Yes Sat Dinner 3 Sun 182 45.35 3.50 Male Yes Sun Dinner 3 Thur 197 43.11 5.00 Female Yes Thur Lunch 4 tip_pct smoker day No Fri 94 0.142857 Sat 212 0.186220 Sun 156 0.103799 Thur 142 0.121389 Yes Fri 95 0.117750 Sat 170 0.196812 Sun 182 0.077178 Thur 197 0.115982 In&nbsp;[295]:result = tips.groupby(&#39;smoker&#39;)[&#39;tip_pct&#39;].describe() result Out[295]:smoker No count 151.000000 mean 0.159328 std 0.039910 min 0.056797 25% 0.136906 50% 0.155625 75% 0.185014 max 0.291990 Yes count 93.000000 mean 0.163196 std 0.085119 min 0.035638 25% 0.106771 50% 0.153846 75% 0.195059 max 0.710345 Name: tip_pct, dtype: float64In&nbsp;[296]:result.unstack(&#39;smoker&#39;) Out[296]:smoker No Yes count 151.000000 93.000000 mean 0.159328 0.163196 std 0.039910 0.085119 min 0.056797 0.035638 25% 0.136906 0.106771 50% 0.155625 0.153846 75% 0.185014 0.195059 max 0.291990 0.710345grouped In&nbsp;[297]:f = lambda x: x.describe() grouped.apply(f) Out[297]: total_bill tip size_ tip_pct sex smoker Female No count 54.000000 54.000000 54.000000 54.000000 mean 18.105185 2.773519 2.592593 0.156921 std 7.286455 1.128425 1.073146 0.036421 min 7.250000 1.000000 1.000000 0.056797 25% 12.650000 2.000000 2.000000 0.139708 50% 16.690000 2.680000 2.000000 0.149691 75% 20.862500 3.437500 3.000000 0.181630 max 35.830000 5.200000 6.000000 0.252672 Yes count 33.000000 33.000000 33.000000 33.000000 mean 17.977879 2.931515 2.242424 0.182150 std 9.189751 1.219916 0.613917 0.071595 min 3.070000 1.000000 1.000000 0.056433 25% 12.760000 2.000000 2.000000 0.152439 50% 16.270000 2.880000 2.000000 0.173913 75% 22.120000 3.500000 2.000000 0.198216 max 44.300000 6.500000 4.000000 0.416667 Male No count 97.000000 97.000000 97.000000 97.000000 mean 19.791237 3.113402 2.711340 0.160669 std 8.726566 1.489559 0.989094 0.041849 min 7.510000 1.250000 2.000000 0.071804 25% 13.810000 2.000000 2.000000 0.131810 50% 18.240000 2.740000 2.000000 0.157604 75% 22.820000 3.710000 3.000000 0.186220 max 48.330000 9.000000 6.000000 0.291990 Yes count 60.000000 60.000000 60.000000 60.000000 mean 22.284500 3.051167 2.500000 0.152771 std 9.911845 1.500120 0.892530 0.090588 min 7.250000 1.000000 1.000000 0.035638 25% 15.272500 2.000000 2.000000 0.101845 50% 20.390000 3.000000 2.000000 0.141015 75% 28.572500 3.820000 3.000000 0.191697 max 50.810000 10.000000 5.000000 0.710345&#31105;&#27490;&#20998;&#32452;&#38190;&#182;In&nbsp;[298]:tips.groupby(&#39;smoker&#39;, group_keys=True).apply(top) Out[298]: total_bill tip sex smoker day time size_ tip_pct smoker No 88 24.71 5.85 Male No Thur Lunch 2 0.236746 185 20.69 5.00 Male No Sun Dinner 5 0.241663 51 10.29 2.60 Female No Sun Dinner 2 0.252672 149 7.51 2.00 Male No Thur Lunch 2 0.266312 232 11.61 3.39 Male No Sat Dinner 2 0.291990 Yes 109 14.31 4.00 Female Yes Sat Dinner 2 0.279525 183 23.17 6.50 Male Yes Sun Dinner 4 0.280535 67 3.07 1.00 Female Yes Sat Dinner 1 0.325733 178 9.60 4.00 Female Yes Sun Dinner 2 0.416667 172 7.25 5.15 Male Yes Sun Dinner 2 0.710345In&nbsp;[299]:tips.groupby(&#39;smoker&#39;, group_keys=False).apply(top) Out[299]: total_bill tip sex smoker day time size_ tip_pct 88 24.71 5.85 Male No Thur Lunch 2 0.236746 185 20.69 5.00 Male No Sun Dinner 5 0.241663 51 10.29 2.60 Female No Sun Dinner 2 0.252672 149 7.51 2.00 Male No Thur Lunch 2 0.266312 232 11.61 3.39 Male No Sat Dinner 2 0.291990 109 14.31 4.00 Female Yes Sat Dinner 2 0.279525 183 23.17 6.50 Male Yes Sun Dinner 4 0.280535 67 3.07 1.00 Female Yes Sat Dinner 1 0.325733 178 9.60 4.00 Female Yes Sun Dinner 2 0.416667 172 7.25 5.15 Male Yes Sun Dinner 2 0.710345&#20998;&#20301;&#25968;&#19982;&#26742;&#20998;&#26512;&#182;In&nbsp;[300]:frame = DataFrame({&#39;data1&#39;: np.random.randn(1000), &#39;data2&#39;: np.random.randn(1000)}) factor = pd.cut(frame.data1, 4) factor[:10] Out[300]:0 (-1.23, 0.489] 1 (-2.956, -1.23] 2 (-1.23, 0.489] 3 (0.489, 2.208] 4 (-1.23, 0.489] 5 (0.489, 2.208] 6 (-1.23, 0.489] 7 (-1.23, 0.489] 8 (0.489, 2.208] 9 (0.489, 2.208] Name: data1, dtype: category Categories (4, object): [(-2.956, -1.23] &lt; (-1.23, 0.489] &lt; (0.489, 2.208] &lt; (2.208, 3.928]]In&nbsp;[301]:def get_stats(group): return {&#39;min&#39;: group.min(), &#39;max&#39;: group.max(), &#39;count&#39;: group.count(), &#39;mean&#39;: group.mean()} grouped = frame.data2.groupby(factor) grouped.apply(get_stats).unstack() #ADAPT the output is not sorted in the book while this is the case now (swap first two lines) Out[301]: count max mean min data1 (-2.956, -1.23] 95.0 1.670835 -0.039521 -3.399312 (-1.23, 0.489] 598.0 3.260383 -0.002051 -2.989741 (0.489, 2.208] 297.0 2.954439 0.081822 -3.745356 (2.208, 3.928] 10.0 1.765640 0.024750 -1.929776In&nbsp;[302]:# Return quantile numbers grouping = pd.qcut(frame.data1, 10, labels=False) grouped = frame.data2.groupby(grouping) grouped.apply(get_stats).unstack() Out[302]: count max mean min data1 0 100.0 1.670835 -0.049902 -3.399312 1 100.0 2.628441 0.030989 -1.950098 2 100.0 2.527939 -0.067179 -2.925113 3 100.0 3.260383 0.065713 -2.315555 4 100.0 2.074345 -0.111653 -2.047939 5 100.0 2.184810 0.052130 -2.989741 6 100.0 2.458842 -0.021489 -2.223506 7 100.0 2.954439 -0.026459 -3.056990 8 100.0 2.735527 0.103406 -3.745356 9 100.0 2.377020 0.220122 -2.064111Example: &#29992;&#29305;&#23450;&#20998;&#32452;&#30340;&#20540;&#22635;&#20805;&#32570;&#22833;&#20540;&#182;In&nbsp;[303]:s = Series(np.random.randn(6)) s[::2] = np.nan s Out[303]:0 NaN 1 -0.125921 2 NaN 3 -0.884475 4 NaN 5 0.227290 dtype: float64In&nbsp;[304]:s.fillna(s.mean()) Out[304]:0 -0.261035 1 -0.125921 2 -0.261035 3 -0.884475 4 -0.261035 5 0.227290 dtype: float64In&nbsp;[305]:states = [&#39;Ohio&#39;, &#39;New York&#39;, &#39;Vermont&#39;, &#39;Florida&#39;, &#39;Oregon&#39;, &#39;Nevada&#39;, &#39;California&#39;, &#39;Idaho&#39;] group_key = [&#39;East&#39;] * 4 + [&#39;West&#39;] * 4 data = Series(np.random.randn(8), index=states) data[[&#39;Vermont&#39;, &#39;Nevada&#39;, &#39;Idaho&#39;]] = np.nan data Out[305]:Ohio 0.922264 New York -2.153545 Vermont NaN Florida -0.375842 Oregon 0.329939 Nevada NaN California 1.105913 Idaho NaN dtype: float64In&nbsp;[306]:data.groupby(group_key).mean() Out[306]:East -0.535707 West 0.717926 dtype: float64gapplydata.groupby(group_key)In&nbsp;[307]:fill_mean = lambda g: g.fillna(g.mean()) data.groupby(group_key).apply(fill_mean) Out[307]:Ohio 0.922264 New York -2.153545 Vermont -0.535707 Florida -0.375842 Oregon 0.329939 Nevada 0.717926 California 1.105913 Idaho 0.717926 dtype: float64groupbykeyvalueDataFrame ObjectIn&nbsp;[308]:fill_values = {&#39;East&#39;: 0.5, &#39;West&#39;: -1} fill_func = lambda g: g.fillna(fill_values[g.name]) data.groupby(group_key).apply(fill_func) Out[308]:Ohio 0.922264 New York -2.153545 Vermont 0.500000 Florida -0.375842 Oregon 0.329939 Nevada -1.000000 California 1.105913 Idaho -1.000000 dtype: float64Example: &#38543;&#26426;&#37319;&#26679;&#21644;&#25490;&#21015;&#182;Hearts, Spades, Clubs, DiamondsIn&nbsp;[309]:# Hearts, Spades, Clubs, Diamonds suits = [&#39;H&#39;, &#39;S&#39;, &#39;C&#39;, &#39;D&#39;] card_val = (list(range(1, 11)) + [10] * 3) * 4 base_names = [&#39;A&#39;] + range(2, 11) + [&#39;J&#39;, &#39;K&#39;, &#39;Q&#39;] cards = [] for suit in [&#39;H&#39;, &#39;S&#39;, &#39;C&#39;, &#39;D&#39;]: cards.extend(str(num) + suit for num in base_names) deck = Series(card_val, index=cards) In&nbsp;[310]:deck[:13] Out[310]:AH 1 2H 2 3H 3 4H 4 5H 5 6H 6 7H 7 8H 8 9H 9 10H 10 JH 10 KH 10 QH 10 dtype: int64In&nbsp;[311]:def draw(deck, n=5): return deck.take(np.random.permutation(len(deck))[:n]) draw(deck) Out[311]:AD 1 8C 8 5H 5 KC 10 2C 2 dtype: int64In&nbsp;[312]:get_suit = lambda card: card[-1] # last letter is suit deck.groupby(get_suit).apply(draw, n=2) Out[312]:C 2C 2 3C 3 D KD 10 8D 8 H KH 10 3H 3 S 2S 2 4S 4 dtype: int64In&nbsp;[313]:# alternatively deck.groupby(get_suit, group_keys=False).apply(draw, n=2) Out[313]:KC 10 JC 10 AD 1 5D 5 5H 5 6H 6 7S 7 KS 10 dtype: int64Example: &#20998;&#32452;&#21152;&#26435;&#24179;&#22343;&#25968;&#21644;&#30456;&#20851;&#31995;&#25968;&#182;In&nbsp;[314]:df = DataFrame({&#39;category&#39;: [&#39;a&#39;, &#39;a&#39;, &#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;b&#39;, &#39;b&#39;], &#39;data&#39;: np.random.randn(8), &#39;weights&#39;: np.random.rand(8)}) df Out[314]: category data weights 0 a 1.561587 0.957515 1 a 1.219984 0.347267 2 a -0.482239 0.581362 3 a 0.315667 0.217091 4 b -0.047852 0.894406 5 b -0.454145 0.918564 6 b -0.556774 0.277825 7 b 0.253321 0.955905In&nbsp;[315]:grouped = df.groupby(&#39;category&#39;) get_wavg = lambda g: np.average(g[&#39;data&#39;], weights=g[&#39;weights&#39;]) grouped.apply(get_wavg) Out[315]:category a 0.811643 b -0.122262 dtype: float64stockIn&nbsp;[316]:close_px = pd.read_csv(&#39;ch09/stock_px.csv&#39;, parse_dates=True, index_col=0) close_px.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; DatetimeIndex: 2214 entries, 2003-01-02 to 2011-10-14 Data columns (total 4 columns): AAPL 2214 non-null float64 MSFT 2214 non-null float64 XOM 2214 non-null float64 SPX 2214 non-null float64 dtypes: float64(4) memory usage: 86.5 KB In&nbsp;[317]:close_px[-4:] Out[317]: AAPL MSFT XOM SPX 2011-10-11 400.29 27.00 76.27 1195.54 2011-10-12 402.19 26.96 77.16 1207.25 2011-10-13 408.43 27.18 76.37 1203.66 2011-10-14 422.00 27.27 78.11 1224.58In&nbsp;[318]:rets = close_px.pct_change().dropna() spx_corr = lambda x: x.corrwith(x[&#39;SPX&#39;]) by_year = rets.groupby(lambda x: x.year) by_year.apply(spx_corr) Out[318]: AAPL MSFT XOM SPX 2003 0.541124 0.745174 0.661265 1.0 2004 0.374283 0.588531 0.557742 1.0 2005 0.467540 0.562374 0.631010 1.0 2006 0.428267 0.406126 0.518514 1.0 2007 0.508118 0.658770 0.786264 1.0 2008 0.681434 0.804626 0.828303 1.0 2009 0.707103 0.654902 0.797921 1.0 2010 0.710105 0.730118 0.839057 1.0 2011 0.691931 0.800996 0.859975 1.0lambdaIn&nbsp;[319]:# Annual correlation of Apple with Microsoft by_year.apply(lambda g: g[&#39;AAPL&#39;].corr(g[&#39;MSFT&#39;])) Out[319]:2003 0.480868 2004 0.259024 2005 0.300093 2006 0.161735 2007 0.417738 2008 0.611901 2009 0.432738 2010 0.571946 2011 0.581987 dtype: float64Example: &#20998;&#32452;&#32423;&#32447;&#22411;&#22238;&#24402;&#182;In&nbsp;[320]:import statsmodels.api as sm def regress(data, yvar, xvars): Y = data[yvar] X = data[xvars] X[&#39;intercept&#39;] = 1. result = sm.OLS(Y, X).fit() return result.params In&nbsp;[321]:by_year.apply(regress, &#39;AAPL&#39;, [&#39;SPX&#39;]) Out[321]: SPX intercept 2003 1.195406 0.000710 2004 1.363463 0.004201 2005 1.766415 0.003246 2006 1.645496 0.000080 2007 1.198761 0.003438 2008 0.968016 -0.001110 2009 0.879103 0.002954 2010 1.052608 0.001261 2011 0.806605 0.001514&#36879;&#35270;&#34920;&#21644;&#20132;&#21449;&#34920;&#182;In&nbsp;[322]:tips[:10] Out[322]: total_bill tip sex smoker day time size_ tip_pct 0 16.99 1.01 Female No Sun Dinner 2 0.059447 1 10.34 1.66 Male No Sun Dinner 3 0.160542 2 21.01 3.50 Male No Sun Dinner 3 0.166587 3 23.68 3.31 Male No Sun Dinner 2 0.139780 4 24.59 3.61 Female No Sun Dinner 4 0.146808 5 25.29 4.71 Male No Sun Dinner 4 0.186240 6 8.77 2.00 Male No Sun Dinner 2 0.228050 7 26.88 3.12 Male No Sun Dinner 4 0.116071 8 15.04 1.96 Male No Sun Dinner 2 0.130319 9 14.78 3.23 Male No Sun Dinner 2 0.218539pivot_tablemean()In&nbsp;[323]:tips.pivot_table(index=[&#39;sex&#39;, &#39;smoker&#39;]) Out[323]: size_ tip tip_pct total_bill sex smoker Female No 2.592593 2.773519 0.156921 18.105185 Yes 2.242424 2.931515 0.182150 17.977879 Male No 2.711340 3.113402 0.160669 19.791237 Yes 2.500000 3.051167 0.152771 22.284500In&nbsp;[324]:tips.pivot_table([&#39;tip_pct&#39;, &#39;size_&#39;], index=[&#39;sex&#39;, &#39;day&#39;], columns=&#39;smoker&#39;) Out[324]: tip_pct size_ smoker No Yes No Yes sex day Female Fri 0.165296 0.209129 2.500000 2.000000 Sat 0.147993 0.163817 2.307692 2.200000 Sun 0.165710 0.237075 3.071429 2.500000 Thur 0.155971 0.163073 2.480000 2.428571 Male Fri 0.138005 0.144730 2.000000 2.125000 Sat 0.162132 0.139067 2.656250 2.629630 Sun 0.158291 0.173964 2.883721 2.600000 Thur 0.165706 0.164417 2.500000 2.300000ALLIn&nbsp;[325]:tips.pivot_table([&#39;tip_pct&#39;, &#39;size_&#39;], index=[&#39;sex&#39;, &#39;day&#39;], columns=&#39;smoker&#39;, margins=True) Out[325]: tip_pct size_ smoker No Yes All No Yes All sex day Female Fri 0.165296 0.209129 0.199388 2.500000 2.000000 2.111111 Sat 0.147993 0.163817 0.156470 2.307692 2.200000 2.250000 Sun 0.165710 0.237075 0.181569 3.071429 2.500000 2.944444 Thur 0.155971 0.163073 0.157525 2.480000 2.428571 2.468750 Male Fri 0.138005 0.144730 0.143385 2.000000 2.125000 2.100000 Sat 0.162132 0.139067 0.151577 2.656250 2.629630 2.644068 Sun 0.158291 0.173964 0.162344 2.883721 2.600000 2.810345 Thur 0.165706 0.164417 0.165276 2.500000 2.300000 2.433333 All 0.159328 0.163196 0.160803 2.668874 2.408602 2.569672In&nbsp;[326]:tips.pivot_table(&#39;tip_pct&#39;, index=[&#39;sex&#39;, &#39;smoker&#39;], columns=&#39;day&#39;, aggfunc=len, margins=True) Out[326]:day Fri Sat Sun Thur All sex smoker Female No 2.0 13.0 14.0 25.0 54.0 Yes 7.0 15.0 4.0 7.0 33.0 Male No 2.0 32.0 43.0 20.0 97.0 Yes 8.0 27.0 15.0 10.0 60.0 All 19.0 87.0 76.0 62.0 244.0In&nbsp;[327]:tips.pivot_table(&#39;size_&#39;, index=[&#39;time&#39;, &#39;sex&#39;, &#39;smoker&#39;], columns=&#39;day&#39;, aggfunc=&#39;sum&#39;, fill_value=0) Out[327]:day Fri Sat Sun Thur time sex smoker Dinner Female No 2 30 43 2 Yes 8 33 10 0 Male No 4 85 124 0 Yes 12 71 39 0 Lunch Female No 3 0 0 60 Yes 6 0 0 17 Male No 0 0 0 50 Yes 5 0 0 23&#20132;&#21449;&#34920;: crosstab&#182;In&nbsp;[328]:from StringIO import StringIO data = &quot;&quot;&quot;\ Sample Gender Handedness 1 Female Right-handed 2 Male Left-handed 3 Female Right-handed 4 Male Right-handed 5 Male Left-handed 6 Male Right-handed 7 Female Right-handed 8 Female Left-handed 9 Male Right-handed 10 Female Right-handed&quot;&quot;&quot; data = pd.read_table(StringIO(data), sep=&#39;\s+&#39;) In&nbsp;[329]:data Out[329]: Sample Gender Handedness 0 1 Female Right-handed 1 2 Male Left-handed 2 3 Female Right-handed 3 4 Male Right-handed 4 5 Male Left-handed 5 6 Male Right-handed 6 7 Female Right-handed 7 8 Female Left-handed 8 9 Male Right-handed 9 10 Female Right-handed......In&nbsp;[330]:pd.crosstab(data.Gender, data.Handedness, margins=True) Out[330]:Handedness Left-handed Right-handed All Gender Female 1 4 5 Male 2 3 5 All 3 7 10In&nbsp;[331]:pd.crosstab([tips.time, tips.day], tips.smoker, margins=True) Out[331]:smoker No Yes All time day Dinner Fri 3 9 12 Sat 45 42 87 Sun 57 19 76 Thur 1 0 1 Lunch Fri 1 6 7 Thur 44 17 61 All 151 93 244Example: 2012 &#32852;&#37030;&#36873;&#20030;&#22996;&#21592;&#20250;&#25968;&#25454;&#24211;&#182;In&nbsp;[332]:fec = pd.read_csv(&#39;ch09/P00000001-ALL.csv&#39;) In&nbsp;[333]:fec.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1001731 entries, 0 to 1001730 Data columns (total 16 columns): cmte_id 1001731 non-null object cand_id 1001731 non-null object cand_nm 1001731 non-null object contbr_nm 1001731 non-null object contbr_city 1001712 non-null object contbr_st 1001727 non-null object contbr_zip 1001620 non-null object contbr_employer 988002 non-null object contbr_occupation 993301 non-null object contb_receipt_amt 1001731 non-null float64 contb_receipt_dt 1001731 non-null object receipt_desc 14166 non-null object memo_cd 92482 non-null object memo_text 97770 non-null object form_tp 1001731 non-null object file_num 1001731 non-null int64 dtypes: float64(1), int64(1), object(14) memory usage: 122.3+ MB In&nbsp;[334]:fec.ix[123456] Out[334]:cmte_id C00431445 cand_id P80003338 cand_nm Obama, Barack contbr_nm ELLMAN, IRA contbr_city TEMPE contbr_st AZ contbr_zip 852816719 contbr_employer ARIZONA STATE UNIVERSITY contbr_occupation PROFESSOR contb_receipt_amt 50 contb_receipt_dt 01-DEC-11 receipt_desc NaN memo_cd NaN memo_text NaN form_tp SA17A file_num 772372 Name: 123456, dtype: objectIn&nbsp;[335]:unique_cands = fec.cand_nm.unique() unique_cands Out[335]:array([&#39;Bachmann, Michelle&#39;, &#39;Romney, Mitt&#39;, &#39;Obama, Barack&#39;, &#34;Roemer, Charles E. &#39;Buddy&#39; III&#34;, &#39;Pawlenty, Timothy&#39;, &#39;Johnson, Gary Earl&#39;, &#39;Paul, Ron&#39;, &#39;Santorum, Rick&#39;, &#39;Cain, Herman&#39;, &#39;Gingrich, Newt&#39;, &#39;McCotter, Thaddeus G&#39;, &#39;Huntsman, Jon&#39;, &#39;Perry, Rick&#39;], dtype=object)In&nbsp;[336]:unique_cands[2] Out[336]:&#39;Obama, Barack&#39;In&nbsp;[337]:parties = {&#39;Bachmann, Michelle&#39;: &#39;Republican&#39;, &#39;Cain, Herman&#39;: &#39;Republican&#39;, &#39;Gingrich, Newt&#39;: &#39;Republican&#39;, &#39;Huntsman, Jon&#39;: &#39;Republican&#39;, &#39;Johnson, Gary Earl&#39;: &#39;Republican&#39;, &#39;McCotter, Thaddeus G&#39;: &#39;Republican&#39;, &#39;Obama, Barack&#39;: &#39;Democrat&#39;, &#39;Paul, Ron&#39;: &#39;Republican&#39;, &#39;Pawlenty, Timothy&#39;: &#39;Republican&#39;, &#39;Perry, Rick&#39;: &#39;Republican&#39;, &quot;Roemer, Charles E. &#39;Buddy&#39; III&quot;: &#39;Republican&#39;, &#39;Romney, Mitt&#39;: &#39;Republican&#39;, &#39;Santorum, Rick&#39;: &#39;Republican&#39;} In&nbsp;[338]:fec.cand_nm[123456:123461] Out[338]:123456 Obama, Barack 123457 Obama, Barack 123458 Obama, Barack 123459 Obama, Barack 123460 Obama, Barack Name: cand_nm, dtype: objectIn&nbsp;[339]:fec.cand_nm[123456:123461].map(parties) Out[339]:123456 Democrat 123457 Democrat 123458 Democrat 123459 Democrat 123460 Democrat Name: cand_nm, dtype: objectpartyIn&nbsp;[340]:# Add it as a column fec[&#39;party&#39;] = fec.cand_nm.map(parties) In&nbsp;[341]:fec[&#39;party&#39;].value_counts() Out[341]:Democrat 593746 Republican 407985 Name: party, dtype: int64In&nbsp;[342]:(fec.contb_receipt_amt &gt; 0).value_counts() Out[342]:True 991475 False 10256 Name: contb_receipt_amt, dtype: int64In&nbsp;[343]:fec = fec[fec.contb_receipt_amt &gt; 0] In&nbsp;[344]:fec_mrbo = fec[fec.cand_nm.isin([&#39;Obama, Barack&#39;, &#39;Romney, Mitt&#39;])] &#26681;&#25454;&#32844;&#19994;&#21644;&#38599;&#20027;&#32479;&#35745;&#36190;&#21161;&#20449;&#24687;&#182;In&nbsp;[345]:fec.contbr_occupation.value_counts()[:10] Out[345]:RETIRED 233990 INFORMATION REQUESTED 35107 ATTORNEY 34286 HOMEMAKER 29931 PHYSICIAN 23432 INFORMATION REQUESTED PER BEST EFFORTS 21138 ENGINEER 14334 TEACHER 13990 CONSULTANT 13273 PROFESSOR 12555 Name: contbr_occupation, dtype: int64In&nbsp;[346]:occ_mapping = { &#39;INFORMATION REQUESTED PER BEST EFFORTS&#39; : &#39;NOT PROVIDED&#39;, &#39;INFORMATION REQUESTED&#39; : &#39;NOT PROVIDED&#39;, &#39;INFORMATION REQUESTED (BEST EFFORTS)&#39; : &#39;NOT PROVIDED&#39;, &#39;C.E.O.&#39;: &#39;CEO&#39; } # If no mapping provided, return x f = lambda x: occ_mapping.get(x, x) fec.contbr_occupation = fec.contbr_occupation.map(f) getIn&nbsp;[347]:emp_mapping = { &#39;INFORMATION REQUESTED PER BEST EFFORTS&#39; : &#39;NOT PROVIDED&#39;, &#39;INFORMATION REQUESTED&#39; : &#39;NOT PROVIDED&#39;, &#39;SELF&#39; : &#39;SELF-EMPLOYED&#39;, &#39;SELF EMPLOYED&#39; : &#39;SELF-EMPLOYED&#39;, } # If no mapping provided, return x f = lambda x: emp_mapping.get(x, x) fec.contbr_employer = fec.contbr_employer.map(f) In&nbsp;[348]:by_occupation = fec.pivot_table(&#39;contb_receipt_amt&#39;, index=&#39;contbr_occupation&#39;, columns=&#39;party&#39;, aggfunc=&#39;sum&#39;) In&nbsp;[362]:over_2mm = by_occupation[by_occupation.sum(1) &gt; 2000000] over_2mm Out[362]:party Democrat Republican contbr_occupation ATTORNEY 11141982.97 7.477194e+06 CEO 2074974.79 4.211041e+06 CONSULTANT 2459912.71 2.544725e+06 ENGINEER 951525.55 1.818374e+06 EXECUTIVE 1355161.05 4.138850e+06 HOMEMAKER 4248875.80 1.363428e+07 INVESTOR 884133.00 2.431769e+06 LAWYER 3160478.87 3.912243e+05 MANAGER 762883.22 1.444532e+06 NOT PROVIDED 4866973.96 2.056547e+07 OWNER 1001567.36 2.408287e+06 PHYSICIAN 3735124.94 3.594320e+06 PRESIDENT 1878509.95 4.720924e+06 PROFESSOR 2165071.08 2.967027e+05 REAL ESTATE 528902.09 1.625902e+06 RETIRED 25305116.38 2.356124e+07 SELF-EMPLOYED 672393.40 1.640253e+06In&nbsp;[350]:over_2mm.plot(kind=&#39;barh&#39;) Out[350]:&lt;matplotlib.axes._subplots.AxesSubplot at 0x340fb4e0&gt;In&nbsp;[373]:def get_top_amounts(group, key, n=5): totals = group.groupby(key)[&#39;contb_receipt_amt&#39;].sum() # Order totals by key in descending order return totals.sort_values()[-n:] In&nbsp;[374]:grouped = fec_mrbo.groupby(&#39;cand_nm&#39;) grouped.apply(get_top_amounts, &#39;contbr_occupation&#39;, n=7) Out[374]:cand_nm contbr_occupation Obama, Barack CONSULTANT 2459912.71 LAWYER 3160478.87 PHYSICIAN 3735124.94 HOMEMAKER 4248875.80 INFORMATION REQUESTED 4866973.96 ATTORNEY 11141982.97 RETIRED 25305116.38 Romney, Mitt C.E.O. 1968386.11 EXECUTIVE 2300947.03 PRESIDENT 2491244.89 ATTORNEY 5364718.82 HOMEMAKER 8147446.22 INFORMATION REQUESTED PER BEST EFFORTS 11396894.84 RETIRED 11508473.59 Name: contb_receipt_amt, dtype: float64In&nbsp;[375]:grouped.apply(get_top_amounts, &#39;contbr_employer&#39;, n=10) Out[375]:cand_nm contbr_employer Obama, Barack MICROSOFT 215585.36 VOLUNTEER 257104.00 STUDENT 318831.45 SELF EMPLOYED 469290.00 SELF 1076531.20 HOMEMAKER 2605408.54 INFORMATION REQUESTED 5053480.37 NOT EMPLOYED 8586308.70 SELF-EMPLOYED 17080985.96 RETIRED 22694358.85 Romney, Mitt H.I.G. CAPITAL 139500.00 BARCLAYS CAPITAL 162750.00 GOLDMAN SACH &amp; CO. 238250.00 MORGAN STANLEY 267266.00 CREDIT SUISSE 281150.00 STUDENT 496490.94 SELF-EMPLOYED 7409860.98 HOMEMAKER 8147196.22 RETIRED 11506225.71 INFORMATION REQUESTED PER BEST EFFORTS 12059527.24 Name: contb_receipt_amt, dtype: float64&#26681;&#25454;&#20986;&#36164;&#39069;&#20998;&#32452;&#182;In&nbsp;[376]:bins = np.array([0, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000]) labels = pd.cut(fec_mrbo.contb_receipt_amt, bins) labels[:10] Out[376]:411 (10, 100] 412 (100, 1000] 413 (100, 1000] 414 (10, 100] 415 (10, 100] 416 (10, 100] 417 (100, 1000] 418 (10, 100] 419 (100, 1000] 420 (10, 100] Name: contb_receipt_amt, dtype: category Categories (8, object): [(0, 1] &lt; (1, 10] &lt; (10, 100] &lt; (100, 1000] &lt; (1000, 10000] &lt; (10000, 100000] &lt; (100000, 1000000] &lt; (1000000, 10000000]]In&nbsp;[377]:grouped = fec_mrbo.groupby([&#39;cand_nm&#39;, labels]) grouped.size().unstack(0) Out[377]:cand_nm Obama, Barack Romney, Mitt contb_receipt_amt (0, 1] 493.0 77.0 (1, 10] 40070.0 3681.0 (10, 100] 372280.0 31853.0 (100, 1000] 153991.0 43357.0 (1000, 10000] 22284.0 26186.0 (10000, 100000] 2.0 1.0 (100000, 1000000] 3.0 NaN (1000000, 10000000] 4.0 NaNIn&nbsp;[356]:bucket_sums = grouped.contb_receipt_amt.sum().unstack(0) bucket_sums Out[356]:cand_nm Obama, Barack Romney, Mitt contb_receipt_amt (0, 1] 318.24 77.00 (1, 10] 337267.62 29819.66 (10, 100] 20288981.41 1987783.76 (100, 1000] 54798531.46 22363381.69 (1000, 10000] 51753705.67 63942145.42 (10000, 100000] 59100.00 12700.00 (100000, 1000000] 1490683.08 NaN (1000000, 10000000] 7148839.76 NaNIn&nbsp;[357]:normed_sums = bucket_sums.div(bucket_sums.sum(axis=1), axis=0) normed_sums Out[357]:cand_nm Obama, Barack Romney, Mitt contb_receipt_amt (0, 1] 0.805182 0.194818 (1, 10] 0.918767 0.081233 (10, 100] 0.910769 0.089231 (100, 1000] 0.710176 0.289824 (1000, 10000] 0.447326 0.552674 (10000, 100000] 0.823120 0.176880 (100000, 1000000] 1.000000 NaN (1000000, 10000000] 1.000000 NaNIn&nbsp;[358]:normed_sums[:-2].plot(kind=&#39;barh&#39;, stacked=True) Out[358]:&lt;matplotlib.axes._subplots.AxesSubplot at 0x14c4db00&gt;&#26681;&#25454;&#24030;&#32479;&#35745;&#36190;&#21161;&#20449;&#24687;&#182;In&nbsp;[359]:grouped = fec_mrbo.groupby([&#39;cand_nm&#39;, &#39;contbr_st&#39;]) totals = grouped.contb_receipt_amt.sum().unstack(0).fillna(0) totals = totals[totals.sum(1) &gt; 100000] totals[:10] Out[359]:cand_nm Obama, Barack Romney, Mitt contbr_st AK 281840.15 86204.24 AL 543123.48 527303.51 AR 359247.28 105556.00 AZ 1506476.98 1888436.23 CA 23824984.24 11237636.60 CO 2132429.49 1506714.12 CT 2068291.26 3499475.45 DC 4373538.80 1025137.50 DE 336669.14 82712.00 FL 7318178.58 8338458.81Mitt is so...poorly...In&nbsp;[360]:percent = totals.div(totals.sum(1), axis=0) percent[:10] Out[360]:cand_nm Obama, Barack Romney, Mitt contbr_st AK 0.765778 0.234222 AL 0.507390 0.492610 AR 0.772902 0.227098 AZ 0.443745 0.556255 CA 0.679498 0.320502 CO 0.585970 0.414030 CT 0.371476 0.628524 DC 0.810113 0.189887 DE 0.802776 0.197224 FL 0.467417 0.532583MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(), i; for(i=0; i < all.length; i += 1) { all[i].SourceElement().parentNode.className += ' has-jax'; } });]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python data analysis learning note 09]]></title>
      <url>%2F2017%2F03%2F07%2Fpython-data-analysis-learning-note-09%2F</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[cs231n Lecture4 note]]></title>
      <url>%2F2017%2F03%2F06%2Fcs231n-Lecture4-note%2F</url>
      <content type="text"><![CDATA[IntroductionMotivation. In this section we will develop expertise with an intuitive understanding of backpropagation, which is a way of computing gradients of expressions through recursive application of chain rule. Understanding of this process and its subtleties is critical for you to understand, and effectively develop, design and debug Neural Networks.Problem statement. The core problem studied in this section is as follows: We are given some function $f(x)$ where $x$ is a vector of inputs and we are interested in computing the gradient of $f$ at $x$ (i.e. $\Delta f(x)$ ).Modularity: Sigmoid examplef(w,x) = \frac{1}{1+e^{-(w_0x_0 + w_1x_1 + w_2)}}The function is made up of multiple gates. In addition to the ones described already above (add, mul, max), there are four more:f(x) = \frac{1}{x} \hspace{1in} \rightarrow \hspace{1in} \frac{df}{dx} = -1/x^2 \\\\ f_c(x) = c + x \hspace{1in} \rightarrow \hspace{1in} \frac{df}{dx} = 1 \\\\ f(x) = e^x \hspace{1in} \rightarrow \hspace{1in} \frac{df}{dx} = e^x \\\\ f_a(x) = ax \hspace{1in} \rightarrow \hspace{1in} \frac{df}{dx} = aThe full circuit then looks as follows:In the example above, we see a long chain of function applications that operates on the result of the dot product between w,x. The function that these operations implement is called the sigmoid function $\sigma (x)$. It turns out that the derivative of the sigmoid function with respect to its input simplifies if you perform the derivation (after a fun tricky part where we add and subtract a 1 in the numerator):\sigma(x) = \frac{1}{1+e^{-x}} \\\\ \rightarrow \hspace{0.3in} \frac{d\sigma(x)}{dx} = \frac{e^{-x}}{(1+e^{-x})^2} = \left( \frac{1 + e^{-x} - 1}{1 + e^{-x}} \right) \left( \frac{1}{1+e^{-x}} \right) = \left( 1 - \sigma(x) \right) \sigma(x)As we see, the gradient turns out to simplify and becomes surprisingly simple. For example, the sigmoid expression receives the input 1.0 and computes the output 0.73 during the forward pass. The derivation above shows that the local gradient would simply be (1 - 0.73) * 0.73 ~= 0.2, as the circuit computed before (see the image above), except this way it would be done with a single, simple and efficient expression (and with less numerical issues). Therefore, in any real practical application it would be very useful to group these operations into a single gate. Lets see the backprop for this neuron in code:123456789101112w = [2,-3,-3] # assume some random weights and datax = [-1, -2]# forward passdot = w[0]*x[0] + w[1]*x[1] + w[2]f = 1.0 / (1 + math.exp(-dot)) # sigmoid function# backward pass through the neuron (backpropagation)ddot = (1 - f) * f # gradient on dot variable, using the sigmoid gradient derivationdx = [w[0] * ddot, w[1] * ddot] # backprop into xdw = [x[0] * ddot, x[1] * ddot, 1.0 * ddot] # backprop into w# we're done! we have the gradients on the inputs to the circuitImplementation protip: staged backpropagation. As shown in the code above, in practice it is always helpful to break down the forward pass into stages that are easily backpropped through. For example here we created an intermediate variable dot which holds the output of the dot product between w and x. During backward pass we then successively compute (in reverse order) the corresponding variables (e.g. ddot, and ultimately dw, dx) that hold the gradients of those variables.Backprop in practice: Staged computationSuppose that we have a function of the form:f(x,y) = \frac{x + \sigma(y)}{\sigma(x) + (x+y)^2}Here is how we would structure the forward pass of such expression:123456789101112x = 3 # example valuesy = -4# forward passsigy = 1.0 / (1 + math.exp(-y)) # sigmoid in numerator #(1)num = x + sigy # numerator #(2)sigx = 1.0 / (1 + math.exp(-x)) # sigmoid in denominator #(3)xpy = x + y #(4)xpysqr = xpy**2 #(5)den = sigx + xpysqr # denominator #(6)invden = 1.0 / den #(7)f = num * invden # done! #(8)For each row, we also highlight which part of the forward pass it refers to:123456789101112131415161718192021# backprop f = num * invdendnum = invden # gradient on numerator #(8)dinvden = num #(8)# backprop invden = 1.0 / den dden = (-1.0 / (den**2)) * dinvden #(7)# backprop den = sigx + xpysqrdsigx = (1) * dden #(6)dxpysqr = (1) * dden #(6)# backprop xpysqr = xpy**2dxpy = (2 * xpy) * dxpysqr #(5)# backprop xpy = x + ydx = (1) * dxpy #(4)dy = (1) * dxpy #(4)# backprop sigx = 1.0 / (1 + math.exp(-x))dx += ((1 - sigx) * sigx) * dsigx # Notice += !! See notes below #(3)# backprop num = x + sigydx += (1) * dnum #(2)dsigy = (1) * dnum #(2)# backprop sigy = 1.0 / (1 + math.exp(-y))dy += ((1 - sigy) * sigy) * dsigy #(1)# done! phewNotice a few things:Cache forward pass variables. To compute the backward pass it is very helpful to have some of the variables that were used in the forward pass. In practice you want to structure your code so that you cache these variables, and so that they are available during backpropagation. If this is too difficult, it is possible (but wasteful) to recompute them.Gradients add up at forks. The forward expression involves the variables x,y multiple times, so when we perform backpropagation we must be careful to use += instead of = to accumulate the gradient on these variables (otherwise we would overwrite it). This follows the multivariable chain rule in Calculus, which states that if a variable branches out to different parts of the circuit, then the gradients that flow back to it will add.Patterns in backward flowIt is interesting to note that in many cases the backward-flowing gradient can be interpreted on an intuitive level. For example, the three most commonly used gates in neural networks (add,mul,max), all have very simple interpretations in terms of how they act during backpropagation. Consider this example circuit:Looking at the diagram above as an example, we can see that:The add gate always takes the gradient on its output and distributes it equally to all of its inputs, regardless of what their values were during the forward pass. This follows from the fact that the local gradient for the add operation is simply +1.0, so the gradients on all inputs will exactly equal the gradients on the output because it will be multiplied by x1.0 (and remain unchanged). In the example circuit above, note that the + gate routed the gradient of 2.00 to both of its inputs, equally and unchanged.The max gate routes the gradient. Unlike the add gate which distributed the gradient unchanged to all its inputs, the max gate distributes the gradient (unchanged) to exactly one of its inputs (the input that had the highest value during the forward pass). This is because the local gradient for a max gate is 1.0 for the highest value, and 0.0 for all other values. In the example circuit above, the max operation routed the gradient of 2.00 to the z variable, which had a higher value than w, and the gradient on w remains zero.The multiply gate is a little less easy to interpret. Its local gradients are the input values (except switched), and this is multiplied by the gradient on its output during the chain rule. In the example above, the gradient on x is -8.00, which is -4.00 x 2.00.Unintuitive effects and their consequences. Notice that if one of the inputs to the multiply gate is very small and the other is very big, then the multiply gate will do something slightly unintuitive: it will assign a relatively huge gradient to the small input and a tiny gradient to the large input. Note that in linear classifiers where the weights are dot producted $w^T x_i$ (multiplied) with the inputs, this implies that the scale of the data has an effect on the magnitude of the gradient for the weights. For example, if you multiplied all input data examples xixi by 1000 during preprocessing, then the gradient on the weights will be 1000 times larger, and youd have to lower the learning rate by that factor to compensate. This is why preprocessing matters a lot, sometimes in subtle ways! And having intuitive understanding for how the gradients flow can help you debug some of these cases.ExtrasSome extra materials provided in here and here.Optional: [1, 2, 3]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python data analysis learning note ch08]]></title>
      <url>%2F2017%2F03%2F05%2Fpython-data-analysis-learning-note-ch08%2F</url>
      <content type="text"><![CDATA[12345678910from __future__ import divisionfrom numpy.random import randnimport numpy as npimport osimport matplotlib.pyplot as pltnp.random.seed(12345)plt.rc('figure', figsize=(10, 6))from pandas import Series, DataFrameimport pandas as pdnp.set_printoptions(precision=4)12from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "all"1%matplotlib inlinematplotlib API 1import matplotlib.pyplot as pltFigure  Subplot1fig = plt.figure()1ax1 = fig.add_subplot(2, 2, 1)12ax2 = fig.add_subplot(2, 2, 2)ax3 = fig.add_subplot(2, 2, 3)12from numpy.random import randnplt.plot(randn(50).cumsum(), 'k--')12_ = ax1.hist(randn(100), bins=20, color='k', alpha=0.3)ax2.scatter(np.arange(30), np.arange(30) + 3 * randn(30))1plt.close('all')12fig, axes = plt.subplots(2, 3)axessubplot12plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)12345fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)for i in range(2): for j in range(2): axes[i, j].hist(randn(500), bins=50, color='k', alpha=0.5)plt.subplots_adjust(wspace=0, hspace=0)(array([ 2., 0., 3., 2., 1., 1., 0., 3., 5., 8., 9., 9., 10., 18., 34., 13., 24., 30., 24., 24., 25., 20., 34., 20., 30., 30., 19., 14., 14., 8., 19., 14., 7., 3., 7., 2., 7., 2., 2., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.]), array([-2.9493, -2.8118, -2.6743, -2.5367, -2.3992, -2.2617, -2.1241, -1.9866, -1.849 , -1.7115, -1.574 , -1.4364, -1.2989, -1.1614, -1.0238, -0.8863, -0.7487, -0.6112, -0.4737, -0.3361, -0.1986, -0.0611, 0.0765, 0.214 , 0.3516, 0.4891, 0.6266, 0.7642, 0.9017, 1.0392, 1.1768, 1.3143, 1.4519, 1.5894, 1.7269, 1.8645, 2.002 , 2.1395, 2.2771, 2.4146, 2.5522, 2.6897, 2.8272, 2.9648, 3.1023, 3.2398, 3.3774, 3.5149, 3.6525, 3.79 , 3.9275]), &lt;a list of 50 Patch objects&gt;) (array([ 1., 1., 0., 2., 0., 1., 1., 5., 7., 4., 5., 8., 12., 12., 13., 15., 17., 13., 22., 30., 21., 24., 17., 20., 20., 20., 18., 26., 16., 24., 19., 8., 14., 15., 7., 11., 5., 4., 9., 7., 6., 1., 6., 2., 4., 2., 0., 2., 1., 2.]), array([-2.595 , -2.4898, -2.3845, -2.2793, -2.1741, -2.0688, -1.9636, -1.8584, -1.7531, -1.6479, -1.5427, -1.4374, -1.3322, -1.227 , -1.1217, -1.0165, -0.9112, -0.806 , -0.7008, -0.5955, -0.4903, -0.3851, -0.2798, -0.1746, -0.0694, 0.0359, 0.1411, 0.2463, 0.3516, 0.4568, 0.562 , 0.6673, 0.7725, 0.8777, 0.983 , 1.0882, 1.1935, 1.2987, 1.4039, 1.5092, 1.6144, 1.7196, 1.8249, 1.9301, 2.0353, 2.1406, 2.2458, 2.351 , 2.4563, 2.5615, 2.6667]), &lt;a list of 50 Patch objects&gt;) (array([ 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 4., 1., 4., 5., 11., 8., 6., 11., 13., 13., 17., 18., 20., 27., 32., 29., 31., 22., 21., 31., 29., 19., 22., 18., 10., 18., 11., 12., 9., 6., 2., 3., 3., 3., 2., 1., 1., 1., 0., 1.]), array([-3.7454, -3.6052, -3.4651, -3.325 , -3.1849, -3.0448, -2.9047, -2.7646, -2.6244, -2.4843, -2.3442, -2.2041, -2.064 , -1.9239, -1.7837, -1.6436, -1.5035, -1.3634, -1.2233, -1.0832, -0.9431, -0.8029, -0.6628, -0.5227, -0.3826, -0.2425, -0.1024, 0.0377, 0.1779, 0.318 , 0.4581, 0.5982, 0.7383, 0.8784, 1.0185, 1.1587, 1.2988, 1.4389, 1.579 , 1.7191, 1.8592, 1.9994, 2.1395, 2.2796, 2.4197, 2.5598, 2.6999, 2.84 , 2.9802, 3.1203, 3.2604]), &lt;a list of 50 Patch objects&gt;) (array([ 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 2., 5., 9., 8., 6., 2., 11., 17., 10., 13., 10., 14., 12., 27., 17., 28., 27., 25., 14., 24., 25., 38., 13., 24., 15., 10., 17., 14., 13., 8., 7., 10., 3., 7., 2., 5., 2., 0., 1., 1.]), array([-3.4283, -3.3066, -3.185 , -3.0633, -2.9417, -2.8201, -2.6984, -2.5768, -2.4551, -2.3335, -2.2119, -2.0902, -1.9686, -1.847 , -1.7253, -1.6037, -1.482 , -1.3604, -1.2388, -1.1171, -0.9955, -0.8739, -0.7522, -0.6306, -0.5089, -0.3873, -0.2657, -0.144 , -0.0224, 0.0993, 0.2209, 0.3425, 0.4642, 0.5858, 0.7074, 0.8291, 0.9507, 1.0724, 1.194 , 1.3156, 1.4373, 1.5589, 1.6806, 1.8022, 1.9238, 2.0455, 2.1671, 2.2887, 2.4104, 2.532 , 2.6537]), &lt;a list of 50 Patch objects&gt;) 1plt.figure()1plt.plot(randn(30).cumsum(), 'ko--')1plt.close('all')1234data = randn(30).cumsum()plt.plot(data, 'k--', label='Default')plt.plot(data, 'k-', drawstyle='steps-post', label='steps-post')plt.legend(loc='best')12345678fig = plt.figure(); ax = fig.add_subplot(1, 1, 1)ax.plot(randn(1000).cumsum())ticks = ax.set_xticks([0, 250, 500, 750, 1000])labels = ax.set_xticklabels(['one', 'two', 'three', 'four', 'five'], rotation=30, fontsize='small')ax.set_title('My first matplotlib plot')ax.set_xlabel('Stages')123456fig = plt.figure(); ax = fig.add_subplot(1, 1, 1)ax.plot(randn(1000).cumsum(), 'k', label='one')ax.plot(randn(1000).cumsum(), 'k--', label='two')ax.plot(randn(1000).cumsum(), 'k.', label='three')ax.legend(loc='best')subplot123456789101112131415161718192021222324252627from datetime import datetimefig = plt.figure()ax = fig.add_subplot(1, 1, 1)data = pd.read_csv('ch08/spx.csv', index_col=0, parse_dates=True)spx = data['SPX']spx.plot(ax=ax, style='k-')crisis_data = [ (datetime(2007, 10, 11), 'Peak of bull market'), (datetime(2008, 3, 12), 'Bear Stearns Fails'), (datetime(2008, 9, 15), 'Lehman Bankruptcy')]for date, label in crisis_data: ax.annotate(label, xy=(date, spx.asof(date) + 50), xytext=(date, spx.asof(date) + 200), arrowprops=dict(facecolor='black'), horizontalalignment='left', verticalalignment='top')# Zoom in on 2007-2010ax.set_xlim(['1/1/2007', '1/1/2011'])ax.set_ylim([600, 1800])ax.set_title('Important dates in 2008-2009 financial crisis')1234567891011fig = plt.figure()ax = fig.add_subplot(1, 1, 1)rect = plt.Rectangle((0.2, 0.75), 0.4, 0.15, color='k', alpha=0.3)circ = plt.Circle((0.7, 0.2), 0.15, color='b', alpha=0.3)pgon = plt.Polygon([[0.15, 0.15], [0.35, 0.4], [0.2, 0.6]], color='g', alpha=0.5)ax.add_patch(rect)ax.add_patch(circ)ax.add_patch(pgon)1fig1fig.savefig('figpath.svg')1fig.savefig('figpath.png', dpi=400, bbox_inches='tight')1234from io import BytesIObuffer = BytesIO()plt.savefig(buffer)plot_data = buffer.getvalue()&lt;matplotlib.figure.Figure at 0xaebe550&gt; matplotlib 1plt.rc('figure', figsize=(10, 10))pandas1plt.close('all')12s = Series(np.random.randn(10).cumsum(), index=np.arange(0, 100, 10))s.plot()1234df = DataFrame(np.random.randn(10, 4).cumsum(0), columns=['A', 'B', 'C', 'D'], index=np.arange(0, 100, 10))df.plot()1234fig, axes = plt.subplots(2, 1)data = Series(np.random.rand(16), index=list('abcdefghijklmnop'))data.plot(kind='bar', ax=axes[0], color='k', alpha=0.7)data.plot(kind='barh', ax=axes[1], color='k', alpha=0.7)12345df = DataFrame(np.random.rand(6, 4), index=['one', 'two', 'three', 'four', 'five', 'six'], columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'))dfdf.plot(kind='bar')GenusABCDone0.3016860.1563330.3719430.270731two0.7505890.5255870.6894290.358974three0.3815040.6677070.4737720.632528four0.9424080.1801860.7082840.641783five0.8402780.9095890.0100410.653207six0.0628540.5898130.8113180.0602171plt.figure()1df.plot(kind='barh', stacked=True, alpha=0.5)123456tips = pd.read_csv('ch08/tips.csv')party_counts = pd.crosstab(tips.day, tips.size_)party_counts# Not many 1- and 6-person partiesparty_counts = party_counts.ix[:, 2:5]party_countssize_123456dayFri1161100Sat253181310Sun039151831Thur1484513size_2345dayFri16110Sat5318131Sun3915183Thur4845112345# Normalize to sum to 1party_pcts = party_counts.div(party_counts.sum(1).astype(float), axis=0)party_pctsparty_pcts.plot(kind='bar', stacked=True)size_2345dayFri0.8888890.0555560.0555560.000000Sat0.6235290.2117650.1529410.011765Sun0.5200000.2000000.2400000.040000Thur0.8275860.0689660.0862070.0172411plt.figure()12tips['tip_pct'] = tips['tip'] / tips['total_bill']tips['tip_pct'].hist(bins=50)1plt.figure()1tips['tip_pct'].plot(kind='kde')1plt.figure()12345comp1 = np.random.normal(0, 1, size=200) # N(0, 1)comp2 = np.random.normal(10, 2, size=200) # N(10, 4)values = Series(np.concatenate([comp1, comp2]))values.hist(bins=100, alpha=0.3, color='k', normed=True)values.plot(kind='kde', style='k--')1234macro = pd.read_csv('ch08/macrodata.csv')data = macro[['cpi', 'm1', 'tbilrate', 'unemp']]trans_data = np.log(data).diff().dropna()trans_data[-5:]cpim1tbilrateunemp198-0.0079040.045361-0.3968810.105361199-0.0219790.066753-2.2772670.1397622000.0023400.0102860.6061360.1603432010.0084190.037461-0.2006710.1273392020.0088940.012202-0.4054650.0425601plt.figure()12plt.scatter(trans_data['m1'], trans_data['unemp'])plt.title('Changes in log %s vs. log %s' % ('m1', 'unemp'))1pd.scatter_matrix(trans_data, diagonal='kde', c='k', alpha=0.3)12data = pd.read_csv('ch08/Haiti.csv')data.info()&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 3593 entries, 0 to 3592 Data columns (total 10 columns): Serial 3593 non-null int64 INCIDENT TITLE 3593 non-null object INCIDENT DATE 3593 non-null object LOCATION 3592 non-null object DESCRIPTION 3593 non-null object CATEGORY 3587 non-null object LATITUDE 3593 non-null float64 LONGITUDE 3593 non-null float64 APPROVED 3593 non-null object VERIFIED 3593 non-null object dtypes: float64(2), int64(1), object(7) memory usage: 280.8+ KB 1data[['INCIDENT DATE', 'LATITUDE', 'LONGITUDE']][:10]INCIDENT DATELATITUDELONGITUDE005/07/2010 17:2618.233333-72.533333128/06/2010 23:0650.2260295.729886224/06/2010 16:2122.278381114.174287320/06/2010 21:5944.4070628.933989418/05/2010 16:2618.571084-72.334671526/04/2010 13:1418.593707-72.310079626/04/2010 14:1918.482800-73.638800726/04/2010 14:2718.415000-73.195000815/03/2010 10:5818.517443-72.236841915/03/2010 11:0018.547790-72.4100101data['CATEGORY'][:6]0 1. Urgences | Emergency, 3. Public Health, 1 1. Urgences | Emergency, 2. Urgences logistiqu... 2 2. Urgences logistiques | Vital Lines, 8. Autr... 3 1. Urgences | Emergency, 4 1. Urgences | Emergency, 5 5e. Communication lines down, Name: CATEGORY, dtype: object 1data.describe()SerialLATITUDELONGITUDEcount3593.0000003593.0000003593.000000mean2080.27748418.611495-72.322680std1171.1003600.7385723.650776min4.00000018.041313-74.45275725%1074.00000018.524070-72.41750050%2163.00000018.539269-72.33500075%3088.00000018.561820-72.293570max4052.00000050.226029114.174287123data = data[(data.LATITUDE &gt; 18) &amp; (data.LATITUDE &lt; 20) &amp; (data.LONGITUDE &gt; -75) &amp; (data.LONGITUDE &lt; -70) &amp; data.CATEGORY.notnull()]12345678910111213def to_cat_list(catstr): stripped = (x.strip() for x in catstr.split(',')) return [x for x in stripped if x]def get_all_categories(cat_series): cat_sets = (set(to_cat_list(x)) for x in cat_series) return sorted(set.union(*cat_sets))def get_english(cat): code, names = cat.split('.') if '|' in names: names = names.split(' | ')[1] return code, names.strip()1get_english('2. Urgences logistiques | Vital Lines')(&#39;2&#39;, &#39;Vital Lines&#39;) 12345all_cats = get_all_categories(data.CATEGORY)# Generator expressionenglish_mapping = dict(get_english(x) for x in all_cats)english_mapping['2a']english_mapping['6c']&#39;Food Shortage&#39; &#39;Earthquake and aftershocks&#39; 1234567def get_code(seq): return [x.split('.')[0] for x in seq if x]all_codes = get_code(all_cats)code_index = pd.Index(np.unique(all_codes))dummy_frame = DataFrame(np.zeros((len(data), len(code_index))), index=data.index, columns=code_index)1dummy_frame.ix[:, :6].info()&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 3569 entries, 0 to 3592 Data columns (total 6 columns): 1 3569 non-null float64 1a 3569 non-null float64 1b 3569 non-null float64 1c 3569 non-null float64 1d 3569 non-null float64 2 3569 non-null float64 dtypes: float64(6) memory usage: 195.2 KB 12345for row, cat in zip(data.index, data.CATEGORY): codes = get_code(to_cat_list(cat)) dummy_frame.ix[row, codes] = 1data = data.join(dummy_frame.add_prefix('category_'))1data.ix[:, 10:15].info()&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 3569 entries, 0 to 3592 Data columns (total 5 columns): category_1 3569 non-null float64 category_1a 3569 non-null float64 category_1b 3569 non-null float64 category_1c 3569 non-null float64 category_1d 3569 non-null float64 dtypes: float64(5) memory usage: 167.3 KB 1234567891011121314151617from mpl_toolkits.basemap import Basemapimport matplotlib.pyplot as pltdef basic_haiti_map(ax=None, lllat=17.25, urlat=20.25, lllon=-75, urlon=-71): # create polar stereographic Basemap instance. m = Basemap(ax=ax, projection='stere', lon_0=(urlon + lllon) / 2, lat_0=(urlat + lllat) / 2, llcrnrlat=lllat, urcrnrlat=urlat, llcrnrlon=lllon, urcrnrlon=urlon, resolution='f') # draw coastlines, state and country boundaries, edge of map. m.drawcoastlines() m.drawstates() m.drawcountries() return m123456789101112131415161718fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))fig.subplots_adjust(hspace=0.05, wspace=0.05)to_plot = ['2a', '1', '3c', '7a']lllat=17.25; urlat=20.25; lllon=-75; urlon=-71for code, ax in zip(to_plot, axes.flat): m = basic_haiti_map(ax, lllat=lllat, urlat=urlat, lllon=lllon, urlon=urlon) cat_data = data[data['category_%s' % code] == 1] # compute map proj coordinates. x, y = m(cat_data.LONGITUDE.values, cat_data.LATITUDE.values) m.plot(x, y, 'k.', alpha=0.5) ax.set_title('%s: %s' % (code, english_mapping[code]))C:\Users\Ewan\Anaconda3\envs\ipykernel_py2\lib\site-packages\mpl_toolkits\basemap\__init__.py:3260: MatplotlibDeprecationWarning: The ishold function was deprecated in version 2.0. b = ax.ishold() C:\Users\Ewan\Anaconda3\envs\ipykernel_py2\lib\site-packages\mpl_toolkits\basemap\__init__.py:3269: MatplotlibDeprecationWarning: axes.hold is deprecated. See the API Changes document (http://matplotlib.org/api/api_changes.html) for more details. ax.hold(b) 12345678910111213141516171819202122#shapefilepath = 'ch08/PortAuPrince_Roads/PortAuPrince_Roads'fig = plt.figure()ax = fig.add_subplot(1,1,1)lat0 = 18.533333;lon0 = -72.333333;change = 0.13;lllat=lat0-change; urlat=lat0+change; lllon=lon0-change; urlon=lon0+change;m = basic_haiti_map(ax, lllat=lllat, urlat=urlat,lllon=lllon, urlon=urlon)m.readshapefile(shapefilepath,'roads') #code = '2a'cat_data = data[data['category_%s' % code] == 1]# compute map proj coordinates.x, y = m(cat_data.LONGITUDE.values, cat_data.LATITUDE.values)m.plot(x, y, 'k.', alpha=0.5)ax.set_title('Food shortages reported in Port-au-Prince')# plt.savefig('myfig.png',dpi=400,bbox_inches='tight')(1583, 3, [-72.749246, 18.409952, 0.0, 0.0], [-71.973789, 18.7147105, 0.0, 0.0],]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[cs231n Assignment#1 softmax]]></title>
      <url>%2F2017%2F03%2F05%2Fcs231n-Assignment-1-softmax%2F</url>
      <content type="text"><![CDATA[Softmax exerciseComplete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the assignments page on the course website.This exercise is analogous to the SVM exercise. You will:implement a fully-vectorized loss function for the Softmax classifierimplement the fully-vectorized expression for its analytic gradientcheck your implementation with numerical gradientuse a validation set to tune the learning rate and regularization strengthoptimize the loss function with SGDvisualize the final learned weights12345678910111213import randomimport numpy as npfrom cs231n.data_utils import load_CIFAR10import matplotlib.pyplot as plt%matplotlib inlineplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'# for auto-reloading extenrnal modules# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython%load_ext autoreload%autoreload 21234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500): """ Load the CIFAR-10 dataset from disk and perform preprocessing to prepare it for the linear classifier. These are the same steps as we used for the SVM, but condensed to a single function. """ # Load the raw CIFAR-10 data cifar10_dir = 'cs231n/datasets/cifar-10-batches-py' X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir) # subsample the data mask = range(num_training, num_training + num_validation) X_val = X_train[mask] y_val = y_train[mask] mask = range(num_training) X_train = X_train[mask] y_train = y_train[mask] mask = range(num_test) X_test = X_test[mask] y_test = y_test[mask] mask = np.random.choice(num_training, num_dev, replace=False) X_dev = X_train[mask] y_dev = y_train[mask] # Preprocessing: reshape the image data into rows X_train = np.reshape(X_train, (X_train.shape[0], -1)) X_val = np.reshape(X_val, (X_val.shape[0], -1)) X_test = np.reshape(X_test, (X_test.shape[0], -1)) X_dev = np.reshape(X_dev, (X_dev.shape[0], -1)) # Normalize the data: subtract the mean image mean_image = np.mean(X_train, axis = 0) X_train -= mean_image X_val -= mean_image X_test -= mean_image X_dev -= mean_image # add bias dimension and transform into columns X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))]) X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))]) X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))]) X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))]) return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev# Invoke the above function to get our data.X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()print 'Train data shape: ', X_train.shapeprint 'Train labels shape: ', y_train.shapeprint 'Validation data shape: ', X_val.shapeprint 'Validation labels shape: ', y_val.shapeprint 'Test data shape: ', X_test.shapeprint 'Test labels shape: ', y_test.shapeprint 'dev data shape: ', X_dev.shapeprint 'dev labels shape: ', y_dev.shapeTrain data shape: (49000L, 3073L) Train labels shape: (49000L,) Validation data shape: (1000L, 3073L) Validation labels shape: (1000L,) Test data shape: (1000L, 3073L) Test labels shape: (1000L,) dev data shape: (500L, 3073L) dev labels shape: (500L,) Softmax ClassifierYour code for this section will all be written inside cs231n/classifiers/softmax.py.1234567891011121314# First implement the naive softmax loss function with nested loops.# Open the file cs231n/classifiers/softmax.py and implement the# softmax_loss_naive function.from cs231n.classifiers.softmax import softmax_loss_naiveimport time# Generate a random softmax weight matrix and use it to compute the loss.W = np.random.randn(3073, 10) * 0.0001loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)# As a rough sanity check, our loss should be something close to -log(0.1).print 'loss: %f' % lossprint 'sanity check: %f' % (-np.log(0.1))loss: 2.395985 sanity check: 2.302585 Inline Question 1:Why do we expect our loss to be close to -log(0.1)? Explain briefly.Your answer: Because the W is selected by random, so the probability of select the true class is 1/10. That is, 0.1.1234567891011121314# Complete the implementation of softmax_loss_naive and implement a (naive)# version of the gradient that uses nested loops.loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)# As we did for the SVM, use numeric gradient checking as a debugging tool.# The numeric gradient should be close to the analytic gradient.from cs231n.gradient_check import grad_check_sparsef = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]grad_numerical = grad_check_sparse(f, W, grad, 10)# similar to SVM case, do another gradient check with regularizationloss, grad = softmax_loss_naive(W, X_dev, y_dev, 1e2)f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 1e2)[0]grad_numerical = grad_check_sparse(f, W, grad, 10)numerical: 2.368141 analytic: 2.368141, relative error: 2.349797e-08 numerical: 1.324690 analytic: 1.324690, relative error: 7.140560e-08 numerical: 3.170412 analytic: 3.170411, relative error: 1.324741e-08 numerical: 0.249509 analytic: 0.249509, relative error: 2.647240e-08 numerical: 1.536095 analytic: 1.536095, relative error: 4.345856e-08 numerical: 1.075819 analytic: 1.075819, relative error: 3.902323e-08 numerical: -0.198098 analytic: -0.198098, relative error: 5.737134e-08 numerical: -0.089902 analytic: -0.089902, relative error: 8.604010e-07 numerical: -0.339487 analytic: -0.339487, relative error: 3.992996e-08 numerical: -4.819781 analytic: -4.819781, relative error: 3.465667e-09 numerical: 1.869922 analytic: 1.869921, relative error: 7.536693e-08 numerical: 0.783465 analytic: 0.783465, relative error: 6.960291e-08 numerical: -3.206007 analytic: -3.206007, relative error: 2.337350e-09 numerical: 0.532183 analytic: 0.532183, relative error: 1.498128e-07 numerical: 0.900500 analytic: 0.900500, relative error: 6.954913e-09 numerical: -0.353224 analytic: -0.353224, relative error: 1.836960e-07 numerical: -1.331470 analytic: -1.331470, relative error: 2.726426e-08 numerical: -0.082452 analytic: -0.082452, relative error: 7.712355e-07 numerical: -1.322133 analytic: -1.322133, relative error: 5.516628e-09 numerical: 0.345814 analytic: 0.345814, relative error: 1.251858e-07 1234567891011121314151617181920# Now that we have a naive implementation of the softmax loss function and its gradient,# implement a vectorized version in softmax_loss_vectorized.# The two versions should compute the same results, but the vectorized version should be# much faster.tic = time.time()loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.00001)toc = time.time()print 'naive loss: %e computed in %fs' % (loss_naive, toc - tic)from cs231n.classifiers.softmax import softmax_loss_vectorizedtic = time.time()loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.00001)toc = time.time()print 'vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic)# As we did for the SVM, we use the Frobenius norm to compare the two versions# of the gradient.grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')print 'Loss difference: %f' % np.abs(loss_naive - loss_vectorized)print 'Gradient difference: %f' % grad_differencenaive loss: 2.395985e+00 computed in 0.080000s vectorized loss: 2.395985e+00 computed in 0.003000s Loss difference: 0.000000 Gradient difference: 0.000000 1234567891011121314151617181920212223242526272829303132333435363738394041424344# Use the validation set to tune hyperparameters (regularization strength and# learning rate). You should experiment with different ranges for the learning# rates and regularization strengths; if you are careful you should be able to# get a classification accuracy of over 0.35 on the validation set.from cs231n.classifiers import Softmaxresults = &#123;&#125;best_val = -1best_softmax = Nonelearning_rates = [1e-8, 1e-7, 2e-7]regularization_strengths = [1e4, 2e4, 3e4, 4e4, 5e4, 6e4, 7e4, 8e4, 1e5]################################################################################# TODO: ## Use the validation set to set the learning rate and regularization strength. ## This should be identical to the validation that you did for the SVM; save ## the best trained softmax classifer in best_softmax. #################################################################################iters = 2000for lr in learning_rates: for rs in regularization_strengths: softmax = Softmax() softmax.train(X_train, y_train, learning_rate=lr, reg=rs, num_iters=iters) y_train_pred = softmax.predict(X_train) acc_train = np.mean(y_train == y_train_pred) y_val_pred = softmax.predict(X_val) acc_val = np.mean(y_val == y_val_pred) results[(lr, rs)] = (acc_train, acc_val) if best_val &lt; acc_val: best_val = acc_val best_softmax = softmax################################################################################# END OF YOUR CODE ################################################################################# # Print out results.for lr, reg in sorted(results): train_accuracy, val_accuracy = results[(lr, reg)] print 'lr %e reg %e train accuracy: %f val accuracy: %f' % ( lr, reg, train_accuracy, val_accuracy) print 'best validation accuracy achieved during cross-validation: %f' % best_vallr 1.000000e-08 reg 1.000000e+04 train accuracy: 0.175633 val accuracy: 0.179000 lr 1.000000e-08 reg 2.000000e+04 train accuracy: 0.174102 val accuracy: 0.161000 lr 1.000000e-08 reg 3.000000e+04 train accuracy: 0.203490 val accuracy: 0.210000 lr 1.000000e-08 reg 4.000000e+04 train accuracy: 0.191367 val accuracy: 0.202000 lr 1.000000e-08 reg 5.000000e+04 train accuracy: 0.208000 val accuracy: 0.197000 lr 1.000000e-08 reg 6.000000e+04 train accuracy: 0.203571 val accuracy: 0.215000 lr 1.000000e-08 reg 7.000000e+04 train accuracy: 0.213551 val accuracy: 0.215000 lr 1.000000e-08 reg 8.000000e+04 train accuracy: 0.238347 val accuracy: 0.229000 lr 1.000000e-08 reg 1.000000e+05 train accuracy: 0.245102 val accuracy: 0.242000 lr 1.000000e-07 reg 1.000000e+04 train accuracy: 0.358265 val accuracy: 0.362000 lr 1.000000e-07 reg 2.000000e+04 train accuracy: 0.356306 val accuracy: 0.374000 lr 1.000000e-07 reg 3.000000e+04 train accuracy: 0.347327 val accuracy: 0.362000 lr 1.000000e-07 reg 4.000000e+04 train accuracy: 0.336347 val accuracy: 0.354000 lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.331490 val accuracy: 0.348000 lr 1.000000e-07 reg 6.000000e+04 train accuracy: 0.320163 val accuracy: 0.336000 lr 1.000000e-07 reg 7.000000e+04 train accuracy: 0.314551 val accuracy: 0.325000 lr 1.000000e-07 reg 8.000000e+04 train accuracy: 0.313082 val accuracy: 0.324000 lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.303000 val accuracy: 0.315000 lr 2.000000e-07 reg 1.000000e+04 train accuracy: 0.374163 val accuracy: 0.389000 lr 2.000000e-07 reg 2.000000e+04 train accuracy: 0.353184 val accuracy: 0.365000 lr 2.000000e-07 reg 3.000000e+04 train accuracy: 0.340265 val accuracy: 0.359000 lr 2.000000e-07 reg 4.000000e+04 train accuracy: 0.334673 val accuracy: 0.351000 lr 2.000000e-07 reg 5.000000e+04 train accuracy: 0.326531 val accuracy: 0.337000 lr 2.000000e-07 reg 6.000000e+04 train accuracy: 0.319857 val accuracy: 0.336000 lr 2.000000e-07 reg 7.000000e+04 train accuracy: 0.317878 val accuracy: 0.329000 lr 2.000000e-07 reg 8.000000e+04 train accuracy: 0.310449 val accuracy: 0.329000 lr 2.000000e-07 reg 1.000000e+05 train accuracy: 0.316286 val accuracy: 0.315000 best validation accuracy achieved during cross-validation: 0.389000 12345# evaluate on test set# Evaluate the best softmax on test sety_test_pred = best_softmax.predict(X_test)test_accuracy = np.mean(y_test == y_test_pred)print 'softmax on raw pixels final test set accuracy: %f' % (test_accuracy, )softmax on raw pixels final test set accuracy: 0.375000 123456789101112131415# Visualize the learned weights for each classw = best_softmax.W[:-1,:] # strip out the biasw = w.reshape(32, 32, 3, 10)w_min, w_max = np.min(w), np.max(w)classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for i in xrange(10): plt.subplot(2, 5, i + 1) # Rescale the weights to be between 0 and 255 wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min) plt.imshow(wimg.astype('uint8')) plt.axis('off') plt.title(classes[i])Codes123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899import numpy as npfrom random import shuffledef softmax_loss_naive(W, X, y, reg): """ Softmax loss function, naive implementation (with loops) Inputs have dimension D, there are C classes, and we operate on minibatches of N examples. Inputs: - W: A numpy array of shape (D, C) containing weights. - X: A numpy array of shape (N, D) containing a minibatch of data. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - reg: (float) regularization strength Returns a tuple of: - loss as single float - gradient with respect to weights W; an array of same shape as W """ # Initialize the loss and gradient to zero. loss = 0.0 dW = np.zeros_like(W) ############################################################################# # TODO: Compute the softmax loss and its gradient using explicit loops. # # Store the loss in loss and the gradient in dW. If you are not careful # # here, it is easy to run into numeric instability. Don't forget the # # regularization! # ############################################################################# num_train = X.shape[0] num_classes = W.shape[1] for i in xrange(num_train): f = X[i, :].dot(W) f -= np.max(f) correct_f = f[y[i]] denom = np.sum(np.exp(f)) p = np.exp(correct_f) / denom loss += -np.log(p) for j in xrange(num_classes): if j == y[i]: dW[:, y[i]] += (np.exp(f[j]) / denom - 1) * X[i, :] else: dW[:, j] += (np.exp(f[j]) / denom) * X[i, :] loss /= num_train loss += 0.5 * reg * np.sum(W * W) dW /= num_train dW += reg * W ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, dWdef softmax_loss_vectorized(W, X, y, reg): """ Softmax loss function, vectorized version. Inputs and outputs are the same as softmax_loss_naive. """ # Initialize the loss and gradient to zero. loss = 0.0 dW = np.zeros_like(W) ############################################################################# # TODO: Compute the softmax loss and its gradient using no explicit loops. # # Store the loss in loss and the gradient in dW. If you are not careful # # here, it is easy to run into numeric instability. Don't forget the # # regularization! # ############################################################################# num_train = X.shape[0] f = X.dot(W) f = f - np.max(f, axis=1)[:, np.newaxis] loss = -np.sum( np.log(np.exp(f[np.arange(num_train), y]) / np.sum(np.exp(f), axis=1))) loss /= num_train loss += 0.5 * reg * np.sum(W * W) ind = np.zeros_like(f) ind[np.arange(num_train), y] = 1 dW = X.T.dot(np.exp(f) / np.sum(np.exp(f), axis=1, keepdims=True) - ind) dW /= num_train dW += reg * W ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, dW]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[cs231n Assignment#1 svm]]></title>
      <url>%2F2017%2F03%2F03%2Fcs231n-Assignment-1-svm%2F</url>
      <content type="text"><![CDATA[Multiclass Support Vector Machine exerciseComplete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the assignments page on the course website.In this exercise you will:implement a fully-vectorized loss function for the SVMimplement the fully-vectorized expression for its analytic gradientcheck your implementation using numerical gradientuse a validation set to tune the learning rate and regularization strengthoptimize the loss function with SGDvisualize the final learned weights123456789101112131415161718# Run some setup code for this notebook.import randomimport numpy as npfrom cs231n.data_utils import load_CIFAR10import matplotlib.pyplot as plt# This is a bit of magic to make matplotlib figures appear inline in the# notebook rather than in a new window.%matplotlib inlineplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'# Some more magic so that the notebook will reload external python modules;# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython%load_ext autoreload%autoreload 2CIFAR-10 Data Loading and Preprocessing123456789# Load the raw CIFAR-10 data.cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)# As a sanity check, we print out the size of the training and test data.print 'Training data shape: ', X_train.shapeprint 'Training labels shape: ', y_train.shapeprint 'Test data shape: ', X_test.shapeprint 'Test labels shape: ', y_test.shapeTraining data shape: (50000L, 32L, 32L, 3L) Training labels shape: (50000L,) Test data shape: (10000L, 32L, 32L, 3L) Test labels shape: (10000L,) 12345678910111213141516# Visualize some examples from the dataset.# We show a few examples of training images from each class.classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']num_classes = len(classes)samples_per_class = 7for y, cls in enumerate(classes): idxs = np.flatnonzero(y_train == y) idxs = np.random.choice(idxs, samples_per_class, replace=False) for i, idx in enumerate(idxs): plt_idx = i * num_classes + y + 1 plt.subplot(samples_per_class, num_classes, plt_idx) plt.imshow(X_train[idx].astype('uint8')) plt.axis('off') if i == 0: plt.title(cls)plt.show()1?np.random.choice1234567891011121314151617181920212223242526272829303132333435363738# Split the data into train, val, and test sets. In addition we will# create a small development set as a subset of the training data;# we can use this for development so our code runs faster.num_training = 49000num_validation = 1000num_test = 1000num_dev = 500# Our validation set will be num_validation points from the original# training set.mask = range(num_training, num_training + num_validation)X_val = X_train[mask]y_val = y_train[mask]# Our training set will be the first num_train points from the original# training set.mask = range(num_training)X_train = X_train[mask]y_train = y_train[mask]# We will also make a development set, which is a small subset of# the training set.mask = np.random.choice(num_training, num_dev, replace=False)X_dev = X_train[mask]y_dev = y_train[mask]# We use the first num_test points of the original test set as our# test set.mask = range(num_test)X_test = X_test[mask]y_test = y_test[mask]print 'Train data shape: ', X_train.shapeprint 'Train labels shape: ', y_train.shapeprint 'Validation data shape: ', X_val.shapeprint 'Validation labels shape: ', y_val.shapeprint 'Test data shape: ', X_test.shapeprint 'Test labels shape: ', y_test.shapeTrain data shape: (49000L, 32L, 32L, 3L) Train labels shape: (49000L,) Validation data shape: (1000L, 32L, 32L, 3L) Validation labels shape: (1000L,) Test data shape: (1000L, 32L, 32L, 3L) Test labels shape: (1000L,) 1234567891011# Preprocessing: reshape the image data into rowsX_train = np.reshape(X_train, (X_train.shape[0], -1))X_val = np.reshape(X_val, (X_val.shape[0], -1))X_test = np.reshape(X_test, (X_test.shape[0], -1))X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))# As a sanity check, print out the shapes of the dataprint 'Training data shape: ', X_train.shapeprint 'Validation data shape: ', X_val.shapeprint 'Test data shape: ', X_test.shapeprint 'dev data shape: ', X_dev.shapeTraining data shape: (49000L, 3072L) Validation data shape: (1000L, 3072L) Test data shape: (1000L, 3072L) dev data shape: (500L, 3072L) 1234567# Preprocessing: subtract the mean image# first: compute the image mean based on the training datamean_image = np.mean(X_train, axis=0)print mean_image[:10] # print a few of the elementsplt.figure(figsize=(4,4))plt.imshow(mean_image.reshape((32,32,3)).astype('uint8')) # visualize the mean imageplt.show()[ 130.64189796 135.98173469 132.47391837 130.05569388 135.34804082 131.75402041 130.96055102 136.14328571 132.47636735 131.48467347] 12345# second: subtract the mean image from train and test dataX_train -= mean_imageX_val -= mean_imageX_test -= mean_imageX_dev -= mean_image12345678# third: append (at the last) the bias dimension of ones (i.e. bias trick) so that our SVM# only has to worry about optimizing a single weight matrix W.X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])print X_train.shape, X_val.shape, X_test.shape, X_dev.shape(49000L, 3073L) (1000L, 3073L) (1000L, 3073L) (500L, 3073L) SVM ClassifierYour code for this section will all be written inside cs231n/classifiers/linear_svm.py.As you can see, we have prefilled the function compute_loss_naive which uses for loops to evaluate the multiclass SVM loss function.123456789# Evaluate the naive implementation of the loss we provided for you:from cs231n.classifiers.linear_svm import svm_loss_naiveimport time# generate a random SVM weight matrix of small numbersW = np.random.randn(3073, 10) * 0.0001 loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.00001)print 'loss: %f' % (loss, )loss: 8.831645 The grad returned from the function above is right now all zero. Derive and implement the gradient for the SVM cost function and implement it inline inside the function svm_loss_naive. You will find it helpful to interleave your new code inside the existing function.To check that you have correctly implemented the gradient correctly, you can numerically estimate the gradient of the loss function and compare the numeric estimate to the gradient that you computed. We have provided code that does this for you:123456789101112131415161718# Once you've implemented the gradient, recompute it with the code below# and gradient check it with the function we provided for you# Compute the loss and its gradient at W.loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.0)# Numerically compute the gradient along several randomly chosen dimensions, and# compare them with your analytically computed gradient. The numbers should match# almost exactly along all dimensions.from cs231n.gradient_check import grad_check_sparsef = lambda w: svm_loss_naive(w, X_dev, y_dev, 0.0)[0]grad_numerical = grad_check_sparse(f, W, grad)# do the gradient check once again with regularization turned on# you didn't forget the regularization gradient did you?loss, grad = svm_loss_naive(W, X_dev, y_dev, 1e2)f = lambda w: svm_loss_naive(w, X_dev, y_dev, 1e2)[0]grad_numerical = grad_check_sparse(f, W, grad)numerical: -13.865929 analytic: -13.865929, relative error: 1.283977e-12 numerical: 7.842142 analytic: 7.735021, relative error: 6.876784e-03 numerical: 3.464393 analytic: 3.464393, relative error: 9.040092e-11 numerical: -23.034911 analytic: -23.034911, relative error: 6.876266e-12 numerical: -0.185311 analytic: -0.185311, relative error: 2.538774e-10 numerical: 25.825504 analytic: 25.825504, relative error: 1.336035e-11 numerical: 4.457836 analytic: 4.457836, relative error: 1.015819e-10 numerical: 3.184691 analytic: 3.184691, relative error: 8.849109e-11 numerical: 10.428446 analytic: 10.374317, relative error: 2.601982e-03 numerical: 12.479957 analytic: 12.479957, relative error: 6.825191e-12 numerical: 12.237949 analytic: 12.326308, relative error: 3.597051e-03 numerical: 4.377103 analytic: 4.377103, relative error: 3.904758e-11 numerical: -1.951930 analytic: -1.951930, relative error: 1.432276e-10 numerical: 33.752503 analytic: 33.752503, relative error: 4.254520e-12 numerical: 11.367149 analytic: 11.367149, relative error: 1.682727e-11 numerical: 16.461879 analytic: 16.461879, relative error: 4.766805e-12 numerical: 3.814562 analytic: 3.814562, relative error: 1.087469e-10 numerical: 13.931226 analytic: 13.931226, relative error: 9.578349e-12 numerical: -27.291095 analytic: -27.395406, relative error: 1.907445e-03 numerical: -7.610407 analytic: -7.610407, relative error: 1.015282e-12 Inline Question 1:It is possible that once in a while a dimension in the gradcheck will not match exactly. What could such a discrepancy be caused by? Is it a reason for concern? What is a simple example in one dimension where a gradient check could fail? Hint: the SVM loss function is not strictly speaking differentiableYour Answer: Maybe the SVM loss function is not differentiable on that dimension1?np.max1np.sum(np.maximum(0, X_dev.dot(W) - X_dev.dot(W)[np.arange(len(y_dev)), [y_dev]].T + 1))4915.822409730994 123456789101112131415# Next implement the function svm_loss_vectorized; for now only compute the loss;# we will implement the gradient in a moment.tic = time.time()loss_naive, grad_naive = svm_loss_naive(W, X_dev, y_dev, 0.00001)toc = time.time()print 'Naive loss: %e computed in %fs' % (loss_naive, toc - tic)from cs231n.classifiers.linear_svm import svm_loss_vectorizedtic = time.time()loss_vectorized, _ = svm_loss_vectorized(W, X_dev, y_dev, 0.00001)toc = time.time()print 'Vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic)# The losses should match but your vectorized implementation should be much faster.print 'difference: %f' % (loss_naive - loss_vectorized)Naive loss: 8.831645e+00 computed in 0.071000s Vectorized loss: 8.831645e+00 computed in 0.000000s difference: 0.000000 1234567891011121314151617181920# Complete the implementation of svm_loss_vectorized, and compute the gradient# of the loss function in a vectorized way.# The naive implementation and the vectorized implementation should match, but# the vectorized version should still be much faster.tic = time.time()_, grad_naive = svm_loss_naive(W, X_dev, y_dev, 0.00001)toc = time.time()print 'Naive loss and gradient: computed in %fs' % (toc - tic)tic = time.time()_, grad_vectorized = svm_loss_vectorized(W, X_dev, y_dev, 0.00001)toc = time.time()print 'Vectorized loss and gradient: computed in %fs' % (toc - tic)# The loss is a single number, so it is easy to compare the values computed# by the two implementations. The gradient on the other hand is a matrix, so# we use the Frobenius norm to compare them.difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')print 'difference: %f' % differenceNaive loss and gradient: computed in 0.084000s Vectorized loss and gradient: computed in 0.005000s difference: 0.000000 Stochastic Gradient DescentWe now have vectorized and efficient expressions for the loss, the gradient and our gradient matches the numerical gradient. We are therefore ready to do SGD to minimize the loss.123456789# In the file linear_classifier.py, implement SGD in the function# LinearClassifier.train() and then run it with the code below.from cs231n.classifiers import LinearSVMsvm = LinearSVM()tic = time.time()loss_hist = svm.train(X_train, y_train, learning_rate=1e-7, reg=5e4, num_iters=1500, verbose=True)toc = time.time()print 'That took %fs' % (toc - tic)iteration 0 / 1500: loss 791.772037 iteration 100 / 1500: loss 286.021346 iteration 200 / 1500: loss 107.673095 iteration 300 / 1500: loss 41.812791 iteration 400 / 1500: loss 18.665578 iteration 500 / 1500: loss 10.614984 iteration 600 / 1500: loss 6.664814 iteration 700 / 1500: loss 6.509693 iteration 800 / 1500: loss 5.792204 iteration 900 / 1500: loss 4.986855 iteration 1000 / 1500: loss 5.914691 iteration 1100 / 1500: loss 5.058078 iteration 1200 / 1500: loss 5.491475 iteration 1300 / 1500: loss 5.609450 iteration 1400 / 1500: loss 5.376595 That took 5.454000s 123456# A useful debugging strategy is to plot the loss as a function of# iteration number:plt.plot(loss_hist)plt.xlabel('Iteration number')plt.ylabel('Loss value')plt.show()123456# Write the LinearSVM.predict function and evaluate the performance on both the# training and validation sety_train_pred = svm.predict(X_train)print 'training accuracy: %f' % (np.mean(y_train == y_train_pred), )y_val_pred = svm.predict(X_val)print 'validation accuracy: %f' % (np.mean(y_val == y_val_pred), )training accuracy: 0.364980 validation accuracy: 0.378000 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# Use the validation set to tune hyperparameters (regularization strength and# learning rate). You should experiment with different ranges for the learning# rates and regularization strengths; if you are careful you should be able to# get a classification accuracy of about 0.4 on the validation set.learning_rates = [1e-8, 1e-7, 2e-7]regularization_strengths = [1e4, 2e4, 3e4, 4e4, 5e4, 6e4, 7e4, 8e4, 1e5]# results is dictionary mapping tuples of the form# (learning_rate, regularization_strength) to tuples of the form# (training_accuracy, validation_accuracy). The accuracy is simply the fraction# of data points that are correctly classified.results = &#123;&#125;best_val = -1 # The highest validation accuracy that we have seen so far.best_svm = None # The LinearSVM object that achieved the highest validation rate.################################################################################# TODO: ## Write code that chooses the best hyperparameters by tuning on the validation ## set. For each combination of hyperparameters, train a linear SVM on the ## training set, compute its accuracy on the training and validation sets, and ## store these numbers in the results dictionary. In addition, store the best ## validation accuracy in best_val and the LinearSVM object that achieves this ## accuracy in best_svm. ## ## Hint: You should use a small value for num_iters as you develop your ## validation code so that the SVMs don't take much time to train; once you are ## confident that your validation code works, you should rerun the validation ## code with a larger value for num_iters. #################################################################################for learning_rate in learning_rates: for regularization_strength in regularization_strengths: svm = LinearSVM() loss_hist = svm.train( X_train, y_train, learning_rate, \ regularization_strength, num_iters=1500, batch_size=200) y_train_pred = svm.predict(X_train) y_val_pred = svm.predict(X_val) training_accuracy = np.mean(y_train == y_train_pred) validation_accuracy = np.mean(y_val == y_val_pred) results[(learning_rate, regularization_strength)] = \ (training_accuracy, validation_accuracy) if validation_accuracy &gt; best_val: best_val = validation_accuracy best_svm = svm################################################################################# END OF YOUR CODE ################################################################################# # Print out results.for lr, reg in sorted(results): train_accuracy, val_accuracy = results[(lr, reg)] print 'lr %e reg %e train accuracy: %f val accuracy: %f' % ( lr, reg, train_accuracy, val_accuracy) print 'best validation accuracy achieved during cross-validation: %f' % best_vallr 1.000000e-08 reg 1.000000e+04 train accuracy: 0.221898 val accuracy: 0.247000 lr 1.000000e-08 reg 2.000000e+04 train accuracy: 0.233653 val accuracy: 0.258000 lr 1.000000e-08 reg 3.000000e+04 train accuracy: 0.234694 val accuracy: 0.225000 lr 1.000000e-08 reg 4.000000e+04 train accuracy: 0.255959 val accuracy: 0.249000 lr 1.000000e-08 reg 5.000000e+04 train accuracy: 0.259755 val accuracy: 0.273000 lr 1.000000e-08 reg 6.000000e+04 train accuracy: 0.267408 val accuracy: 0.269000 lr 1.000000e-08 reg 7.000000e+04 train accuracy: 0.269102 val accuracy: 0.287000 lr 1.000000e-08 reg 8.000000e+04 train accuracy: 0.277102 val accuracy: 0.285000 lr 1.000000e-08 reg 1.000000e+05 train accuracy: 0.295306 val accuracy: 0.301000 lr 1.000000e-07 reg 1.000000e+04 train accuracy: 0.369388 val accuracy: 0.374000 lr 1.000000e-07 reg 2.000000e+04 train accuracy: 0.380265 val accuracy: 0.390000 lr 1.000000e-07 reg 3.000000e+04 train accuracy: 0.375490 val accuracy: 0.378000 lr 1.000000e-07 reg 4.000000e+04 train accuracy: 0.375633 val accuracy: 0.385000 lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.369694 val accuracy: 0.375000 lr 1.000000e-07 reg 6.000000e+04 train accuracy: 0.372469 val accuracy: 0.383000 lr 1.000000e-07 reg 7.000000e+04 train accuracy: 0.356000 val accuracy: 0.370000 lr 1.000000e-07 reg 8.000000e+04 train accuracy: 0.352816 val accuracy: 0.355000 lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.356796 val accuracy: 0.377000 lr 2.000000e-07 reg 1.000000e+04 train accuracy: 0.393510 val accuracy: 0.395000 lr 2.000000e-07 reg 2.000000e+04 train accuracy: 0.377020 val accuracy: 0.382000 lr 2.000000e-07 reg 3.000000e+04 train accuracy: 0.363857 val accuracy: 0.373000 lr 2.000000e-07 reg 4.000000e+04 train accuracy: 0.368714 val accuracy: 0.372000 lr 2.000000e-07 reg 5.000000e+04 train accuracy: 0.361531 val accuracy: 0.364000 lr 2.000000e-07 reg 6.000000e+04 train accuracy: 0.354714 val accuracy: 0.368000 lr 2.000000e-07 reg 7.000000e+04 train accuracy: 0.348306 val accuracy: 0.365000 lr 2.000000e-07 reg 8.000000e+04 train accuracy: 0.358082 val accuracy: 0.378000 lr 2.000000e-07 reg 1.000000e+05 train accuracy: 0.347898 val accuracy: 0.358000 best validation accuracy achieved during cross-validation: 0.395000 123456789101112131415161718192021222324# Visualize the cross-validation resultsimport mathx_scatter = [math.log10(x[0]) for x in results]y_scatter = [math.log10(x[1]) for x in results]# plot training accuracymarker_size = 100colors = [results[x][0] for x in results]plt.subplot(3, 1, 1)plt.scatter(x_scatter, y_scatter, marker_size, c=colors)plt.colorbar()plt.xlabel('log learning rate')plt.ylabel('log regularization strength')plt.title('CIFAR-10 training accuracy')# plot validation accuracycolors = [results[x][1] for x in results] # default size of markers is 20plt.subplot(3, 1, 3)plt.scatter(x_scatter, y_scatter, marker_size, c=colors)plt.colorbar()plt.xlabel('log learning rate')plt.ylabel('log regularization strength')plt.title('CIFAR-10 validation accuracy')plt.show()1234# Evaluate the best svm on test sety_test_pred = best_svm.predict(X_test)test_accuracy = np.mean(y_test == y_test_pred)print 'linear SVM on raw pixels final test set accuracy: %f' % test_accuracylinear SVM on raw pixels final test set accuracy: 0.383000 12x = np.array([[[0], [1], [2]]])np.squeeze(x)array([0, 1, 2]) 123456789101112131415# Visualize the learned weights for each class.# Depending on your choice of learning rate and regularization strength, these may# or may not be nice to look at.w = best_svm.W[:-1,:] # strip out the biasw = w.reshape(32, 32, 3, 10)w_min, w_max = np.min(w), np.max(w)classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']for i in xrange(10): plt.subplot(2, 5, i + 1) # Rescale the weights to be between 0 and 255 wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min) plt.imshow(wimg.astype('uint8')) plt.axis('off') plt.title(classes[i])Inline question 2:Describe what your visualized SVM weights look like, and offer a brief explanation for why they look they way that they do.Your answer: fill this inCodeslinear_svm.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123import numpy as npfrom random import shuffledef svm_loss_naive(W, X, y, reg): """ Structured SVM loss function, naive implementation (with loops). Inputs have dimension D, there are C classes, and we operate on minibatches of N examples. Inputs: - W: A numpy array of shape (D, C) containing weights. - X: A numpy array of shape (N, D) containing a minibatch of data. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label c, where 0 &lt;= c &lt; C. - reg: (float) regularization strength Returns a tuple of: - loss as single float - gradient with respect to weights W; an array of same shape as W """ dW = np.zeros(W.shape) # initialize the gradient as zero # compute the loss and the gradient num_classes = W.shape[1] num_train = X.shape[0] loss = 0.0 for i in xrange(num_train): scores = X[i].dot(W) correct_class_score = scores[y[i]] for j in xrange(num_classes): if j == y[i]: continue margin = scores[j] - correct_class_score + 1 # note delta = 1 if margin &gt; 0: dW[:, y[i]] -= X[i, :] dW[:, j] += X[i, :] loss += margin # Right now the loss is a sum over all training examples, but we want it # to be an average instead so we divide by num_train. loss /= num_train dW /= num_train # Add regularization to the loss. loss += 0.5 * reg * np.sum(W * W) dW += reg * W ############################################################################# # TODO: # # Compute the gradient of the loss function and store it dW. # # Rather that first computing the loss and then computing the derivative, # # it may be simpler to compute the derivative at the same time that the # # loss is being computed. As a result you may need to modify some of the # # code above to compute the gradient. # ############################################################################# return loss, dWdef svm_loss_vectorized(W, X, y, reg): """ Structured SVM loss function, vectorized implementation. Inputs and outputs are the same as svm_loss_naive. """ loss = 0.0 dW = np.zeros(W.shape) # initialize the gradient as zero ############################################################################# # TODO: # # Implement a vectorized version of the structured SVM loss, storing the # # result in loss. # ############################################################################# num_train = X.shape[0] delta = 1.0 scores = X.dot(W) correct_class_score = scores[np.arange(num_train), y] margins = np.maximum( 0, scores - correct_class_score[:, np.newaxis] + delta) margins[np.arange(num_train), y] = 0 loss = np.sum(margins) loss /= num_train loss += 0.5 * reg * np.sum(W.T.dot(W)) ############################################################################# # END OF YOUR CODE # ############################################################################# ############################################################################# # TODO: # # Implement a vectorized version of the gradient for the structured SVM # # loss, storing the result in dW. # # # # Hint: Instead of computing the gradient from scratch, it may be easier # # to reuse some of the intermediate values that you used to compute the # # loss. # ############################################################################# X_mask = np.zeros(margins.shape) X_mask[margins &gt; 0] = 1 count = np.sum(X_mask, axis=1) X_mask[np.arange(num_train), y] = -count dW = X.T.dot(X_mask) dW /= num_train dW += np.multiply(W, reg) ############################################################################# # END OF YOUR CODE # ############################################################################# return loss, dWlinear_classifier123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134import numpy as npfrom cs231n.classifiers.linear_svm import *from cs231n.classifiers.softmax import *class LinearClassifier(object): def __init__(self): self.W = None def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_iters=100, batch_size=200, verbose=False): """ Train this linear classifier using stochastic gradient descent. Inputs: - X: A numpy array of shape (N, D) containing training data; there are N training samples each of dimension D. - y: A numpy array of shape (N,) containing training labels; y[i] = c means that X[i] has label 0 &lt;= c &lt; C for C classes. - learning_rate: (float) learning rate for optimization. - reg: (float) regularization strength. - num_iters: (integer) number of steps to take when optimizing - batch_size: (integer) number of training examples to use at each step. - verbose: (boolean) If true, print progress during optimization. Outputs: A list containing the value of the loss function at each training iteration. """ num_train, dim = X.shape num_classes = np.max(y) + 1 # assume y takes values 0...K-1 where K is number of classes if self.W is None: # lazily initialize W self.W = 0.001 * np.random.randn(dim, num_classes) # Run stochastic gradient descent to optimize W loss_history = [] for it in xrange(num_iters): X_batch = None y_batch = None ######################################################################### # TODO: # # Sample batch_size elements from the training data and their # # corresponding labels to use in this round of gradient descent. # # Store the data in X_batch and their corresponding labels in # # y_batch; after sampling X_batch should have shape (dim, batch_size) # # and y_batch should have shape (batch_size,) # # # # Hint: Use np.random.choice to generate indices. Sampling with # # replacement is faster than sampling without replacement. # ######################################################################### mask = np.random.choice(num_train, batch_size, replace=True) X_batch = X[mask] y_batch = y[mask] ######################################################################### # END OF YOUR CODE # ######################################################################### # evaluate loss and gradient loss, grad = self.loss(X_batch, y_batch, reg) loss_history.append(loss) # perform parameter update ######################################################################### # TODO: # # Update the weights using the gradient and the learning rate. # ######################################################################### self.W = self.W - learning_rate * grad ######################################################################### # END OF YOUR CODE # ######################################################################### if verbose and it % 100 == 0: print 'iteration %d / %d: loss %f' % (it, num_iters, loss) return loss_history def predict(self, X): """ Use the trained weights of this linear classifier to predict labels for data points. Inputs: - X: D x N array of training data. Each column is a D-dimensional point. Returns: - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional array of length N, and each element is an integer giving the predicted class. """ X = X.T y_pred = np.zeros(X.shape[1]) ########################################################################### # TODO: # # Implement this method. Store the predicted labels in y_pred. # ########################################################################### scores = X.T.dot(self.W) y_pred = np.argsort(scores, axis=1)[:, -1] ########################################################################### # END OF YOUR CODE # ########################################################################### return y_pred def loss(self, X_batch, y_batch, reg): """ Compute the loss function and its derivative. Subclasses will override this. Inputs: - X_batch: A numpy array of shape (N, D) containing a minibatch of N data points; each point has dimension D. - y_batch: A numpy array of shape (N,) containing labels for the minibatch. - reg: (float) regularization strength. Returns: A tuple containing: - loss as a single float - gradient with respect to self.W; an array of the same shape as W """ passclass LinearSVM(LinearClassifier): """ A subclass that uses the Multiclass SVM loss function """ def loss(self, X_batch, y_batch, reg): return svm_loss_vectorized(self.W, X_batch, y_batch, reg)class Softmax(LinearClassifier): """ A subclass that uses the Softmax + Cross-entropy loss function """ def loss(self, X_batch, y_batch, reg): return softmax_loss_vectorized(self.W, X_batch, y_batch, reg)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[cs231n Assignment#1 kNN]]></title>
      <url>%2F2017%2F03%2F02%2Fcs231n-Assignment-1-kNN%2F</url>
      <content type="text"><![CDATA[k-Nearest Neighbor (kNN) exerciseComplete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the assignments page on the course website.The kNN classifier consists of two stages:During training, the classifier takes the training data and simply remembers itDuring testing, kNN classifies every test image by comparing to all training images and transfering the labels of the k most similar training examplesThe value of k is cross-validatedIn this exercise you will implement these steps and understand the basic Image Classification pipeline, cross-validation, and gain proficiency in writing efficient, vectorized code.123456789101112131415161718# Run some setup code for this notebook.import randomimport numpy as npfrom cs231n.data_utils import load_CIFAR10import matplotlib.pyplot as plt# This is a bit of magic to make matplotlib figures appear inline in the notebook# rather than in a new window.%matplotlib inlineplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'# Some more magic so that the notebook will reload external python modules;# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython%load_ext autoreload%autoreload 2123456789# Load the raw CIFAR-10 data.cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)# As a sanity check, we print out the size of the training and test data.print 'Training data shape: ', X_train.shapeprint 'Training labels shape: ', y_train.shapeprint 'Test data shape: ', X_test.shapeprint 'Test labels shape: ', y_test.shapeTraining data shape: (50000L, 32L, 32L, 3L) Training labels shape: (50000L,) Test data shape: (10000L, 32L, 32L, 3L) Test labels shape: (10000L,) 12345678910111213141516# Visualize some examples from the dataset.# We show a few examples of training images from each class.classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']num_classes = len(classes)samples_per_class = 7for y, cls in enumerate(classes): idxs = np.flatnonzero(y_train == y) idxs = np.random.choice(idxs, samples_per_class, replace=False) for i, idx in enumerate(idxs): plt_idx = i * num_classes + y + 1 plt.subplot(samples_per_class, num_classes, plt_idx) plt.imshow(X_train[idx].astype('uint8')) plt.axis('off') if i == 0: plt.title(cls)plt.show()12345678910# Subsample the data for more efficient code execution in this exercisenum_training = 5000mask = range(num_training)X_train = X_train[mask]y_train = y_train[mask]num_test = 500mask = range(num_test)X_test = X_test[mask]y_test = y_test[mask]1234# Reshape the image data into rowsX_train = np.reshape(X_train, (X_train.shape[0], -1)) # Wow~X_test = np.reshape(X_test, (X_test.shape[0], -1))print X_train.shape, X_test.shape(5000L, 3072L) (500L, 3072L) 1234567from cs231n.classifiers import KNearestNeighbor# Create a kNN classifier instance. # Remember that training a kNN classifier is a noop: # the Classifier simply remembers the data and does no further processing classifier = KNearestNeighbor()classifier.train(X_train, y_train)We would now like to classify the test data with the kNN classifier. Recall that we can break down this process into two steps:First we must compute the distances between all test examples and all train examples.Given these distances, for each test example we find the k nearest examples and have them vote for the labelLets begin with computing the distance matrix between all training and test examples. For example, if there are Ntr training examples and Nte test examples, this stage should result in a Nte x Ntr matrix where each element (i,j) is the distance between the i-th test and j-th train example.First, open cs231n/classifiers/k_nearest_neighbor.py and implement the function compute_distances_two_loops that uses a (very inefficient) double loop over all pairs of (test, train) examples and computes the distance matrix one element at a time.123456# Open cs231n/classifiers/k_nearest_neighbor.py and implement# compute_distances_two_loops.# Test your implementation:dists = classifier.compute_distances_two_loops(X_test)print dists.shape(500L, 5000L) 1234# We can visualize the distance matrix: each row is a single test example and# its distances to training examplesplt.imshow(dists, interpolation='none')plt.show()Inline Question #1: Notice the structured patterns in the distance matrix, where some rows or columns are visible brighter. (Note that with the default color scheme black indicates low distances while white indicates high distances.)What in the data is the cause behind the distinctly bright rows?What causes the columns?Your Answer: Maybe exists noises in test data set and train data set.12345678# Now implement the function predict_labels and run the code below:# We use k = 1 (which is Nearest Neighbor).y_test_pred = classifier.predict_labels(dists, k=1)# Compute and print the fraction of correctly predicted examplesnum_correct = np.sum(y_test_pred == y_test)accuracy = float(num_correct) / num_testprint 'Got %d / %d correct =&gt; accuracy: %f' % (num_correct, num_test, accuracy)Got 137 / 500 correct =&gt; accuracy: 0.274000 You should expect to see approximately 27% accuracy. Now lets try out a larger k, say k = 5:1234y_test_pred = classifier.predict_labels(dists, k=5)num_correct = np.sum(y_test_pred == y_test)accuracy = float(num_correct) / num_testprint 'Got %d / %d correct =&gt; accuracy: %f' % (num_correct, num_test, accuracy)Got 142 / 500 correct =&gt; accuracy: 0.284000 You should expect to see a slightly better performance than with k = 1.1234567891011121314151617# Now lets speed up distance matrix computation by using partial vectorization# with one loop. Implement the function compute_distances_one_loop and run the# code below:dists_one = classifier.compute_distances_one_loop(X_test)# To ensure that our vectorized implementation is correct, we make sure that it# agrees with the naive implementation. There are many ways to decide whether# two matrices are similar; one of the simplest is the Frobenius norm. In case# you haven't seen it before, the Frobenius norm of two matrices is the square# root of the squared sum of differences of all elements; in other words, reshape# the matrices into vectors and compute the Euclidean distance between them.difference = np.linalg.norm(dists - dists_one, ord='fro')print 'Difference was: %f' % (difference, )if difference &lt; 0.001: print 'Good! The distance matrices are the same'else: print 'Uh-oh! The distance matrices are different'Difference was: 0.000000 Good! The distance matrices are the same 1234567891011# Now implement the fully vectorized version inside compute_distances_no_loops# and run the codedists_two = classifier.compute_distances_no_loops(X_test)# check that the distance matrix agrees with the one we computed before:difference = np.linalg.norm(dists - dists_two, ord='fro')print 'Difference was: %f' % (difference, )if difference &lt; 0.001: print 'Good! The distance matrices are the same'else: print 'Uh-oh! The distance matrices are different'Difference was: 0.000000 Good! The distance matrices are the same 123456789101112131415161718192021# Let's compare how fast the implementations aredef time_function(f, *args): """ Call a function f with args and return the time (in seconds) that it took to execute. """ import time tic = time.time() f(*args) toc = time.time() return toc - tictwo_loop_time = time_function(classifier.compute_distances_two_loops, X_test)print 'Two loop version took %f seconds' % two_loop_timeone_loop_time = time_function(classifier.compute_distances_one_loop, X_test)print 'One loop version took %f seconds' % one_loop_timeno_loop_time = time_function(classifier.compute_distances_no_loops, X_test)print 'No loop version took %f seconds' % no_loop_time# you should see significantly faster performance with the fully vectorized implementationTwo loop version took 27.001000 seconds One loop version took 59.630000 seconds No loop version took 0.205000 seconds Cross-validationWe have implemented the k-Nearest Neighbor classifier but we set the value k = 5 arbitrarily. We will now determine the best value of this hyperparameter with cross-validation.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758num_folds = 5k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]X_train_folds = []y_train_folds = []################################################################################# TODO: ## Split up the training data into folds. After splitting, X_train_folds and ## y_train_folds should each be lists of length num_folds, where ## y_train_folds[i] is the label vector for the points in X_train_folds[i]. ## Hint: Look up the numpy array_split function. #################################################################################X_train_folds = np.array_split(X_train, num_folds)y_train_folds = np.array_split(y_train, num_folds)################################################################################# END OF YOUR CODE ################################################################################## A dictionary holding the accuracies for different values of k that we find# when running cross-validation. After running cross-validation,# k_to_accuracies[k] should be a list of length num_folds giving the different# accuracy values that we found when using that value of k.k_to_accuracies = &#123;&#125;################################################################################# TODO: ## Perform k-fold cross validation to find the best value of k. For each ## possible value of k, run the k-nearest-neighbor algorithm num_folds times, ## where in each case you use all but one of the folds as training data and the ## last fold as a validation set. Store the accuracies for all fold and all ## values of k in the k_to_accuracies dictionary. #################################################################################for k in k_choices: k_to_accuracies[k] = [] for fold in xrange(num_folds): train_X = np.append( X_train_folds[:fold], X_train_folds[fold+1:]).reshape( (X_train.shape[0] - X_train.shape[0]/num_folds, -1)) train_y = np.append( y_train_folds[:fold], y_train_folds[fold+1:]).reshape( (y_train.shape[0] - y_train.shape[0]/num_folds, -1)).flatten() classifier.train(train_X, train_y) dists = classifier.compute_distances_no_loops(X_train_folds[fold]) y_test_pred = classifier.predict_labels(dists, k) num_correct = np.sum(y_test_pred == y_train_folds[fold]) accuracy = float(num_correct) / len(y_train_folds[fold]) k_to_accuracies[k].append(accuracy) ################################################################################# END OF YOUR CODE ################################################################################## Print out the computed accuraciesfor k in sorted(k_to_accuracies): for accuracy in k_to_accuracies[k]: print 'k = %d, accuracy = %f' % (k, accuracy)k = 1, accuracy = 0.263000 k = 1, accuracy = 0.257000 k = 1, accuracy = 0.264000 k = 1, accuracy = 0.278000 k = 1, accuracy = 0.266000 k = 3, accuracy = 0.241000 k = 3, accuracy = 0.249000 k = 3, accuracy = 0.243000 k = 3, accuracy = 0.273000 k = 3, accuracy = 0.264000 k = 5, accuracy = 0.258000 k = 5, accuracy = 0.273000 k = 5, accuracy = 0.281000 k = 5, accuracy = 0.290000 k = 5, accuracy = 0.272000 k = 8, accuracy = 0.263000 k = 8, accuracy = 0.288000 k = 8, accuracy = 0.278000 k = 8, accuracy = 0.285000 k = 8, accuracy = 0.277000 k = 10, accuracy = 0.265000 k = 10, accuracy = 0.296000 k = 10, accuracy = 0.278000 k = 10, accuracy = 0.284000 k = 10, accuracy = 0.286000 k = 12, accuracy = 0.260000 k = 12, accuracy = 0.294000 k = 12, accuracy = 0.281000 k = 12, accuracy = 0.282000 k = 12, accuracy = 0.281000 k = 15, accuracy = 0.255000 k = 15, accuracy = 0.290000 k = 15, accuracy = 0.281000 k = 15, accuracy = 0.281000 k = 15, accuracy = 0.276000 k = 20, accuracy = 0.270000 k = 20, accuracy = 0.281000 k = 20, accuracy = 0.280000 k = 20, accuracy = 0.282000 k = 20, accuracy = 0.284000 k = 50, accuracy = 0.271000 k = 50, accuracy = 0.288000 k = 50, accuracy = 0.278000 k = 50, accuracy = 0.269000 k = 50, accuracy = 0.266000 k = 100, accuracy = 0.256000 k = 100, accuracy = 0.270000 k = 100, accuracy = 0.263000 k = 100, accuracy = 0.256000 k = 100, accuracy = 0.263000 12345678910111213# plot the raw observationsfor k in k_choices: accuracies = k_to_accuracies[k] plt.scatter([k] * len(accuracies), accuracies)# plot the trend line with error bars that correspond to standard deviationaccuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)plt.title('Cross-validation on k')plt.xlabel('k')plt.ylabel('Cross-validation accuracy')plt.show()12345678910111213# Based on the cross-validation results above, choose the best value for k, # retrain the classifier using all the training data, and test it on the test# data. You should be able to get above 28% accuracy on the test data.best_k = 10classifier = KNearestNeighbor()classifier.train(X_train, y_train)y_test_pred = classifier.predict(X_test, k=best_k)# Compute and display the accuracynum_correct = np.sum(y_test_pred == y_test)accuracy = float(num_correct) / num_testprint 'Got %d / %d correct =&gt; accuracy: %f' % (num_correct, num_test, accuracy)Got 139 / 500 correct =&gt; accuracy: 0.278000 k_nearest_neighbor.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186import numpy as npimport operatorclass KNearestNeighbor(object): """ a kNN classifier with L2 distance """ def __init__(self): pass def train(self, X, y): """ Train the classifier. For k-nearest neighbors this is just memorizing the training data. Inputs: - X: A numpy array of shape (num_train, D) containing the training data consisting of num_train samples each of dimension D. - y: A numpy array of shape (N,) containing the training labels, where y[i] is the label for X[i]. """ self.X_train = X self.y_train = y def predict(self, X, k=1, num_loops=0): """ Predict labels for test data using this classifier. Inputs: - X: A numpy array of shape (num_test, D) containing test data consisting of num_test samples each of dimension D. - k: The number of nearest neighbors that vote for the predicted labels. - num_loops: Determines which implementation to use to compute distances between training points and testing points. Returns: - y: A numpy array of shape (num_test,) containing predicted labels for the test data, where y[i] is the predicted label for the test point X[i]. """ if num_loops == 0: dists = self.compute_distances_no_loops(X) elif num_loops == 1: dists = self.compute_distances_one_loop(X) elif num_loops == 2: dists = self.compute_distances_two_loops(X) else: raise ValueError('Invalid value %d for num_loops' % num_loops) return self.predict_labels(dists, k=k) def compute_distances_two_loops(self, X): """ Compute the distance between each test point in X and each training point in self.X_train using a nested loop over both the training data and the test data. Inputs: - X: A numpy array of shape (num_test, D) containing test data. Returns: - dists: A numpy array of shape (num_test, num_train) where dists[i, j] is the Euclidean distance between the ith test point and the jth training point. """ num_test = X.shape[0] num_train = self.X_train.shape[0] dists = np.zeros((num_test, num_train)) for i in xrange(num_test): for j in xrange(num_train): ############################################################### # TODO: # # Compute the l2 distance between the ith test point and the jth # # training point, and store the result in dists[i, j]. You should # # not use a loop over dimension. # ############################################################### dists[i, j] = np.sqrt(np.sum((X[i, :] - self.X_train[j, :]) ** 2)) ############################################################### # END OF YOUR CODE # ############################################################### return dists def compute_distances_one_loop(self, X): """ Compute the distance between each test point in X and each training point in self.X_train using a single loop over the test data. Input / Output: Same as compute_distances_two_loops """ num_test = X.shape[0] num_train = self.X_train.shape[0] dists = np.zeros((num_test, num_train)) for i in xrange(num_test): ################################################################### # TODO: # # Compute the l2 distance between the ith test point and all training # # points, and store the result in dists[i, :]. # ################################################################### dists[i, :] = np.sqrt(np.sum(np.square(X[i, :] - self.X_train), axis=1)) ################################################################### # END OF YOUR CODE # ################################################################### return dists def compute_distances_no_loops(self, X): """ Compute the distance between each test point in X and each training point in self.X_train using no explicit loops. Input / Output: Same as compute_distances_two_loops """ num_test = X.shape[0] num_train = self.X_train.shape[0] dists = np.zeros((num_test, num_train)) ####################################################################### # TODO: # # Compute the l2 distance between all test points and all training # # points without using any explicit loops, and store the result in # # dists. # # # # You should implement this function using only basic array operations; # # in particular you should not use functions from scipy. # # # # HINT: Try to formulate the l2 distance using matrix multiplication # # and two broadcast sums. # ####################################################################### dists = np.sqrt(np.multiply(np.dot(X, self.X_train.T), -2) + np.sum(self.X_train ** 2, axis=1) + np.sum(X ** 2, axis=1)[:, np.newaxis]) ####################################################################### # END OF YOUR CODE # ####################################################################### return dists def predict_labels(self, dists, k=1): """ Given a matrix of distances between test points and training points, predict a label for each test point. Inputs: - dists: A numpy array of shape (num_test, num_train) where dists[i, j] gives the distance betwen the ith test point and the jth training point. Returns: - y: A numpy array of shape (num_test,) containing predicted labels for the test data, where y[i] is the predicted label for the test point X[i]. """ num_test = dists.shape[0] y_pred = np.zeros(num_test) for i in xrange(num_test): # A list of length k storing the labels of the k nearest neighbors to # the ith test point. closest_y = [] ################################################################### # TODO: # # Use the distance matrix to find the k nearest neighbors of the ith # # testing point, and use self.y_train to find the labels of these # # neighbors. Store these labels in closest_y. # # Hint: Look up the function numpy.argsort. # ################################################################### k_nearest_index = np.argsort(dists[i, :])[:k] ################################################################### # TODO: # # Now that you have found the labels of the k nearest neighbors, you # # need to find the most common label in the list closest_y of labels. # # Store this label in y_pred[i]. Break ties by choosing the smaller # # label. # ################################################################### closest_y = self.y_train[k_nearest_index] labels_counts = &#123;&#125; for label in closest_y: if label in labels_counts.keys(): labels_counts[label] += 1 else: labels_counts[label] = 0 sorted_labels_counts = sorted( labels_counts.items(), key=operator.itemgetter(1), reverse=True) y_pred[i] = sorted_labels_counts[0][0] ################################################################### # END OF YOUR CODE # ################################################################### return y_pred]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CS231n Lecture3 note]]></title>
      <url>%2F2017%2F03%2F02%2FCS231n-Lecture3-note%2F</url>
      <content type="text"><![CDATA[Loss functionSource is here.Multiclass Support Vector Machine lossThe SVM loss is set up so that the SVM wants the correct class for each image to a have a score higher than the incorrect classes by some fixed margin $\Delta$The Multiclass SVM loss for the i-th example is formalized as follows:Example$s = [13, -7, 11]$ and $\Delta = 10$, then,L_i = \max(0, -7 - 13 + 10) + \max(0, 11 - 13 + 10)In summary, the SVM loss function wants the score of the correct class $y_i$ to be larger than the incorrect class scores by at least by $\Delta$ (delta). If this is not the case, we will accumulate loss.Note that $f(x_i; W) = W x_i$, so we can also rewrite the loss function in this equivalent form:L_i = \sum_{j\neq y_i} \max(0, w_j^T x_i - w_{y_i}^T x_i + \Delta)A last piece of terminology well mention before we finish with this section is that the threshold at zero $\max(0,)$ function is often called the hinge loss. Youll sometimes hear about people instead using the squared hinge loss SVM (or L2-SVM), which uses the form $\max(0,)^2$ that penalizes violated margins more strongly (quadratically instead of linearly). The unsquared version is more standard, but in some datasets the squared hinge loss can work better. This can be determined during cross-validation.The follow image shows the motivation of the SVM loss functionRegularizationThere is one bug with the loss function we presented above. Suppose that we have a dataset and a set of parameters W that correctly classify every example (i.e. all scores are so that all the margins are met, and $L_i=0$ for all i). The issue is that this set of W is not necessarily unique: there might be many similar W that correctly classify the examples. One easy way to see this is that if some parameters W correctly classify all examples (so loss is zero for each example), then any multiple of these parameters $\lambda W$ where $\lambda &gt; 1$ will also give zero loss because this transformation uniformly stretches all score magnitudes and hence also their absolute differences. For example, if the difference in scores between a correct class and a nearest incorrect class was 15, then multiplying all elements of W by 2 would make the new difference 30.We can avoid this by extending the loss function with a regularization penalty $R(W)$. The most common regularization penalty is the L2 norm:R(W) = \sum_k\sum_l W_{k,l}^2That is, the full Multiclass SVM loss becomes:L = \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \lambda R(W) }_\text{regularization loss} \\\\Or expanding this out in its full form:L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] + \lambda \sum_k\sum_l W_{k,l}^2Including the L2 penalty leads to the appealing max margin property in SVMs (See CS229 lecture notes for full details if you are interested).The most appealing property is that penalizing large weights tends to improve generalization, because it means that no input dimension can have a very large influence on the scores all by itself. For example, suppose that we have some input vector $x=[1,1,1,1]$ and two weight vectors $w_1=[1,0,0,0]$, $w_2=[0.25,0.25,0.25,0.25]$. Then $w^T_1x=w^T_2x=1$ so both weight vectors lead to the same dot product, but the L2 penalty of $w_1$ is 1.0 while the L2 penalty of $w_2$ is only 0.25. Therefore, according to the L2 penalty the weight vector $w_2$ would be preferred since it achieves a lower regularization loss. Intuitively, this is because the weights in $w_2$ are smaller and more diffuse. Since the L2 penalty prefers smaller and more diffuse weight vectors, the final classifier is encouraged to take into account all input dimensions to small amounts rather than a few input dimensions and very strongly. As we will see later in the class, this effect can improve the generalization performance of the classifiers on test images and lead to less overfitting.Code12345678910111213141516171819202122232425262728293031323334353637383940414243444546def L_i(x, y, W): """ unvectorized version. Compute the multiclass svm loss for a single example (x,y) - x is a column vector representing an image (e.g. 3073 x 1 in CIFAR-10) with an appended bias dimension in the 3073-rd position (i.e. bias trick) - y is an integer giving index of correct class (e.g. between 0 and 9 in CIFAR-10) - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10) """ delta = 1.0 # see notes about delta later in this section scores = W.dot(x) # scores becomes of size 10 x 1, the scores for each class correct_class_score = scores[y] D = W.shape[0] # number of classes, e.g. 10 loss_i = 0.0 for j in xrange(D): # iterate over all wrong classes if j == y: # skip for the true class to only loop over incorrect classes continue # accumulate loss for the i-th example loss_i += max(0, scores[j] - correct_class_score + delta) return loss_idef L_i_vectorized(x, y, W): """ A faster half-vectorized implementation. half-vectorized refers to the fact that for a single example the implementation contains no for loops, but there is still one loop over the examples (outside this function) """ delta = 1.0 scores = W.dot(x) # compute the margins for all classes in one vector operation margins = np.maximum(0, scores - scores[y] + delta) # on y-th position scores[y] - scores[y] canceled and gave delta. We want # to ignore the y-th position and only consider margin on max wrong class margins[y] = 0 loss_i = np.sum(margins) return loss_idef L(X, y, W): """ fully-vectorized implementation : - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10) - y is array of integers specifying correct class (e.g. 50,000-D array) - W are weights (e.g. 10 x 3073) """ # evaluate loss over all examples in X without using any for loops # left as exercise to reader in the assignmentPractice ConsiderationsSetting DeltaNote that we brushed over the hyperparameter $\Delta$ and its setting. What value should it be set to, and do we have to cross-validate it? It turns out that this hyperparameter can safely be set to $\Delta = 1.0$ in all cases. The hyperparameters $\Delta$ and $\lambda$ seem like two different hyperparameters, but in fact they both control the same tradeoff: The tradeoff between the data loss and the regularization loss in the objective. The key to understanding this is that the magnitude of the weights W has direct effect on the scores (and hence also their differences): As we shrink all values inside W the score differences will become lower, and as we scale up the weights the score differences will all become higher. Therefore, the exact value of the margin between the scores (e.g. $\Delta = 10$, or$\Delta = 100$) is in some sense meaningless because the weights can shrink or stretch the differences arbitrarily. Hence, the only real tradeoff is how large we allow the weights to grow (through the regularization strength $\lambda$).Softmax classifierIn the Softmax classifier, the function mapping $f(x_i; W) = W x_i$ stays unchanged, but we now interpret these scores as the unnormalized log probabilities for each class and replace the hinge loss with a cross-entropy loss that has the form:L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L_i = -f_{y_i} + \log\sum_j e^{f_j}The function $f_j(z) = \frac{e^{z_j}}{\sum_k e^{z_k}}$ is called the softmax function.Information theory viewThe cross-entropy between a true distribution $p$ and an estimated distribution $q$ is defined as:H(p,q) = - \sum_x p(x) \log q(x)The Softmax classifier is hence minimizing the cross-entropy between the estimated class probabilities ( $q = e^{f_{y_i}} / \sum_j e^{f_j}$ as seen above) and the true distribution, which in this interpretation is the distribution where all probability mass is on the correct class (i.e. $p = [0, \ldots 1, \ldots, 0]$ contains a single 1 at the $y_i$ -th position.).Moreover, since the cross-entropy can be written in terms of entropy and the Kullback-Leibler divergence as $H(p,q) = H(p) + D_{KL}(p||q)$, and the entropy of the delta function $p$ is zero, this is also equivalent to minimizing the KL divergence between the two distributions (a measure of distance). In other words, the cross-entropy objective wants the predicted distribution to have all of its mass on the correct answer.Probabilistic interpretationP(y_i \mid x_i; W) = \frac{e^{f_{y_i}}}{\sum_j e^{f_j} }can be interpreted as the (normalized) probability assigned to the correct label $y_i$given the image $x_i$ and parameterized by W. To see this, remember that the Softmax classifier interprets the scores inside the output vector $f$ as the unnormalized log probabilities. Exponentiating these quantities therefore gives the (unnormalized) probabilities, and the division performs the normalization so that the probabilities sum to one. In the probabilistic interpretation, we are therefore minimizing the negative log likelihood of the correct class, which can be interpreted as performing Maximum Likelihood Estimation (MLE). A nice feature of this view is that we can now also interpret the regularization term $R(W)$ in the full loss function as coming from a Gaussian prior over the weight matrix W, where instead of MLE we are performing the Maximum a posteriori (MAP) estimation.Numeric stabilityWhen youre writing code for computing the Softmax function in practice, the intermediate term $e^{f_{y_i}}$ and $\sum_j e^{f_j}$ may be very large due to the exponentials. Dividing large numbers can be numerically unstable, so it is important to use a normalization trick. Notice that if we multiply the top and bottom of the fraction by a constant C and push it into the sum, we get the following (mathematically equivalent) expression:\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}= \frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}= \frac{e^{f_{y_i} + \log C}}{\sum_j e^{f_j + \log C}}We are free to choose the value of C. This will not change any of the results, but we can use this value to improve the numerical stability of the computation. A common choice for C is to set $\log C = -\max_j f_j$. This simply states that we should shift the values inside the vector ff so that the highest value is zero. In code:123456f = np.array([123, 456, 789]) # example with 3 classes and each having large scoresp = np.exp(f) / np.sum(np.exp(f)) # Bad: Numeric problem, potential blowup# instead: first shift the values of f so that the highest number is 0:f -= np.max(f) # f becomes [-666, -333, 0]p = np.exp(f) / np.sum(np.exp(f)) # safe to do, gives the correct answerSome tricksHow peaky or diffuse these probabilities are depends directly on the regularization strength $\lambda$ - which you are in charge of as input to the system. For example, suppose that the unnormalized log-probabilities for some three classes come out to be [1, -2, 0]. The softmax function would then compute:[1, -2, 0] \rightarrow [e^1, e^{-2}, e^0] = [2.71, 0.14, 1] \rightarrow [0.7, 0.04, 0.26]Where the steps taken are to exponentiate and normalize to sum to one. Now, if the regularization strength $\lambda$ was higher, the weights W would be penalized more and this would lead to smaller weights. For example, suppose that the weights became one half smaller ([0.5, -1, 0]). The softmax would now compute:[0.5, -1, 0] \rightarrow [e^{0.5}, e^{-1}, e^0] = [1.65, 0.37, 1] \rightarrow [0.55, 0.12, 0.33]where the probabilites are now more diffuse.Futher ReadingDeep Learning using Linear Support Vector Machines from Charlie Tang 2013 presents some results claiming that the L2SVM outperforms Softmax.OptimizationStrategy #1: A first very bad idea solution: Random search12345678910111213141516171819202122# assume X_train is the data where each column is an example (e.g. 3073 x 50,000)# assume Y_train are the labels (e.g. 1D array of 50,000)# assume the function L evaluates the loss functionbestloss = float("inf") # Python assigns the highest possible float valuefor num in xrange(1000): W = np.random.randn(10, 3073) * 0.0001 # generate random parameters loss = L(X_train, Y_train, W) # get the loss over the entire training set if loss &lt; bestloss: # keep track of the best solution bestloss = loss bestW = W print 'in attempt %d the loss was %f, best %f' % (num, loss, bestloss)# prints:# in attempt 0 the loss was 9.401632, best 9.401632# in attempt 1 the loss was 8.959668, best 8.959668# in attempt 2 the loss was 9.044034, best 8.959668# in attempt 3 the loss was 9.278948, best 8.959668# in attempt 4 the loss was 8.857370, best 8.857370# in attempt 5 the loss was 8.943151, best 8.857370# in attempt 6 the loss was 8.605604, best 8.605604# ... (trunctated: continues for 1000 lines)We can take the best weights W found by this search and try it out on the test set:1234567# Assume X_test is [3073 x 10000], Y_test [10000 x 1]scores = Wbest.dot(Xte_cols) # 10 x 10000, the class scores for all test examples# find the index with max score in each column (the predicted class)Yte_predict = np.argmax(scores, axis = 0)# and calculate accuracy (fraction of predictions that are correct)np.mean(Yte_predict == Yte)# returns 0.1555With the best W this gives an accuracy of about 15.5%.Core idea: iterative refinement. Of course, it turns out that we can do much better. The core idea is that finding the best set of weights W is a very difficult or even impossible problem (especially once W contains weights for entire complex neural networks), but the problem of refining a specific set of weights W to be slightly better is significantly less difficult. In other words, our approach will be to start with a random W and then iteratively refine it, making it slightly better each time.Our strategy will be to start with random weights and iteratively refine them over time to get lower lossStrategy #2: Random Local SearchConcretely, we will start out with a random WW, generate random perturbations $\delta W$ to it and if the loss at the perturbed $W + \delta W$ is lower, we will perform an update. The code for this procedure is as follows:12345678910W = np.random.randn(10, 3073) * 0.001 # generate random starting Wbestloss = float("inf")for i in xrange(1000): step_size = 0.0001 Wtry = W + np.random.randn(10, 3073) * step_size loss = L(Xtr_cols, Ytr, Wtry) if loss &lt; bestloss: W = Wtry bestloss = loss print 'iter %d loss is %f' % (i, bestloss)This approach achieves test set classification accuracy of 21.4%.Strategy #3: Following the GradientThe mathematical expression for the derivative of a 1-D function with respect its input is:\frac{df(x)}{dx} = \lim_{h\ \to 0} \frac{f(x + h) - f(x)}{h}When the functions of interest take a vector of numbers instead of a single number, we call the derivatives partial derivatives, and the gradient is simply the vector of partial derivatives in each dimension.Computing the gradientThere are two ways to compute the gradient: A slow, approximate but easy way (numerical gradient), and a fast, exact but more error-prone way that requires calculus (analytic gradient). We will now present both.Computing the gradient numerically with finite differences123456789101112131415161718192021222324252627def eval_numerical_gradient(f, x): """ a naive implementation of numerical gradient of f at x - f should be a function that takes a single argument - x is the point (numpy array) to evaluate the gradient at """ fx = f(x) # evaluate function value at original point grad = np.zeros(x.shape) h = 0.00001 # iterate over all indexes in x it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite']) while not it.finished: # evaluate function at x+h ix = it.multi_index old_value = x[ix] x[ix] = old_value + h # increment by h fxh = f(x) # evalute f(x + h) x[ix] = old_value # restore to previous value (very important!) # compute the partial derivative grad[ix] = (fxh - fx) / h # the slope it.iternext() # step to next dimension return gradPractical considerations.Note that in the mathematical formulation the gradient is defined in the limit as h goes towards zero, but in practice it is often sufficient to use a very small value (such as 1e-5 as seen in the example). Ideally, you want to use the smallest step size that does not lead to numerical issues. Additionally, in practice it often works better to compute the numeric gradient using the centered difference formula:[f(x+h) - f(x-h)] / 2 hSee wiki for details.1234567# to use the generic code above we want a function that takes a single argument# (the weights in our case) so we close over X_train and Y_traindef CIFAR10_loss_fun(W): return L(X_train, Y_train, W)W = np.random.rand(10, 3073) * 0.001 # random weight vectordf = eval_numerical_gradient(CIFAR10_loss_fun, W) # get the gradientThen we can use to make an update:12345678910111213141516171819202122loss_original = CIFAR10_loss_fun(W) # the original lossprint 'original loss: %f' % (loss_original, )# lets see the effect of multiple step sizesfor step_size_log in [-10, -9, -8, -7, -6, -5,-4,-3,-2,-1]: step_size = 10 ** step_size_log W_new = W - step_size * df # new position in the weight space loss_new = CIFAR10_loss_fun(W_new) print 'for step size %f new loss: %f' % (step_size, loss_new)# prints:# original loss: 2.200718# for step size 1.000000e-10 new loss: 2.200652# for step size 1.000000e-09 new loss: 2.200057# for step size 1.000000e-08 new loss: 2.194116# for step size 1.000000e-07 new loss: 2.135493# for step size 1.000000e-06 new loss: 1.647802# for step size 1.000000e-05 new loss: 2.844355# for step size 1.000000e-04 new loss: 25.558142# for step size 1.000000e-03 new loss: 254.086573# for step size 1.000000e-02 new loss: 2539.370888# for step size 1.000000e-01 new loss: 25392.214036Effect of step sizeComputing the gradient analytically with CalculusHowever, unlike the numerical gradient it can be more error prone to implement, which is why in practice it is very common to compute the analytic gradient and compare it to the numerical gradient to check the correctness of your implementation. This is called a gradient check.Lets use the example of the SVM loss function for a single datapoint:L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]\nabla_{w_{y_i}} L_i = - \left( \sum_{j\neq y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) \right) x_iwhen youre implementing this in code youd simply count the number of classes that didnt meet the desired margin (and hence contributed to the loss function) and then the data vector $x_i$ scaled by this number is the gradient.\nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python data analysis Learning note Ch07]]></title>
      <url>%2F2017%2F02%2F28%2FPython-data-analysis-Learning-note-Ch07%2F</url>
      <content type="text"><![CDATA[1234567891011121314from __future__ import divisionfrom numpy.random import randnimport numpy as npimport osimport matplotlib.pyplot as pltnp.random.seed(12345)plt.rc('figure', figsize=(10, 6))from pandas import Series, DataFrameimport pandasimport pandas as pdnp.set_printoptions(precision=4, threshold=500)pd.options.display.max_rows = 100from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "all"1%matplotlib inlineDataFrame12345df1 = DataFrame(&#123;'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)&#125;)df2 = DataFrame(&#123;'key': ['a', 'b', 'd'], 'data2': range(3)&#125;)df1data1key00b11b22a33c44a55a66b1df2data2key00a11b22d1pd.merge(df1, df2)data1keydata200b111b126b132a044a055a01pd.merge(df1, df2, on='key')data1keydata200b111b126b132a044a055a01234df3 = DataFrame(&#123;'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)&#125;)df4 = DataFrame(&#123;'rkey': ['a', 'b', 'd'], 'data2': range(3)&#125;)1df3data1lkey00b11b22a33c44a55a66b1df4data2rkey00a11b22d1pd.merge(df3, df4, left_on='lkey', right_on='rkey')data1lkeydata2rkey00b1b11b1b26b1b32a0a44a0a55a0ainner outer1pd.merge(df1, df2, how='outer')data1keydata200.0b1.011.0b1.026.0b1.032.0a0.044.0a0.055.0a0.063.0cNaN7NaNd2.01234df1 = DataFrame(&#123;'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6)&#125;)df2 = DataFrame(&#123;'key': ['a', 'b', 'a', 'b', 'd'], 'data2': range(5)&#125;)1df1data1key00b11b22a33c44a55b1df2data2key00a11b22a33b44d1pd.merge(df1, df2, on='key', how='left')data1keydata200b1.010b3.021b1.031b3.042a0.052a2.063cNaN74a0.084a2.095b1.0105b3.01pd.merge(df1, df2, how='inner')data1keydata200b110b321b131b345b155b362a072a284a094a2123456left = DataFrame(&#123;'key1': ['foo', 'foo', 'bar'], 'key2': ['one', 'two', 'one'], 'lval': [1, 2, 3]&#125;)right = DataFrame(&#123;'key1': ['foo', 'foo', 'bar', 'bar'], 'key2': ['one', 'one', 'one', 'two'], 'rval': [4, 5, 6, 7]&#125;)121leftkey1key2lval0fooone11footwo22barone31rightkey1key2rval0fooone41fooone52barone63bartwo71pd.merge(left, right, on=['key1', 'key2'], how='outer')key1key2lvalrval0fooone1.04.01fooone1.05.02footwo2.0NaN3barone3.06.04bartwoNaN7.01pd.merge(left, right, on='key1')key1key2_xlvalkey2_yrval0fooone1one41fooone1one52footwo2one43footwo2one54barone3one65barone3two71pd.merge(left, right, on='key1', suffixes=('_left', '_right'))key1key2_leftlvalkey2_rightrval0fooone1one41fooone1one52footwo2one43footwo2one54barone3one65barone3two7123left1 = DataFrame(&#123;'key': ['a', 'b', 'a', 'a', 'b', 'c'], 'value': range(6)&#125;)right1 = DataFrame(&#123;'group_val': [3.5, 7]&#125;, index=['a', 'b'])1left1keyvalue0a01b12a23a34b45c51right1group_vala3.5b7.01pd.merge(left1, right1, left_on='key', right_index=True)keyvaluegroup_val0a03.52a23.53a33.51b17.04b47.01pd.merge(left1, right1, left_on='key', right_index=True, how='outer')keyvaluegroup_val0a03.52a23.53a33.51b17.04b47.05c5NaN12345678lefth = DataFrame(&#123;'key1': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], 'key2': [2000, 2001, 2002, 2001, 2002], 'data': np.arange(5.)&#125;)righth = DataFrame(np.arange(12).reshape((6, 2)), index=[['Nevada', 'Nevada', 'Ohio', 'Ohio', 'Ohio', 'Ohio'], [2001, 2000, 2000, 2000, 2001, 2002]], columns=['event1', 'event2'])lefthdatakey1key200.0Ohio200011.0Ohio200122.0Ohio200233.0Nevada200144.0Nevada20021righthevent1event2Nevada200101200023Ohio200045200067200189200210111pd.merge(lefth, righth, left_on=['key1', 'key2'], right_index=True)datakey1key2event1event200.0Ohio20004500.0Ohio20006711.0Ohio20018922.0Ohio2002101133.0Nevada20010112pd.merge(lefth, righth, left_on=['key1', 'key2'], right_index=True, how='outer')datakey1key2event1event200.0Ohio2000.04.05.000.0Ohio2000.06.07.011.0Ohio2001.08.09.022.0Ohio2002.010.011.033.0Nevada2001.00.01.044.0Nevada2002.0NaNNaN4NaNNevada2000.02.03.01234left2 = DataFrame([[1., 2.], [3., 4.], [5., 6.]], index=['a', 'c', 'e'], columns=['Ohio', 'Nevada'])right2 = DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]], index=['b', 'c', 'd', 'e'], columns=['Missouri', 'Alabama'])1left2OhioNevadaa1.02.0c3.04.0e5.06.01right2MissouriAlabamab7.08.0c9.010.0d11.012.0e13.014.01pd.merge(left2, right2, how='outer', left_index=True, right_index=True)OhioNevadaMissouriAlabamaa1.02.0NaNNaNbNaNNaN7.08.0c3.04.09.010.0dNaNNaN11.012.0e5.06.013.014.01left2.join(right2, how='outer')OhioNevadaMissouriAlabamaa1.02.0NaNNaNbNaNNaN7.08.0c3.04.09.010.0dNaNNaN11.012.0e5.06.013.014.01left1.join(right1, on='key')keyvaluegroup_val0a03.51b17.02a23.53a33.54b47.05c5NaN12another = DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]], index=['a', 'c', 'e', 'f'], columns=['New York', 'Oregon'])New YorkOregona7.08.0c9.010.0e11.012.0f16.017.01234left2right2anotherleft2.join([right2, another])OhioNevadaa1.02.0c3.04.0e5.06.0MissouriAlabamab7.08.0c9.010.0d11.012.0e13.014.0New YorkOregona7.08.0c9.010.0e11.012.0f16.017.0OhioNevadaMissouriAlabamaNew YorkOregona1.02.0NaNNaN7.08.0c3.04.09.010.09.010.0e5.06.013.014.011.012.01left2.join([right2, another], how='outer')1arr = np.arange(12).reshape((3, 4))1arrarray([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) 1np.concatenate([arr, arr], axis=1)array([[ 0, 1, 2, 3, 0, 1, 2, 3], [ 4, 5, 6, 7, 4, 5, 6, 7], [ 8, 9, 10, 11, 8, 9, 10, 11]]) 123s1 = Series([0, 1], index=['a', 'b'])s2 = Series([2, 3, 4], index=['c', 'd', 'e'])s3 = Series([5, 6], index=['f', 'g'])1pd.concat([s1, s2, s3])a 0 b 1 c 2 d 3 e 4 f 5 g 6 dtype: int64 1pd.concat([s1, s2, s3], axis=1)012a0.0NaNNaNb1.0NaNNaNcNaN2.0NaNdNaN3.0NaNeNaN4.0NaNfNaNNaN5.0gNaNNaN6.012s4 = pd.concat([s1 * 5, s3])s4a 0 b 5 f 5 g 6 dtype: int64 1pd.concat([s1, s4], axis=1)01a0.00b1.05fNaN5gNaN61pd.concat([s1, s4], axis=1, join='inner')01a00b151pd.concat([s1, s4], axis=1, join_axes=[['a', 'c', 'b', 'e']])01a0.00.0cNaNNaNb1.05.0eNaNNaN123s1s3result = pd.concat([s1, s1, s3], keys=['one', 'two', 'three'])a 0 b 1 dtype: int64 f 5 g 6 dtype: int64 1resultone a 0 b 1 two a 0 b 1 three f 5 g 6 dtype: int64 12# Much more on the unstack function laterresult.unstack()abfgone0.01.0NaNNaNtwo0.01.0NaNNaNthreeNaNNaN5.06.01pd.concat([s1, s2, s3], axis=1, keys=['one', 'two', 'three'])onetwothreea0.0NaNNaNb1.0NaNNaNcNaN2.0NaNdNaN3.0NaNeNaN4.0NaNfNaNNaN5.0gNaNNaN6.012345678df1 = DataFrame(np.arange(6).reshape(3, 2), index=['a', 'b', 'c'], columns=['one', 'two'])df2 = DataFrame(5 + np.arange(4).reshape(2, 2), index=['a', 'c'], columns=['three', 'four'])df1df2pd.concat([df1, df2], keys=['level1', 'level2'])pd.concat([df1, df2], axis=1, keys=['level1', 'level2'])onetwoa01b23c45threefoura56c78fouronethreetwolevel1aNaN0.0NaN1.0bNaN2.0NaN3.0cNaN4.0NaN5.0level2a6.0NaN5.0NaNc8.0NaN7.0NaNlevel1level2onetwothreefoura015.06.0b23NaNNaNc457.08.012pd.concat(&#123;'level1': df1, 'level2': df2&#125;, axis=0)pd.concat(&#123;'level1': df1, 'level2': df2&#125;, axis=1)fouronethreetwolevel1aNaN0.0NaN1.0bNaN2.0NaN3.0cNaN4.0NaN5.0level2a6.0NaN5.0NaNc8.0NaN7.0NaNlevel1level2onetwothreefoura015.06.0b23NaNNaNc457.08.012pd.concat([df1, df2], axis=1, keys=['level1', 'level2'], names=['upper', 'lower'])upperlevel1level2loweronetwothreefoura015.06.0b23NaNNaNc457.08.012df1 = DataFrame(np.random.randn(3, 4), columns=['a', 'b', 'c', 'd'])df2 = DataFrame(np.random.randn(2, 3), columns=['b', 'd', 'a'])1df1abcd0-0.2047080.478943-0.519439-0.55573011.9657811.3934060.0929080.28174620.7690231.2464351.007189-1.2962211df2bda00.2749920.2289131.35291710.886429-2.001637-0.37184312pd.concat([df1, df2], ignore_index=False)pd.concat([df1, df2], ignore_index=True)abcd0-0.2047080.478943-0.519439-0.55573011.9657811.3934060.0929080.28174620.7690231.2464351.007189-1.29622101.3529170.274992NaN0.2289131-0.3718430.886429NaN-2.001637abcd0-0.2047080.478943-0.519439-0.55573011.9657811.3934060.0929080.28174620.7690231.2464351.007189-1.29622131.3529170.274992NaN0.2289134-0.3718430.886429NaN-2.00163712345a = Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan], index=['f', 'e', 'd', 'c', 'b', 'a'])b = Series(np.arange(len(a), dtype=np.float64), index=['f', 'e', 'd', 'c', 'b', 'a'])b[-1] = np.nan1af NaN e 2.5 d NaN c 3.5 b 4.5 a NaN dtype: float64 1bf 0.0 e 1.0 d 2.0 c 3.0 b 4.0 a NaN dtype: float64 1np.where(pd.isnull(a), b, a)array([ 0. , 2.5, 2. , 3.5, 4.5, nan]) combine_first, 1b[:-2].combine_first(a[2:])a NaN b 4.5 c 3.0 d 2.0 e 1.0 f 0.0 dtype: float64 12345678df1 = DataFrame(&#123;'a': [1., np.nan, 5., np.nan], 'b': [np.nan, 2., np.nan, 6.], 'c': range(2, 18, 4)&#125;)df2 = DataFrame(&#123;'a': [5., 4., np.nan, 3., 7.], 'b': [np.nan, 3., 4., 6., 8.]&#125;)df1df2df1.combine_first(df2)abc01.0NaN21NaN2.0625.0NaN103NaN6.014ab05.0NaN14.03.02NaN4.033.06.047.08.0abc01.0NaN2.014.02.06.025.04.010.033.06.014.047.08.0NaN1234data = DataFrame(np.arange(6).reshape((2, 3)), index=pd.Index(['Ohio', 'Colorado'], name='state'), columns=pd.Index(['one', 'two', 'three'], name='number'))datanumberonetwothreestateOhio012Colorado345stack12result = data.stack()resultstate number Ohio one 0 two 1 three 2 Colorado one 3 two 4 three 5 dtype: int32 unstack1result.unstack()numberonetwothreestateOhio012Colorado3451result.unstack(0)stateOhioColoradonumberone03two14three251result.unstack('state')stateOhioColoradonumberone03two14three251234567s1 = Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd'])s2 = Series([4, 5, 6], index=['c', 'd', 'e'])s1s2data2 = pd.concat([s1, s2], keys=['one', 'two'])data2data2.unstack()a 0 b 1 c 2 d 3 dtype: int64 c 4 d 5 e 6 dtype: int64 one a 0 b 1 c 2 d 3 two c 4 d 5 e 6 dtype: int64 abcdeone0.01.02.03.0NaNtwoNaNNaN4.05.06.0stack1data2.unstack().stack()one a 0.0 b 1.0 c 2.0 d 3.0 two c 4.0 d 5.0 e 6.0 dtype: float64 1data2.unstack().stack(dropna=False)one a 0.0 b 1.0 c 2.0 d 3.0 e NaN two a NaN b NaN c 4.0 d 5.0 e 6.0 dtype: float64 1234resultdf = DataFrame(&#123;'left': result, 'right': result + 5&#125;, columns=pd.Index(['left', 'right'], name='side'))dfstate number Ohio one 0 two 1 three 2 Colorado one 3 two 4 three 5 dtype: int32 sideleftrightstatenumberOhioone05two16three27Coloradoone38two49three510DataFrameaxis=MAX1df.unstack('state')sideleftrightstateOhioColoradoOhioColoradonumberone0358two1469three25710stackaxis-1?1df.unstack('state').stack('side')stateOhioColoradonumbersideoneleft03right58twoleft14right69threeleft25right71012df.unstack('state')df.unstack('state').stack('state')sideleftrightstateOhioColoradoOhioColoradonumberone0358two1469three25710sideleftrightnumberstateoneOhio05Colorado38twoOhio16Colorado49threeOhio27Colorado51012345678910111213data = pd.read_csv('ch07/macrodata.csv')data[:10]periods = pd.PeriodIndex(year=data.year, quarter=data.quarter, name='date')periods[:10]data = DataFrame(data.to_records(), columns=pd.Index(['realgdp', 'infl', 'unemp'], name='item'), index=periods.to_timestamp('D', 'end'))data[:10]data.to_records()[:10]data.stack()[:10]ldata = data.stack().reset_index().rename(columns=&#123;0: 'value'&#125;)wdata = ldata.pivot('date', 'item', 'value')yearquarterrealgdprealconsrealinvrealgovtrealdpicpim1tbilrateunemppopinflrealint01959.01.02710.3491707.4286.898470.0451886.928.98139.72.825.8177.1460.000.0011959.02.02778.8011733.7310.859481.3011919.729.15141.73.085.1177.8302.340.7421959.03.02775.4881751.8289.226491.2601916.429.35140.53.825.3178.6572.741.0931959.04.02785.2041753.7299.356484.0521931.329.37140.04.335.6179.3860.274.0641960.01.02847.6991770.5331.722462.1991955.529.54139.63.505.2180.0072.311.1951960.02.02834.3901792.9298.152460.4001966.129.55140.22.685.2180.6710.142.5561960.03.02839.0221785.8296.375474.6761967.829.75140.92.365.6181.5282.70-0.3471960.04.02802.6161788.2259.764476.4341966.629.84141.12.296.3182.2871.211.0881961.01.02819.2641787.7266.405475.8541984.529.81142.12.376.8182.992-0.402.7791961.02.02872.0051814.3286.246480.3282014.429.92142.92.297.0183.6911.470.81PeriodIndex([&#39;1959Q1&#39;, &#39;1959Q2&#39;, &#39;1959Q3&#39;, &#39;1959Q4&#39;, &#39;1960Q1&#39;, &#39;1960Q2&#39;, &#39;1960Q3&#39;, &#39;1960Q4&#39;, &#39;1961Q1&#39;, &#39;1961Q2&#39;], dtype=&#39;int64&#39;, name=&#39;date&#39;, freq=&#39;Q-DEC&#39;) itemrealgdpinflunempdate1959-03-312710.3490.005.81959-06-302778.8012.345.11959-09-302775.4882.745.31959-12-312785.2040.275.61960-03-312847.6992.315.21960-06-302834.3900.145.21960-09-302839.0222.705.61960-12-312802.6161.216.31961-03-312819.264-0.406.81961-06-302872.0051.477.0rec.array([(datetime.datetime(1959, 3, 31, 0, 0), 2710.349, 0.0, 5.8), (datetime.datetime(1959, 6, 30, 0, 0), 2778.801, 2.34, 5.1), (datetime.datetime(1959, 9, 30, 0, 0), 2775.488, 2.74, 5.3), (datetime.datetime(1959, 12, 31, 0, 0), 2785.204, 0.27, 5.6), (datetime.datetime(1960, 3, 31, 0, 0), 2847.699, 2.31, 5.2), (datetime.datetime(1960, 6, 30, 0, 0), 2834.39, 0.14, 5.2), (datetime.datetime(1960, 9, 30, 0, 0), 2839.022, 2.7, 5.6), (datetime.datetime(1960, 12, 31, 0, 0), 2802.616, 1.21, 6.3), (datetime.datetime(1961, 3, 31, 0, 0), 2819.264, -0.4, 6.8), (datetime.datetime(1961, 6, 30, 0, 0), 2872.005, 1.47, 7.0)], dtype=[(&#39;date&#39;, &#39;O&#39;), (&#39;realgdp&#39;, &#39;&lt;f8&#39;), (&#39;infl&#39;, &#39;&lt;f8&#39;), (&#39;unemp&#39;, &#39;&lt;f8&#39;)]) date item 1959-03-31 realgdp 2710.349 infl 0.000 unemp 5.800 1959-06-30 realgdp 2778.801 infl 2.340 unemp 5.100 1959-09-30 realgdp 2775.488 infl 2.740 unemp 5.300 1959-12-31 realgdp 2785.204 dtype: float64 1ldata[:10]dateitemvalue01959-03-31realgdp2710.34911959-03-31infl0.00021959-03-31unemp5.80031959-06-30realgdp2778.80141959-06-30infl2.34051959-06-30unemp5.10061959-09-30realgdp2775.48871959-09-30infl2.74081959-09-30unemp5.30091959-12-31realgdp2785.20412pivoted = ldata.pivot('date', 'item', 'value')pivoted.head()iteminflrealgdpunempdate1959-03-310.002710.3495.81959-06-302.342778.8015.11959-09-302.742775.4885.31959-12-310.272785.2045.61960-03-312.312847.6995.212ldata['value2'] = np.random.randn(len(ldata))ldata[:10]dateitemvaluevalue201959-03-31realgdp2710.349-0.20470811959-03-31infl0.0000.47894321959-03-31unemp5.800-0.51943931959-06-30realgdp2778.801-0.55573041959-06-30infl2.3401.96578151959-06-30unemp5.1001.39340661959-09-30realgdp2775.4880.09290871959-09-30infl2.7400.28174681959-09-30unemp5.3000.76902391959-12-31realgdp2785.2041.24643512pivoted = ldata.pivot('date', 'item')pivoted[:5]valuevalue2iteminflrealgdpunempinflrealgdpunempdate1959-03-310.002710.3495.80.478943-0.204708-0.5194391959-06-302.342778.8015.11.965781-0.5557301.3934061959-09-302.742775.4885.30.2817460.0929080.7690231959-12-310.272785.2045.61.0071891.246435-1.2962211960-03-312.312847.6995.20.2289130.2749921.3529171pivoted['value'][:5]iteminflrealgdpunempdate1959-03-310.002710.3495.81959-06-302.342778.8015.11959-09-302.742775.4885.31959-12-310.272785.2045.61960-03-312.312847.6995.2123ldata.set_index(['date', 'item'])[:9]unstacked = ldata.set_index(['date', 'item']).unstack('item')unstacked[:7]valuevalue2dateitem1959-03-31realgdp2710.349-0.204708infl0.0000.478943unemp5.800-0.5194391959-06-30realgdp2778.801-0.555730infl2.3401.965781unemp5.1001.3934061959-09-30realgdp2775.4880.092908infl2.7400.281746unemp5.3000.769023valuevalue2iteminflrealgdpunempinflrealgdpunempdate1959-03-310.002710.3495.80.478943-0.204708-0.5194391959-06-302.342778.8015.11.965781-0.5557301.3934061959-09-302.742775.4885.30.2817460.0929080.7690231959-12-310.272785.2045.61.0071891.246435-1.2962211960-03-312.312847.6995.20.2289130.2749921.3529171960-06-300.142834.3905.2-2.0016370.886429-0.3718431960-09-302.702839.0225.6-0.4385701.669025-0.539741123data = DataFrame(&#123;'k1': ['one'] * 3 + ['two'] * 4, 'k2': [1, 1, 2, 3, 3, 4, 4]&#125;)datak1k20one11one12one23two34two35two46two41data.duplicated()0 False 1 True 2 False 3 False 4 True 5 False 6 True dtype: bool 1data.drop_duplicates()k1k20one12one23two35two4123data['v1'] = range(7)datadata.drop_duplicates(['k1'])k1k2v10one101one112one223two334two345two456two46k1k2v10one103two3312data.drop_duplicates(['k1', 'k2'], keep='last')data.drop_duplicates(['k1', 'k2'], keep='first')k1k2v11one112one224two346two46k1k2v10one102one223two335two4512345data = DataFrame(&#123;'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami', 'corned beef', 'Bacon', 'pastrami', 'honey ham', 'nova lox'], 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]&#125;)datafoodounces0bacon4.01pulled pork3.02bacon12.03Pastrami6.04corned beef7.55Bacon8.06pastrami3.07honey ham5.08nova lox6.012345678meat_to_animal = &#123; 'bacon': 'pig', 'pulled pork': 'pig', 'pastrami': 'cow', 'corned beef': 'cow', 'honey ham': 'pig', 'nova lox': 'salmon'&#125;12data['animal'] = data['food'].map(str.lower).map(meat_to_animal)datafoodouncesanimal0bacon4.0pig1pulled pork3.0pig2bacon12.0pig3Pastrami6.0cow4corned beef7.5cow5Bacon8.0pig6pastrami3.0cow7honey ham5.0pig8nova lox6.0salmon1data['food'].map(lambda x: meat_to_animal[x.lower()])0 pig 1 pig 2 pig 3 cow 4 cow 5 pig 6 cow 7 pig 8 salmon Name: food, dtype: object 12data = Series([1., -999., 2., -999., -1000., 3.])data0 1.0 1 -999.0 2 2.0 3 -999.0 4 -1000.0 5 3.0 dtype: float64 1data.replace(-999, np.nan)0 1.0 1 NaN 2 2.0 3 NaN 4 -1000.0 5 3.0 dtype: float64 1data.replace([-999, -1000], np.nan)0 1.0 1 NaN 2 2.0 3 NaN 4 NaN 5 3.0 dtype: float64 1data.replace([-999, -1000], [np.nan, 0])0 1.0 1 NaN 2 2.0 3 NaN 4 0.0 5 3.0 dtype: float64 1data.replace(&#123;-999: np.nan, -1000: 0&#125;)0 1.0 1 NaN 2 2.0 3 NaN 4 0.0 5 3.0 dtype: float64 1234data = DataFrame(np.arange(12).reshape((3, 4)), index=['Ohio', 'Colorado', 'New York'], columns=['one', 'two', 'three', 'four'])dataonetwothreefourOhio0123Colorado4567New York8910111data.index.map(str.upper)array([&#39;OHIO&#39;, &#39;COLORADO&#39;, &#39;NEW YORK&#39;], dtype=object) 12data.index = data.index.map(str.upper)dataonetwothreefourOHIO0123COLORADO4567NEW YORK8910111data.rename(index=str.title, columns=str.upper)ONETWOTHREEFOUROhio0123Colorado4567New York89101112data.rename(index=&#123;'OHIO': 'INDIANA'&#125;, columns=&#123;'three': 'peekaboo'&#125;)onetwopeekaboofourINDIANA0123COLORADO4567NEW YORK891011123# Always returns a reference to a DataFrame_ = data.rename(index=&#123;'OHIO': 'INDIANA'&#125;, inplace=True)dataonetwothreefourINDIANA0123COLORADO4567NEW YORK8910111ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]123bins = [18, 25, 35, 60, 100]cats = pd.cut(ages, bins)cats[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]] Length: 12 Categories (4, object): [(18, 25] &lt; (25, 35] &lt; (35, 60] &lt; (60, 100]] 1cats.codesarray([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8) 1cats.categoriesIndex([&#39;(18, 25]&#39;, &#39;(25, 35]&#39;, &#39;(35, 60]&#39;, &#39;(60, 100]&#39;], dtype=&#39;object&#39;) 1pd.value_counts(cats)(18, 25] 5 (35, 60] 3 (25, 35] 3 (60, 100] 1 dtype: int64 1pd.cut(ages, [18, 26, 36, 61, 100], right=False)[[18, 26), [18, 26), [18, 26), [26, 36), [18, 26), ..., [26, 36), [61, 100), [36, 61), [36, 61), [26, 36)] Length: 12 Categories (4, object): [[18, 26) &lt; [26, 36) &lt; [36, 61) &lt; [61, 100)] 12group_names = ['Youth', 'YoungAdult', 'MiddleAged', 'Senior']pd.cut(ages, bins, labels=group_names)[Youth, Youth, Youth, YoungAdult, Youth, ..., YoungAdult, Senior, MiddleAged, MiddleAged, YoungAdult] Length: 12 Categories (4, object): [Youth &lt; YoungAdult &lt; MiddleAged &lt; Senior] 12data = np.random.rand(20)pd.cut(data, 4, precision=2)[(0.25, 0.49], (0.25, 0.49], (0.73, 0.98], (0.25, 0.49], (0.25, 0.49], ..., (0.25, 0.49], (0.73, 0.98], (0.49, 0.73], (0.49, 0.73], (0.49, 0.73]] Length: 20 Categories (4, object): [(0.0032, 0.25] &lt; (0.25, 0.49] &lt; (0.49, 0.73] &lt; (0.73, 0.98]] 123data = np.random.randn(1000) # Normally distributedcats = pd.qcut(data, 4) # Cut into quartilescats[(0.636, 3.26], [-3.745, -0.648], (0.636, 3.26], (-0.022, 0.636], (-0.648, -0.022], ..., (0.636, 3.26], (-0.022, 0.636], [-3.745, -0.648], (-0.022, 0.636], (-0.022, 0.636]] Length: 1000 Categories (4, object): [[-3.745, -0.648] &lt; (-0.648, -0.022] &lt; (-0.022, 0.636] &lt; (0.636, 3.26]] 1pd.value_counts(cats)(0.636, 3.26] 250 (-0.022, 0.636] 250 (-0.648, -0.022] 250 [-3.745, -0.648] 250 dtype: int64 1pd.qcut(data, [0, 0.1, 0.5, 0.9, 1.])[(-0.022, 1.298], [-3.745, -1.274], (-0.022, 1.298], (-0.022, 1.298], (-1.274, -0.022], ..., (-0.022, 1.298], (-0.022, 1.298], [-3.745, -1.274], (-0.022, 1.298], (-0.022, 1.298]] Length: 1000 Categories (4, object): [[-3.745, -1.274] &lt; (-1.274, -0.022] &lt; (-0.022, 1.298] &lt; (1.298, 3.26]] 123np.random.seed(12345)data = DataFrame(np.random.randn(1000, 4))data.describe()0123count1000.0000001000.0000001000.0000001000.000000mean-0.0676840.0679240.025598-0.002298std0.9980350.9921061.0068350.996794min-3.428254-3.548824-3.184377-3.74535625%-0.774890-0.591841-0.641675-0.64414450%-0.1164010.1011430.002073-0.01361175%0.6163660.7802820.6803910.654328max3.3666262.6536563.2603833.92752812col = data[3]col[np.abs(col) &gt; 3]97 3.927528 305 -3.399312 400 -3.745356 Name: 3, dtype: float64 1data[(np.abs(data) &gt; 3).any(1)]01235-0.5397410.4769853.248944-1.02122897-0.7743630.5529360.1060613.927528102-0.655054-0.5652303.1768730.959533305-2.3155550.457246-0.025907-3.3993123240.0501881.9513123.2603830.9633014000.1463260.508391-0.196713-3.745356499-0.293333-0.242459-3.0569901.918403523-3.428254-0.296336-0.439938-0.8671655860.2751441.179227-3.1843771.369891808-0.362528-3.5488241.553205-2.1863019003.366626-2.3722140.8510101.33284612data[np.abs(data) &gt; 3] = np.sign(data) * 3data.describe()0123count1000.0000001000.0000001000.0000001000.000000mean-0.0676230.0684730.025153-0.002081std0.9954850.9902531.0039770.989736min-3.000000-3.000000-3.000000-3.00000025%-0.774890-0.591841-0.641675-0.64414450%-0.1164010.1011430.002073-0.01361175%0.6163660.7802820.6803910.654328max3.0000002.6536563.0000003.000000123df = DataFrame(np.arange(5 * 4).reshape((5, 4)))sampler = np.random.permutation(5)samplerarray([1, 0, 2, 3, 4]) 1df0123001231456728910113121314154161718191df.take(sampler)0123145670012328910113121314154161718191df.take(np.random.permutation(len(df))[:3])0123145670012341617181912bag = np.array([5, 7, -1, 6, 4])sampler = np.random.randint(0, len(bag), size=10)1samplerarray([3, 0, 4, 1, 1, 2, 3, 0, 1, 2]) 12draws = bag.take(sampler)drawsarray([ 6, 5, 4, 7, 7, -1, 6, 5, 7, -1])  / 1234df = DataFrame(&#123;'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6)&#125;)dfpd.get_dummies(df['key'])data1key00b11b22a33c44a55babc00.01.00.010.01.00.021.00.00.030.00.01.041.00.00.050.01.00.01234dummies = pd.get_dummies(df['key'], prefix='key')dummiesdf_with_dummy = df[['data1']].join(dummies)df_with_dummykey_akey_bkey_c00.01.00.010.01.00.021.00.00.030.00.01.041.00.00.050.01.00.0data1key_akey_bkey_c000.01.00.0110.01.00.0221.00.00.0330.00.01.0441.00.00.0550.01.00.01234mnames = ['movie_id', 'title', 'genres']movies = pd.read_table('ch02/movielens/movies.dat', sep='::', header=None, names=mnames)movies[:10]C:\Users\Ewan\Anaconda3\lib\site-packages\ipykernel\__main__.py:3: ParserWarning: Falling back to the &#39;python&#39; engine because the &#39;c&#39; engine does not support regex separators (separators &gt; 1 char and different from &#39;\s+&#39; are interpreted as regex); you can avoid this warning by specifying engine=&#39;python&#39;. app.launch_new_instance() movie_idtitlegenres01Toy Story (1995)Animation|Children's|Comedy12Jumanji (1995)Adventure|Children's|Fantasy23Grumpier Old Men (1995)Comedy|Romance34Waiting to Exhale (1995)Comedy|Drama45Father of the Bride Part II (1995)Comedy56Heat (1995)Action|Crime|Thriller67Sabrina (1995)Comedy|Romance78Tom and Huck (1995)Adventure|Children's89Sudden Death (1995)Action910GoldenEye (1995)Action|Adventure|Thriller123genre_iter = (set(x.split('|')) for x in movies.genres)genres = sorted(set.union(*genre_iter))genres[&#39;Action&#39;, &#39;Adventure&#39;, &#39;Animation&#39;, &quot;Children&#39;s&quot;, &#39;Comedy&#39;, &#39;Crime&#39;, &#39;Documentary&#39;, &#39;Drama&#39;, &#39;Fantasy&#39;, &#39;Film-Noir&#39;, &#39;Horror&#39;, &#39;Musical&#39;, &#39;Mystery&#39;, &#39;Romance&#39;, &#39;Sci-Fi&#39;, &#39;Thriller&#39;, &#39;War&#39;, &#39;Western&#39;] 12dummies = DataFrame(np.zeros((len(movies), len(genres))), columns=genres)dummies[:10].ix[:, :5]ActionAdventureAnimationChildren'sComedy00.00.00.00.00.010.00.00.00.00.020.00.00.00.00.030.00.00.00.00.040.00.00.00.00.050.00.00.00.00.060.00.00.00.00.070.00.00.00.00.080.00.00.00.00.090.00.00.00.00.0123for i, gen in enumerate(movies.genres): dummies.ix[i, gen.split('|')] = 1dummies[:10].ix[:, :5]ActionAdventureAnimationChildren'sComedy00.00.01.01.01.010.01.00.01.00.020.00.00.00.01.030.00.00.00.01.040.00.00.00.01.051.00.00.00.00.060.00.00.00.01.070.01.00.01.00.081.00.00.00.00.091.01.00.00.00.012movies_windic = movies.join(dummies.add_prefix('Genre_'))movies_windic.ix[0]movie_id 1 title Toy Story (1995) genres Animation|Children&#39;s|Comedy Genre_Action 0 Genre_Adventure 0 Genre_Animation 1 Genre_Children&#39;s 1 Genre_Comedy 1 Genre_Crime 0 Genre_Documentary 0 Genre_Drama 0 Genre_Fantasy 0 Genre_Film-Noir 0 Genre_Horror 0 Genre_Musical 0 Genre_Mystery 0 Genre_Romance 0 Genre_Sci-Fi 0 Genre_Thriller 0 Genre_War 0 Genre_Western 0 Name: 0, dtype: object 1np.random.seed(12345)12values = np.random.rand(10)valuesarray([ 0.9296, 0.3164, 0.1839, 0.2046, 0.5677, 0.5955, 0.9645, 0.6532, 0.7489, 0.6536]) 12bins = [0, 0.2, 0.4, 0.6, 0.8, 1]pd.get_dummies(pd.cut(values, bins))(0, 0.2](0.2, 0.4](0.4, 0.6](0.6, 0.8](0.8, 1]00.00.00.00.01.010.01.00.00.00.021.00.00.00.00.030.01.00.00.00.040.00.01.00.00.050.00.01.00.00.060.00.00.00.01.070.00.00.01.00.080.00.00.01.00.090.00.00.01.00.012val = 'a,b, guido'val.split(',')[&#39;a&#39;, &#39;b&#39;, &#39; guido&#39;] 12pieces = [x.strip() for x in val.split(',')]pieces[&#39;a&#39;, &#39;b&#39;, &#39;guido&#39;] 12first, second, third = piecesfirst + '::' + second + '::' + third&#39;a::b::guido&#39; Surprise :P1'::'.join(pieces)&#39;a::b::guido&#39; 1'guido' in valTrue 1val.index(',')1 1val.find(':')-1 1val.index(':')--------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-110-280f8b2856ce&gt; in &lt;module&gt;() ----&gt; 1 val.index(&#39;:&#39;) ValueError: substring not found 1val.count(',')2 1val.replace(',', '::')&#39;a::b:: guido&#39; 1val.replace(',', '')&#39;ab guido&#39; 123import retext = "foo bar\t baz \tqux"re.split('\s+', text)[&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;qux&#39;] 12regex = re.compile('\s+')regex.split(text)[&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;qux&#39;] 1regex.findall(text)[&#39; &#39;, &#39;\t &#39;, &#39; \t&#39;] 123456789text = """Dave dave@google.comSteve steve@gmail.comRob rob@gmail.comRyan ryan@yahoo.com"""pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]&#123;2,4&#125;'# re.IGNORECASE makes the regex case-insensitiveregex = re.compile(pattern, flags=re.IGNORECASE)1regex.findall(text)[&#39;dave@google.com&#39;, &#39;steve@gmail.com&#39;, &#39;rob@gmail.com&#39;, &#39;ryan@yahoo.com&#39;] Search12m = regex.search(text)m&lt;_sre.SRE_Match object; span=(5, 20), match=&#39;dave@google.com&#39;&gt; 1text[m.start():m.end()]&#39;dave@google.com&#39; 1print(regex.match(text))None 1print(regex.sub('REDACTED', text))Dave REDACTED Steve REDACTED Rob REDACTED Ryan REDACTED 12pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]&#123;2,4&#125;)'regex = re.compile(pattern, flags=re.IGNORECASE)12m = regex.match('wesm@bright.net')m.groups()(&#39;wesm&#39;, &#39;bright&#39;, &#39;net&#39;) 1regex.findall(text)[(&#39;dave&#39;, &#39;google&#39;, &#39;com&#39;), (&#39;steve&#39;, &#39;gmail&#39;, &#39;com&#39;), (&#39;rob&#39;, &#39;gmail&#39;, &#39;com&#39;), (&#39;ryan&#39;, &#39;yahoo&#39;, &#39;com&#39;)] 1print(regex.sub(r'Username: \1, Domain: \2, Suffix: \3', text))Dave Username: dave, Domain: google, Suffix: com Steve Username: steve, Domain: gmail, Suffix: com Rob Username: rob, Domain: gmail, Suffix: com Ryan Username: ryan, Domain: yahoo, Suffix: com 123456regex = re.compile(r""" (?P&lt;username&gt;[A-Z0-9._%+-]+) @ (?P&lt;domain&gt;[A-Z0-9.-]+) \. (?P&lt;suffix&gt;[A-Z]&#123;2,4&#125;)""", flags=re.IGNORECASE|re.VERBOSE)12m = regex.match('wesm@bright.net')m.groupdict(){&#39;domain&#39;: &#39;bright&#39;, &#39;suffix&#39;: &#39;net&#39;, &#39;username&#39;: &#39;wesm&#39;} pandas123data = &#123;'Dave': 'dave@google.com', 'Steve': 'steve@gmail.com', 'Rob': 'rob@gmail.com', 'Wes': np.nan&#125;data = Series(data)1dataDave dave@google.com Rob rob@gmail.com Steve steve@gmail.com Wes NaN dtype: object 1data.isnull()Dave False Rob False Steve False Wes True dtype: bool 1data.str.contains('gmail')Dave False Rob True Steve True Wes NaN dtype: object 1pattern&#39;([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})&#39; 1data.str.findall(pattern, flags=re.IGNORECASE)Dave [(dave, google, com)] Rob [(rob, gmail, com)] Steve [(steve, gmail, com)] Wes NaN dtype: object 12matches = data.str.match(pattern, flags=re.IGNORECASE)matchesC:\Users\Ewan\Anaconda3\lib\site-packages\ipykernel\__main__.py:1: FutureWarning: In future versions of pandas, match will change to always return a bool indexer. if __name__ == &#39;__main__&#39;: Dave (dave, google, com) Rob (rob, gmail, com) Steve (steve, gmail, com) Wes NaN dtype: object 1matches.str.get(1)Dave google Rob gmail Steve gmail Wes NaN dtype: object 1matches.str[0]Dave dave Rob rob Steve steve Wes NaN dtype: object 1data.str[:5]Dave dave@ Rob rob@g Steve steve Wes NaN dtype: object Example: USDA Food Database123456789101112131415161718192021222324252627&#123; "id": 21441, "description": "KENTUCKY FRIED CHICKEN, Fried Chicken, EXTRA CRISPY,Wing, meat and skin with breading", "tags": ["KFC"], "manufacturer": "Kentucky Fried Chicken", "group": "Fast Foods", "portions": [ &#123; "amount": 1, "unit": "wing, with skin", "grams": 68.0 &#125;, ... ], "nutrients": [ &#123; "value": 20.8, "units": "g", "description": "Protein", "group": "Composition" &#125;, ... ]&#125;123import jsondb = json.load(open('ch07/foods-2011-10-03.json'))len(db)6636 1db[0].keys()dict_keys([&#39;id&#39;, &#39;tags&#39;, &#39;portions&#39;, &#39;nutrients&#39;, &#39;description&#39;, &#39;group&#39;, &#39;manufacturer&#39;]) 1db[0]['nutrients'][0]{&#39;description&#39;: &#39;Protein&#39;, &#39;group&#39;: &#39;Composition&#39;, &#39;units&#39;: &#39;g&#39;, &#39;value&#39;: 25.18} 12nutrients = DataFrame(db[0]['nutrients'])nutrients[:7]descriptiongroupunitsvalue0ProteinCompositiong25.181Total lipid (fat)Compositiong29.202Carbohydrate, by differenceCompositiong3.063AshOtherg3.284EnergyEnergykcal376.005WaterCompositiong39.286EnergyEnergykJ1573.0012info_keys = ['description', 'group', 'id', 'manufacturer']info = DataFrame(db, columns=info_keys)1info[:5]descriptiongroupidmanufacturer0Cheese, carawayDairy and Egg Products10081Cheese, cheddarDairy and Egg Products10092Cheese, edamDairy and Egg Products10183Cheese, fetaDairy and Egg Products10194Cheese, mozzarella, part skim milkDairy and Egg Products10281pd.value_counts(info.group)[:10]Vegetables and Vegetable Products 812 Beef Products 618 Baked Products 496 Breakfast Cereals 403 Legumes and Legume Products 365 Fast Foods 365 Lamb, Veal, and Game Products 345 Sweets 341 Pork Products 328 Fruits and Fruit Juices 328 Name: group, dtype: int64 12345678nutrients = []for rec in db: fnuts = DataFrame(rec['nutrients']) fnuts['id'] = rec['id'] nutrients.append(fnuts)nutrients = pd.concat(nutrients, ignore_index=True)1nutrients[:10]descriptiongroupunitsvalueid0ProteinCompositiong25.1810081Total lipid (fat)Compositiong29.2010082Carbohydrate, by differenceCompositiong3.0610083AshOtherg3.2810084EnergyEnergykcal376.0010085WaterCompositiong39.2810086EnergyEnergykJ1573.0010087Fiber, total dietaryCompositiong0.0010088Calcium, CaElementsmg673.0010089Iron, FeElementsmg0.6410081nutrients.duplicated().sum()14179 1nutrients = nutrients.drop_duplicates()1234col_mapping = &#123;'description' : 'food', 'group' : 'fgroup'&#125;info = info.rename(columns=col_mapping, copy=False)info[:10]foodfgroupidmanufacturer0Cheese, carawayDairy and Egg Products10081Cheese, cheddarDairy and Egg Products10092Cheese, edamDairy and Egg Products10183Cheese, fetaDairy and Egg Products10194Cheese, mozzarella, part skim milkDairy and Egg Products10285Cheese, mozzarella, part skim milk, low moistureDairy and Egg Products10296Cheese, romanoDairy and Egg Products10387Cheese, roquefortDairy and Egg Products10398Cheese spread, pasteurized process, american, ...Dairy and Egg Products10489Cream, fluid, half and halfDairy and Egg Products10491234col_mapping = &#123;'description' : 'nutrient', 'group' : 'nutgroup'&#125;nutrients = nutrients.rename(columns=col_mapping, copy=False)nutrients[:10]nutrientnutgroupunitsvalueid0ProteinCompositiong25.1810081Total lipid (fat)Compositiong29.2010082Carbohydrate, by differenceCompositiong3.0610083AshOtherg3.2810084EnergyEnergykcal376.0010085WaterCompositiong39.2810086EnergyEnergykJ1573.0010087Fiber, total dietaryCompositiong0.0010088Calcium, CaElementsmg673.0010089Iron, FeElementsmg0.6410081ndata = pd.merge(nutrients, info, on='id', how='outer')1ndata[:10]nutrientnutgroupunitsvalueidfoodfgroupmanufacturer0ProteinCompositiong25.181008Cheese, carawayDairy and Egg Products1Total lipid (fat)Compositiong29.201008Cheese, carawayDairy and Egg Products2Carbohydrate, by differenceCompositiong3.061008Cheese, carawayDairy and Egg Products3AshOtherg3.281008Cheese, carawayDairy and Egg Products4EnergyEnergykcal376.001008Cheese, carawayDairy and Egg Products5WaterCompositiong39.281008Cheese, carawayDairy and Egg Products6EnergyEnergykJ1573.001008Cheese, carawayDairy and Egg Products7Fiber, total dietaryCompositiong0.001008Cheese, carawayDairy and Egg Products8Calcium, CaElementsmg673.001008Cheese, carawayDairy and Egg Products9Iron, FeElementsmg0.641008Cheese, carawayDairy and Egg Products1ndata.ix[30000]nutrient Glycine nutgroup Amino Acids units g value 0.04 id 6158 food Soup, tomato bisque, canned, condensed fgroup Soups, Sauces, and Gravies manufacturer Name: 30000, dtype: object 123result = ndata.groupby(['nutrient', 'fgroup'])['value'].quantile(0.5)result[:10]result['Zinc, Zn'].sort_values().plot(kind='barh')nutrient fgroup Adjusted Protein Sweets 12.900 Vegetables and Vegetable Products 2.180 Alanine Baby Foods 0.085 Baked Products 0.248 Beef Products 1.550 Beverages 0.003 Breakfast Cereals 0.311 Cereal Grains and Pasta 0.373 Dairy and Egg Products 0.271 Ethnic Foods 1.290 Name: value, dtype: float64 &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba08c9e780&gt; 123456789by_nutrient = ndata.groupby(['nutgroup', 'nutrient'])get_maximum = lambda x: x.xs(x.value.idxmax())get_minimum = lambda x: x.xs(x.value.idxmin())max_foods = by_nutrient.apply(get_maximum)[['value', 'food']]# make the food a little smallermax_foods.food = max_foods.food.str[:50]1max_foods.ix['Amino Acids']['food']nutrient Alanine Gelatins, dry powder, unsweetened Arginine Seeds, sesame flour, low-fat Aspartic acid Soy protein isolate Cystine Seeds, cottonseed flour, low fat (glandless) Glutamic acid Soy protein isolate Glycine Gelatins, dry powder, unsweetened Histidine Whale, beluga, meat, dried (Alaska Native) Hydroxyproline KENTUCKY FRIED CHICKEN, Fried Chicken, ORIGINA... Isoleucine Soy protein isolate, PROTEIN TECHNOLOGIES INTE... Leucine Soy protein isolate, PROTEIN TECHNOLOGIES INTE... Lysine Seal, bearded (Oogruk), meat, dried (Alaska Na... Methionine Fish, cod, Atlantic, dried and salted Phenylalanine Soy protein isolate, PROTEIN TECHNOLOGIES INTE... Proline Gelatins, dry powder, unsweetened Serine Soy protein isolate, PROTEIN TECHNOLOGIES INTE... Threonine Soy protein isolate, PROTEIN TECHNOLOGIES INTE... Tryptophan Sea lion, Steller, meat with fat (Alaska Native) Tyrosine Soy protein isolate, PROTEIN TECHNOLOGIES INTE... Valine Soy protein isolate, PROTEIN TECHNOLOGIES INTE... Name: food, dtype: object]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python data analysis Learning note Ch06]]></title>
      <url>%2F2017%2F02%2F28%2FPython-data-analysis-Learning-note-Ch06%2F</url>
      <content type="text"><![CDATA[Data loading, storage, and file formats12345678910111213from __future__ import divisionfrom numpy.random import randnimport numpy as npimport osimport sysimport matplotlib.pyplot as pltnp.random.seed(12345)plt.rc('figure', figsize=(10, 6))from pandas import Series, DataFrameimport pandas as pdnp.set_printoptions(precision=4)from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "all"1%pwd&#39;C:\\Users\\Ewan\\Downloads\\pydata-book-master&#39; Reading and Writing Data in Text Format1!more ch06\ex1.csva,b,c,d,message 1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo 12df = pd.read_csv('ch06/ex1.csv')dfabcdmessage01234hello15678world29101112foo1pd.read_table('ch06/ex1.csv', sep=',')abcdmessage01234hello15678world29101112foo1!more ch06\ex2.csv1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo 12pd.read_csv('ch06/ex2.csv', header=None)pd.read_csv('ch06/ex2.csv', names=['a', 'b', 'c', 'd', 'message'])0123401234hello15678world29101112fooabcdmessage01234hello15678world29101112foo12names = ['a', 'b', 'c', 'd', 'message']pd.read_csv('ch06/ex2.csv', names=names, index_col='message')abcdmessagehello1234world5678foo9101112123!more ch06\csv_mindex.csvparsed = pd.read_csv('ch06/csv_mindex.csv', index_col=['key1', 'key2'])parsedkey1,key2,value1,value2 one,a,1,2 one,b,3,4 one,c,5,6 one,d,7,8 two,a,9,10 two,b,11,12 two,c,13,14 two,d,15,16 value1value2key1key2onea12b34c56d78twoa910b1112c1314d15161list(open('ch06/ex3.txt'))[&#39; A B C\n&#39;, &#39;aaa -0.264438 -1.026059 -0.619500\n&#39;, &#39;bbb 0.927272 0.302904 -0.032399\n&#39;, &#39;ccc -0.264273 -0.386314 -0.217601\n&#39;, &#39;ddd -0.871858 -0.348382 1.100491\n&#39;] 12result = pd.read_table('ch06/ex3.txt', sep='\s+')resultABCaaa-0.264438-1.026059-0.619500bbb0.9272720.302904-0.032399ccc-0.264273-0.386314-0.217601ddd-0.871858-0.3483821.10049112!more ch06\ex4.csvpd.read_csv('ch06/ex4.csv', skiprows=[0, 2, 3])# hey! a,b,c,d,message # just wanted to make things more difficult for you # who reads CSV files with computers, anyway? 1,2,3,4,hello 5,6,7,8,world 9,10,11,12,foo abcdmessage01234hello15678world29101112foo1234!more ch06\ex5.csvresult = pd.read_csv('ch06/ex5.csv')resultpd.isnull(result)something,a,b,c,d,message one,1,2,3,4,NA two,5,6,,8,world three,9,10,11,12,foo somethingabcdmessage0one123.04NaN1two56NaN8world2three91011.012foosomethingabcdmessage0FalseFalseFalseFalseFalseTrue1FalseFalseFalseTrueFalseFalse2FalseFalseFalseFalseFalseFalse12result = pd.read_csv('ch06/ex5.csv', na_values=['NULL'])resultsomethingabcdmessage0one123.04NaN1two56NaN8world2three91011.012foo12sentinels = &#123;'message': ['foo', 'NA'], 'something': ['two']&#125;pd.read_csv('ch06/ex5.csv', na_values=sentinels)somethingabcdmessage0one123.04NaN1NaN56NaN8world2three91011.012NaN12result = pd.read_csv('ch06/ex6.csv')resultonetwothreefourkey00.467976-0.038649-0.295344-1.824726L1-0.3588931.4044530.704965-0.200638B2-0.5018400.659254-0.421691-0.057688G30.2048861.0741341.388361-0.982404R40.354628-0.1331160.283763-0.837063Q51.8174800.7422730.419395-2.251035Q6-0.7767640.935518-0.332872-1.875641U7-0.9131351.530624-0.5726570.477252K80.358480-0.497572-0.3670160.507702S9-1.740877-1.160417-1.6378302.172201G100.240564-0.3282491.2521551.0727968110.7640181.165476-0.6395441.495258R120.571035-0.3105370.582437-0.2987651132.3176580.430710-1.3342160.199679P141.547771-1.119753-2.2776340.329586J15-1.3106080.401719-1.0009871.156708E16-0.0884960.6347120.1533240.415335B17-0.018663-0.247487-1.4465220.750938A18-0.070127-1.5790970.1208920.671432F19-0.194678-0.4920392.3596050.319810H20-0.2486180.868707-0.492226-0.717959W21-1.091549-0.867110-0.647760-0.832562C220.641404-0.138822-0.621963-0.284839C231.2164080.9926870.165162-0.069619V24-0.5644740.7928320.7470530.571675I251.759879-0.515666-0.2304811.362317S260.1262660.3092810.382820-0.239199L271.334360-0.100152-0.840731-0.643967628-0.7376200.278087-0.053235-0.950972J29-1.148486-0.986292-0.1449630.124362Y..................99700.633495-0.1865240.9276270.143164499710.308636-0.1128570.762842-1.07297719972-1.627051-0.9781510.154745-1.229037Z99730.3148470.0979890.1996080.955193P99741.6669070.9920050.496128-0.686391S99750.0106030.708540-1.2587110.226541K99760.118693-0.714455-0.501342-0.254764K99770.302616-2.011527-0.6280850.768827H9978-0.0985721.769086-0.215027-0.053076A9979-0.0190581.9649940.738538-0.883776F9980-0.5953490.001781-1.423355-1.458477M99811.392170-1.396560-1.425306-0.847535H9982-0.896029-0.1522871.9244830.36518469983-2.274642-0.9018741.5003520.996541N9984-0.3018981.0199061.1021602.624526I9985-2.548389-0.5853741.496201-0.718815D9986-0.0645880.759292-1.568415-0.420933E9987-0.143365-1.111760-1.8155810.43527429988-0.070412-1.0559210.338017-0.440763X99890.6491480.994273-1.3842270.485120Q9990-0.3707690.404356-1.051628-1.05089989991-0.4099800.155627-0.8189901.277350W99920.301214-1.1112030.6682580.671922A99931.8211170.4164450.1738740.505118X99940.0688041.3227590.8023460.223618H99952.311896-0.417070-1.409599-0.515821L9996-0.479893-0.6504190.745152-0.646038E99970.5233310.7871120.4860661.093156K9998-0.3625590.598894-1.8432010.887292G9999-0.096376-1.012999-0.657431-0.573315010000 rows  5 columns1pd.read_csv('ch06/ex6.csv', nrows=5)onetwothreefourkey00.467976-0.038649-0.295344-1.824726L1-0.3588931.4044530.704965-0.200638B2-0.5018400.659254-0.421691-0.057688G30.2048861.0741341.388361-0.982404R40.354628-0.1331160.283763-0.837063Q12chunker = pd.read_csv('ch06/ex6.csv', chunksize=1000)chunker&lt;pandas.io.parsers.TextFileReader at 0x2035229de80&gt; 1234567chunker = pd.read_csv('ch06/ex6.csv', chunksize=1000)tot = Series([])for piece in chunker: tot = tot.add(piece['key'].value_counts(), fill_value=0)tot = tot.sort_values(ascending=False)1tot[:10]E 368.0 X 364.0 L 346.0 O 343.0 Q 340.0 M 338.0 J 337.0 F 335.0 K 334.0 H 330.0 dtype: float64 12data = pd.read_csv('ch06/ex5.csv')datasomethingabcdmessage0one123.04NaN1two56NaN8world2three91011.012foo12data.to_csv('ch06/out.csv')!more ch06\out.csv,something,a,b,c,d,message 0,one,1,2,3.0,4, 1,two,5,6,,8,world 2,three,9,10,11.0,12,foo 1data.to_csv(sys.stdout, sep='|')|something|a|b|c|d|message 0|one|1|2|3.0|4| 1|two|5|6||8|world 2|three|9|10|11.0|12|foo 1data.to_csv(sys.stdout, na_rep='NULL'),something,a,b,c,d,message 0,one,1,2,3.0,4,NULL 1,two,5,6,NULL,8,world 2,three,9,10,11.0,12,foo 1data.to_csv(sys.stdout, index=False, header=False)one,1,2,3.0,4, two,5,6,,8,world three,9,10,11.0,12,foo 1data.to_csv(sys.stdout, index=False, columns=['a', 'b', 'c'])a,b,c 1,2,3.0 5,6, 9,10,11.0 123456dates = pd.date_range('1/1/2000', periods=7)datests = Series(np.arange(7), index=dates)tsts.to_csv('ch06/tseries.csv')!more ch06\tseries.csvDatetimeIndex([&#39;2000-01-01&#39;, &#39;2000-01-02&#39;, &#39;2000-01-03&#39;, &#39;2000-01-04&#39;, &#39;2000-01-05&#39;, &#39;2000-01-06&#39;, &#39;2000-01-07&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) 2000-01-01 0 2000-01-02 1 2000-01-03 2 2000-01-04 3 2000-01-05 4 2000-01-06 5 2000-01-07 6 Freq: D, dtype: int32 2000-01-01,0 2000-01-02,1 2000-01-03,2 2000-01-04,3 2000-01-05,4 2000-01-06,5 2000-01-07,6 1Series.from_csv('ch06/tseries.csv', parse_dates=True)2000-01-01 0 2000-01-02 1 2000-01-03 2 2000-01-04 3 2000-01-05 4 2000-01-06 5 2000-01-07 6 dtype: int64 1!more ch06\ex7.csv&quot;a&quot;,&quot;b&quot;,&quot;c&quot; &quot;1&quot;,&quot;2&quot;,&quot;3&quot; &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot; 1234import csvf = open('ch06/ex7.csv')reader = csv.reader(f)12for line in reader: print(line)[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;] [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;] [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;] 12345678910lines = list(csv.reader(open('ch06/ex7.csv')))header, values = lines[0], lines[1:]for item in zip(*values): print(item) for h, v in zip(header, zip(*values)): print(h, v)data_dict = &#123;h: v for h, v in zip(header, zip(*values))&#125;data_dict(&#39;1&#39;, &#39;1&#39;) (&#39;2&#39;, &#39;2&#39;) (&#39;3&#39;, &#39;3&#39;) a (&#39;1&#39;, &#39;1&#39;) b (&#39;2&#39;, &#39;2&#39;) c (&#39;3&#39;, &#39;3&#39;) {&#39;a&#39;: (&#39;1&#39;, &#39;1&#39;), &#39;b&#39;: (&#39;2&#39;, &#39;2&#39;), &#39;c&#39;: (&#39;3&#39;, &#39;3&#39;)} 12345class my_dialect(csv.Dialect): lineterminator = '\n' delimiter = ';' quotechar = '"' quoting = csv.QUOTE_MINIMAL123456with open('mydata.csv', 'w') as f: writer = csv.writer(f, dialect=my_dialect) writer.writerow(('one', 'two', 'three')) writer.writerow(('1', '2', '3')) writer.writerow(('4', '5', '6')) writer.writerow(('7', '8', '9'))14 6 6 6 1!more mydata.csvone;two;three 1;2;3 4;5;6 7;8;9 JSON12345678obj = """&#123;"name": "Wes", "places_lived": ["United States", "Spain", "Germany"], "pet": null, "siblings": [&#123;"name": "Scott", "age": 25, "pet": "Zuko"&#125;, &#123;"name": "Katie", "age": 33, "pet": "Cisco"&#125;]&#125;"""123import jsonresult = json.loads(obj)result{&#39;name&#39;: &#39;Wes&#39;, &#39;pet&#39;: None, &#39;places_lived&#39;: [&#39;United States&#39;, &#39;Spain&#39;, &#39;Germany&#39;], &#39;siblings&#39;: [{&#39;age&#39;: 25, &#39;name&#39;: &#39;Scott&#39;, &#39;pet&#39;: &#39;Zuko&#39;}, {&#39;age&#39;: 33, &#39;name&#39;: &#39;Katie&#39;, &#39;pet&#39;: &#39;Cisco&#39;}]} 1asjson = json.dumps(result) # convert to json12siblings = DataFrame(result['siblings'], columns=['name', 'age'])siblingsnameage0Scott251Katie33XMLHTML WebNB. The Yahoo! Finance API has changed and this example no longer works123456from lxml.html import parsefrom urllib.request import urlopenparsed = parse(urlopen('http://finance.yahoo.com/q/op?s=AAPL+Options'))doc = parsed.getroot()12links = doc.findall('.//a')links[15:20][&lt;Element a at 0x20352cad598&gt;, &lt;Element a at 0x20352cad5e8&gt;, &lt;Element a at 0x20352cad638&gt;, &lt;Element a at 0x20352cad688&gt;, &lt;Element a at 0x20352cad6d8&gt;] 1234lnk = links[28]lnklnk.get('href')lnk.text_content()&lt;Element a at 0x20352cad9a8&gt; &#39;/quote/NFLX?p=NFLX&#39; &#39;NFLX&#39; 12urls = [lnk.get('href') for lnk in doc.findall('.//a')]urls[-10:][&#39;//finance.yahoo.com/broker-comparison?bypass=true&#39;, &#39;https://help.yahoo.com/kb/index?page=content&amp;y=PROD_MAIL_ML&amp;locale=en_US&amp;id=SLN2310&amp;actp=productlink&#39;, &#39;http://help.yahoo.com/l/us/yahoo/finance/&#39;, &#39;https://yahoo.uservoice.com/forums/382977&#39;, &#39;http://info.yahoo.com/privacy/us/yahoo/&#39;, &#39;http://info.yahoo.com/relevantads/&#39;, &#39;http://info.yahoo.com/legal/us/yahoo/utos/utos-173.html&#39;, &#39;http://twitter.com/YahooFinance&#39;, &#39;http://facebook.com/yahoofinance&#39;, &#39;http://yahoofinance.tumblr.com&#39;] 123tables = doc.findall('.//table')len(tables)calls = tables[0]1 1rows = calls.findall('.//tr')123def _unpack(row, kind='td'): elts = row.findall('.//%s' % kind) return [val.text_content() for val in elts]12_unpack(rows[0], kind='th')_unpack(rows[1], kind='td')[] --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-87-7d371ed47023&gt; in &lt;module&gt;() 1 _unpack(rows[0], kind=&#39;th&#39;) ----&gt; 2 _unpack(rows[1], kind=&#39;td&#39;) IndexError: list index out of range 1234567from pandas.io.parsers import TextParserdef parse_options_data(table): rows = table.findall('.//tr') header = _unpack(rows[0], kind='th') data = [_unpack(r) for r in rows[1:]] return TextParser(data, names=header).get_chunk()123call_data = parse_options_data(calls)put_data = parse_options_data(puts)call_data[:10]Parsing XML with lxml.objectify12345from lxml import objectifypath = '.\ch06\mta_perf\Performance_MNR.xml'parsed = objectify.parse(open(path))root = parsed.getroot()12345678910111213data = []skip_fields = ['PARENT_SEQ', 'INDICATOR_SEQ', 'DESIRED_CHANGE', 'DECIMAL_PLACES']for elt in root.INDICATOR: el_data = &#123;&#125; for child in elt.getchildren(): if child.tag in skip_fields: continue el_data[child.tag] = child.pyval data.append(el_data)12perf = DataFrame(data)perf.ix[:10, 5:]INDICATOR_UNITMONTHLY_ACTUALMONTHLY_TARGETPERIOD_MONTHPERIOD_YEARYTD_ACTUALYTD_TARGET0%96.9951200896.9951%95952200896952%96.9953200896.3953%98.3954200896.8954%95.8955200896.6955%94.4956200896.2956%96957200896.2957%96.4958200896.2958%93.7959200895.9959%96.495102008969510%96.99511200896.195123frame = pd.read_csv('ch06/ex1.csv')frameframe.to_pickle('ch06/frame_pickle')abcdmessage01234hello15678world29101112foo1pd.read_pickle('ch06/frame_pickle')abcdmessage01234hello15678world29101112fooHDF51234store = pd.HDFStore('mydata.h5')store['obj1'] = framestore['obj1_col'] = frame['a']store&lt;class &#39;pandas.io.pytables.HDFStore&#39;&gt; File path: mydata.h5 /obj1 frame (shape-&gt;[3,5]) /obj1_col series (shape-&gt;[3]) 1store['obj1']abcdmessage01234hello15678world29101112foo12store.close()os.remove('mydata.h5')1234567891011import sqlite3query = """CREATE TABLE test(a VARCHAR(20), b VARCHAR(20), c REAL, d INTEGER);"""con = sqlite3.connect(':memory:')con.execute(query)con.commit()&lt;sqlite3.Cursor at 0x2035487c880&gt; 1234567data = [('Atlanta', 'Georgia', 1.25, 6), ('Tallahassee', 'Florida', 2.6, 3), ('Sacramento', 'California', 1.7, 5)]stmt = "INSERT INTO test VALUES(?, ?, ?, ?)"con.executemany(stmt, data)con.commit()&lt;sqlite3.Cursor at 0x2035487c810&gt; 123cursor = con.execute('select * from test')rows = cursor.fetchall()rows[(&#39;Atlanta&#39;, &#39;Georgia&#39;, 1.25, 6), (&#39;Tallahassee&#39;, &#39;Florida&#39;, 2.6, 3), (&#39;Sacramento&#39;, &#39;California&#39;, 1.7, 5)] 12import pandas.io.sql as sqlsql.read_sql('select * from test', con)abcd0AtlantaGeorgia1.2561TallahasseeFlorida2.6032SacramentoCalifornia1.705]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python data analysis Learning note ch05]]></title>
      <url>%2F2017%2F02%2F28%2FPython-data-analysis-Learning-note-ch05%2F</url>
      <content type="text"><![CDATA[pandaspackage12from pandas import Series, DataFrameimport pandas as pd123456789101112from __future__ import divisionfrom numpy.random import randnimport numpy as npimport osimport matplotlib.pyplot as pltnp.random.seed(12345)plt.rc('figure', figsize=(10, 6))from pandas import Series, DataFrameimport pandas as pdnp.set_printoptions(precision=4)from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "all"pandasSeriesSeries12obj = Series([4, 7, -5, 3])obj0 4 1 7 2 -5 3 3 dtype: int64 12obj.valuesobj.indexarray([ 4, 7, -5, 3], dtype=int64) RangeIndex(start=0, stop=4, step=1) 12obj2 = Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c'])obj2d 4 b 7 a -5 c 3 dtype: int64 1obj2.indexIndex([&#39;d&#39;, &#39;b&#39;, &#39;a&#39;, &#39;c&#39;], dtype=&#39;object&#39;) 1obj2['a']-5 12obj2['d'] = 6obj2[['c', 'a', 'd']]c 3 a -5 d 6 dtype: int64 Numpy1obj2[obj2 &gt; 0]d 6 b 7 c 3 dtype: int64 1obj2 * 2d 12 b 14 a -10 c 6 dtype: int64 1np.exp(obj2)d 403.428793 b 1096.633158 a 0.006738 c 20.085537 dtype: float64 1'b' in obj2True 1'e' in obj2False NumpyDictSeries123sdata = &#123;'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000&#125;obj3 = Series(sdata)obj3Ohio 35000 Oregon 16000 Texas 71000 Utah 5000 dtype: int64 indexDictNaN123states = ['California', 'Ohio', 'Oregon', 'Texas']obj4 = Series(sdata, index=states)obj4California NaN Ohio 35000.0 Oregon 16000.0 Texas 71000.0 dtype: float64 1pd.isnull(obj4)California True Ohio False Oregon False Texas False dtype: bool 1pd.notnull(obj4)California False Ohio True Oregon True Texas True dtype: bool 1obj4.isnull()California True Ohio False Oregon False Texas False dtype: bool Series1obj3Ohio 35000 Oregon 16000 Texas 71000 Utah 5000 dtype: int64 1obj4California NaN Ohio 35000.0 Oregon 16000.0 Texas 71000.0 dtype: float64 1obj3 + obj4California NaN Ohio 70000.0 Oregon 32000.0 Texas 142000.0 Utah NaN dtype: float64 Seriesname123obj4.name = 'population'obj4.index.name = 'state'obj4state California NaN Ohio 35000.0 Oregon 16000.0 Texas 71000.0 Name: population, dtype: float64 index12obj.index = ['Bob', 'Steve', 'Jeff', 'Ryan']objBob 4 Steve 7 Jeff -5 Ryan 3 dtype: int64 DataFrameDataFrameSeriesSeries1234data = &#123;'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'], 'year': [2000, 2001, 2002, 2001, 2002], 'pop': [1.5, 1.7, 3.6, 2.4, 2.9]&#125;frame = DataFrame(data)1framepopstateyear01.5Ohio200011.7Ohio200123.6Ohio200232.4Nevada200142.9Nevada20021DataFrame(data, columns=['year', 'state', 'pop'])yearstatepop02000Ohio1.512001Ohio1.722002Ohio3.632001Nevada2.442002Nevada2.9123frame2 = DataFrame(data, columns=['year', 'state', 'pop', 'debt'], index=['one', 'two', 'three', 'four', 'five'])frame2yearstatepopdebtone2000Ohio1.5NaNtwo2001Ohio1.7NaNthree2002Ohio3.6NaNfour2001Nevada2.4NaNfive2002Nevada2.9NaN1frame2.columnsIndex([&#39;year&#39;, &#39;state&#39;, &#39;pop&#39;, &#39;debt&#39;], dtype=&#39;object&#39;) DataFrameKeyValueSeries1frame2['state']one Ohio two Ohio three Ohio four Nevada five Nevada Name: state, dtype: object 1frame2.yearone 2000 two 2001 three 2002 four 2001 five 2002 Name: year, dtype: int64 nameix1frame2.ix['three']year 2002 state Ohio pop 3.6 debt NaN Name: three, dtype: object Numpy12frame2['debt'] = 16.5frame2yearstatepopdebtone2000Ohio1.516.5two2001Ohio1.716.5three2002Ohio3.616.5four2001Nevada2.416.5five2002Nevada2.916.512frame2['debt'] = np.arange(5.)frame2yearstatepopdebtone2000Ohio1.50.0two2001Ohio1.71.0three2002Ohio3.62.0four2001Nevada2.43.0five2002Nevada2.94.0SeriesNaN123val = Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five'])frame2['debt'] = valframe2yearstatepopdebtone2000Ohio1.5NaNtwo2001Ohio1.7-1.2three2002Ohio3.6NaNfour2001Nevada2.4-1.5five2002Nevada2.9-1.712frame2['eastern'] = frame2.state == 'Ohio'frame2yearstatepopdebteasternone2000Ohio1.5NaNTruetwo2001Ohio1.7-1.2Truethree2002Ohio3.6NaNTruefour2001Nevada2.4-1.5Falsefive2002Nevada2.9-1.7Falsedel12del frame2['eastern']frame2.columnsIndex([&#39;year&#39;, &#39;state&#39;, &#39;pop&#39;, &#39;debt&#39;], dtype=&#39;object&#39;) DataFrameindexcolums12pop = &#123;'Nevada': &#123;2001: 2.4, 2002: 2.9&#125;, 'Ohio': &#123;2000: 1.5, 2001: 1.7, 2002: 3.6&#125;&#125;12frame3 = DataFrame(pop)frame3NevadaOhio2000NaN1.520012.41.720022.93.6indexcolumn1frame3.T200020012002NevadaNaN2.42.9Ohio1.51.73.6NaN1DataFrame(pop, index=[2001, 2002, 2003])NevadaOhio20012.41.720022.93.62003NaNNaN1frame3NevadaOhio2000NaN1.520012.41.720022.93.6123pdata = &#123;'Ohio': frame3['Ohio'][:-1], 'Nevada': frame3['Nevada'][:2]&#125;DataFrame(pdata)NevadaOhio2000NaN1.520012.41.71frame3NevadaOhio2000NaN1.520012.41.720022.93.6name12frame3.index.name = 'year'; frame3.columns.name = 'state'frame3stateNevadaOhioyear2000NaN1.520012.41.720022.93.6valuesindexkey1frame3.valuesarray([[ nan, 1.5], [ 2.4, 1.7], [ 2.9, 3.6]]) 1frame2yearstatepopdebtone2000Ohio1.5NaNtwo2001Ohio1.7-1.2three2002Ohio3.6NaNfour2001Nevada2.4-1.5five2002Nevada2.9-1.71frame2.valuesarray([[2000, &#39;Ohio&#39;, 1.5, nan], [2001, &#39;Ohio&#39;, 1.7, -1.2], [2002, &#39;Ohio&#39;, 3.6, nan], [2001, &#39;Nevada&#39;, 2.4, -1.5], [2002, &#39;Nevada&#39;, 2.9, -1.7]], dtype=object) Index123obj = Series(range(3), index=['a', 'b', 'c'])index = obj.indexindexIndex([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], dtype=&#39;object&#39;) 1index[1:]Index([&#39;b&#39;, &#39;c&#39;], dtype=&#39;object&#39;) ~1index[1] = 'd'--------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-52-676fdeb26a68&gt; in &lt;module&gt;() ----&gt; 1 index[1] = &#39;d&#39; C:\Users\Ewan\Anaconda3\lib\site-packages\pandas\indexes\base.py in __setitem__(self, key, value) 1243 1244 def __setitem__(self, key, value): -&gt; 1245 raise TypeError(&quot;Index does not support mutable operations&quot;) 1246 1247 def __getitem__(self, key): TypeError: Index does not support mutable operations Index123index = pd.Index(np.arange(3))obj2 = Series([1.5, -2.5, 0], index=index)obj2.index is indexTrue 1frame3stateNevadaOhioyear2000NaN1.520012.41.720022.93.61'Ohio' in frame3.columnsTrue 12003 in frame3.indexFalse 12obj = Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])objd 4.5 b 7.2 a -5.3 c 3.6 dtype: float64 12obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'])obj2a -5.3 b 7.2 c 3.6 d 4.5 e NaN dtype: float64 1obj.reindex(['a', 'b', 'c', 'd', 'e'], fill_value=0)a -5.3 b 7.2 c 3.6 d 4.5 e 0.0 dtype: float64 12obj3 = Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])obj3.reindex(range(6), method='ffill') # 0 blue 1 blue 2 purple 3 purple 4 yellow 5 yellow dtype: object 123frame = DataFrame(np.arange(9).reshape((3, 3)), index=['a', 'c', 'd'], columns=['Ohio', 'Texas', 'California'])frameOhioTexasCaliforniaa012c345d67812frame2 = frame.reindex(['a', 'b', 'c', 'd'])frame2OhioTexasCaliforniaa0.01.02.0bNaNNaNNaNc3.04.05.0d6.07.08.012states = ['Texas', 'Utah', 'California']frame.reindex(columns=states)TexasUtahCaliforniaa1NaN2c4NaN5d7NaN812frame.reindex(index=['a', 'b', 'c', 'd'], method='ffill', columns=states)TexasUtahCaliforniaa1NaN2b1NaN2c4NaN5d7NaN8ix1frame.ix[['a', 'b', 'c', 'd'], states]TexasUtahCaliforniaa1.0NaN2.0bNaNNaNNaNc4.0NaN5.0d7.0NaN8.01frame.ix[['a', 'b', 'c', 'd'], states]TexasUtahCaliforniaa1.0NaN2.0bNaNNaNNaNc4.0NaN5.0d7.0NaN8.0123obj = Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])new_obj = obj.drop('c')new_obja 0.0 b 1.0 d 3.0 e 4.0 dtype: float64 1obj.drop(['d', 'c'])a 0.0 b 1.0 e 4.0 dtype: float64 1234data = DataFrame(np.arange(16).reshape((4, 4)), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['one', 'two', 'three', 'four'])dataonetwothreefourOhio0123Colorado4567Utah891011New York121314151data.drop(['Colorado', 'Ohio'])onetwothreefourUtah891011New York121314151data.drop('two', axis=1)onethreefourOhio023Colorado467Utah81011New York1214151data.drop(['two', 'four'], axis=1)onethreeOhio02Colorado46Utah810New York1214123obj = Series(np.arange(4.), index=['a', 'b', 'c', 'd'])objobj['b']a 0.0 b 1.0 c 2.0 d 3.0 dtype: float64 1.0 1obj[1]1.0 1obj[2:4]c 2.0 d 3.0 dtype: float64 1obj[['b', 'a', 'd']]b 1.0 a 0.0 d 3.0 dtype: float64 1obj[[1, 3]]b 1.0 d 3.0 dtype: float64 1obj[obj &lt; 2] # dataa 0.0 b 1.0 dtype: float64 1obj['b':'c']b 1.0 c 2.0 dtype: float64 12obj['b':'c'] = 5obja 0.0 b 5.0 c 5.0 d 3.0 dtype: float64 1234data = DataFrame(np.arange(16).reshape((4, 4)), index=['Ohio', 'Colorado', 'Utah', 'New York'], columns=['one', 'two', 'three', 'four'])dataonetwothreefourOhio0123Colorado4567Utah891011New York121314151data['two']Ohio 1 Colorado 5 Utah 9 New York 13 Name: two, dtype: int32 1data[['three', 'one']]threeoneOhio20Colorado64Utah108New York14121data[:2] # axis=0onetwothreefourOhio0123Colorado45671data[data['three'] &gt; 5]onetwothreefourColorado4567Utah891011New York121314151data &lt; 5onetwothreefourOhioTrueTrueTrueTrueColoradoTrueFalseFalseFalseUtahFalseFalseFalseFalseNew YorkFalseFalseFalseFalse1data[data &lt; 5] = 01dataonetwothreefourOhio0000Colorado0567Utah891011New York121314151data.ix['Colorado', ['two', 'three']]two 5 three 6 Name: Colorado, dtype: int32 1data.ix[['Colorado', 'Utah'], [3, 0, 1]]fouronetwoColorado705Utah11891data.ix[2]one 8 two 9 three 10 four 11 Name: Utah, dtype: int32 1data.ix[:'Utah', 'two']Ohio 0 Colorado 5 Utah 9 Name: two, dtype: int32 1data.ix[data.three &gt; 5, :3]onetwothreeColorado056Utah8910New York121314DataFramename12s1 = Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'])s2 = Series([-2.1, 3.6, -1.5, 4, 3.1], index=['a', 'c', 'e', 'f', 'g'])1s1a 7.3 c -2.5 d 3.4 e 1.5 dtype: float64 1s2a -2.1 c 3.6 e -1.5 f 4.0 g 3.1 dtype: float64 1s1 + s2a 5.2 c 1.1 d NaN e 0.0 f NaN g NaN dtype: float64 12345df1 = DataFrame(np.arange(9.).reshape((3, 3)), columns=list('bcd'), index=['Ohio', 'Texas', 'Colorado'])df2 = DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])df1bcdOhio0.01.02.0Texas3.04.05.0Colorado6.07.08.01df2bdeUtah0.01.02.0Ohio3.04.05.0Texas6.07.08.0Oregon9.010.011.01df1 + df2bcdeColoradoNaNNaNNaNNaNOhio3.0NaN6.0NaNOregonNaNNaNNaNNaNTexas9.0NaN12.0NaNUtahNaNNaNNaNNaNcolumn123df1 = DataFrame(np.arange(12.).reshape((3, 4)), columns=list('abcd'))df2 = DataFrame(np.arange(20.).reshape((4, 5)), columns=list('abcde'))df1abcd00.01.02.03.014.05.06.07.028.09.010.011.01df2abcde00.01.02.03.04.015.06.07.08.09.0210.011.012.013.014.0315.016.017.018.019.01df1 + df2abcde00.02.04.06.0NaN19.011.013.015.0NaN218.020.022.024.0NaN3NaNNaNNaNNaNNaNadd1df1.add(df2, fill_value=0)abcde00.02.04.06.04.019.011.013.015.09.0218.020.022.024.014.0315.016.017.018.019.0reindexadd1df1.reindex(columns=df2.columns, fill_value=0)abcde00.01.02.03.0014.05.06.07.0028.09.010.011.00DataFrameSeries12arr = np.arange(12.).reshape((3, 4))arrarray([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]]) 1arr[0]array([ 0., 1., 2., 3.]) 1arr - arr[0]array([[ 0., 0., 0., 0.], [ 4., 4., 4., 4.], [ 8., 8., 8., 8.]]) 1234frame = DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])series = frame.ix[0]framebdeUtah0.01.02.0Ohio3.04.05.0Texas6.07.08.0Oregon9.010.011.0SeriesnameDataFrame1seriesb 0.0 d 1.0 e 2.0 Name: Utah, dtype: float64 DataFrameSeriesSeriesindexDataFramecolumn, 1frame - seriesbdeUtah0.00.00.0Ohio3.03.03.0Texas6.06.06.0Oregon9.09.09.0SeriesindexDataFramecolumn12series2 = Series(range(3), index=['b', 'e', 'f'])frame + series2bdefUtah0.0NaN3.0NaNOhio3.0NaN6.0NaNTexas6.0NaN9.0NaNOregon9.0NaN12.0NaN12series3 = frame['d']framebdeUtah0.01.02.0Ohio3.04.05.0Texas6.07.08.0Oregon9.010.011.01series3Utah 1.0 Ohio 4.0 Texas 7.0 Oregon 10.0 Name: d, dtype: float64  axis12frame.sub(series3, axis=0)frame.sub(series3, axis=1)bdeUtah-1.00.01.0Ohio-1.00.01.0Texas-1.00.01.0Oregon-1.00.01.0OhioOregonTexasUtahbdeUtahNaNNaNNaNNaNNaNNaNNaNOhioNaNNaNNaNNaNNaNNaNNaNTexasNaNNaNNaNNaNNaNNaNNaNOregonNaNNaNNaNNaNNaNNaNNaN12frame = DataFrame(np.random.randn(4, 3), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])1framebdeUtah-0.2047080.478943-0.519439Ohio-0.5557301.9657811.393406Texas0.0929080.2817460.769023Oregon1.2464351.007189-1.296221NumpyDataFrameDataFrameNumpy.array1np.abs(frame)bdeUtah0.2047080.4789430.519439Ohio0.5557301.9657811.393406Texas0.0929080.2817460.769023Oregon1.2464351.0071891.2962211f = lambda x: x.max() - x.min()apply1frame.apply(f) # axis=0b 1.802165 d 1.684034 e 2.689627 dtype: float64 1frame.apply(f, axis=1)Utah 0.998382 Ohio 2.521511 Texas 0.676115 Oregon 2.542656 dtype: float64 1234def f(x): return Series([x.min(), x.max()], index=['min', 'max'])frame.apply(f)frame.apply(f, axis=1)bdemin-0.5557300.281746-1.296221max1.2464351.9657811.393406minmaxUtah-0.5194390.478943Ohio-0.5557301.965781Texas0.0929080.769023Oregon-1.2962211.246435applymap Seriesmap12format = lambda x: '%.2f' % xframe.applymap(format)bdeUtah-0.200.48-0.52Ohio-0.561.971.39Texas0.090.280.77Oregon1.251.01-1.301frame['e'].map(format)Utah -0.52 Ohio 1.39 Texas 0.77 Oregon -1.30 Name: e, dtype: object column12obj = Series(range(4), index=['d', 'a', 'b', 'c'])obj.sort_index()a 1 b 2 c 3 d 0 dtype: int32 123frame = DataFrame(np.arange(8).reshape((2, 4)), index=['three', 'one'], columns=['d', 'a', 'b', 'c'])frame.sort_index()dabcone4567three01231frame.sort_index(axis=1)abcdthree1230one56741frame.sort_index(axis=1, ascending=False)dcbathree0321one4765data12obj = Series([4, 7, -3, 2])obj.sort_values()2 -3 3 2 0 4 1 7 dtype: int64 Series12obj = Series([4, np.nan, 7, np.nan, -3, 2])obj.sort_values()4 -3.0 5 2.0 0 4.0 2 7.0 1 NaN 3 NaN dtype: float64 12frame = DataFrame(&#123;'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]&#125;)frameab00411720-3312indexcolumn1frame.sort_values(by='b')ab20-3312004117multi-indexmulti-column1frame.sort_values(by=['a', 'b'])ab20-3004312117rankrankrand12obj = Series([7, -5, 7, 4, 2, 0, 4, 4])obj.rank()0 7.5 1 1.0 2 7.5 3 5.0 4 3.0 5 2.0 6 5.0 7 5.0 dtype: float64 1obj.rank(method='first')0 7.0 1 1.0 2 8.0 3 4.0 4 3.0 5 2.0 6 5.0 7 6.0 dtype: float64 1obj.rank(ascending=False, method='max')0 2.0 1 8.0 2 2.0 3 5.0 4 6.0 5 7.0 6 5.0 7 5.0 dtype: float64 123frame = DataFrame(&#123;'b': [4.3, 7, -3, 2], 'a': [0, 1, 0, 1], 'c': [-2, 5, 8, -2.5]&#125;)frameabc004.3-2.0117.05.020-3.08.0312.0-2.51frame.rank(axis=1)abc02.03.01.011.03.02.022.01.03.032.03.01.012obj = Series(range(5), index=['a', 'a', 'b', 'b', 'c'])obja 0 a 1 b 2 b 3 c 4 dtype: int32 1obj.index.is_uniqueFalse Series1obj['a']a 0 a 1 dtype: int32 1obj['c']4 12df = DataFrame(np.random.randn(4, 3), index=['a', 'a', 'b', 'b'])df012a0.2749920.2289131.352917a0.886429-2.001637-0.371843b1.669025-0.438570-0.539741b0.4769853.248944-1.0212281df.ix['b']012b1.669025-0.438570-0.539741b0.4769853.248944-1.02122812345df = DataFrame([[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]], index=['a', 'b', 'c', 'd'], columns=['one', 'two'])dfonetwoa1.40NaNb7.10-4.5cNaNNaNd0.75-1.31df.sum() # axis=0 skipna=Trueone 9.25 two -5.80 dtype: float64 1df.sum(axis=1) # skipna=Truea 1.40 b 2.60 c 0.00 d -0.55 dtype: float64 1df.mean(axis=1, skipna=False)a NaN b 1.300 c NaN d -0.275 dtype: float64 1df.idxmax()one b two d dtype: object 1df.cumsum()onetwoa1.40NaNb8.50-4.5cNaNNaNd9.25-5.8describe1df.describe()C:\Users\Ewan\Anaconda3\lib\site-packages\numpy\lib\function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile RuntimeWarning) onetwocount3.0000002.000000mean3.083333-2.900000std3.4936852.262742min0.750000-4.50000025%NaNNaN50%NaNNaN75%NaNNaNmax7.100000-1.300000123obj = Series(['a', 'a', 'b', 'c'] * 4)objobj.describe()0 a 1 a 2 b 3 c 4 a 5 a 6 b 7 c 8 a 9 a 10 b 11 c 12 a 13 a 14 b 15 c dtype: object count 16 unique 3 top a freq 8 dtype: object xi12345678910import pandas_datareader.data as weball_data = &#123;&#125;for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG']: all_data[ticker] = web.get_data_yahoo(ticker)price = DataFrame(&#123;tic: data['Adj Close'] for tic, data in all_data.items()&#125;)volume = DataFrame(&#123;tic: data['Volume'] for tic, data in all_data.items()&#125;)1price[:10]AAPLGOOGIBMMSFTDate2010-01-0427.727039313.062468111.40500025.5554852010-01-0527.774976311.683844110.05923225.5637412010-01-0627.333178303.826685109.34428325.4068592010-01-0727.282650296.753749108.96578625.1426342010-01-0827.464034300.709808110.05923225.3160312010-01-1127.221758300.255255108.90690324.9940072010-01-1226.912110294.945572109.77324524.8288662010-01-1327.291720293.252243109.53773525.0600642010-01-1427.133657294.630868111.28724525.5637412010-01-1526.680198289.710772110.84145825.4811721volume[:10]AAPLGOOGIBMMSFTDate2010-01-0412343240039270006155300384091002010-01-0515047620060319006841400497496002010-01-0613804000079871005605300581824002010-01-07119282800128766005840600505597002010-01-0811190270094839004197200511974002010-01-11115557400144798005730400687547002010-01-1214861490097429008081500659121002010-01-13151473000130418006455400518635002010-01-1410822350085119007111800632281002010-01-1514851690010909600849440079913200price.pct_changeSignature: price.pct_change(periods=1, fill_method=pad, limit=None, freq=None, **kwargs)Docstring:Percent change over given number of periods.Parametersperiods : int, default 1Periods to shift for forming percent changefill_method : str, default padHow to handle NAs before computing percent changeslimit : int, default NoneThe number of consecutive NAs to fill before stoppingfreq : DateOffset, timedelta, or offset alias string, optionalIncrement to use from time series API (e.g. M or BDay())Returnschg : NDFrameNotesBy default, the percentage change is calculated along the stataxis: 0, or Index, for DataFrame and 1, or minor forPanel. You can change this with the axis keyword argument.12returns = price.pct_change()returns.tail()AAPLGOOGIBMMSFTDate2017-02-210.0072210.004335-0.002269-0.0020122017-02-220.002999-0.0010820.004937-0.0020162017-02-23-0.0042300.0006860.0027600.0040402017-02-240.000952-0.003236-0.0016510.0000002017-02-270.0019760.000772-0.010753-0.0060351returns.MSFT.corr(returns.IBM)0.49525655865062668 1returns.MSFT.cov(returns.IBM)8.5880535146740545e-05 1returns.corr()AAPLGOOGIBMMSFTAAPL1.0000000.4095230.3813740.388875GOOG0.4095231.0000000.4027810.470781IBM0.3813740.4027811.0000000.495257MSFT0.3888750.4707810.4952571.0000001returns.cov()AAPLGOOGIBMMSFTAAPL0.0002690.0001050.0000750.000092GOOG0.0001050.0002440.0000750.000106IBM0.0000750.0000750.0001440.000086MSFT0.0000920.0001060.0000860.0002091returns.corrwith(returns.IBM)AAPL 0.381374 GOOG 0.402781 IBM 1.000000 MSFT 0.495257 dtype: float64 1returns.corrwith(volume)AAPL -0.074055 GOOG -0.009543 IBM -0.194107 MSFT -0.090724 dtype: float64  1obj = Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c'])12uniques = obj.unique()uniquesarray([&#39;c&#39;, &#39;a&#39;, &#39;d&#39;, &#39;b&#39;], dtype=object) 1obj.value_counts()c 3 a 3 b 2 d 1 dtype: int64 1pd.value_counts(obj.values, sort=False)a 3 d 1 b 2 c 3 dtype: int64 12mask = obj.isin(['b', 'c'])mask0 True 1 False 2 False 3 False 4 False 5 True 6 True 7 True 8 True dtype: bool 1obj[mask]0 c 5 b 6 b 7 c 8 c dtype: object 1234data = DataFrame(&#123;'Qu1': [1, 3, 4, 3, 4], 'Qu2': [2, 3, 1, 2, 3], 'Qu3': [1, 5, 2, 4, 4]&#125;)dataQu1Qu2Qu30121133524123324443412result = data.apply(pd.value_counts).fillna(0)resultQu1Qu2Qu311.01.01.020.02.01.032.02.00.042.00.02.050.00.01.012string_data = Series(['aardvark', 'artichoke', np.nan, 'avocado'])string_data0 aardvark 1 artichoke 2 NaN 3 avocado dtype: object 1string_data.isnull()0 False 1 False 2 True 3 False dtype: bool 12string_data[0] = Nonestring_data.isnull()0 True 1 False 2 True 3 False dtype: bool 123from numpy import nan as NAdata = Series([1, NA, 3.5, NA, 7])data.dropna()0 1.0 2 3.5 4 7.0 dtype: float64 1data[data.notnull()]0 1.0 2 3.5 4 7.0 dtype: float64 1234data = DataFrame([[1., 6.5, 3.], [1., NA, NA], [NA, NA, NA], [NA, 6.5, 3.]])cleaned = data.dropna()data01201.06.53.011.0NaNNaN2NaNNaNNaN3NaN6.53.01cleaned01201.06.53.01data.dropna(how='all')01201.06.53.011.0NaNNaN3NaN6.53.012data[4] = NAdata012401.06.53.0NaN11.0NaNNaNNaN2NaNNaNNaNNaN3NaN6.53.0NaN1data.dropna(axis=1, how='all')01201.06.53.011.0NaNNaN2NaNNaNNaN3NaN6.53.0123df = DataFrame(np.random.randn(7, 3))df.ix[:4, 1] = NA; df.ix[:2, 2] = NAdf0120-0.204708NaNNaN1-0.555730NaNNaN20.092908NaNNaN31.246435NaN-1.29622140.274992NaN1.35291750.886429-2.001637-0.37184361.669025-0.438570-0.5397411df.dropna(thresh=2)01231.246435NaN-1.29622140.274992NaN1.35291750.886429-2.001637-0.37184361.669025-0.438570-0.5397411df.fillna(0)0120-0.2047080.0000000.0000001-0.5557300.0000000.00000020.0929080.0000000.00000031.2464350.000000-1.29622140.2749920.0000001.35291750.886429-2.001637-0.37184361.669025-0.438570-0.5397411df.fillna(&#123;1: 0.5, 3: -1&#125;)0120-0.2047080.500000NaN1-0.5557300.500000NaN20.0929080.500000NaN31.2464350.500000-1.29622140.2749920.5000001.35291750.886429-2.001637-0.37184361.669025-0.438570-0.539741fillna123# always returns a reference to the filled object_ = df.fillna(0, inplace=True)df0120-0.2047080.0000000.0000001-0.5557300.0000000.00000020.0929080.0000000.00000031.2464350.000000-1.29622140.2749920.0000001.35291750.886429-2.001637-0.37184361.669025-0.438570-0.539741123df = DataFrame(np.random.randn(6, 3))df.ix[2:, 1] = NA; df.ix[4:, 2] = NAdf01200.4769853.248944-1.0212281-0.5770870.1241210.30261420.523772NaN1.3438103-0.713544NaN-2.3702324-1.860761NaNNaN5-1.265934NaNNaN1df.fillna(method='ffill')01200.4769853.248944-1.0212281-0.5770870.1241210.30261420.5237720.1241211.3438103-0.7135440.124121-2.3702324-1.8607610.124121-2.3702325-1.2659340.124121-2.3702321df.fillna(method='ffill', limit=2)01200.4769853.248944-1.0212281-0.5770870.1241210.30261420.5237720.1241211.3438103-0.7135440.124121-2.3702324-1.860761NaN-2.3702325-1.265934NaN-2.37023212data = Series([1., NA, 3.5, NA, 7])data.fillna(data.mean())0 1.000000 1 3.833333 2 3.500000 3 3.833333 4 7.000000 dtype: float64 1234data = Series(np.random.randn(10), index=[['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'd', 'd'], [1, 2, 3, 1, 2, 3, 1, 2, 2, 3]])dataa 1 0.332883 2 -2.359419 3 -0.199543 b 1 -1.541996 2 -0.970736 3 -1.307030 c 1 0.286350 2 0.377984 d 2 -0.753887 3 0.331286 dtype: float64 1data.indexMultiIndex(levels=[[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;], [1, 2, 3]], labels=[[0, 0, 0, 1, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 1, 2, 0, 1, 1, 2]]) 1data['b']1 -1.541996 2 -0.970736 3 -1.307030 dtype: float64 1data['b':'c']b 1 -1.541996 2 -0.970736 3 -1.307030 c 1 0.286350 2 0.377984 dtype: float64 1data.ix[['b', 'd']]b 1 -1.541996 2 -0.970736 3 -1.307030 d 2 -0.753887 3 0.331286 dtype: float64 1data[:, 2]a -2.359419 b -0.970736 c 0.377984 d -0.753887 dtype: float64 1data.unstack()123a0.332883-2.359419-0.199543b-1.541996-0.970736-1.307030c0.2863500.377984NaNdNaN-0.7538870.3312861data.unstack().stack()a 1 0.332883 2 -2.359419 3 -0.199543 b 1 -1.541996 2 -0.970736 3 -1.307030 c 1 0.286350 2 0.377984 d 2 -0.753887 3 0.331286 dtype: float64 12345frame = DataFrame(np.arange(12).reshape((4, 3)), index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]], columns=[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']])frameOhioColoradoGreenRedGreena10122345b1678291011123frame.index.names = ['key1', 'key2']frame.columns.names = ['state', 'color']framestateOhioColoradocolorGreenRedGreenkey1key2a10122345b16782910111frame['Ohio']colorGreenRedkey1key2a101234b1672910MultiIndex12MultiIndex.from_arrays([[&apos;Ohio&apos;, &apos;Ohio&apos;, &apos;Colorado&apos;], [&apos;Green&apos;, &apos;Red&apos;, &apos;Green&apos;]], names=[&apos;state&apos;, &apos;color&apos;])1frame.swaplevel('key1', 'key2')stateOhioColoradocolorGreenRedGreenkey2key11a0122a3451b6782b910111frame.sortlevel(1)stateOhioColoradocolorGreenRedGreenkey1key2a1012b1678a2345b2910111frame.swaplevel(0, 1).sortlevel(0)stateOhioColoradocolorGreenRedGreenkey2key11a012b6782a345b910111frame.sum(level='key2')stateOhioColoradocolorGreenRedGreenkey21681021214161frame.sum(level='color', axis=1)colorGreenRedkey1key2a121284b114722010DataFrame1234frame = DataFrame(&#123;'a': range(7), 'b': range(7, 0, -1), 'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'], 'd': [0, 1, 2, 0, 1, 2, 3]&#125;)frameabcd007one0116one1225one2334two0443two1552two2661two312frame2 = frame.set_index(['c', 'd'])frame2abcdone007116225two0341432523611frame.set_index(['c', 'd'], drop=False)abcdcdone007one0116one1225one2two034two0143two1252two2361two31frame2.reset_index()cdab0one0071one1162one2253two0344two1435two2526two36112ser = Series(np.arange(3.))ser.iloc[-1]2.0 1ser0 0.0 1 1.0 2 2.0 dtype: float64 12ser2 = Series(np.arange(3.), index=['a', 'b', 'c'])ser2[-1]2.0 1ser.ix[:1]0 0.0 1 1.0 dtype: float64 12ser3 = Series(range(3), index=[-5, 1, 3])ser3.iloc[2]2 123frame = DataFrame(np.arange(6).reshape((3, 2)), index=[2, 0, 1])frameframe.iloc[0]012010231450 0 1 1 Name: 2, dtype: int32 1234import pandas_datareader.data as webpdata = pd.Panel(dict((stk, web.get_data_yahoo(stk)) for stk in ['AAPL', 'GOOG', 'MSFT', 'DELL']))1pdata&lt;class &#39;pandas.core.panel.Panel&#39;&gt; Dimensions: 4 (items) x 1820 (major_axis) x 6 (minor_axis) Items axis: AAPL to MSFT Major_axis axis: 2010-01-04 00:00:00 to 2017-02-27 00:00:00 Minor_axis axis: Open to Adj Close 12pdata = pdata.swapaxes('items', 'minor')pdata['Adj Close'].iloc[:10]AAPLDELLGOOGMSFTDate2010-01-0427.72703914.06528313.06246825.5554852010-01-0527.77497614.38450311.68384425.5637412010-01-0627.33317814.10397303.82668525.4068592010-01-0727.28265014.23940296.75374925.1426342010-01-0827.46403414.36516300.70980825.3160312010-01-1127.22175814.37483300.25525524.9940072010-01-1226.91211014.56830294.94557224.8288662010-01-1327.29172014.57797293.25224325.0600642010-01-1427.13365714.22005294.63086825.5637412010-01-1526.68019813.92985289.71077225.4811721pdata.ix[:, '6/1/2012', :]OpenHighLowCloseVolumeAdj CloseAAPL569.159996572.650009560.520012560.989983130246900.072.681610DELL12.15000012.30000012.04500012.07000019397600.011.675920GOOG571.790972572.650996568.350996570.9810006138700.0285.205295MSFT28.76000028.95999928.44000128.45000156634300.024.9422391pdata.ix['Adj Close', '5/22/2012':, :].iloc[:10]AAPLDELLGOOGMSFTDate2012-05-2272.16078614.58765300.10041226.0907212012-05-2373.92149412.08221304.42610625.5208642012-05-2473.24260712.04351301.52897825.4857952012-05-2572.85003812.05319295.47005025.4770282012-05-28NaN12.05319NaNNaN2012-05-2974.14304112.24666296.87364525.9153802012-05-3075.03700512.14992293.82167425.7225052012-05-3174.85044211.92743290.14035425.5910002012-06-0172.68161011.67592285.20529524.9422392012-06-0473.10915611.60821289.00648025.02990812stacked = pdata.ix[:, '5/30/2012':, :].to_frame()stackedOpenHighLowCloseVolumeAdj CloseDateminor2012-05-30AAPL569.199997579.989990566.559990579.169998132357400.075.037005DELL12.59000012.70000012.46000012.56000019787800.012.149920GOOG588.161028591.901014583.530999588.2309923827600.0293.821674MSFT29.35000029.48000029.12000129.34000041585500.025.7225052012-05-31AAPL580.740021581.499985571.460022577.730019122918600.074.850442DELL12.53000012.54000012.33000012.33000019955600.011.927430GOOG588.720982590.001032579.001013580.8609905958800.0290.140354MSFT29.29999929.42000028.94000129.19000139134000.025.5910002012-06-01AAPL569.159996572.650009560.520012560.989983130246900.072.681610DELL12.15000012.30000012.04500012.07000019397600.011.675920GOOG571.790972572.650996568.350996570.9810006138700.0285.205295MSFT28.76000028.95999928.44000128.45000156634300.024.9422392012-06-04AAPL561.500008567.499985548.499977564.289978139248900.073.109156DELL12.11000012.11250011.80000012.00000017015700.011.608210GOOG570.220958580.491016570.011006578.5909734883500.0289.006480MSFT28.62000128.78000128.32000028.54999947926300.025.0299082012-06-05AAPL561.269989566.470001558.330002562.83002597053600.072.920005DELL11.95000012.24000011.95000012.16000015620900.011.762980GOOG575.451008578.131003566.470986570.4109994697200.0284.920579MSFT28.51000028.75000028.38999928.51000045715400.024.9948412012-06-06AAPL567.770004573.849983565.499992571.460022100363900.074.038104DELL12.21000012.28000012.09000012.21500020779900.011.816190GOOG576.480979581.970971573.611004580.5709664207200.0289.995487MSFT28.87999929.37000128.80999929.35000046860500.025.7312732012-06-07AAPL577.290009577.320023570.500000571.72000194941700.074.071787DELL12.32000012.41000012.12000012.13000020074000.011.733960GOOG587.601014587.891038577.251006578.2309863530100.0288.826666MSFT29.63999929.70000129.17000029.23000037792800.025.6260672012-06-08AAPL571.599998580.580017568.999992580.31998486879100.075.185997DELL12.13000012.22500012.02000012.12000018155600.011.724290........................2017-02-13AAPL133.080002133.820007132.750000133.28999323035400.0133.289993GOOG816.000000820.958984815.489990819.2399901198100.0819.239990MSFT64.23999864.86000164.12999764.72000122920100.064.3300002017-02-14AAPL133.470001135.089996133.250000135.02000432815500.0135.020004GOOG819.000000823.000000816.000000820.4500121053600.0820.450012MSFT64.41000464.72000164.01999764.57000023065900.064.5700002017-02-15AAPL135.520004136.270004134.619995135.50999535501600.0135.509995GOOG819.359985823.000000818.469971818.9799801304000.0818.979980MSFT64.50000064.57000064.16000464.52999916917000.064.5299992017-02-16AAPL135.669998135.899994134.839996135.35000622118000.0135.350006GOOG819.929993824.400024818.979980824.1599731281700.0824.159973MSFT64.73999865.23999864.44000264.51999720524700.064.5199972017-02-17AAPL135.100006135.830002135.100006135.72000122084500.0135.720001GOOG823.020020828.070007821.655029828.0700071597800.0828.070007MSFT64.47000164.69000264.30000364.62000321234600.064.6200032017-02-21AAPL136.229996136.750000135.979996136.69999724265100.0136.699997GOOG828.659973833.450012828.349976831.6599731247700.0831.659973MSFT64.61000164.94999764.44999764.48999819384900.064.4899982017-02-22AAPL136.429993137.119995136.110001137.11000120745300.0137.110001GOOG828.659973833.250000828.640015830.760010982900.0830.760010MSFT64.33000264.38999964.05000364.36000119259700.064.3600012017-02-23AAPL137.380005137.479996136.300003136.52999920704100.0136.529999GOOG830.119995832.460022822.880005831.3300171470100.0831.330017MSFT64.41999864.73000364.19000264.62000320235200.064.6200032017-02-24AAPL135.910004136.660004135.279999136.66000421690900.0136.660004GOOG827.729980829.000000824.200012828.6400151386600.0828.640015MSFT64.52999964.80000364.13999964.62000321705200.064.6200032017-02-27AAPL137.139999137.440002136.279999136.92999320196400.0136.929993GOOG824.549988830.500000824.000000829.2800291099500.0829.280029MSFT64.54000164.54000164.05000364.23000315850400.064.2300033952 rows  6 columns1stacked.to_panel()&lt;class &#39;pandas.core.panel.Panel&#39;&gt; Dimensions: 6 (items) x 1207 (major_axis) x 4 (minor_axis) Items axis: Open to Adj Close Major_axis axis: 2012-05-30 00:00:00 to 2017-02-27 00:00:00 Minor_axis axis: AAPL to MSFT]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python data analysis-Learning note-Ch04]]></title>
      <url>%2F2017%2F02%2F26%2FPython-data-analysis-Learning-note-Ch04%2F</url>
      <content type="text"><![CDATA[Numpy1%matplotlib inline1234from __future__ import divisionfrom numpy.random import randnimport numpy as npnp.set_printoptions(precision=4, suppress=True)12from IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "all"NumPy ndarray: 1data = randn(2, 3)123datadata * 10data + dataarray([[ 0.1584, 0.299 , -0.2555], [ 0.3277, -0.6934, 1.3191]]) array([[ 1.5842, 2.9896, -2.5545], [ 3.2767, -6.9342, 13.1913]]) array([[ 0.3168, 0.5979, -0.5109], [ 0.6553, -1.3868, 2.6383]]) 12data.shapedata.dtype(2, 3) dtype(&#39;float64&#39;) ndarray123data1 = [6, 7.5, 8, 0, 1]arr1 = np.array(data1)arr1array([ 6. , 7.5, 8. , 0. , 1. ]) 12345data2 = [[1, 2, 3, 4], [5, 6, 7, 8]]arr2 = np.array(data2)arr2arr2.ndimarr2.shapearray([[1, 2, 3, 4], [5, 6, 7, 8]]) 2 (2, 4) np.array12arr1.dtypearr2.dtypedtype(&#39;float64&#39;) dtype(&#39;int32&#39;) 123np.zeros(10)np.zeros((3, 6))np.empty((2, 3, 2))array([ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) array([[ 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0.]]) array([[[ 0., 0.], [ 0., 0.], [ 0., 0.]], [[ 0., 0.], [ 0., 0.], [ 0., 0.]]]) 1np.arange(15)array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]) ones_like, zeros_like, empty_likedtype1 0ndarray1234arr1 = np.array([1, 2, 3], dtype=np.float64)arr2 = np.array([1, 2, 3], dtype=np.int32)arr1.dtypearr2.dtypedtype(&#39;float64&#39;) dtype(&#39;int32&#39;) 1234arr = np.array([1, 2, 3, 4, 5])arr.dtypefloat_arr = arr.astype(np.float64) float_arr.dtypedtype(&#39;int32&#39;) dtype(&#39;float64&#39;) 123arr = np.array([3.7, -1.2, -2.6, 0.5, 12.9, 10.1])arrarr.astype(np.int32)array([ 3.7, -1.2, -2.6, 0.5, 12.9, 10.1]) array([ 3, -1, -2, 0, 12, 10]) 12numeric_strings = np.array(['1.25', '-9.6', '42'], dtype=np.string_)numeric_strings.astype(float)array([ 1.25, -9.6 , 42. ]) 123int_array = np.arange(10)calibers = np.array([.22, .270, .357, .380, .44, .50], dtype=np.float64)int_array.astype(calibers.dtype)array([ 0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]) 12empty_uint32 = np.empty(8, dtype='u4')empty_uint32array([1, 2, 3, 4, 5, 6, 7, 8], dtype=uint32) astype1234arr = np.array([[1., 2., 3.], [4., 5., 6.]])arrarr * arrarr - arrarray([[ 1., 2., 3.], [ 4., 5., 6.]]) array([[ 1., 4., 9.], [ 16., 25., 36.]]) array([[ 0., 0., 0.], [ 0., 0., 0.]]) 121 / arrarr ** 0.5array([[ 1. , 0.5 , 0.3333], [ 0.25 , 0.2 , 0.1667]]) array([[ 1. , 1.4142, 1.7321], [ 2. , 2.2361, 2.4495]]) 123456arr = np.arange(10)arrarr[5]arr[5:8]arr[5:8] = 12arrarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 5 array([5, 6, 7]) array([ 0, 1, 2, 3, 4, 12, 12, 12, 8, 9]) copy()12345arr_slice = arr[5:8]arr_slice[1] = 12345arrarr_slice[:] = 64arrarray([ 0, 1, 2, 3, 4, 12, 12345, 12, 8, 9]) array([ 0, 1, 2, 3, 4, 64, 64, 64, 8, 9]) 12arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])arr2d[2]array([7, 8, 9]) 12arr2d[0][2]arr2d[0, 2]3 3 12arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])arr3darray([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]]) 1arr3d[0]array([[1, 2, 3], [4, 5, 6]]) 12345old_values = arr3d[0].copy()arr3d[0] = 42arr3darr3d[0] = old_valuesarr3darray([[[42, 42, 42], [42, 42, 42]], [[ 7, 8, 9], [10, 11, 12]]]) array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]]) 1arr3d[1, 0]array([7, 8, 9]) 1arr[1:6]array([ 1, 2, 3, 4, 64]) 12arr2darr2d[:2]array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) array([[1, 2, 3], [4, 5, 6]]) 1arr2d[:2, 1:]array([[2, 3], [5, 6]]) 12arr2d[1, :2]arr2d[2, :1]array([4, 5]) array([7]) 1arr2d[:, :1]array([[1], [4], [7]]) 1arr2d[:2, 1:] = 01234names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])data = randn(7, 4)namesdataarray([&#39;Bob&#39;, &#39;Joe&#39;, &#39;Will&#39;, &#39;Bob&#39;, &#39;Will&#39;, &#39;Joe&#39;, &#39;Joe&#39;], dtype=&#39;&lt;U4&#39;) array([[-2.9033, 1.4721, 0.9512, 1.7727], [ 2.2303, -1.0259, 1.0664, 0.534 ], [-0.9725, 0.2226, -0.1538, -0.4994], [-1.4289, 0.1665, -1.2874, -1.0817], [ 1.3581, -1.0734, -0.1387, 0.1673], [ 1.2816, 1.8883, 0.5699, -0.5843], [-0.0464, -0.9633, 0.2855, -0.6473]]) 1names == 'Bob'array([ True, False, False, True, False, False, False], dtype=bool) 1data[names == 'Bob']array([[-2.9033, 1.4721, 0.9512, 1.7727], [-1.4289, 0.1665, -1.2874, -1.0817]]) 12data[names == 'Bob', 2:]data[names == 'Bob', 3]array([[ 0.9512, 1.7727], [-1.2874, -1.0817]]) array([ 1.7727, -1.0817]) 12names != 'Bob'data[~(names == 'Bob')]array([False, True, True, False, True, True, True], dtype=bool) array([[ 2.2303, -1.0259, 1.0664, 0.534 ], [-0.9725, 0.2226, -0.1538, -0.4994], [ 1.3581, -1.0734, -0.1387, 0.1673], [ 1.2816, 1.8883, 0.5699, -0.5843], [-0.0464, -0.9633, 0.2855, -0.6473]]) 123mask = (names == 'Bob') | (names == 'Will')maskdata[mask]array([ True, False, True, True, True, False, False], dtype=bool) array([[-2.9033, 1.4721, 0.9512, 1.7727], [-0.9725, 0.2226, -0.1538, -0.4994], [-1.4289, 0.1665, -1.2874, -1.0817], [ 1.3581, -1.0734, -0.1387, 0.1673]]) Pythonandor12data[data &lt; 0] = 0dataarray([[ 0. , 1.4721, 0.9512, 1.7727], [ 2.2303, 0. , 1.0664, 0.534 ], [ 0. , 0.2226, 0. , 0. ], [ 0. , 0.1665, 0. , 0. ], [ 1.3581, 0. , 0. , 0.1673], [ 1.2816, 1.8883, 0.5699, 0. ], [ 0. , 0. , 0.2855, 0. ]]) 12data[names != 'Joe'] = 7dataarray([[ 7. , 7. , 7. , 7. ], [ 2.2303, 0. , 1.0664, 0.534 ], [ 7. , 7. , 7. , 7. ], [ 7. , 7. , 7. , 7. ], [ 7. , 7. , 7. , 7. ], [ 1.2816, 1.8883, 0.5699, 0. ], [ 0. , 0. , 0.2855, 0. ]]) 1234arr = np.empty((8, 4))for i in range(8): arr[i] = iarrarray([[ 0., 0., 0., 0.], [ 1., 1., 1., 1.], [ 2., 2., 2., 2.], [ 3., 3., 3., 3.], [ 4., 4., 4., 4.], [ 5., 5., 5., 5.], [ 6., 6., 6., 6.], [ 7., 7., 7., 7.]]) 1arr[[4, 3, 0, 6]]array([[ 4., 4., 4., 4.], [ 3., 3., 3., 3.], [ 0., 0., 0., 0.], [ 6., 6., 6., 6.]]) 1arr[[-3, -5, -7]]array([[ 5., 5., 5., 5.], [ 3., 3., 3., 3.], [ 1., 1., 1., 1.]]) 1234# more on reshape in Chapter 12arr = np.arange(32).reshape((8, 4))arrarr[[1, 5, 7, 2], [0, 3, 1, 2]]array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]) array([ 4, 23, 29, 10]) 1arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]]array([[ 4, 7, 5, 6], [20, 23, 21, 22], [28, 31, 29, 30], [ 8, 11, 9, 10]]) np.ix_1arr[np.ix_([1, 5, 7, 2], [0, 3, 1, 2])]array([[ 4, 7, 5, 6], [20, 23, 21, 22], [28, 31, 29, 30], [ 8, 11, 9, 10]]) 123arr = np.arange(15).reshape((3, 5))arrarr.Tarray([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) array([[ 0, 5, 10], [ 1, 6, 11], [ 2, 7, 12], [ 3, 8, 13], [ 4, 9, 14]]) 12arr = np.random.randn(6, 3)np.dot(arr.T, arr)array([[ 3.6804, 0.0133, 1.0388], [ 0.0133, 1.6074, 0.1836], [ 1.0388, 0.1836, 3.5281]]) 123arr = np.arange(16).reshape((2, 2, 4))arrarr.transpose((1, 0, 2))array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7]], [[ 8, 9, 10, 11], [12, 13, 14, 15]]]) array([[[ 0, 1, 2, 3], [ 8, 9, 10, 11]], [[ 4, 5, 6, 7], [12, 13, 14, 15]]]) Refered from here.In short: transposing an array means that NumPy just needs to permute the stride and shape information for each axis:&gt;&gt;&gt; arr.strides (64, 32, 8) &gt;&gt;&gt; arr.transpose(1, 0, 2).strides (32, 64, 8) Notice that the strides for the first and second axes were swapped here. This means that no data needs to be copied; NumPy can simply change how it looks at the memory to construct the array.What are strides?The values in a 3D array arr are stored in a contiguous block of memory like this:[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] In the case of arr, each integer takes up 8 bytes of memory (i.e. were using the int64 dtype).A stride tells NumPy how many bytes to skip in order to move to the next value along an axis. For example, to get the next value in a row in arr (axis 2), we just need to move 8 bytes (1 number).The strides for arr.transpose(1, 0, 2) are (32, 64, 8). To move along the first axis, instead of 64 bytes (8 numbers) NumPy will now only skip 32 bytes (4 numbers) each time:[[[0 ...] [... ...]] [[4 ...] [... ...]]] Similarly, NumPy will now skip 64 bytes (8 numbers) in order to move along axis 1:[[[0 ...] [8 ...]] [[4 ...] [12 ...]]] The actual code that does the transposing is written in C and can be found here.swapaxes123arrarr.swapaxes(1, 2)arrarray([[[ 0, 1, 2, 3], [ 4, 5, 6, 7]], [[ 8, 9, 10, 11], [12, 13, 14, 15]]]) array([[[ 0, 4], [ 1, 5], [ 2, 6], [ 3, 7]], [[ 8, 12], [ 9, 13], [10, 14], [11, 15]]]) array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7]], [[ 8, 9, 10, 11], [12, 13, 14, 15]]]) 123arr = np.arange(10)np.sqrt(arr)np.exp(arr)array([ 0. , 1. , 1.4142, 1.7321, 2. , 2.2361, 2.4495, 2.6458, 2.8284, 3. ]) array([ 1. , 2.7183, 7.3891, 20.0855, 54.5982, 148.4132, 403.4288, 1096.6332, 2980.958 , 8103.0839]) 12345x = randn(8)y = randn(8)xynp.maximum(x, y) # array([ 0.811 , -0.0214, -0.3702, -0.4856, 1.1449, -0.4246, 0.9396, 0.0382]) array([-1.223 , 0.3271, -1.7197, -2.2636, -0.1154, -1.4122, -0.0989, 0.4477]) array([ 0.811 , 0.3271, -0.3702, -0.4856, 1.1449, -0.4246, 0.9396, 0.4477]) modf123arr = randn(7) * 5arrnp.modf(arr)array([ 10.3171, -4.733 , -6.3358, 3.2457, -7.3823, 2.7036, -2.6173]) (array([ 0.3171, -0.733 , -0.3358, 0.2457, -0.3823, 0.7036, -0.6173]), array([ 10., -4., -6., 3., -7., 2., -2.])) meshgridpoints1234points = np.arange(-5, 5, 0.01) # 1000 equally spaced pointsxs, ys = np.meshgrid(points, points)xsysarray([[-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], ..., [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99]]) array([[-5. , -5. , -5. , ..., -5. , -5. , -5. ], [-4.99, -4.99, -4.99, ..., -4.99, -4.99, -4.99], [-4.98, -4.98, -4.98, ..., -4.98, -4.98, -4.98], ..., [ 4.97, 4.97, 4.97, ..., 4.97, 4.97, 4.97], [ 4.98, 4.98, 4.98, ..., 4.98, 4.98, 4.98], [ 4.99, 4.99, 4.99, ..., 4.99, 4.99, 4.99]]) 1from matplotlib.pyplot import imshow, title12345import matplotlib.pyplot as pltz = np.sqrt(xs ** 2 + ys ** 2)zplt.imshow(z, cmap=plt.cm.gray); plt.colorbar()plt.title("Image plot of $\sqrt&#123;x^2 + y^2&#125;$ for a grid of values")array([[ 7.0711, 7.064 , 7.0569, ..., 7.0499, 7.0569, 7.064 ], [ 7.064 , 7.0569, 7.0499, ..., 7.0428, 7.0499, 7.0569], [ 7.0569, 7.0499, 7.0428, ..., 7.0357, 7.0428, 7.0499], ..., [ 7.0499, 7.0428, 7.0357, ..., 7.0286, 7.0357, 7.0428], [ 7.0569, 7.0499, 7.0428, ..., 7.0357, 7.0428, 7.0499], [ 7.064 , 7.0569, 7.0499, ..., 7.0428, 7.0499, 7.0569]]) &lt;matplotlib.image.AxesImage at 0x23400a22b38&gt; &lt;matplotlib.colorbar.Colorbar at 0x23400a7c7b8&gt; &lt;matplotlib.text.Text at 0x23400a03da0&gt; 1plt.draw()&lt;matplotlib.figure.Figure at 0x23401396eb8&gt; 123xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])cond = np.array([True, False, True, True, False])123result = [(x if c else y) for x, y, c in zip(xarr, yarr, cond)]result[1.1000000000000001, 2.2000000000000002, 1.3, 1.3999999999999999, 2.5] Python12result = np.where(cond, xarr, yarr)resultarray([ 1.1, 2.2, 1.3, 1.4, 2.5]) 1234arr = randn(4, 4)arrnp.where(arr &gt; 0, 2, -2)np.where(arr &gt; 0, 2, arr) # set only positive values to 2array([[-0.7355, -0.3188, -0.2358, 0.3137], [-0.6196, -0.5803, -0.5504, -1.1508], [ 0.1719, -1.1599, -0.7115, 1.7869], [-0.2306, 0.2068, 1.5366, 1.6154]]) array([[-2, -2, -2, 2], [-2, -2, -2, -2], [ 2, -2, -2, 2], [-2, 2, 2, 2]]) array([[-0.7355, -0.3188, -0.2358, 2. ], [-0.6196, -0.5803, -0.5504, -1.1508], [ 2. , -1.1599, -0.7115, 2. ], [-0.2306, 2. , 2. , 2. ]]) where12345678910result = []for i in range(n): if cond1[i] and cond2[i]: result.append(0) elif cond1[i]: result.append(1) elif cond2[i]: result.append(2) else: result.append(3)where123np.where(cond1 &amp; cond2, 0, np.where(cond1, 1, np.where(cond2, 2, 3)))magic1result = 1 * cond1 + 2 * cond2 + 3 * -(cond1 | cond2)123456arr = np.random.randn(5, 4) # arr# arr.mean()np.mean(arr)arr.sum()array([[ 1.4513, -0.8225, 0.7011, -0.617 ], [ 1.5872, 1.2937, 1.0151, 0.7123], [-0.2012, -0.0168, -0.3847, 0.5274], [-0.6312, -0.2762, 0.4869, 0.0462], [-0.5268, -1.1071, 1.8642, 0.2282]]) 0.26650934393195791 0.26650934393195791 5.3301868786391582 12arr.mean(axis=1)arr.sum(0) # axis=0array([ 0.1782, 1.1521, -0.0188, -0.0936, 0.1146]) array([ 1.6793, -0.9289, 3.6826, 0.8971]) 1234arr = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])arrarr.cumsum(0) # axis=0arr.cumprod(1) # axis=1array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) array([[ 0, 1, 2], [ 3, 5, 7], [ 9, 12, 15]], dtype=int32) array([[ 0, 0, 0], [ 3, 12, 60], [ 6, 42, 336]], dtype=int32) 123arr = randn(100)arr(arr &gt; 0).sum() # Number of positive valuesarray([ 0.7828, 0.1372, -0.6264, 1.8927, -0.2104, 0.2822, -0.3672, -0.3601, 0.5918, 0.9285, 0.1808, -0.4021, 0.4086, -0.2949, 0.5633, -0.7462, -0.1635, 0.1482, -0.3226, -1.2127, -0.9821, 0.0536, -0.1772, -0.4714, -0.9002, -0.0037, 0.7352, 0.5675, -1.1612, 0.5288, 0.3319, 0.7315, 0.6841, -0.6881, 1.5654, -0.4605, -0.5423, 0.0184, -0.8153, -0.1313, 0.4594, 0.0228, 0.255 , -2.2361, 0.8703, -1.5153, -0.9458, 0.2769, 0.9986, 0.7699, -0.7948, -1.2508, 1.7059, 0.1805, -1.0265, -0.0181, -0.9415, 0.1265, -0.2576, 0.6791, 0.3969, 0.8027, -0.6792, -0.7487, -1.9949, -0.9595, 0.5706, -0.5727, -1.0204, 0.1521, -0.9755, -0.4094, 0.67 , 0.212 , 0.4081, -0.1435, 0.3964, -0.1865, -0.6018, -2.6185, -0.5073, -0.6328, -0.2631, 0.6637, -0.5586, 1.3346, -0.5317, 0.8572, 1.1159, 0.9563, -0.0434, -1.0534, 0.5869, 0.0502, -0.0479, -0.8673, 0.1531, 1.0646, -0.2624, -0.3726]) 47 1234bools = np.array([False, False, True, False])boolsbools.any()bools.all()array([False, False, True, False], dtype=bool) True False 1234arr = randn(8)arrarr.sort()arrarray([ 1.0584, 1.9062, -0.2923, 0.7169, 0.5186, -0.6089, -2.0444, -0.5661]) array([-2.0444, -0.6089, -0.5661, -0.2923, 0.5186, 0.7169, 1.0584, 1.9062]) 1234arr = randn(5, 3)arrarr.sort(1) # axis=1arrarray([[ 0.0118, -2.8916, -0.4477], [-1.9768, 1.859 , -1.128 ], [-2.6262, 0.5791, 0.7594], [-0.5254, -0.9059, 0.0203], [-1.4029, -1.8566, 0.1892]]) array([[-2.8916, -0.4477, 0.0118], [-1.9768, -1.128 , 1.859 ], [-2.6262, 0.5791, 0.7594], [-0.9059, -0.5254, 0.0203], [-1.8566, -1.4029, 0.1892]]) 12345large_arr = randn(1000)large_arrlarge_arr.sort()large_arrlarge_arr[int(0.05 * len(large_arr))] # 5% quantilearray([ 1.2296, 0.3794, -0.1526, 2.1223, -0.0675, 0.6867, -0.5742, -1.4291, 0.6856, 0.1364, -0.3966, -0.7793, 0.4965, 0.2447, -0.7487, 0.7695, 0.5358, -0.4813, 0.9949, -0.6489, -0.3656, 1.9551, 0.8327, 1.497 , -0.4431, -0.8357, -0.821 , -0.7348, 1.9294, -0.3144, 0.1396, -0.9111, 0.0943, 0.8043, 1.067 , 0.9362, -2.2574, 0.7475, -1.0152, -1.1234, -0.3774, 1.076 , 0.8743, 1.1864, 0.0801, 0.3995, 0.2536, -0.9371, -1.669 , -2.2444, 1.2544, 1.0539, -0.7579, 0.2963, 0.7496, -1.3655, 0.1552, -0.6259, 0.2621, -1.5415, -0.1036, -0.5794, 1.2098, 1.3388, 0.3159, 1.0998, 0.5109, -0.3927, 1.4797, -1.4891, 0.3624, 0.966 , 0.0756, -0.4703, 0.1859, 1.6091, 0.662 , -0.4808, 0.8744, 0.4738, 1.1351, 0.0251, -1.017 , -0.849 , -0.1602, -1.5392, 0.0601, 1.7323, 1.1837, 0.4657, 0.8858, -0.211 , 0.1865, 0.673 , 0.3086, -1.2527, -0.7802, 0.407 , -1.118 , -0.2058, 0.7921, 0.5284, -2.3038, -0.4038, -1.1087, -0.827 , -2.6518, 0.3711, -0.0244, 1.1103, 0.2748, -0.7962, 1.9456, 0.5347, 0.1862, -0.3734, -0.3036, 0.6831, -0.9419, 1.4848, -0.1247, -0.4138, -0.601 , 0.6138, 1.1334, 0.4386, 0.0466, -0.0588, 0.6883, -1.2912, -0.2381, 0.3934, 0.2132, -0.4143, 1.0844, -0.5258, -0.9944, 1.0977, 0.3528, 1.9928, 1.421 , 0.8634, 0.1973, -1.1799, -2.9433, 2.697 , 0.4778, 0.6464, 0.049 , -0.2339, 1.6945, -0.6568, -0.5972, -0.8324, -0.6443, 0.0882, -0.3686, 0.0419, 0.5119, -0.641 , 1.1545, 1.0735, -0.5329, -0.1126, 0.0375, -1.0699, -1.3153, -1.6097, 2.5671, -0.9516, -0.388 , -0.0129, -0.0171, -1.0763, -0.7125, 0.767 , 0.2254, -0.7638, -0.2065, 1.2797, 0.0784, -0.7762, 1.7106, -0.0136, -0.4435, 1.2946, -2.5489, 0.4241, 0.5675, -0.7596, 0.6128, 1.1161, -1.2456, -0.131 , -0.2684, 1.6461, -0.2497, -0.4294, 1.122 , 0.5969, 0.3335, -0.0453, 1.1567, 0.0216, -0.7277, -2.5465, -2.4542, -1.5895, 0.4607, -0.8303, 0.0263, 0.0301, -1.2365, -0.146 , -0.8632, 0.6449, 0.1958, -0.6914, -0.3223, 0.4037, 0.9918, -0.3542, 0.8442, 0.7751, -1.6248, 2.6081, 0.3524, 1.5298, 0.4421, 1.5228, -1.5263, -1.3994, 0.0285, -0.5389, 1.4047, -2.1117, -1.0397, 0.6495, 0.9073, 1.8738, 0.2913, -1.069 , -0.7835, -0.6437, 0.6739, 0.3272, -0.8483, -0.2971, 0.2882, 0.1778, -0.6705, -1.4129, -0.1935, 0.6615, -0.4423, -1.2472, -0.9816, 0.927 , -2.2774, 0.5736, 1.3996, 1.1653, -0.3253, -0.2074, -0.2447, 0.4925, 1.8415, -1.1551, -0.5131, -0.6407, 0.5033, -0.817 , 0.0479, -0.9106, 1.4391, -1.5824, -0.4652, 1.253 , -0.6051, 0.6699, 0.3803, 1.0767, 1.5449, 0.106 , -0.7215, -0.354 , 0.1016, -1.3191, -0.6596, -0.9632, -0.3655, 0.8411, -0.2314, 1.9493, -0.6966, -1.2598, 0.4023, 0.1704, -0.452 , 1.5924, 0.381 , -0.4731, -1.2467, -0.4264, -0.2298, -0.1792, -0.5009, -1.0032, 1.0126, 0.5436, 1.1366, -1.0318, 1.3289, 0.3218, -0.2828, 0.5597, -0.0213, -0.078 , 0.7667, -0.3984, -1.0263, -0.5557, -2.0724, -0.9343, -0.6877, 1.0567, -0.605 , 1.7923, 0.6351, -1.769 , 0.4175, 0.8266, 0.3767, -0.1508, -0.4301, -0.3397, 0.7248, 0.188 , 1.1632, -1.0831, -0.5726, -0.475 , 0.092 , -0.1566, 1.9074, -1.4261, 1.8589, -0.7534, -1.0767, -0.2704, 0.7567, 0.5903, -1.5612, -1.1097, 0.3504, -0.9086, -0.1691, 0.6714, -0.6033, 1.8315, -0.8141, 0.5968, -0.408 , -1.1843, 0.5146, 0.6201, 0.4293, 0.9797, 1.066 , -1.3325, -1.733 , 0.8545, 0.3993, -0.2041, -0.4624, 0.0272, -0.005 , 0.9237, -0.5523, 0.9975, -0.4374, 0.1351, -0.6148, 0.3185, 0.0572, -0.3002, 0.0889, -0.0894, -0.5617, -2.0553, -0.2923, 0.7227, 0.604 , -0.6623, -0.6126, -0.4991, 0.0923, -0.6982, 0.2099, -0.6853, -0.4752, -1.625 , 0.0443, 2.5507, -1.1597, 0.3504, -0.7654, -1.4366, -1.3755, 0.3702, -1.7853, -0.7326, -1.2803, -0.6089, -0.4472, 0.462 , 0.7799, 0.3141, 0.8064, -1.0487, 0.7317, -0.2446, 0.3061, 0.1384, -0.572 , -0.0311, 0.3572, -0.6371, -0.2236, 0.0806, 0.6648, -0.148 , -0.2547, 1.3649, -0.1595, 1.3632, -0.8858, 1.1801, 0.5533, 2.3306, 0.2724, 0.7073, -0.5605, -0.8849, 0.9533, 0.3683, -0.2901, -0.0453, 0.1064, 1.3342, -0.7036, 0.7127, 1.2156, 0.9017, 1.2378, -1.1017, 1.0558, 1.4273, 0.7003, 1.1649, 0.0334, 0.3433, -0.3997, -0.1195, 1.3725, -0.3746, 0.8444, 0.961 , -0.2644, 0.3245, -1.3583, 0.387 , 1.2944, 0.0274, -0.5057, 0.15 , 0.6 , -0.5752, 0.3746, 1.7114, -0.0026, -0.1221, -0.8084, -0.9521, -0.6332, 0.7254, 1.7032, -0.0879, 0.3329, -1.9525, -0.7083, -0.4113, 1.163 , 0.9018, -0.3667, 0.8419, 0.4417, 0.2904, 0.1666, 1.3722, -0.4455, -1.4876, 0.4103, 2.3672, 0.3569, -0.8546, 0.5152, 0.9623, 1.1777, 1.6789, -1.7793, -0.7797, -1.0923, 0.07 , -0.8974, -0.3151, -0.3675, -1.9851, -2.3352, 0.3566, 1.1929, 1.5275, 1.4349, -1.4742, -0.1913, 1.5874, -0.7264, -0.5594, 0.3166, -0.9377, -0.6452, 0.394 , -0.2238, -1.1239, -0.0324, 1.3866, -0.6174, -0.1301, -0.0328, -0.92 , 1.8067, 0.2576, -0.5248, 0.4114, 0.1655, -0.1674, 0.2743, 0.0835, -0.145 , 1.1658, 1.2624, 0.0404, 2.0929, 0.6047, 1.0317, -0.4956, -1.5666, 1.1729, 0.484 , 0.955 , 1.0546, 0.0106, 0.5062, 0.3211, 0.8503, 0.4706, 1.9953, -0.9362, 0.6326, -0.3154, 1.4987, -0.1695, 1.0906, -0.686 , 0.2501, -0.316 , 0.3032, 0.4873, 0.6402, -0.1209, -0.1857, -0.3707, -0.3082, -0.4769, -0.858 , -0.1521, -0.3403, -0.9853, -0.5049, 0.3338, -0.3197, -0.5789, -0.7124, -0.8867, -0.0228, -1.5519, 1.8517, 0.5229, 0.7613, -0.5586, 0.4827, -1.3011, -0.5284, -0.3806, -0.7719, 1.6304, 0.0375, -0.9122, -0.1006, 0.382 , 0.0969, 1.7784, 0.1831, -1.8866, 0.2996, 0.4778, -0.2491, -1.6537, 0.022 , -0.101 , 0.5912, -0.2249, -1.1422, -0.6436, -1.4096, -0.7446, 0.8055, 1.0727, 0.2426, -0.8079, -1.4692, 0.062 , -0.4466, 0.3786, -2.0461, 0.7238, -1.6195, 1.4005, 0.4881, -0.8161, -0.582 , 0.3456, 1.2922, 0.2469, 1.9035, 0.9072, -0.0729, -0.9424, -1.1129, 0.8922, -0.5628, 1.6215, -0.7022, 0.8395, -0.3423, 0.6048, -0.248 , 0.7411, 0.3546, 0.6176, -0.8221, -0.338 , -2.1051, -1.0049, -0.0659, 0.0917, -0.6661, -0.5234, 0.9574, -0.6316, -0.0047, -0.4773, 0.1562, -0.116 , -1.6255, -0.9108, -1.4767, -0.7765, -1.7101, 0.0557, 0.8112, 0.7382, 1.8806, 0.9239, 1.8638, 0.8426, 0.0359, 0.2743, 1.9204, 1.2223, 0.4575, -0.3408, 0.3727, 0.5036, 0.5392, -1.3331, -0.4008, -0.1341, -1.5197, 0.1923, 0.2128, 1.1533, -1.4284, -0.7483, -0.4092, 1.2843, -0.4489, -0.6624, 0.9255, -0.0895, 0.3199, -0.2564, -0.1166, -1.4701, 1.1799, -1.6238, 0.0508, 0.2312, 0.7322, -1.3623, -0.232 , -0.2206, 0.566 , 1.2411, -1.1563, 1.1777, -1.1481, -0.6716, 0.4596, -0.2422, -0.8654, 0.4441, 0.1869, 1.4626, 0.7621, 0.4249, 0.252 , 0.632 , 0.5626, -0.7925, 1.1995, 1.5665, 0.6096, 0.4821, -0.7324, -0.7624, 1.858 , -0.8434, -0.4408, 0.2011, 0.7552, -0.8955, -1.3255, 0.7022, 0.1507, 0.662 , -1.2229, 0.5199, 0.9837, -0.3947, -0.5262, -1.0424, -1.4582, 0.5126, -0.3606, 0.4427, -2.3922, 1.2784, -0.8382, -0.0198, 1.2136, -0.4212, -0.7798, -1.3387, -0.7141, 0.9581, -0.8575, -0.2255, 0.8436, -2.2162, 0.0742, 0.9683, -0.3633, -0.0227, -1.2176, 1.1482, -0.6697, 0.9643, -1.2802, -0.3651, -1.29 , 0.851 , 1.0167, 1.0011, -1.3014, -0.7205, 1.3621, -0.692 , 1.0637, 0.5637, 0.0851, 2.1514, -0.272 , 0.3136, 0.2179, 0.7035, -1.3028, -0.1032, 0.0611, 1.2002, -0.7346, 0.9991, -0.3747, 0.7908, -0.9573, -0.5114, -0.8607, -0.6711, 1.3335, -0.6671, -0.1687, 0.4601, 0.5747, -0.0767, -0.8428, 0.3372, -1.7756, -2.5264, -1.503 , -0.5669, 0.0167, -1.961 , 0.8861, 1.1902, 2.239 , 0.2481, 0.7361, -1.1103, 0.8368, -1.0434, 0.6809, -0.0839, -0.6972, -1.5492, -1.4129, 0.5889, 0.2138, 1.7689, -0.4861, -0.1124, 0.2032, 1.0664, -0.369 , 2.3793, 0.4406, -1.1741, 1.0812, 1.3965, -0.149 , 0.8793, 1.3494, 1.2159, -0.0001, 1.1929, -0.1966, -0.1666, 1.7097, -0.4273, 0.4831, -0.2411, -1.4517, -0.7317, 0.099 , 1.7922, 0.2313, -0.5031, -0.0849, 0.7331, -0.1483, -0.8003, 1.1897, 0.031 , -0.3624, -1.1133, 1.4647, 2.5653, -1.9536, -0.4528, -1.693 , 0.4847, 0.1368, 0.6859, -0.9872, 0.8425, -0.1492, -0.1335, -0.0229, -0.0903, -0.4381, 1.2552, 1.5763, 0.2375, -0.7597, 0.0845, 0.0894, -1.6022, -0.1988, 0.3095, -1.0785, -1.6044, -0.4922, 0.4583, 0.3168, -2.0485, -1.2147, -0.2803, -0.2071, 0.0767, 1.9544, -1.7648, 0.2873, -0.4029, -0.8128, -0.1081, 0.0332, 2.5288, 0.9933, 0.4378, -0.8208, -0.2451, 0.3472, -0.2917, 2.0775, 1.7381, -0.467 , -0.8943, -1.4171, -0.3905, 0.2591, 0.8118, -0.643 , 1.0387, 0.0049, 1.7299, -0.6882, -1.4132, -1.0893, 0.4606, -1.546 , -2.87 , 0.3492, -1.5968, 0.9858, 0.1384, -0.6016, -0.9632, -0.9088, 0.3711, 1.3509, 0.4601, -1.4963, -0.043 , 0.5588, 0.2638, -1.1118, -0.9376, -0.9139, 0.6551, 0.4876, -1.7039, -0.2915, 0.3867, -0.1795, 1.2298, 0.0893, -0.6019, 1.4109, -1.1918, 0.5009, 0.0157, -1.1307, 1.0407, 1.9742, -1.0377, -0.6151, -0.8398, 1.4096, -0.012 , -1.5323, 0.3323, 0.0539, 0.2383, -0.4059, 2.285 , 0.1536, 0.3838, 0.3623, -0.4326, -0.0975, -1.8119]) array([-2.9433, -2.87 , -2.6518, -2.5489, -2.5465, -2.5264, -2.4542, -2.3922, -2.3352, -2.3038, -2.2774, -2.2574, -2.2444, -2.2162, -2.1117, -2.1051, -2.0724, -2.0553, -2.0485, -2.0461, -1.9851, -1.961 , -1.9536, -1.9525, -1.8866, -1.8119, -1.7853, -1.7793, -1.7756, -1.769 , -1.7648, -1.733 , -1.7101, -1.7039, -1.693 , -1.669 , -1.6537, -1.6255, -1.625 , -1.6248, -1.6238, -1.6195, -1.6097, -1.6044, -1.6022, -1.5968, -1.5895, -1.5824, -1.5666, -1.5612, -1.5519, -1.5492, -1.546 , -1.5415, -1.5392, -1.5323, -1.5263, -1.5197, -1.503 , -1.4963, -1.4891, -1.4876, -1.4767, -1.4742, -1.4701, -1.4692, -1.4582, -1.4517, -1.4366, -1.4291, -1.4284, -1.4261, -1.4171, -1.4132, -1.4129, -1.4129, -1.4096, -1.3994, -1.3755, -1.3655, -1.3623, -1.3583, -1.3387, -1.3331, -1.3325, -1.3255, -1.3191, -1.3153, -1.3028, -1.3014, -1.3011, -1.2912, -1.29 , -1.2803, -1.2802, -1.2598, -1.2527, -1.2472, -1.2467, -1.2456, -1.2365, -1.2229, -1.2176, -1.2147, -1.1918, -1.1843, -1.1799, -1.1741, -1.1597, -1.1563, -1.1551, -1.1481, -1.1422, -1.1307, -1.1239, -1.1234, -1.118 , -1.1133, -1.1129, -1.1118, -1.1103, -1.1097, -1.1087, -1.1017, -1.0923, -1.0893, -1.0831, -1.0785, -1.0767, -1.0763, -1.0699, -1.069 , -1.0487, -1.0434, -1.0424, -1.0397, -1.0377, -1.0318, -1.0263, -1.017 , -1.0152, -1.0049, -1.0032, -0.9944, -0.9872, -0.9853, -0.9816, -0.9632, -0.9632, -0.9573, -0.9521, -0.9516, -0.9424, -0.9419, -0.9377, -0.9376, -0.9371, -0.9362, -0.9343, -0.92 , -0.9139, -0.9122, -0.9111, -0.9108, -0.9106, -0.9088, -0.9086, -0.8974, -0.8955, -0.8943, -0.8867, -0.8858, -0.8849, -0.8654, -0.8632, -0.8607, -0.858 , -0.8575, -0.8546, -0.849 , -0.8483, -0.8434, -0.8428, -0.8398, -0.8382, -0.8357, -0.8324, -0.8303, -0.827 , -0.8221, -0.821 , -0.8208, -0.817 , -0.8161, -0.8141, -0.8128, -0.8084, -0.8079, -0.8003, -0.7962, -0.7925, -0.7835, -0.7802, -0.7798, -0.7797, -0.7793, -0.7765, -0.7762, -0.7719, -0.7654, -0.7638, -0.7624, -0.7597, -0.7596, -0.7579, -0.7534, -0.7487, -0.7483, -0.7446, -0.7348, -0.7346, -0.7326, -0.7324, -0.7317, -0.7277, -0.7264, -0.7215, -0.7205, -0.7141, -0.7125, -0.7124, -0.7083, -0.7036, -0.7022, -0.6982, -0.6972, -0.6966, -0.692 , -0.6914, -0.6882, -0.6877, -0.686 , -0.6853, -0.6716, -0.6711, -0.6705, -0.6697, -0.6671, -0.6661, -0.6624, -0.6623, -0.6596, -0.6568, -0.6489, -0.6452, -0.6443, -0.6437, -0.6436, -0.643 , -0.641 , -0.6407, -0.6371, -0.6332, -0.6316, -0.6259, -0.6174, -0.6151, -0.6148, -0.6126, -0.6089, -0.6051, -0.605 , -0.6033, -0.6019, -0.6016, -0.601 , -0.5972, -0.582 , -0.5794, -0.5789, -0.5752, -0.5742, -0.5726, -0.572 , -0.5669, -0.5628, -0.5617, -0.5605, -0.5594, -0.5586, -0.5557, -0.5523, -0.5389, -0.5329, -0.5284, -0.5262, -0.5258, -0.5248, -0.5234, -0.5131, -0.5114, -0.5057, -0.5049, -0.5031, -0.5009, -0.4991, -0.4956, -0.4922, -0.4861, -0.4813, -0.4808, -0.4773, -0.4769, -0.4752, -0.475 , -0.4731, -0.4703, -0.467 , -0.4652, -0.4624, -0.4528, -0.452 , -0.4489, -0.4472, -0.4466, -0.4455, -0.4435, -0.4431, -0.4423, -0.4408, -0.4381, -0.4374, -0.4326, -0.4301, -0.4294, -0.4273, -0.4264, -0.4212, -0.4143, -0.4138, -0.4113, -0.4092, -0.408 , -0.4059, -0.4038, -0.4029, -0.4008, -0.3997, -0.3984, -0.3966, -0.3947, -0.3927, -0.3905, -0.388 , -0.3806, -0.3774, -0.3747, -0.3746, -0.3734, -0.3707, -0.369 , -0.3686, -0.3675, -0.3667, -0.3656, -0.3655, -0.3651, -0.3633, -0.3624, -0.3606, -0.3542, -0.354 , -0.3423, -0.3408, -0.3403, -0.3397, -0.338 , -0.3253, -0.3223, -0.3197, -0.316 , -0.3154, -0.3151, -0.3144, -0.3082, -0.3036, -0.3002, -0.2971, -0.2923, -0.2917, -0.2915, -0.2901, -0.2828, -0.2803, -0.272 , -0.2704, -0.2684, -0.2644, -0.2564, -0.2547, -0.2497, -0.2491, -0.248 , -0.2451, -0.2447, -0.2446, -0.2422, -0.2411, -0.2381, -0.2339, -0.232 , -0.2314, -0.2298, -0.2255, -0.2249, -0.2238, -0.2236, -0.2206, -0.211 , -0.2074, -0.2071, -0.2065, -0.2058, -0.2041, -0.1988, -0.1966, -0.1935, -0.1913, -0.1857, -0.1795, -0.1792, -0.1695, -0.1691, -0.1687, -0.1674, -0.1666, -0.1602, -0.1595, -0.1566, -0.1526, -0.1521, -0.1508, -0.1492, -0.149 , -0.1483, -0.148 , -0.146 , -0.145 , -0.1341, -0.1335, -0.131 , -0.1301, -0.1247, -0.1221, -0.1209, -0.1195, -0.1166, -0.116 , -0.1126, -0.1124, -0.1081, -0.1036, -0.1032, -0.101 , -0.1006, -0.0975, -0.0903, -0.0895, -0.0894, -0.0879, -0.0849, -0.0839, -0.078 , -0.0767, -0.0729, -0.0675, -0.0659, -0.0588, -0.0453, -0.0453, -0.043 , -0.0328, -0.0324, -0.0311, -0.0244, -0.0229, -0.0228, -0.0227, -0.0213, -0.0198, -0.0171, -0.0136, -0.0129, -0.012 , -0.005 , -0.0047, -0.0026, -0.0001, 0.0049, 0.0106, 0.0157, 0.0167, 0.0216, 0.022 , 0.0251, 0.0263, 0.0272, 0.0274, 0.0285, 0.0301, 0.031 , 0.0332, 0.0334, 0.0359, 0.0375, 0.0375, 0.0404, 0.0419, 0.0443, 0.0466, 0.0479, 0.049 , 0.0508, 0.0539, 0.0557, 0.0572, 0.0601, 0.0611, 0.062 , 0.07 , 0.0742, 0.0756, 0.0767, 0.0784, 0.0801, 0.0806, 0.0835, 0.0845, 0.0851, 0.0882, 0.0889, 0.0893, 0.0894, 0.0917, 0.092 , 0.0923, 0.0943, 0.0969, 0.099 , 0.1016, 0.106 , 0.1064, 0.1351, 0.1364, 0.1368, 0.1384, 0.1384, 0.1396, 0.15 , 0.1507, 0.1536, 0.1552, 0.1562, 0.1655, 0.1666, 0.1704, 0.1778, 0.1831, 0.1859, 0.1862, 0.1865, 0.1869, 0.188 , 0.1923, 0.1958, 0.1973, 0.2011, 0.2032, 0.2099, 0.2128, 0.2132, 0.2138, 0.2179, 0.2254, 0.2312, 0.2313, 0.2375, 0.2383, 0.2426, 0.2447, 0.2469, 0.2481, 0.2501, 0.252 , 0.2536, 0.2576, 0.2591, 0.2621, 0.2638, 0.2724, 0.2743, 0.2743, 0.2748, 0.2873, 0.2882, 0.2904, 0.2913, 0.2963, 0.2996, 0.3032, 0.3061, 0.3086, 0.3095, 0.3136, 0.3141, 0.3159, 0.3166, 0.3168, 0.3185, 0.3199, 0.3211, 0.3218, 0.3245, 0.3272, 0.3323, 0.3329, 0.3335, 0.3338, 0.3372, 0.3433, 0.3456, 0.3472, 0.3492, 0.3504, 0.3504, 0.3524, 0.3528, 0.3546, 0.3566, 0.3569, 0.3572, 0.3623, 0.3624, 0.3683, 0.3702, 0.3711, 0.3711, 0.3727, 0.3746, 0.3767, 0.3786, 0.3794, 0.3803, 0.381 , 0.382 , 0.3838, 0.3867, 0.387 , 0.3934, 0.394 , 0.3993, 0.3995, 0.4023, 0.4037, 0.407 , 0.4103, 0.4114, 0.4175, 0.4241, 0.4249, 0.4293, 0.4378, 0.4386, 0.4406, 0.4417, 0.4421, 0.4427, 0.4441, 0.4575, 0.4583, 0.4596, 0.4601, 0.4601, 0.4606, 0.4607, 0.462 , 0.4657, 0.4706, 0.4738, 0.4778, 0.4778, 0.4821, 0.4827, 0.4831, 0.484 , 0.4847, 0.4873, 0.4876, 0.4881, 0.4925, 0.4965, 0.5009, 0.5033, 0.5036, 0.5062, 0.5109, 0.5119, 0.5126, 0.5146, 0.5152, 0.5199, 0.5229, 0.5284, 0.5347, 0.5358, 0.5392, 0.5436, 0.5533, 0.5588, 0.5597, 0.5626, 0.5637, 0.566 , 0.5675, 0.5736, 0.5747, 0.5889, 0.5903, 0.5912, 0.5968, 0.5969, 0.6 , 0.604 , 0.6047, 0.6048, 0.6096, 0.6128, 0.6138, 0.6176, 0.6201, 0.632 , 0.6326, 0.6351, 0.6402, 0.6449, 0.6464, 0.6495, 0.6551, 0.6615, 0.662 , 0.662 , 0.6648, 0.6699, 0.6714, 0.673 , 0.6739, 0.6809, 0.6831, 0.6856, 0.6859, 0.6867, 0.6883, 0.7003, 0.7022, 0.7035, 0.7073, 0.7127, 0.7227, 0.7238, 0.7248, 0.7254, 0.7317, 0.7322, 0.7331, 0.7361, 0.7382, 0.7411, 0.7475, 0.7496, 0.7552, 0.7567, 0.7613, 0.7621, 0.7667, 0.767 , 0.7695, 0.7751, 0.7799, 0.7908, 0.7921, 0.8043, 0.8055, 0.8064, 0.8112, 0.8118, 0.8266, 0.8327, 0.8368, 0.8395, 0.8411, 0.8419, 0.8425, 0.8426, 0.8436, 0.8442, 0.8444, 0.8503, 0.851 , 0.8545, 0.8634, 0.8743, 0.8744, 0.8793, 0.8858, 0.8861, 0.8922, 0.9017, 0.9018, 0.9072, 0.9073, 0.9237, 0.9239, 0.9255, 0.927 , 0.9362, 0.9533, 0.955 , 0.9574, 0.9581, 0.961 , 0.9623, 0.9643, 0.966 , 0.9683, 0.9797, 0.9837, 0.9858, 0.9918, 0.9933, 0.9949, 0.9975, 0.9991, 1.0011, 1.0126, 1.0167, 1.0317, 1.0387, 1.0407, 1.0539, 1.0546, 1.0558, 1.0567, 1.0637, 1.066 , 1.0664, 1.067 , 1.0727, 1.0735, 1.076 , 1.0767, 1.0812, 1.0844, 1.0906, 1.0977, 1.0998, 1.1103, 1.1161, 1.122 , 1.1334, 1.1351, 1.1366, 1.1482, 1.1533, 1.1545, 1.1567, 1.163 , 1.1632, 1.1649, 1.1653, 1.1658, 1.1729, 1.1777, 1.1777, 1.1799, 1.1801, 1.1837, 1.1864, 1.1897, 1.1902, 1.1929, 1.1929, 1.1995, 1.2002, 1.2098, 1.2136, 1.2156, 1.2159, 1.2223, 1.2296, 1.2298, 1.2378, 1.2411, 1.253 , 1.2544, 1.2552, 1.2624, 1.2784, 1.2797, 1.2843, 1.2922, 1.2944, 1.2946, 1.3289, 1.3335, 1.3342, 1.3388, 1.3494, 1.3509, 1.3621, 1.3632, 1.3649, 1.3722, 1.3725, 1.3866, 1.3965, 1.3996, 1.4005, 1.4047, 1.4096, 1.4109, 1.421 , 1.4273, 1.4349, 1.4391, 1.4626, 1.4647, 1.4797, 1.4848, 1.497 , 1.4987, 1.5228, 1.5275, 1.5298, 1.5449, 1.5665, 1.5763, 1.5874, 1.5924, 1.6091, 1.6215, 1.6304, 1.6461, 1.6789, 1.6945, 1.7032, 1.7097, 1.7106, 1.7114, 1.7299, 1.7323, 1.7381, 1.7689, 1.7784, 1.7922, 1.7923, 1.8067, 1.8315, 1.8415, 1.8517, 1.858 , 1.8589, 1.8638, 1.8738, 1.8806, 1.9035, 1.9074, 1.9204, 1.9294, 1.9456, 1.9493, 1.9544, 1.9551, 1.9742, 1.9928, 1.9953, 2.0775, 2.0929, 2.1223, 2.1514, 2.239 , 2.285 , 2.3306, 2.3672, 2.3793, 2.5288, 2.5507, 2.5653, 2.5671, 2.6081, 2.697 ]) -1.5519406239259821 1234names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])np.unique(names)ints = np.array([3, 3, 3, 2, 2, 1, 1, 4, 4])np.unique(ints)array([&#39;Bob&#39;, &#39;Joe&#39;, &#39;Will&#39;], dtype=&#39;&lt;U4&#39;) array([1, 2, 3, 4]) 1sorted(set(names))[&#39;Bob&#39;, &#39;Joe&#39;, &#39;Will&#39;] in1d12values = np.array([6, 0, 0, 3, 2, 5, 6])np.in1d(values, [2, 3, 6])array([ True, False, False, True, True, False, True], dtype=bool) 12arr = np.arange(10)np.save('some_array', arr)1np.load('some_array.npy')array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 1np.savez('array_archive.npz', a=arr[:4], b=arr)123arch = np.load('array_archive.npz')arch['a']arch['b']array([0, 1, 2, 3]) array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 1!more ch04\array_ex.txt0.580052,0.186730,1.040717,1.134411 0.194163,-0.636917,-0.938659,0.124094 -0.126410,0.268607,-0.695724,0.047428 -1.484413,0.004176,-0.744203,0.005487 2.302869,0.200131,1.670238,-1.881090 -0.193230,1.047233,0.482803,0.960334 12arr = np.loadtxt('.\\ch04\\array_ex.txt', delimiter=',')arrarray([[ 0.5801, 0.1867, 1.0407, 1.1344], [ 0.1942, -0.6369, -0.9387, 0.1241], [-0.1264, 0.2686, -0.6957, 0.0474], [-1.4844, 0.0042, -0.7442, 0.0055], [ 2.3029, 0.2001, 1.6702, -1.8811], [-0.1932, 1.0472, 0.4828, 0.9603]]) 12345x = np.array([[1., 2., 3.], [4., 5., 6.]])y = np.array([[6., 23.], [-1, 7], [8, 9]])xyx.dot(y) # equivalently np.dot(x, y)array([[ 1., 2., 3.], [ 4., 5., 6.]]) array([[ 6., 23.], [ -1., 7.], [ 8., 9.]]) array([[ 28., 64.], [ 67., 181.]]) 1np.dot(x, np.ones(3))array([ 6., 15.]) 1np.random.seed(12345)123456789from numpy.linalg import inv, qrX = randn(5, 5)Xmat = X.T.dot(X)matinv(mat)mat.dot(inv(mat))q, r = qr(mat) # QRrarray([[-0.5031, -0.6223, -0.9212, -0.7262, 0.2229], [ 0.0513, -1.1577, 0.8167, 0.4336, 1.0107], [ 1.8249, -0.9975, 0.8506, -0.1316, 0.9124], [ 0.1882, 2.1695, -0.1149, 2.0037, 0.0296], [ 0.7953, 0.1181, -0.7485, 0.585 , 0.1527]]) array([[ 4.2538, -1.0645, 1.4407, 0.9898, 1.7318], [-1.0645, 7.4431, -1.5585, 4.4972, -2.1367], [ 1.4407, -1.5585, 2.8126, 0.243 , 1.2786], [ 0.9898, 4.4972, 0.243 , 5.0897, 0.305 ], [ 1.7318, -2.1367, 1.2786, 0.305 , 1.928 ]]) array([[ 0.4057, -0.1875, -0.0764, 0.1229, -0.541 ], [-0.1875, 2.462 , 0.2537, -2.3367, 3.0984], [-0.0764, 0.2537, 0.5435, -0.2369, 0.0268], [ 0.1229, -2.3367, -0.2369, 2.4239, -2.9264], [-0.541 , 3.0984, 0.0268, -2.9264, 4.8837]]) array([[ 1., 0., -0., -0., -0.], [ 0., 1., -0., -0., -0.], [ 0., 0., 1., 0., -0.], [ 0., -0., 0., 1., 0.], [ 0., 0., -0., 0., 1.]]) array([[-5.0281, 2.7734, -2.8428, -1.0619, -3.0078], [ 0. , -8.7212, 1.2925, -6.5614, 1.622 ], [ 0. , 0. , -2.0873, -1.0487, -0.6291], [ 0. , 0. , 0. , -1.408 , -0.955 ], [ 0. , 0. , 0. , 0. , 0.1537]]) 12samples = np.random.normal(size=(4, 4))samplesarray([[-0.5196, 1.297 , 0.9062, 0.5809], [ 1.2233, -1.3301, 1.0483, 0.357 ], [-0.7935, -0.406 , -0.0096, -0.596 ], [ 1.3833, -0.2029, -1.0547, -0.9795]]) 1234from random import normalvariateN = 1000000%timeit samples = [normalvariate(0, 1) for _ in range(N)]%timeit np.random.normal(size=N)1 loop, best of 3: 814 ms per loop 10 loops, best of 3: 28.4 ms per loop numpyExample: 123456789import randomposition = 0walk = [position]steps = 1000for i in range(steps): step = 1 if random.randint(0, 1) else -1 position += step walk.append(position)numpy1np.random.seed(12345)1234nsteps = 1000draws = np.random.randint(0, 2, size=nsteps)steps = np.where(draws &gt; 0, 1, -1)walk = steps.cumsum()1234import matplotlib.pyplot as pltindex = [x + 1 for x in range(len(walk))]plt.plot(index, walk)[&lt;matplotlib.lines.Line2D at 0x234014e9f98&gt;] 12walk.min()walk.max()-3 31 1(np.abs(walk) &gt;= 10).argmax() # the first index37 123456nwalks = 5000 # 5000 random walknsteps = 1000draws = np.random.randint(0, 2, size=(nwalks, nsteps)) # 0 or 1steps = np.where(draws &gt; 0, 1, -1)walks = steps.cumsum(1)walksarray([[ -1, 0, -1, ..., 24, 23, 22], [ -1, 0, -1, ..., -36, -37, -36], [ 1, 2, 3, ..., -42, -41, -40], ..., [ 1, 0, -1, ..., 48, 49, 50], [ -1, -2, -3, ..., -38, -39, -40], [ -1, 0, 1, ..., -48, -47, -48]], dtype=int32) 12walks.max()walks.min()130 -117 123hits30 = (np.abs(walks) &gt;= 30).any(1)hits30hits30.sum() # Number that hit 30 or -30array([ True, True, True, ..., True, True, True], dtype=bool) 3412 12crossing_times = (np.abs(walks[hits30]) &gt;= 30).argmax(1)crossing_times.mean()497.04103165298943]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Naive Bayes]]></title>
      <url>%2F2017%2F02%2F25%2FNaive-Bayes%2F</url>
      <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960def LoadDataSet(): """ Load a vector-like data set tranfered by a data set list that generated by artifical. Returns: return_vec: the vector-like data set. class_vec: the class label corresponds to the data items. """ posting_list = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] class_vec = [0, 1, 0, 1, 0, 1] # 1 is abusive, 0 not return posting_list, class_vecdef CreateVocabList(data_set): """ Create vocabulary list from vector-like data set. Arguments: data_set: the data source. Returns: vocab_list: the vocabulary list. """ vocab_set = set([]) for document in data_set: vocab_set = vocab_set | set(document) return list(vocab_set)def SetOfWords2Vec(vocab_list, input_set): """ Transfer the words list to vector for each posting. Arguments: vocab_list: The vocabulary list. input_set: The posting that ready to transfer to vector. Returns: return_vec: the result vector. """ # Initialize return_vec = [0] * len(vocab_list) for word in input_set: if word in vocab_list: return_vec[vocab_list.index(word)] = 1 else: print("the word: %s is not in my Vocabulary" % word) return return_vec123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110In [13]: import bayesIn [14]: list_of_posts, list_classes = bayes.LoadDataSet()In [15]: my_vocab_list = bayes.CreateVocabList(list_of_posts)In [16]: my_vocab_listOut[16]:['help', 'worthless', 'I', 'take', 'love', 'maybe', 'stupid', 'to', 'not', 'please', 'quit', 'park', 'posting', 'dog', 'dalmation', 'steak', 'my', 'how', 'food', 'so', 'stop', 'is', 'garbage', 'flea', 'problems', 'has', 'buying', 'ate', 'him', 'licks', 'mr', 'cute']In [17]: bayes.SetOfWords2Vec(my_vocab_list, list_of_posts[0])Out[17]:[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]In [18]: bayes.SetOfWords2Vec(my_vocab_list, list_of_posts[3])Out[18]:[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]workp(c_i | w) = \frac{p(w | c_i) p(c_i)}{p(w)}$w$ $c_i$p(w | c_i) = p(w_0, w_1, w_2, \cdots, w_N | c_i) = p(w_0 | c_i)p(w_1 | c_i)p(w_2 | c_i) \cdots p(w_N | c_i)12345678910for  for  if    for  for   $p(w_j | c_i)$123456789101112131415161718192021222324252627282930313233def TrainNaiveBayes0(train_matrix, train_category): """ the training method. Arguments: train_matrix: The train data. train_category: The train label. Returns: p0_vect: The conditional probability of w by c0 p1_vect: The conditional probability of w by c1 p_abusive: The conditional probability of c1 """ num_train_docs = len(train_matrix) num_words = len(train_matrix[0]) p_abusive = sum(train_category) / num_train_docs p0_num = zeros(num_words) p1_num = zeros(num_words) p0_denom = 0.0 p1_denom = 0.0 for i in range(num_train_docs): if train_category[i] == 1: p1_num += train_matrix[i] p1_denom += sum(train_matrix[i]) else: p0_num += train_matrix[i] p0_denom += sum(train_matrix[i]) p1_vect = p1_num / p1_denom p0_vect = p0_num / p0_denom return p0_vect, p1_vect, p_abusive123456789101112131415161718192021222324252627282930In [25]: train_mat = []In [26]: for post_in_doc in list_of_posts: ...: train_mat.append(bayes.SetOfWords2Vec(my_vocab_list, post_in_doc)) ...:In [27]: p0_v, p1_v, p_ab = bayes.TrainNaiveBayes0(train_mat, list_classes)In [28]: p_abOut[28]: 0.5In [29]: p0_vOut[29]:array([ 0.04166667, 0. , 0.04166667, 0. , 0.04166667, 0. , 0. , 0.04166667, 0. , 0.04166667, 0. , 0. , 0. , 0.04166667, 0.04166667, 0.04166667, 0.125 , 0.04166667, 0. , 0.04166667, 0.04166667, 0.04166667, 0. , 0.04166667, 0.04166667, 0.04166667, 0. , 0.04166667, 0.08333333, 0.04166667, 0.04166667, 0.04166667])In [30]: p1_vOut[30]:array([ 0. , 0.10526316, 0. , 0.05263158, 0. , 0.05263158, 0.15789474, 0.05263158, 0.05263158, 0. , 0.05263158, 0.05263158, 0.05263158, 0.10526316, 0. , 0. , 0. , 0. , 0.05263158, 0. , 0.05263158, 0. , 0.05263158, 0. , 0. , 0. , 0.05263158, 0. , 0.05263158, 0. , 0. , 0. ])$p(w_j | c_i)$00 (2)1234p0_num = ones(num_words)p1_num = ones(num_words)p0_denom = 2.0p1_denom = 2.0log12p1_vect = log(p1_num / p1_denom)p0_vect = log(p0_num / p0_denom)123456789101112131415161718192021222324252627282930313233343536373839404142def ClassifyNaiveBayes(vec_to_classify, p0_vect, p1_vect, p_abusive): """ Classify. Arguments: vec_to_classify: The vector to classify. p0_vect: The conditional probability of w by c0. p1_vect: The conditional probability of w by c1. p_abusive: The conditional probability of c1. Returns: 0: The predict class is 0 1: The predict class is 1 """ p1 = sum(vec_to_classify * p1_vect) + log(p_abusive) p0 = sum(vec_to_classify * p0_vect) + log(1 - p_abusive) if p1 &gt; p0: return 1 else: return 0def TestNaiveBayes(): """ A test method. """ list_of_posts, list_of_classes = LoadDataSet() my_vocab_list = CreateVocabList(list_of_posts) train_mat = [] for post_in_doc in list_of_posts: train_mat.append(SetOfWords2Vec(my_vocab_list, post_in_doc)) p0_v, p1_v, p_ab = TrainNaiveBayes0( array(train_mat), array(list_of_classes)) test_entry = ['love', 'my', 'dalmation'] this_doc = array(SetOfWords2Vec(my_vocab_list, test_entry)) print(test_entry, 'classified as: ', ClassifyNaiveBayes(this_doc, p0_v, p1_v, p_ab)) test_entry = ['stupid', 'garbage'] this_doc = array(SetOfWords2Vec(my_vocab_list, test_entry)) print(test_entry, 'classified as: ', ClassifyNaiveBayes(this_doc, p0_v, p1_v, p_ab))Test123In [32]: bayes.TestNaiveBayes()['love', 'my', 'dalmation'] classified as: 0['stupid', 'garbage'] classified as: 1Ok, bravo! 1234567891011121314151617181920def BagOfWords2Vec(vocab_list, input_set): """ Transfer the words list to vector for each posting. Arguments: vocab_list: The vocabulary list. input_set: The posting that ready to transfer to vector. Returns: return_vec: the result vector. """ # Initialize return_vec = [0] * len(vocab_list) for word in input_set: if word in vocab_list: return_vec[vocab_list.index(word)] += 1 else: print("the word: %s is not in my Vocabulary" % word) return return_vec$p(w_j | c_i)$sk-learn123456789In [33]: from sklearn import datasets ...: iris = datasets.load_iris() ...: from sklearn.naive_bayes import GaussianNB ...: gnb = GaussianNB() ...: y_pred = gnb.fit(iris.data, iris.target).predict(iris.data) ...: print("Number of mislabeled points out of a total %d points : %d" ...: % (iris.data.shape[0],(iris.target != y_pred).sum())) ...:Number of mislabeled points out of a total 150 points : 6]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CS231n Lecture2 note]]></title>
      <url>%2F2017%2F02%2F24%2FCS231n-Lecture2-note%2F</url>
      <content type="text"><![CDATA[ pipeline -&gt;  -&gt; L1 distanced_1 (I_1, I_2) = \sum_{p} \left| I^p_1 - I^p_2 \right|L2 distanced_2 (I_1, I_2) = \sqrt{\sum_{p} \left( I^p_1 - I^p_2 \right)^2}1234Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/') # a magic function we provide# flatten out all images to be one-dimensionalXtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072123456nn = NearestNeighbor() # create a Nearest Neighbor classifier classnn.train(Xtr_rows, Ytr) # train the classifier on the training images and labelsYte_predict = nn.predict(Xte_rows) # predict labels on the test images# and now print the classification accuracy, which is the average number# of examples that are correctly predicted (i.e. label matches)print 'accuracy: %f' % ( np.mean(Yte_predict == Yte) )123456789101112131415161718192021222324252627import numpy as npclass NearestNeighbor(object): def __init__(self): pass def train(self, X, y): """ X is N x D where each row is an example. Y is 1-dimension of size N """ # the nearest neighbor classifier simply remembers all the training data self.Xtr = X self.ytr = y def predict(self, X): """ X is N x D where each row is an example we wish to predict label for """ num_test = X.shape[0] # lets make sure that the output type matches the input type Ypred = np.zeros(num_test, dtype = self.ytr.dtype) # loop over all test rows for i in xrange(num_test): # find the nearest training image to the i'th test image # using the L1 distance (sum of absolute value differences) distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1) min_index = np.argmin(distances) # get the index with smallest distance Ypred[i] = self.ytr[min_index] # predict the label of the nearest example return YpredL1-distance 38.6% on CIFAR-10L2-distance 35.4% on CIFAR-10L1 vs. L2 L2L1K123456789101112131415161718192021# assume we have Xtr_rows, Ytr, Xte_rows, Yte as before# recall Xtr_rows is 50,000 x 3072 matrixXval_rows = Xtr_rows[:1000, :] # take first 1000 for validationYval = Ytr[:1000]Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for trainYtr = Ytr[1000:]# find hyperparameters that work best on the validation setvalidation_accuracies = []for k in [1, 3, 5, 10, 20, 50, 100]: # use a particular value of k and evaluation on validation data nn = NearestNeighbor() nn.train(Xtr_rows, Ytr) # here we assume a modified NearestNeighbor class that can take a k as input Yval_predict = nn.predict(Xval_rows, k = k) acc = np.mean(Yval_predict == Yval) print 'accuracy: %f' % (acc,) # keep track of what works on the validation set validation_accuracies.append((k, acc)) 1. ANN 2. FANN(http://cs231n.github.io/assets/pixels_embed_cifar10_big.jpg)t-SNE http://lvdmaaten.github.io/tsne/random projection http://scikit-learn.org/stable/modules/random_projection.htmlINTUITION FAILS IN HIGH DIMENSIONS http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdfRecognizing and Learning Object Categories http://people.csail.mit.edu/torralba/shortCourseRLOC/index.htmlf(x_i, W, b) = W x_i + bx shape is [D x 1], W shape is [K x D], b shape is [K x 1]WKKWWbiasW ]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Qiniu cloud images batch upload and directory synchronization]]></title>
      <url>%2F2017%2F02%2F24%2FQiniu-cloud-images-batch-upload-and-directory-synchronization%2F</url>
      <content type="text"><![CDATA[]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Correlation Analysis]]></title>
      <url>%2F2017%2F02%2F24%2FCorrelation-Analysis%2F</url>
      <content type="text"><![CDATA[--ANOVAgumpies, sticklebarbs, spotheads300gumpiessticklebarbsspothheadsTotals8912091300100100100300\frac{ - }{}gumpies: $\frac{89 - 100}{100} = -0.11$sticklebarbs: $\frac{120 - 100}{100} = +0.20$spothheads: $\frac{91 - 100}{100} = -0.09$\frac{( - )^2}{}gumpies: $\frac{(89 - 100)^2}{100} = 1.21$sticklebarbs: $\frac{(120 - 100)^2}{100} = 4.0$spothheads: $\frac{(91 - 100)}{100} = 0.81$sum: $1.21 + 4.0 + 0.81 = 6.02$sumchi-square$\chi^2$ $O$ $E$ \chi^2 = \sum \frac{(O - E) ^ 2}{E}3006.02agumpies, bsticklebarbs, cspothheads300a, b, ca = b = c = 1001~210000 5%6.0295%$O$Alzhemers onset -during 5-year periodnoyesrecieved-yes1479156estrogenno8101589689571671124AAlzhemers onset -during 5-year periodnoyes(R) recieved-yes[cell a][cell b]156estrogenno[cell c][cell d]9689571671124aE_a = \frac{156}{1124} \times \frac{957}{1124} \times 1124$A$$no$$R$$yes$$[cell_a]$$cell$$R$$cell$$C$$cell$$N$E_{cell} =\frac{R}{N} \times \frac{C}{N} \times N$E$AAlzhemers onset -during 5-year periodnoyes(R) recieved-yes$E_a = \frac{156 \times 957}{1124} = 132.82$$E_b = \frac{156 \times 167}{1124} = 23.18$156estrogenno$E_c = \frac{968 \times 957}{1124} = 824.18$$E_d = \frac{968 \times 167}{1124} = 143.82$9689571671124\chi^2 = \sum \frac{(O - E) ^ 2}{E}2\chi^2 = \sum \frac{(|O - E| - 0.5) ^ 2}{E}$11.01$df = (r - 1)(c - 1)r = number of rowsc = number of columnsANOVAA B C DAB C DABCDTotal27.022.821.923.526.223.123.419.628.827.720.123.733.527.627.820.828.824.019.323.9$M_a = 28.86$$M_b = 25.04$$M_c = 22.50$$M_d = 22.30$$M_T = 24.68$ANOVA$F$F = \frac{MS_{bg}}{MS_{wg}} = \frac{}{}1 ABCDTotal$N_A = 5$$N_B = 5$$N_C = 5$$N_D = 5$$N_T = 20$$\sum X_{Ai} = 144.30$$\sum X_{Bi} = 125.20$$\sum X_{Ci} = 112.50$$\sum X_{Di} = 111.50$$\sum X_{Ti} = 493.50$$\sum X^2_{Ai} = 4196.57$$\sum X^2_{Bi} = 3158.50$$\sum X^2_{Ci} = 2576.51$$\sum X^2_{Di} = 2501.95$$\sum X^2_{Ti} = 12433.53$$SS_A = 32.07$$SS_B = 23.49$$SS_C = 45.26$$SS_D = 15.50$$SS_T = 256.42$SS = \sum X^2_i - \frac{(\sum X_i)^2}{N}2$SS{wg}$$SS{bg}$SS_{wg} = SS_A + SS_B + SS_C + SS_DSS_{bg} = SS_T - SS_{wg}4df_{bg} = k - 1 = 4 - 1 = 3df_{wg} = (N_A - 1) + (N_B - 1) + (N_C - 1) + (N_D - 1)5 $MS{bg}$$MS{wg}$MS_{bg} = \frac{SS_{bg}}{df_{bg}}MS_{wg} = \frac{SS_{wg}}{df_{wg}}6$F$F = 6.42 df = 3, 16123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269import osimport xlrdimport numpy as npimport scipy.stats as statsdef GetChildDetailLab(combine=True): """ Get the detail labs of each child data. Returns: child_detail_lab: the detail labs. """ CHILDS_FEATURE_LAB = ['tid', 'age_m', 'female', 'onlychild', 'divorce', 'medu_newcat', 'income_newcat', 'scr_ave', 'edu_ave', 'edu_of_scr', 'scr_h_cat', 'mediacoview', 'mediacontact'] CHILDS_CAT_LAB = ['emo_cat', 'con_cat', 'hyp_cat', 'pee_cat', 'difficulties_cat', 'pro_cat'] if combine: CHILDS_DETAIL_LAB = CHILDS_FEATURE_LAB CHILDS_DETAIL_LAB.extend(CHILDS_CAT_LAB) return CHILDS_DETAIL_LAB else: return CHILDS_FEATURE_LAB, CHILDS_CAT_LABdef ReadChildInfoFromExcel( file_name='SDQ.xlsx', sheet_name='data'): """ Read the screen-exposed vs.SDQ detail information of each child from the excel-type file. Arguments: file_name: the name of the excel-type file. sheet_name: the name of the sheet of the excel file. Returns: child_scr_exp_sdq: A list that contains the detail information of each child. labs: The lab corresponds to each colume of the data. """ CHILDS_FILE_NAME = 'child_scr_exp_sdq.npy' CHILDS_DETAIL_LAB = GetChildDetailLab() # print(CHILDS_DETAIL_LAB) NOT_INT_LAB_INDEIES = [CHILDS_DETAIL_LAB.index('age_m'), CHILDS_DETAIL_LAB.index('scr_ave'), CHILDS_DETAIL_LAB.index('edu_ave'), CHILDS_DETAIL_LAB.index('edu_of_scr')] child_scr_exp_sdq = [] if (os.path.isfile(CHILDS_FILE_NAME)): with open(CHILDS_FILE_NAME, 'rb') as f: child_scr_exp_sdq = np.load(f) else: workBook = xlrd.open_workbook(file_name) bookSheet = workBook.sheet_by_name(sheet_name) # read from second row because of the first row has tabs for row in range(1, bookSheet.nrows): child_row = [] for col in range(bookSheet.ncols): cel = bookSheet.cell(row, col) try: val = str(cel.value) # tolerant the value error if val == '': val = '-1.0' except Exception as e: print(e) # because of the type is different try: if col in NOT_INT_LAB_INDEIES: val = float(val) else: # in Excel, if cel.value is 1, then str(cel.value) is # '1.0' val = val.split('.')[0] val = int(val) except Exception as e: print(e) val = -1 child_row.append(val) child_scr_exp_sdq.append(child_row) child_scr_exp_sdq = np.array(child_scr_exp_sdq) with open(CHILDS_FILE_NAME, 'wb') as f: np.save(f, child_scr_exp_sdq) return child_scr_exp_sdq, CHILDS_DETAIL_LABdef SplitDataSet(data_set, feature, cat): """ Split the data set to two column, that is feature and cat Arguments: data_set: the source data set. feature: the input vector cat: the correspond category. Returns: splited_data_set: self-explation. """ CHILDS_DETAIL_LAB = GetChildDetailLab() feature_index = CHILDS_DETAIL_LAB.index(feature) cat_index = CHILDS_DETAIL_LAB.index(cat) # print(feature_index, cat_index) return data_set[:, (feature_index, cat_index)]def CalChi2(data_set): """ Calculate the chi-square value and p-value corresponds to the data set. Arguments: data_set: the object data set. Returns: chi2: the chi-square value. p: the p-value. """ rows_number = len(set(data_set[:, -1])) columns_number = len(set(data_set[:, 0])) # print(rows_number, columns_number) counts = np.zeros((rows_number, columns_number)) for row in data_set: if row[-1] != -1: if row[0] != -1: try: counts[int(row[-1])][int(row[0])] += 1 except: pass # drop the row that all item is 0 del_row_index = [] for index, count in enumerate(counts): if not count.any(): del_row_index.append(index) counts = np.delete(counts, tuple(del_row_index), axis=0) # drop the column that all item is 0 del_col_index = [] for index, count in enumerate(counts.T): if not count.any(): del_col_index.append(index) counts = np.delete(counts, tuple(del_col_index), axis=1) # print(counts) # calculate the chi-square value and correspond p-value chi2, p, dof, excepted = stats.chi2_contingency(counts) return chi2, pdef ANOVATest(data_set): """ Implement a ANOVA test on the data set. Arguments: data_set: the object data set. Return: f: The computed F-value of the test. p: The associated p-value from the F-distribution. """ # Initial the three categories normal = [] critical = [] abnormal = [] for data in data_set: if data[0] != -1: if data[-1] == 0: normal.append(data[0]) elif data[-1] == 1: critical.append(data[0]) elif data[-1] == 2: abnormal.append(data[0]) f, p = stats.f_oneway(normal, critical, abnormal) return f, pdef GenerateCoffMatrix(data_set): """ Calculate the chi-square and p-value of each feature-category pair. Arguments: data_set: the source data set. Returns: coff_matrix: the final cofficient matrix. """ coff_matrix = &#123;&#125; CHILDS_FEATURE_LAB, CHILDS_CAT_LAB = GetChildDetailLab(combine=False) NOT_KEEP_FEATURE_LAB = ['tid', 'age_m', 'scr_ave', 'edu_ave', 'edu_of_scr'] for feature in CHILDS_FEATURE_LAB: if feature in NOT_KEEP_FEATURE_LAB: if feature != NOT_KEEP_FEATURE_LAB[0]: for cat in CHILDS_CAT_LAB: splited_data_set = SplitDataSet(data_set, feature, cat) # print(feature, cat) f, p = ANOVATest(splited_data_set) key = feature + '-' + cat coff_matrix[key] = (f, p) else: for cat in CHILDS_CAT_LAB: splited_data_set = SplitDataSet(data_set, feature, cat) # print(feature, cat) chi2, p = CalChi2(splited_data_set) key = feature + '-' + cat coff_matrix[key] = (chi2, p) return coff_matrixdef SiftRelativeFeature(coff_matrix, conf=1e-5): """ Sift the feature that satisfy the caonfident condition. Arguemnts: coff_matrix: the calculated cofficient matrix for all features and categories. conf: the confident. Returns: relative_feature_matrix: the satisfied feature and correspond category and chi2 and p-value. """ relative_feature_matrix = &#123;&#125; for key in coff_matrix.keys(): if coff_matrix[key][-1] &lt;= conf: relative_feature_matrix[key] = coff_matrix[key] return relative_feature_matrixdef WriteResult(coff_matrix, file_name='result.txt'): """ Write the result to file. Arguments: relative_feature_matrix: the satisfied feature and correspond category and chi2 and p-value. file_name: the result file name. """ # Sort sorted_coff_matrix = sorted(coff_matrix.items(), key=lambda item: item[1][-1], reverse=False) # print(sorted_coff_matrix) with open(file_name, 'w') as f: for item in sorted_coff_matrix: f.write(str(item)) f.write('\n')if __name__ == '__main__': data_set, labels = ReadChildInfoFromExcel() # splited_data_set = SplitDataSet(data_set, 'female', 'difficulties_cat') # chi2, p = CalChi2(splited_data_set) coff_matrix = GenerateCoffMatrix(data_set) # relative_feature = SiftRelativeFeature(coff_matrix, 1) WriteResult(coff_matrix)(https://www.zhihu.com/question/24524693)SPSS( SPSS-)2017.2.27 Updates1234567import pandas as pdfrom sklearn import treeimport numpy as npfrom sklearn.model_selection import cross_val_scorefrom IPython.core.interactiveshell import InteractiveShellInteractiveShell.ast_node_interactivity = "all"Read data1data = pd.read_excel('./scr_SDQ.xlsx', sheetname='data', index_col=0).dropna().sort_index()Convert the data format1234float_columns = ['scr_ave', 'edu_ave','scr_of_edu']for column in data.columns: if column not in float_columns: data[column] = data[column].astype(int)Split the data123data_feature_with_edu_ave = data.ix[:, :'mediacontact'].drop('scr_of_edu', axis=1)data_feature_with_scr_of_edu = data.ix[:, :'mediacontact'].drop('edu_ave', axis=1)data_classes = data.ix[:, 'emo_cat':]12# dtree = tree.DecisionTreeClassifier(min_samples_leaf=500)# cross_val_score(dtree,data_feature_with_edu_ave, data_classes['difficulties_cat'], cv=10)array([ 0.64356436, 0.64356436, 0.64391855, 0.64391855, 0.64407713, 0.64407713, 0.64407713, 0.64407713, 0.64407713, 0.64407713]) difficulties_cat12345678910111213141516dtree_with_edu_ave = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_edu_ave = dtree_with_edu_ave.fit(data_feature_with_edu_ave, data_classes['difficulties_cat'])pd.DataFrame(dtree_with_edu_ave.feature_importances_, columns = ["Imp"], index = data_feature_with_edu_ave.columns).sort_values(by='Imp', ascending = False)dtree_with_scr_of_edu = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_scr_of_edu = dtree_with_scr_of_edu.fit(data_feature_with_scr_of_edu, data_classes['difficulties_cat'])pd.DataFrame(dtree_with_scr_of_edu.feature_importances_, columns = ["Imp"], index = data_feature_with_scr_of_edu.columns).sort_values(by='Imp', ascending = False)# dtree_with_edu_ave_diff.pngwith open('dtree_with_edu_ave_diff.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_edu_ave, out_file=dot_file, feature_names=data_feature_with_edu_ave.columns)# dtree_with_scr_of_edu_diff.pngwith open('dtree_with_scr_of_edu_diff.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_scr_of_edu, out_file=dot_file, feature_names=data_feature_with_scr_of_edu.columns)Impscr_ave0.553782medu_newcat0.217218age_m0.085820income_newcat0.048912edu_ave0.029740female0.026161onlychild0.021336mediacontact0.017030divorce0.000000scr_h_cat0.000000mediacoview0.000000Impscr_ave0.525587medu_newcat0.213067age_m0.084708scr_of_edu0.080575mediacontact0.029232female0.025661onlychild0.020929income_newcat0.020240divorce0.000000scr_h_cat0.000000mediacoview0.000000emo_cat12345678910111213141516dtree_with_edu_ave = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_edu_ave = dtree_with_edu_ave.fit(data_feature_with_edu_ave, data_classes['emo_cat'])pd.DataFrame(dtree_with_edu_ave.feature_importances_, columns = ["Imp"], index = data_feature_with_edu_ave.columns).sort_values(by='Imp', ascending = False)dtree_with_scr_of_edu = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_scr_of_edu = dtree_with_scr_of_edu.fit(data_feature_with_scr_of_edu, data_classes['emo_cat'])pd.DataFrame(dtree_with_scr_of_edu.feature_importances_, columns = ["Imp"], index = data_feature_with_scr_of_edu.columns).sort_values(by='Imp', ascending = False)# dtree_with_edu_ave_emo.pngwith open('dtree_with_edu_ave_emo.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_edu_ave, out_file=dot_file, feature_names=data_feature_with_edu_ave.columns)# dtree_with_scr_of_edu_emo.pngwith open('dtree_with_scr_of_edu_emo.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_scr_of_edu, out_file=dot_file, feature_names=data_feature_with_scr_of_edu.columns)Impscr_ave0.521694medu_newcat0.159798income_newcat0.147978edu_ave0.083233age_m0.040750female0.023781mediacontact0.019127mediacoview0.003639onlychild0.000000divorce0.000000scr_h_cat0.000000Impscr_ave0.520711income_newcat0.155111medu_newcat0.146762scr_of_edu0.115745age_m0.023767female0.021924mediacontact0.011410mediacoview0.004571onlychild0.000000divorce0.000000scr_h_cat0.000000con_cat12345678910111213141516dtree_with_edu_ave = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_edu_ave = dtree_with_edu_ave.fit(data_feature_with_edu_ave, data_classes['con_cat'])pd.DataFrame(dtree_with_edu_ave.feature_importances_, columns = ["Imp"], index = data_feature_with_edu_ave.columns).sort_values(by='Imp', ascending = False)dtree_with_scr_of_edu = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_scr_of_edu = dtree_with_scr_of_edu.fit(data_feature_with_scr_of_edu, data_classes['con_cat'])pd.DataFrame(dtree_with_scr_of_edu.feature_importances_, columns = ["Imp"], index = data_feature_with_scr_of_edu.columns).sort_values(by='Imp', ascending = False)# dtree_with_edu_ave_con.pngwith open('dtree_with_edu_ave_con.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_edu_ave, out_file=dot_file, feature_names=data_feature_with_edu_ave.columns)# dtree_with_scr_of_edu_con.pngwith open('dtree_with_scr_of_edu_con.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_scr_of_edu, out_file=dot_file, feature_names=data_feature_with_scr_of_edu.columns)Impscr_ave0.562325medu_newcat0.098819mediacontact0.095089edu_ave0.077572female0.064213income_newcat0.056334age_m0.023696onlychild0.013513mediacoview0.008440divorce0.000000scr_h_cat0.000000Impscr_ave0.511282scr_of_edu0.110155medu_newcat0.097473mediacontact0.093793female0.082843income_newcat0.055566age_m0.035552onlychild0.013335divorce0.000000scr_h_cat0.000000mediacoview0.000000hyp_cat12345678910111213141516dtree_with_edu_ave = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_edu_ave = dtree_with_edu_ave.fit(data_feature_with_edu_ave, data_classes['hyp_cat'])pd.DataFrame(dtree_with_edu_ave.feature_importances_, columns = ["Imp"], index = data_feature_with_edu_ave.columns).sort_values(by='Imp', ascending = False)dtree_with_scr_of_edu = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_scr_of_edu = dtree_with_scr_of_edu.fit(data_feature_with_scr_of_edu, data_classes['hyp_cat'])pd.DataFrame(dtree_with_scr_of_edu.feature_importances_, columns = ["Imp"], index = data_feature_with_scr_of_edu.columns).sort_values(by='Imp', ascending = False)# dtree_with_edu_ave_hyp.pngwith open('dtree_with_edu_ave_hyp.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_edu_ave, out_file=dot_file, feature_names=data_feature_with_edu_ave.columns)# dtree_with_scr_of_edu_hyp.pngwith open('dtree_with_scr_of_edu_hyp.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_scr_of_edu, out_file=dot_file, feature_names=data_feature_with_scr_of_edu.columns)Impmedu_newcat0.343448scr_ave0.265652onlychild0.165487edu_ave0.076194income_newcat0.054466age_m0.046774mediacontact0.020992mediacoview0.015532female0.011454divorce0.000000scr_h_cat0.000000Impmedu_newcat0.335192scr_ave0.257218onlychild0.161509scr_of_edu0.105471age_m0.065618income_newcat0.033129mediacontact0.022542mediacoview0.012901female0.006421divorce0.000000scr_h_cat0.000000pee_cat1234567891011121314151617dtree_with_edu_ave = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_edu_ave = dtree_with_edu_ave.fit(data_feature_with_edu_ave, data_classes['pee_cat'])pd.DataFrame(dtree_with_edu_ave.feature_importances_, columns = ["Imp"], index = data_feature_with_edu_ave.columns).sort_values(by='Imp', ascending = False)dtree_with_scr_of_edu = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_scr_of_edu = dtree_with_scr_of_edu.fit(data_feature_with_scr_of_edu, data_classes['pee_cat'])pd.DataFrame(dtree_with_scr_of_edu.feature_importances_, columns = ["Imp"], index = data_feature_with_scr_of_edu.columns).sort_values(by='Imp', ascending = False)# dtree_with_edu_ave_pee.pngwith open('dtree_with_edu_ave_pee.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_edu_ave, out_file=dot_file, feature_names=data_feature_with_edu_ave.columns)# dtree_with_scr_of_edu_pee.pngwith open('dtree_with_scr_of_edu_pee.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_scr_of_edu, out_file=dot_file, feature_names=data_feature_with_scr_of_edu.columns)Impscr_ave0.441246income_newcat0.210646female0.152568age_m0.151888medu_newcat0.033530mediacoview0.009625edu_ave0.000498onlychild0.000000divorce0.000000scr_h_cat0.000000mediacontact0.000000Impscr_ave0.430946income_newcat0.200188age_m0.151286female0.139104medu_newcat0.033289scr_of_edu0.033259mediacoview0.011927onlychild0.000000divorce0.000000scr_h_cat0.000000mediacontact0.000000pro_cat12345678910111213141516dtree_with_edu_ave = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_edu_ave = dtree_with_edu_ave.fit(data_feature_with_edu_ave, data_classes['pro_cat'])pd.DataFrame(dtree_with_edu_ave.feature_importances_, columns = ["Imp"], index = data_feature_with_edu_ave.columns).sort_values(by='Imp', ascending = False)dtree_with_scr_of_edu = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_with_scr_of_edu = dtree_with_scr_of_edu.fit(data_feature_with_scr_of_edu, data_classes['pro_cat'])pd.DataFrame(dtree_with_scr_of_edu.feature_importances_, columns = ["Imp"], index = data_feature_with_scr_of_edu.columns).sort_values(by='Imp', ascending = False)# dtree_with_edu_ave_pro.pngwith open('dtree_with_edu_ave_pro.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_edu_ave, out_file=dot_file, feature_names=data_feature_with_edu_ave.columns)# dtree_with_scr_of_edu_pro.pngwith open('dtree_with_scr_of_edu_pro.dot', 'w') as dot_file: tree.export_graphviz(dtree_with_scr_of_edu, out_file=dot_file, feature_names=data_feature_with_scr_of_edu.columns)Impfemale0.295389scr_ave0.252091mediacontact0.145010age_m0.137453income_newcat0.085421edu_ave0.062697medu_newcat0.021938onlychild0.000000divorce0.000000scr_h_cat0.000000mediacoview0.000000Impfemale0.299316scr_ave0.204496mediacontact0.131972age_m0.125169scr_of_edu0.111909income_newcat0.080072medu_newcat0.047066onlychild0.000000divorce0.000000scr_h_cat0.000000mediacoview0.000000Convert continuous variables to categorical variables1234data_category = data.copy()for column in data_category.columns: if column in float_columns: data_category[column] = pd.cut(data_category[column], 10, labels=np.arange(10))123data_cate_feature_with_edu_ave = data_category.ix[:, :'mediacontact'].drop('scr_of_edu', axis=1)data_cate_feature_with_scr_of_edu = data_category.ix[:, :'mediacontact'].drop('edu_ave', axis=1)data_cate_classes = data.ix[:, 'emo_cat':]12dtree_cate = tree.DecisionTreeClassifier(min_samples_leaf=50)cross_val_score(dtree_cate,data_cate_feature_with_edu_ave, data_cate_classes['difficulties_cat'], cv=10).sum() / 100.63948514409153423 12345678910111213141516dtree_cate_with_edu_ave = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_cate_with_edu_ave = dtree_with_edu_ave.fit(data_cate_feature_with_edu_ave, data_cate_classes['difficulties_cat'])pd.DataFrame(dtree_cate_with_edu_ave.feature_importances_, columns = ["Imp"], index = data_cate_feature_with_edu_ave.columns).sort_values(by='Imp', ascending = False)dtree_cate_with_scr_of_edu = tree.DecisionTreeClassifier(min_samples_leaf=500)dtree_cate_with_scr_of_edu = dtree_cate_with_scr_of_edu.fit(data_cate_feature_with_scr_of_edu, data_cate_classes['difficulties_cat'])pd.DataFrame(dtree_cate_with_scr_of_edu.feature_importances_, columns = ["Imp"], index = data_cate_feature_with_scr_of_edu.columns).sort_values(by='Imp', ascending = False)# dtree_cate_with_edu_ave_diff.pngwith open('dtree_cate_with_edu_ave_diff.dot', 'w') as dot_file: tree.export_graphviz(dtree_cate_with_edu_ave, out_file=dot_file, feature_names=data_cate_feature_with_edu_ave.columns)# dtree_cate_with_scr_of_edu_diff.pngwith open('dtree_cate_with_scr_of_edu_diff.dot', 'w') as dot_file: tree.export_graphviz(dtree_cate_with_scr_of_edu, out_file=dot_file, feature_names=data_cate_feature_with_scr_of_edu.columns)Impscr_h_cat0.528976medu_newcat0.221779age_m0.092168income_newcat0.057032onlychild0.034724mediacontact0.027193female0.021036scr_ave0.011653mediacoview0.005439divorce0.000000edu_ave0.000000Impscr_h_cat0.507678medu_newcat0.215210age_m0.089438scr_of_edu0.042832mediacontact0.041463income_newcat0.035742onlychild0.033695female0.020413scr_ave0.013527divorce0.000000mediacoview0.000000]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Get Pois uses God-map apis]]></title>
      <url>%2F2017%2F02%2F21%2FGet-Pois-uses-God-map-apis%2F</url>
      <content type="text"><![CDATA[12345Excelhouse: location locationmap api 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132import osimport xlrdimport pickleimport requestsdef ReadHousesInfoFromExcel( file_name='houses_nadrop.xls', sheet_name=''): """ Read the houses detail information from the excel-type file. Arguments: file_name: the name of the excel-type file. sheet_name: the name of the sheet of the excel file. Returns: houses: A dict that contains the detail information of each house. """ HOUSES_FILE_NAME = 'houses.pkl' HOUSES_DETAIL_TAB = ['name', 'address', 'property_category', 'area', 'avg_price', 'location', 'property_costs', 'volume_rate', 'green_rate'] houses = [] if (os.path.isfile(HOUSES_FILE_NAME)): with open(HOUSES_FILE_NAME, 'rb') as f: houses = pickle.load(f) else: workBook = xlrd.open_workbook(file_name) bookSheet = workBook.sheet_by_name(sheet_name) # read from second row because of the first row has tabs for row in range(1, bookSheet.nrows): house = &#123;&#125; for col in range(bookSheet.ncols): cel = bookSheet.cell(row, col) try: val = cel.value except: pass val = str(val) house[HOUSES_DETAIL_TAB[col]] = val houses.append(house) with open(HOUSES_FILE_NAME, 'wb') as f: pickle.dump(houses, f) return housesdef Geocode(location, poi_type): """ A tool that call the God-Map api. Arguments: location: The location of house. poi_type: The poi type. Returns: answer: The JSON-type data that contains pois infomation. """ location = str(location).strip() parameters = &#123;'location': location, 'key': 'e798a5bfb344a09977b79552ae415974', 'types': poi_type, 'offset': 10, 'page': 1, 'extensions': 'base'&#125; base = 'http://restapi.amap.com/v3/place/around' try: response = requests.get(base, parameters) answer = response.json() except Exception as e: print('error!', e) answer = 'null' finally: pass return answerdef GetPOI(houses): """ Get the pois information of the houses according to the location. Arguments: houses: The house detail information. Returns: houses_with_pois: The house detail information that contains the pois information. """ POI_TYPE_LAB = ['subway_station', 'bus_station', 'parking_lot', 'primary_school', 'secondary_school', 'university', 'mall', 'park'] POI_TYPE_CODE = ['150500', '150700', '150904', '141203', '141202', '141201', '060100', '110101'] KEEP_INFO_LAB = ['name', 'location', 'distance'] NO_INFO_NOW = '-' SIZE = len(houses) houses_with_pois = houses.copy() count = 0 for house in houses_with_pois: count = count + 1 if count % 100 == 0: print(count, '', SIZE) house['pois'] = &#123;&#125; for poi_type_index in range(len(POI_TYPE_LAB)): poi_info_json = Geocode(house['location'], POI_TYPE_CODE[poi_type_index]) if poi_info_json == 'null' or poi_info_json['pois'] is None: house['pois'][POI_TYPE_LAB[poi_type_index]] = NO_INFO_NOW else: house['pois'][POI_TYPE_LAB[poi_type_index]] = [] for poi in poi_info_json['pois']: pois_without_useless = &#123;&#125; for key in poi.keys(): if key in KEEP_INFO_LAB: pois_without_useless[key] = poi[key] house['pois'][POI_TYPE_LAB[poi_type_index]].append( pois_without_useless) # return houses_with_pois return houses_with_poisif __name__ == '__main__': houses = ReadHousesInfoFromExcel() # answer = Geocode(houses[0]['location'], '150905') houses_with_pois = GetPOI(houses)parameterslocationforpickleExcelstr]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python data analysis-Learning note-Ch02]]></title>
      <url>%2F2017%2F02%2F19%2FPython%20data%20analysis-Learning%20notes-ch02%2F</url>
      <content type="text"><![CDATA[PythonJSON123456'&#123; "a": "Mozilla\\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\\/535.11 (KHTML, like Gecko)Chrome\\/17.0.963.78 Safari\\/535.11", "c": "US", "nk": 1, "tz": "America\\/New_York", "gr":"MA", "g": "A6qOVH", "h": "wfLQtf", "l": "orofrog", "al": "en-US,en;q=0.8", "hh": "1.usa.gov","r": "http:\\/\\/www.facebook.com\\/l\\/7AQEFzjSi\\/1.usa.gov\\/wfLQtf", "u":"http:\\/\\/www.ncbi.nlm.nih.gov\\/pubmed\\/22415991", "t": 1331923247, "hc": 1331822918,"cy": "Danvers", "ll": [ 42.576698, -70.954903 ] &#125;\n'123import jsonpath = 'ch02/usagov_bitly_data2012-03-16-1331923249.txt'records = [json.loads(line) for line in open(path)]123456789101112131415161718records[0]-----------------------------------&#123;'a': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.78 Safari/535.11', 'al': 'en-US,en;q=0.8', 'c': 'US', 'cy': 'Danvers', 'g': 'A6qOVH', 'gr': 'MA', 'h': 'wfLQtf', 'hc': 1331822918, 'hh': '1.usa.gov', 'l': 'orofrog', 'll': [42.576698, -70.954903], 'nk': 1, 'r': 'http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf', 't': 1331923247, 'tz': 'America/New_York', 'u': 'http://www.ncbi.nlm.nih.gov/pubmed/22415991'&#125;pure python vs. pandas1time_zones = [rec['tz'] for rec in records if 'tz' in rec]123456789101112time_zones[:10]-----------------------------------['America/New_York', 'America/Denver', 'America/New_York', 'America/Sao_Paulo', 'America/New_York', 'America/New_York', 'Europe/Warsaw', '', '', '']python12345678def get_counts(sequence): counts = &#123;&#125; for x in sequence: if x in counts: counts[x] += 1 else: counts[x] = 1 return counts1234567from collections import defaultdictdef get_counts2(sequence): counts = defaultdict(int) # values will initialize to 0 for x in sequence: counts[x] += 1 return counts1234def top_counts(count_dict, n=10): value_key_pairs = [(count, tz) for tz, count in count_dict.items()] value_key_pairs.sort() return value_key_pairs[-n:]123456789101112top_counts(counts)--------------------------------------[(33, 'America/Sao_Paulo'), (35, 'Europe/Madrid'), (36, 'Pacific/Honolulu'), (37, 'Asia/Tokyo'), (74, 'Europe/London'), (191, 'America/Denver'), (382, 'America/Los_Angeles'), (400, 'America/Chicago'), (521, ''), (1251, 'America/New_York')]python1from collections import Counter1counts = Counter(time_zones)123456789101112counts.most_common(10)--------------------------------[('America/New_York', 1251), ('', 521), ('America/Chicago', 400), ('America/Los_Angeles', 382), ('America/Denver', 191), ('Europe/London', 74), ('Asia/Tokyo', 37), ('Pacific/Honolulu', 36), ('Europe/Madrid', 35), ('America/Sao_Paulo', 33)]pandaspandasDataFrame 12345from pandas import DataFrame, Seriesimport pandas as pdframe = DataFrame(records)frame12345678910111213frame['tz'][:10]-------------------------------0 America/New_York1 America/Denver2 America/New_York3 America/Sao_Paulo4 America/New_York5 America/New_York6 Europe/Warsaw7 8 9 Name: tz, dtype: object1234567891011121314tz_counts = frame['tz'].value_counts()tz_counts[:10]--------------------------------------------------America/New_York 1251 521America/Chicago 400America/Los_Angeles 382America/Denver 191Europe/London 74Asia/Tokyo 37Pacific/Honolulu 36Europe/Madrid 35America/Sao_Paulo 33Name: tz, dtype: int6412345678910111213141516clean_tz = frame['tz'].fillna('Missing')clean_tz[clean_tz == ''] = 'Unknown'tz_counts = clean_tz.value_counts()tz_counts[:10]----------------------------------------------America/New_York 1251Unknown 521America/Chicago 400America/Los_Angeles 382America/Denver 191Missing 120Europe/London 74Asia/Tokyo 37Pacific/Honolulu 36Europe/Madrid 35Name: tz, dtype: int6412plt.figure(figsize=(10, 4))tz_counts[:10].plot(kind='barh', rot=0)SeriesDataFrame123456789results = Series([x.split()[0] for x in frame.a.dropna()])results[:5]---------------------------------------------------0 Mozilla/5.01 GoogleMaps/RochesterNY2 Mozilla/4.03 Mozilla/5.04 Mozilla/5.0dtype: object1234567891011results.value_counts()[:8]-----------------------------------------Mozilla/5.0 2594Mozilla/4.0 601GoogleMaps/RochesterNY 121Opera/9.80 34TEST_INTERNET_AGENT 24GoogleProducer 21Mozilla/6.0 5BlackBerry8520/5.0.0.681 4dtype: int64WindowsNon-Windows1cframe = frame[frame.a.notnull()]123456operating_system = np.where(cframe['a'].str.contains('Windows'), 'Windows', 'Not Windows')operating_system[:5]-----------------------------------------------------------------array(['Windows', 'Not Windows', 'Windows', 'Not Windows', 'Windows'], dtype='&lt;U11')1by_tz_os = cframe.groupby(['tz', operating_system])by_tz_os1by_tz_os.size()unstack() 12345678910111213141516# Use to sort in ascending orderindexer = agg_counts.sum(1).argsort()indexer[:10]------------------------------------------------tz 24Africa/Cairo 20Africa/Casablanca 21Africa/Ceuta 92Africa/Johannesburg 87Africa/Lusaka 53America/Anchorage 54America/Argentina/Buenos_Aires 57America/Argentina/Cordoba 26America/Argentina/Mendoza 55dtype: int6412count_subset = agg_counts.take(indexer)[-10:]count_subset1count_subset.plot(kind='barh', stacked=True)12normed_subset = count_subset.div(count_subset.sum(1), axis=0)normed_subset.plot(kind='barh', stacked=True)123456789101112131415import pandas as pdimport osencoding = 'latin1'upath = os.path.expanduser('ch02/movielens/users.dat')rpath = os.path.expanduser('ch02/movielens/ratings.dat')mpath = os.path.expanduser('ch02/movielens/movies.dat')unames = ['user_id', 'gender', 'age', 'occupation', 'zip']rnames = ['user_id', 'movie_id', 'rating', 'timestamp']mnames = ['movie_id', 'title', 'genres']users = pd.read_csv(upath, sep='::', header=None, names=unames, encoding=encoding)ratings = pd.read_csv(rpath, sep='::', header=None, names=rnames, encoding=encoding)movies = pd.read_csv(mpath, sep='::', header=None, names=mnames, encoding=encoding)1users[:5]1ratings[:5]1movies[:5]12data = pd.merge(pd.merge(ratings, users), movies)data12345678910111213data.ix[0]--------------------------------------------user_id 1movie_id 1193rating 5timestamp 978300760gender Fage 1occupation 10zip 48067title One Flew Over the Cuckoo's Nest (1975)genres DramaName: 0, dtype: object123mean_ratings = data.pivot_table('rating', index='title', columns='gender', aggfunc='mean')mean_ratings[:5]2501ratings_by_title = data.groupby('title').size()123456789ratings_by_title[:5]-----------------------------------------title$1,000,000 Duck (1971) 37'Night Mother (1986) 70'Til There Was You (1997) 52'burbs, The (1989) 303...And Justice for All (1979) 199dtype: int641active_titles = ratings_by_title.index[ratings_by_title &gt;= 250]12345678active_titles[:10]-----------------------------------------Index([''burbs, The (1989)', '10 Things I Hate About You (1999)', '101 Dalmatians (1961)', '101 Dalmatians (1996)', '12 Angry Men (1957)', '13th Warrior, The (1999)', '2 Days in the Valley (1996)', '20,000 Leagues Under the Sea (1954)', '2001: A Space Odyssey (1968)', '2010 (1984)'], dtype='object', name='title')ix12mean_ratings = mean_ratings.ix[active_titles]mean_ratings12top_female_ratings = mean_ratings.sort_values(by='F', ascending=False)top_female_ratings[:10]US Baby Names 1880-2010123import pandas as pdnames1880 = pd.read_csv('ch02/names/yob1880.txt', names=['name', 'sex', 'births'])names1880123456789101112131415# 2010 is the last available year right nowyears = range(1880, 2011)pieces = []columns = ['name', 'sex', 'births']for year in years: path = 'ch02/names/yob%d.txt' % year frame = pd.read_csv(path, names=columns) frame['year'] = year pieces.append(frame)# Concatenate everything into a single DataFramenames = pd.concat(pieces, ignore_index=True)12total_births = names.pivot_table('births', index='year', columns='sex', aggfunc=sum)1total_births.tail()1234567def add_prop(group): # Integer division floors births = group.births.astype(float) group['prop'] = births / births.sum() return groupnames = names.groupby(['year', 'sex']).apply(add_prop)1names123np.allclose(names.groupby(['year', 'sex']).prop.sum(), 1)--------------------------------------------Trueyear/sex10001234def get_top1000(group): return group.sort_values(by='births', ascending=False)[:1000]grouped = names.groupby(['year', 'sex'])top1000 = grouped.apply(get_top1000)numpy1top1000.index = np.arange(len(top1000))Analyzing naming trends12boys = top1000[top1000.sex == 'M']girls = top1000[top1000.sex == 'F']123total_births = top1000.pivot_table('births', index='year', columns='name', aggfunc=sum)total_births123subset = total_births[['John', 'Harry', 'Mary', 'Marilyn']]subset.plot(subplots=True, figsize=(12, 10), grid=False, title="Number of births per year")Measuring the increase in naming diversity10001234table = top1000.pivot_table('prop', index='year', columns='sex', aggfunc=sum)table.plot(title='Sum of table1000.prop by year and sex', yticks=np.linspace(0, 1.2, 13), xticks=range(1880, 2020, 10))50%50%20101df = boys[boys.year == 2010]1234567891011121314prop_cumsum = df.sort_index(by='prop', ascending=False).prop.cumsum()prop_cumsum[:10]--------------------------------------------------260877 0.011523260878 0.020934260879 0.029959260880 0.038930260881 0.047817260882 0.056579260883 0.065155260884 0.073414260885 0.081528260886 0.089621Name: prop, dtype: float641160117123prop_cumsum.values.searchsorted(0.5)---------------------------------------------------116190012345df = boys[boys.year == 1900]in1900 = df.sort_index(by='prop', ascending=False).prop.cumsum()in1900.values.searchsorted(0.5) + 1---------------------------------------------------25123456def get_quantile_count(group, q=0.5): group = group.sort_values(by='prop', ascending=False) return group.prop.cumsum().values.searchsorted(q) + 1diversity = top1000.groupby(['year', 'sex']).apply(get_quantile_count)diversity = diversity.unstack('sex')diversity.head()1diversity.plot(title="Number of popular names in top 50%")The Last letter Revolution1234567# extract last letter from name columnget_last_letter = lambda x: x[-1]last_letters = names.name.map(get_last_letter)last_letters.name = 'last_letter'table = names.pivot_table('births', index=last_letters, columns=['sex', 'year'], aggfunc=sum)12subtable = table.reindex(columns=[1910, 1960, 2010], level='year')subtable.head()12345678910subtable.sum()-------------------------------------sex yearF 1910 396416.0 1960 2022062.0 2010 1759010.0M 1910 194198.0 1960 2132588.0 2010 1898382.0dtype: float641letter_prop = subtable / subtable.sum().astype(float)123456import matplotlib.pyplot as pltfig, axes = plt.subplots(2, 1, figsize=(10, 8))letter_prop['M'].plot(kind='bar', rot=0, ax=axes[0], title='Male')letter_prop['F'].plot(kind='bar', rot=0, ax=axes[1], title='Female', legend=False)12letter_prop = table / table.sum().astype(float)dny_ts = letter_prop.ix[['d', 'n', 'y'], 'M'].T1dny_ts.plot()Boy names that became girl names (and vice versa)lesl123456all_names = top1000.name.unique()mask = np.array(['lesl' in x.lower() for x in all_names])lesley_like = all_names[mask]lesley_like----------------------------------------------array(['Leslie', 'Lesley', 'Leslee', 'Lesli', 'Lesly'], dtype=object)12345678910filtered = top1000[top1000.name.isin(lesley_like)]filtered.groupby('name').births.sum()----------------------------------------------nameLeslee 1082Lesley 35022Lesli 929Leslie 370429Lesly 10067Name: births, dtype: int641234table = filtered.pivot_table('births', index='year', columns='sex', aggfunc='sum')table = table.div(table.sum(1), axis=0)table.tail()1table.plot(style=&#123;'M': 'k-', 'F': 'k--'&#125;)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spider the house infomation and save to excel file]]></title>
      <url>%2F2017%2F02%2F18%2FSpider-the-house-infomation-and-save-to-excel-file%2F</url>
      <content type="text"><![CDATA[http://sh.fang.com/1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150""" &lt;A spider to crawl the house information.&gt; Copyright (C) &lt;2017&gt; Li W.H., Duan X This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;. """class HouseSpider(scrapy.Spider): name = "house" head = "http://esf.sh.fang.com" allowed_domains = ["sh.fang.com"] start_urls = [ "http://esf.sh.fang.com/housing/" ] # url area_map = &#123;25: 'pudong', 18: 'minhang', 19: 'xuhui', 30: 'baoshan', 28: 'putuo', 20: 'changning', 26: 'yangpu', 586: 'songjiang', 29: 'jiading', 23: 'hongkou', 27: 'zhabei', 21: 'jingan', 24: 'huangpu', 22: 'luwan', 31: 'qingpu', 32: 'fengxian', 35: 'jinshan', 996: 'chongming'&#125; estate_to_area_map = &#123;&#125; seperator = '=\n' def __init__(self): for key, value in self.area_map.items(): self.estate_to_area_map[key] = [] # print(self.estate_to_area_map) def parse(self, response): #  area_lis = response.xpath('//*[@id="houselist_B03_02"]/div[1]') for a in area_lis.xpath('./a'): # areas = items.AreaItem() # areas['name'] = a.xpath('text()').extract()[0] yield Request(self.head + a.xpath('@href').extract()[0], callback=self.parse_area) # print(a.xpath('text()').extract()[0]) def parse_area(self, response): # response area_index = str(response).split('/')[-2].split('_')[0] if area_index == '': return else: #  detail_str = 'xiangqing' estate_list = response.xpath('/html/body/div[4]/div[5]/div[4]') for a in estate_list.xpath('.//a[@class="plotTit"]'): estate_url = a.xpath('@href').extract()[0] if estate_url.find('esf') != -1: estate_url = estate_url.replace('esf', detail_str) else: estate_url = estate_url + detail_str if estate_url.find('http') != -1: # print(estate_url) self.estate_to_area_map[int(area_index)].append(estate_url) # print(len(self.estate_to_area_map[int(area_index)])) next_page = response.xpath('//*[@id="PageControl1_hlk_next"]') if len(next_page) != 0: yield Request(self.head + next_page.xpath('@href').extract()[0], callback=self.parse_area) else: # print(len(self.estate_to_area_map[int(area_index)])) for url in self.estate_to_area_map[int(area_index)]: request = Request(url, callback=self.parse_house, dont_filter=True) request.meta['index'] = int(area_index) yield request def parse_house(self, response): flag = 0 area_index = response.meta['index'] area_name = self.area_map[area_index] filename = area_name + '.txt' # print(response.xpath('/html')) #  house_name = response.xpath( '/html/body/div[4]/div[2]/div[2]/h1/a/text()') if len(house_name) == 0: # house_name = response.xpath( # '/html/body/div[1]/div[3]/div[2]/h1/a/text()') # flag = 1 return house_name = house_name.extract()[0] #  house_name = re.sub(r'', '', house_name) result_str = '' + house_name + '\n' if flag == 0: avg_price_xpath = response.xpath( '/html/body/div[4]/div[4]/div[1]/div[1]/dl[1]/dd/span/text()') avg_price = avg_price_xpath.extract()[0] result_str = result_str + '' + avg_price + '\n' detail_block_list = response.xpath( '/html/body/div[4]/div[4]/div[1]') for headline in detail_block_list.xpath('.//h3'): head_str = headline.xpath('./text()').extract()[0] if head_str == '': result_str = result_str + \ '' + \ head_str + '\n' for item in headline.xpath( '../../div[@class="inforwrap clearfix"]/dl/dd'): if len(item.xpath('./strong/text()')) != 0: if len(item.xpath('./text()')) != 0: result_str = result_str + \ item.xpath( './strong/text()').extract()[0] result_str = result_str + \ item.xpath('./text()').extract()[0] + '\n' # print(result_str) # elif head_str == '': # result_str = result_str + \ # '' + \ # head_str + '\n' # tempstr = headline.xpath( # '../../div[@class="inforwrap clearfix"]/dl/dt/text()').extract()[0] # result_str = result_str + tempstr + '\n' # # print(result_str) # elif head_str == '': # result_str = result_str + \ # '' + \ # head_str + '\n' # for item in headline.xpath( # '../../div[@class="inforwrap clearfix"]/dl/dt'): # result_str = result_str + \ # item.xpath('./text()').extract()[0] + '\n' # # print(result_str) elif head_str == '': result_str = result_str + \ '' + \ head_str + '\n' for item in headline.xpath( '../../div[@class="inforwrap clearfix"]/dl/dd'): result_str = result_str + \ item.xpath('./a/text()').extract()[0] + '\n' result_str = result_str + self.seperator # print(result_str) with open(filename, 'a', errors='ignore') as f: f.write(result_str)2123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136""" &lt;A formatter&gt; Copyright (C) &lt;2017&gt; Li W.H., Duan X This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;."""def GetDataFileList(path='.'): """ Get the houses file list. Arguments: path: Dir path. Returns: file_list: the list of data file that find houses data. """ file_list = [x for x in os.listdir(path) if os.path.isfile( x) and os.path.splitext(x)[1] == '.txt'] return file_listdef Parse(file_list): """ Parse the txt file that find houses data. Extract some import infomation such as house name, avarage price, address and so on. Arguments: file_list: the list of data file that find houses data. Returns: houses_dict_list: the list that each item find the detail dict of each house. """ HOUSE_NAME = '' HOUSE_NAME_SPLITOR = '' HOUSE_ADDRESS = '' HOUSE_ADDRESS_SPLITOR = '' HOUSE_AVG_PRICE = '' HOUSE_AVG_PRICE_SPLITOR = '' AREA_OF_HOUSE_BELONGS_TO = '' AREA_OF_HOUSE_BELONGS_TO_SPLITOR_1 = '' AREA_OF_HOUSE_BELONGS_TO_SPLITOR_2 = ' ' PROPERTY_CATEGORY = '' PROPERTY_CATEGORY_SPLITOR = '' GREEN_RATE = '  ' GREEN_RATE_SPLITOR = '' VOLUME_RATE = '  ' VOLUME_RATE_SPLITOR = '' PROPERTY_COSTS = '  ' PROPERTY_COSTS_SPLITOR = '' NO_INFO_NOW = '' DETAIL_LIST = [HOUSE_NAME, HOUSE_AVG_PRICE, HOUSE_ADDRESS, AREA_OF_HOUSE_BELONGS_TO, PROPERTY_CATEGORY, GREEN_RATE, VOLUME_RATE, PROPERTY_COSTS] houses_dict_list = [] for file_name in file_list: raw_houses_string = '' # read all lines as a string with open(file_name, 'r', errors='ignore') as f: for line in f.readlines(): raw_houses_string += line # split the string to the houses raw info list raw_houses_list = raw_houses_string.split('=\n') raw_houses_details_list = [] for raw_house in raw_houses_list: # format house raw info to lines raw_houses_details = raw_house.split('\n')[:-1] if len(raw_houses_details) == 0: continue # combine the all formated house raw info to a list raw_houses_details_list.append(raw_houses_details) for raw_house_details in raw_houses_details_list: house_details_dict = &#123;&#125; for raw_detail in raw_house_details: # search house name if re.search(HOUSE_NAME, raw_detail): house_details_dict[HOUSE_NAME] = raw_detail.split( HOUSE_NAME_SPLITOR)[-1] # search house avarage price elif re.search(HOUSE_AVG_PRICE, raw_detail): # print(raw_detail) house_details_dict[HOUSE_AVG_PRICE] = raw_detail.split( HOUSE_AVG_PRICE_SPLITOR)[-1] # search house address elif re.search(HOUSE_ADDRESS, raw_detail): house_details_dict[HOUSE_ADDRESS] = raw_detail.split( HOUSE_ADDRESS_SPLITOR)[-1] # search the area of house belongs to elif re.search(AREA_OF_HOUSE_BELONGS_TO, raw_detail): temp_detail_value = raw_detail.split( AREA_OF_HOUSE_BELONGS_TO_SPLITOR_1)[-1] detail_value = temp_detail_value.split( AREA_OF_HOUSE_BELONGS_TO_SPLITOR_2)[0] house_details_dict[AREA_OF_HOUSE_BELONGS_TO] = detail_value # search the property category of house elif re.search(PROPERTY_CATEGORY, raw_detail): house_details_dict[PROPERTY_CATEGORY] = raw_detail.split( PROPERTY_CATEGORY_SPLITOR)[-1] # search the green rate elif re.search(GREEN_RATE, raw_detail): house_details_dict[GREEN_RATE] = raw_detail.split( GREEN_RATE_SPLITOR)[-1] # search the volume rate elif re.search(VOLUME_RATE, raw_detail): house_details_dict[VOLUME_RATE] = raw_detail.split( VOLUME_RATE_SPLITOR)[-1] # search the property costs elif re.search(PROPERTY_COSTS, raw_detail): house_details_dict[PROPERTY_COSTS] = raw_detail.split( PROPERTY_COSTS_SPLITOR)[-1] # Judge if all details are contained. # If not, set to null. house_details_dict_keys = house_details_dict.keys() for detail_name in DETAIL_LIST: if detail_name not in house_details_dict_keys: house_details_dict[detail_name] = NO_INFO_NOW houses_dict_list.append(house_details_dict) return houses_dict_list3api123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100""" &lt;A toolto transfer position.&gt; Copyright (C) &lt;2017&gt; Li W.H., Duan X This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;."""def Geocode(address): """ A tool that call the God-Map api. Arguments: address: the address to transfer. Returns: location: the transfered location. """ CITY_NAME = '' parameters = &#123;'address': address, 'key': 'your key', 'city': CITY_NAME&#125; base = 'http://restapi.amap.com/v3/geocode/geo' try: response = requests.get(base, parameters) except Exception as e: print('error!', e) finally: pass answer = response.json() return answerdef GETGodMapLocation(houses): """ Get the location that corresponds to the house name. Use the God-Map api to get the corresponding location. Arguments: houses_dict_list: the houses info. Returns: houses_dict_list_contains_loc: the houses info that contains the location info. """ HOUSE_NAME = '' HOUSE_LOCATION = '' NO_INFO_NOW = '' houses_dict_list = houses.copy() error_count = 0 count = 0 size = len(houses) for house_dict in houses_dict_list: # Count count = count + 1 # Loading needs if count % 1000 == 0: print(count, '/', size) address = house_dict[HOUSE_NAME] answer = Geocode(address) # print(answer) # If find if len(answer['geocodes']) != 0: # print(address + "", answer['geocodes'][0]['location']) house_dict[HOUSE_LOCATION] = answer['geocodes'][0]['location'] else: # remaking the invalid address # print('address remaking...') if re.search(r'', address): re.sub(r'', '', address) else: address = address + '' # print('retransfering...') # transfer again answer = Geocode(address) if len(answer['geocodes']) != 0: # print(address + "", answer['geocodes'][0]['location']) house_dict[HOUSE_LOCATION] = answer['geocodes'][0]['location'] else: # print(address) error_count += 1 house_dict[HOUSE_LOCATION] = NO_INFO_NOW print('error counts: ', error_count) return houses_dict_list4excel1234567891011121314151617181920212223242526272829303132333435363738394041424344""" &lt;A tool to save the excel file.&gt; Copyright (C) &lt;2017&gt; Li W.H., Duan X This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.""" def Save2ExcelFile(houses): """ Save the python based list file to excel file. Arguments: houses: the houses list. """ houses_dict_list = houses.copy() house_list = [] # format the source data to fit the xlwt package keys = houses[0].keys() for key in keys: house = [] house.append(key) for house_dict in houses_dict_list: house.append(house_dict[key]) house_list.append(house) # return house_list xls = ExcelWrite.Workbook() sheet = xls.add_sheet('') for i in range(len(house_list)): for j in range(len(house_list[0])): sheet.write(j, i, house_list[i][j]) xls.save('houses.xls')]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[python_god_web_api]]></title>
      <url>%2F2017%2F02%2F17%2Fpython-god-web-api%2F</url>
      <content type="text"><![CDATA[http://lbs.amap.com/api/webservice/guide/api/search123456789101112131415161718#!/usr/bin/env python3#-*- coding:utf-8 -*-'''api'''import requestsdef geocode(address): parameters = &#123;'address': address, 'key': 'e798a5bfb344a09977b79552ae415974'&#125; base = 'http://restapi.amap.com/v3/geocode/geo' response = requests.get(base, parameters) answer = response.json() print(address + "", answer['geocodes'][0]['location'])if __name__=='__main__': #address = input(":") address = '' geocode(address)12345678910111213141516171819202122232425262728293031import xlrddef readXlsx(self, filename='CenterBottom2013.xlsx', sheetname='Sheet1'): rawData = [] if (os.path.isfile(self.fn_rawDat)): with open(self.fn_rawDat, 'rb') as f: self.rawDat = np.load(f) else: workBook = xlrd.open_workbook(filename) bookSheet = workBook.sheet_by_name(sheetname) #  for row in range(1, bookSheet.nrows): rowData = [] for col in range(bookSheet.ncols): cel = bookSheet.cell(row, col) try: val = cel.value except: pass if type(val) == float: val = float(val) else: val = str(val) rowData.append(val) rawData.append(rowData) self.rawDat = np.array(rawData) with open(self.fn_rawDat, 'wb') as f: np.save(f, self.rawDat) return self.rawDatRead Excel filesTransfer the address to locaion infoPut back]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Decision tree]]></title>
      <url>%2F2017%2F02%2F15%2FDecision-tree%2F</url>
      <content type="text"><![CDATA[ID31234567891011createbranch(): If so return ; Else    for  createBranch return ID3l(x_i) = -log_{2}p(x_i)$x_i$$p(x_i)$H = \sum_{i=1}^{n}p(x_i)l(x_i)=-\sum_{i=1}^{n}p(x_i)log_{2}p(x_i)IG(S|T) = H(S) - \sum_{value(T)} \frac{|S_v|}{|S|} H(S_v)$S$ $value(T) $ $T$$v$  $T$ $S_v$ $S$  $T$  $v$ $|S_v|$  $S_v$ $|S|$  $S$ 123456789101112131415161718192021222324252627from math import logdef CalcShannonEnt(data_set): """ Calculate the Shannon Entropy. Arguments: data_set: The object dataset. Returns: shannon_ent: The Shannon entropy of the object data set. """ # Initiation num_entries = len(data_set) label_counts = &#123;&#125; # Statistics the frequency of each class in the dataset for feat_vec in data_set: current_label = feat_vec[-1] if current_label not in label_counts.keys(): label_counts[current_label] = 0 label_counts[current_label] += 1 # Calculates the Shannon entropy shannon_ent = 0.0 for key in label_counts: prob = float(label_counts[key]) / num_entries shannon_ent -= prob * log(prob, 2) return shannon_entnaive123456789101112131415def CreateDataSet(): """ A naive data generation method. Returns: data_set: The data set excepts label info. labels: The data set only contains label info. """ data_set = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] labels = ['no surfacing', 'flippers'] return data_set, labelslabelsyesnolabelsdemo:123456789In [22]: import treesIn [23]: my_dat, labels = trees.CreateDataSet()In [24]: my_datOut[24]: [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]In [25]: trees.CalcShannonEnt(my_dat)Out[25]: 0.9709505944546686Gini impurityG = \sum_{i \ne j}p(x_i)p(x_j) = \sum_{i}p(x_i)\sum_{j \ne i}p(x_j) = \sum_{i}p(x_i)(1-p(x_i)) = \sum_{i}p(x_i) - \sum_{i}(p(x_i))^2 = 1 - \sum_{i}(p(x_i))^21234567891011121314151617181920212223242526def CalcGiniImpurity(data_set): """ Calculate the Gini impurity. Arguments: data_set: The object dataset. Returns: gini_impurity: The Gini impurity of the object data set. """ # Initiation num_entries = len(data_set) label_counts = &#123;&#125; # Statistics the frequency of each class in the dataset for feat_vec in data_set: current_label = feat_vec[-1] if current_label not in label_counts.keys(): label_counts[current_label] = 0 label_counts[current_label] += 1 # Calculates the Gini impurity gini_impurity = 0.0 for key in label_counts: prob = float(label_counts[key]) / num_entries gini_impurity += pow(prob, 2) gini_impurity = 1 - gini_impurity return gini_impuritydemo123456789In [4]: import treesIn [5]: my_dat, labels = trees.CreateDataSet()In [6]: my_datOut[6]: [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]In [7]: trees.CalcGiniImpurity(my_dat)Out[7]: 0.48M = 1 - \max_{i}(p(x_i))123456789101112131415161718192021222324def CalcMisClassifyImpurity(data_set): """ Calculate the misclassification impurity. Arguments: data_set: The object dataset. Returns: mis_classify_impurity: The misclassification impurity of the object data set. """ # Initiation num_entries = len(data_set) label_counts = &#123;&#125; # Statistics the frequency of each class in the dataset for feat_vec in data_set: current_label = feat_vec[-1] if current_label not in label_counts.keys(): label_counts[current_label] = 0 label_counts[current_label] += 1 # Calculates the misclassification impurity mis_classify_impurity = 0.0 max_prob = max(label_counts.values()) / num_entries mis_classify_impurity = 1 - max_prob return mis_classify_impuritydemo:12345678910In [25]: reload(trees)Out[25]: &lt;module 'trees' from 'C:\\Users\\Ewan\\Documents\\GitHub\\hexo\\public\\2017\\02\\15\\Decision-tree\\trees.py'&gt;In [26]: my_dat, labels = trees.CreateDataSet()In [27]: my_datOut[27]: [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]In [28]: trees.CalcMisClassifyImpurity(my_dat)Out[28]: 0.4[Ref: http://www.cse.msu.edu/~cse802/DecisionTrees.pdf]ID31234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556def SplitDataSet(data_set, axis, value): """ Split the data set according to the given axis and correspond value. Arguments: data_set: Object data set. axis: The split-feature index. value: The value of the split-feature. Returns: ret_data_set: The splited data set. """ ret_data_set = [] for feat_vec in data_set: if feat_vec[axis] == value: reduced_feat_vec = feat_vec[:axis] reduced_feat_vec.extend(feat_vec[axis + 1:]) ret_data_set.append(reduced_feat_vec) return ret_data_setdef ChooseBestFeatureToSplit(data_set): """ Choose the best feature to split. Arguments: data_set: Object data set. Returns: best_feature: The index of the feature to split. """ # Initiation # Because the range() method excepts the lastest number num_features = len(data_set[0]) - 1 base_entropy = CalcShannonEnt(data_set) best_info_gain = 0.0 best_feature = -1 for i in range(num_features): # Choose the i-th feature of all data feat_list = [example[i] for example in data_set] # Abandon the repeat feature value(s) unique_vals = set(feat_list) new_entropy = 0.0 # Calculates the Shannon entropy of the splited data set for value in unique_vals: sub_data_set = SplitDataSet(data_set, i, value) prob = len(sub_data_set) / len(data_set) new_entropy += prob * CalcShannonEnt(sub_data_set) # base_entropy is equal or greatter than new_entropy info_gain = base_entropy - new_entropy if info_gain &gt; best_info_gain: best_info_gain = info_gain best_feature = i return best_featureID3naive12345678910111213141516171819202122def majority_cnt(class_list): """ Decided the final class. When the splited data is not belongs to the same class while all feature is handled, the final class is decided by the majority class. Arguments: class_list: The class list of the splited data set. Returns: sorted_class_count[0][0]: The majority class. """ class_count = &#123;&#125; for vote in class_list: if vote not in class_count.keys(): class_count[vote] = 0 class_count[vote] += 1 sorted_class_count = sorted( class_count.iteritems(), key=operator.itemgetter(1), reverse=True) return sorted_class_count[0][0]1234567891011121314151617181920212223242526272829303132333435def CreateTree(data_set, labels): """ Create decision tree. Arguments: data_set: The object data set. labels: The feature labels in the data_set. Returns: my_tree: A dict that represents the decision tree. """ class_list = [example[-1] for example in data_set] # If the classes are fully same if class_list.count(class_list[0]) == len(class_list): return class_list[0] # If all feature is handled if len(data_set[0]) == 1: return majority_cnt(class_list) # Get the best split-feature and the correspond label best_feat = ChooseBestFeatureToSplit(data_set) best_feat_label = labels[best_feat] # Build a recurrence dict my_tree = &#123;best_feat_label: &#123;&#125;&#125; # Get the next step labels parameter del(labels[best_feat]) # Next step start feat_values = [example[best_feat] for example in data_set] unique_vals = set(feat_values) for value in unique_vals: sub_labels = labels[:] # Recurrence calls my_tree[best_feat_label][value] = CreateTree( SplitDataSet(data_set, best_feat, value), sub_labels) return my_tree123456789In [27]: reload(trees)Out[27]: &lt;module 'trees' from 'C:\\Users\\Ewan\\Documents\\GitHub\\hexo\\public\\2017\\02\\15\\Decision-tree\\trees.py'&gt;In [28]: my_dat, labels = trees.CreateDataSet()In [29]: my_tree = trees.CreateTree(my_dat, labels)In [30]: my_treeOut[30]: &#123;'no surfacing': &#123;0: 'no', 1: &#123;'flippers': &#123;0: 'no', 1: 'yes'&#125;&#125;&#125;&#125;demo123456789101112131415161718192021In [63]: reload(trees)Out[63]: &lt;module 'trees' from 'C:\\Users\\Ewan\\Documents\\GitHub\\hexo\\public\\2017\\02\\15\\Decision-tree\\trees.py'&gt;In [64]: my_dat, labels = trees.CreateDataSet()In [65]: labelsOut[65]: ['no surfacing', 'flippers']In [66]: my_tree = trees.CreateTree(my_dat, labels)In [67]: labelsOut[67]: ['no surfacing', 'flippers']In [68]: my_treeOut[68]: &#123;'no surfacing': &#123;0: 'no', 1: &#123;'flippers': &#123;0: 'no', 1: 'yes'&#125;&#125;&#125;&#125;In [69]: trees.Classify(my_tree, labels, [1, 0])Out[69]: 'no'In [70]: trees.Classify(my_tree, labels, [1, 1])Out[70]: 'yes'C4.5C4.5ID3 (IGR)IGR = \frac{IG}{IV}ID3ID3 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465def ChooseBestFeatureToSplit(data_set, flag='ID3'): """ Choose the best feature to split. Arguments: data_set: Object data set. flag: Decide if use the infomation gain rate or not. Returns: best_feature: The index of the feature to split. """ # Initiation # Because the range() method excepts the lastest number num_features = len(data_set[0]) - 1 base_entropy = CalcShannon(data_set) method = 'ID3' best_feature = -1 best_info_gain = 0.0 best_info_gain_rate = 0.0 for i in range(num_features): new_entropy = 0.0 # Choose the i-th feature of all data feat_list = [example[i] for example in data_set] # Abandon the repeat feature value(s) unique_vals = set(feat_list) if len(unique_vals) &gt; 3: method = 'C4.5' if method == 'ID3': # Calculates the Shannon entropy of the splited data set for value in unique_vals: sub_data_set = SplitDataSet(data_set, i, value) prob = len(sub_data_set) / len(data_set) new_entropy += prob * CalcShannon(sub_data_set) else: data_set = np.array(data_set) sorted_feat = np.argsort(feat_list) for index in range(len(sorted_feat) - 1): pre_sorted_feat, post_sorted_feat = np.split( sorted_feat, [index + 1, ]) pre_data_set = data_set[pre_sorted_feat] post_data_set = data_set[post_sorted_feat] pre_coff = len(pre_sorted_feat) / len(sorted_feat) post_coff = len(post_sorted_feat) / len(sorted_feat) # Calucate the split info iv = pre_coff * CalcShannon(pre_data_set) + \ post_coff * CalcShannon(post_data_set) if iv &gt; new_entropy: new_entropy = iv # base_entropy is equal or greatter than new_entropy info_gain = base_entropy - new_entropy if flag == 'C4.5': info_gain_rate = info_gain / new_entropy # print('index', i, 'info_gain_rate', info_gain_rate) if info_gain_rate &gt; best_info_gain_rate: best_info_gain_rate = info_gain_rate best_feature = i if flag == 'ID3': if info_gain &gt; best_info_gain: best_info_gain = info_gain best_feature = i return best_featurenaiveRef: http://blog.csdn.net/lemon_tree12138/article/details/51840361 1234567891011121314151617181920212223242526272829303132333435363738def CreateDataSet(method='ID3'): """ A naive data generation method. Arguments: method: The algorithm class Returns: data_set: The data set excepts label info. labels: The data set only contains label info. """ # Arguments check if method not in ('ID3', 'C4.5'): raise ValueError('invalid value: %s' % method) if method == 'ID3': data_set = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] labels = ['no surfacing', 'flippers'] else: data_set = [[85, 85, 'no'], [80, 90, 'yes'], [83, 78, 'no'], [70, 96, 'no'], [68, 80, 'no'], [65, 70, 'yes'], [64, 65, 'yes'], [72, 95, 'no'], [69, 70, 'no'], [75, 80, 'no'], [75, 70, 'yes'], [72, 90, 'yes'], [81, 75, 'no'], [71, 80, 'yes']] labels = ['temperature', 'humidity'] return data_set, labels[[85, No], [80, No], [83, Yes], [70, Yes], [68, Yes], [65, No], [64, Yes], [72, No], [69, Yes], [75, Yes], [75, Yes], [72, Yes], [81, Yes], [71, No]][[64, Yes], [65, No], [68, Yes], [69, Yes], [70, Yes], [71, No], [72, No], [72, Yes], [75, Yes], [75, Yes], [80, No], [81, Yes], [83, Yes], [85, No]] index = 4 IV(v_4) = IV([4, 1], [5, 4]) = \frac{5}{14}IV([4, 1]) + \frac{9}{14}IV([5, 4])IV(v_4) = \frac{5}{14}(-\frac{4}{5} \log_{2} \frac{4}{5} - \frac{1}{5} \log_{2} \frac{1}{5}) + \frac{9}{14}(-\frac{5}{9} \log_{2} \frac{5}{9} - \frac{4}{9} \log_{2} \frac{4}{9}) (Classify)trees.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383from math import logimport operatorimport numpy as npdef CalcShannon(data_set): """ Calculate the Shan0n Entropy. Arguments: data_set: The object dataset. Returns: shan0n_ent: The Shan0n entropy of the object data set. """ # Initiation num_entries = len(data_set) label_counts = &#123;&#125; # Statistics the frequency of each class in the dataset for feat_vec in data_set: current_label = feat_vec[-1] if current_label not in label_counts.keys(): label_counts[current_label] = 0 label_counts[current_label] += 1 # print(label_counts) # Calculates the Shan0n entropy shan0n_ent = 0.0 for key in label_counts: prob = float(label_counts[key]) / num_entries shan0n_ent -= prob * log(prob, 2) return shan0n_entdef CalcGiniImpurity(data_set): """ Calculate the Gini impurity. Arguments: data_set: The object dataset. Returns: gini_impurity: The Gini impurity of the object data set. """ # Initiation num_entries = len(data_set) label_counts = &#123;&#125; # Statistics the frequency of each class in the dataset for feat_vec in data_set: current_label = feat_vec[-1] if current_label not in label_counts.keys(): label_counts[current_label] = 0 label_counts[current_label] += 1 # Calculates the Gini impurity gini_impurity = 0.0 for key in label_counts: prob = float(label_counts[key]) / num_entries gini_impurity += pow(prob, 2) gini_impurity = 1 - gini_impurity return gini_impuritydef CalcMisClassifyImpurity(data_set): """ Calculate the misclassification impurity. Arguments: data_set: The object dataset. Returns: mis_classify_impurity: The misclassification impurity of the object data set. """ # Initiation num_entries = len(data_set) label_counts = &#123;&#125; # Statistics the frequency of each class in the dataset for feat_vec in data_set: current_label = feat_vec[-1] if current_label not in label_counts.keys(): label_counts[current_label] = 0 label_counts[current_label] += 1 # Calculates the misclassification impurity mis_classify_impurity = 0.0 max_prob = max(label_counts.values()) / num_entries mis_classify_impurity = 1 - max_prob return mis_classify_impuritydef CreateDataSet(method='ID3'): """ A naive data generation method. Arguments: method: The algorithm class Returns: data_set: The data set excepts label info. labels: The data set only contains label info. """ # Arguments check if method not in ('ID3', 'C4.5'): raise ValueError('invalid value: %s' % method) if method == 'ID3': data_set = [[1, 1, 1], [1, 1, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0]] labels = ['0 surfacing', 'flippers'] else: data_set = [[1, 85, 85, 0, 0], [1, 80, 90, 1, 0], [2, 83, 78, 0, 1], [3, 70, 96, 0, 1], [3, 68, 80, 0, 1], [3, 65, 70, 1, 0], [2, 64, 65, 1, 1], [1, 72, 95, 0, 0], [1, 69, 70, 0, 1], [3, 75, 80, 0, 1], [1, 75, 70, 1, 1], [2, 72, 90, 1, 1], [2, 81, 75, 0, 1], [3, 71, 80, 1, 0]] labels = ['outlook', 'temperature', 'humidity', 'windy'] return data_set, labelsdef SplitDataSet(data_set, axis, value): """ Split the data set according to the given axis and correspond value. Arguments: data_set: Object data set. axis: The split-feature index. value: The value of the split-feature. Returns: ret_data_set: The splited data set. """ ret_data_set = [] for feat_vec in data_set: if feat_vec[axis] == value: reduced_feat_vec = feat_vec[:axis] reduced_feat_vec.extend(feat_vec[axis + 1:]) ret_data_set.append(reduced_feat_vec) return ret_data_setdef ChooseBestFeatureToSplit(data_set, flag='ID3'): """ Choose the best feature to split. Arguments: data_set: Object data set. flag: Decide if use the infomation gain rate or not. Returns: best_feature: The index of the feature to split. """ # Initiation # Because the range() method excepts the lastest number num_features = len(data_set[0]) - 1 base_entropy = CalcShannon(data_set) method = 'ID3' best_feature = -1 best_info_gain = 0.0 best_info_gain_rate = 0.0 for i in range(num_features): new_entropy = 0.0 # Choose the i-th feature of all data feat_list = [example[i] for example in data_set] # Abandon the repeat feature value(s) unique_vals = set(feat_list) if len(unique_vals) &gt; 3: method = 'C4.5' if method == 'ID3': # Calculates the Shannon entropy of the splited data set for value in unique_vals: sub_data_set = SplitDataSet(data_set, i, value) prob = len(sub_data_set) / len(data_set) new_entropy += prob * CalcShannon(sub_data_set) else: data_set = np.array(data_set) sorted_feat = np.argsort(feat_list) for index in range(len(sorted_feat) - 1): pre_sorted_feat, post_sorted_feat = np.split( sorted_feat, [index + 1, ]) pre_data_set = data_set[pre_sorted_feat] post_data_set = data_set[post_sorted_feat] pre_coff = len(pre_sorted_feat) / len(sorted_feat) post_coff = len(post_sorted_feat) / len(sorted_feat) # Calucate the split info iv = pre_coff * CalcShannon(pre_data_set) + \ post_coff * CalcShannon(post_data_set) if iv &gt; new_entropy: new_entropy = iv # base_entropy is equal or greatter than new_entropy info_gain = base_entropy - new_entropy if flag == 'C4.5': info_gain_rate = info_gain / new_entropy # print('index', i, 'info_gain_rate', info_gain_rate) if info_gain_rate &gt; best_info_gain_rate: best_info_gain_rate = info_gain_rate best_feature = i if flag == 'ID3': if info_gain &gt; best_info_gain: best_info_gain = info_gain best_feature = i return best_featuredef majority_cnt(class_list): """ Decided the final class. When the splited data is 0t belongs to the same class while all feature is handled, the final class is decided by the majority class. Arguments: class_list: The class list of the splited data set. Returns: sorted_class_count[0][0]: The majority class. """ class_count = &#123;&#125; for vote in class_list: if vote not in class_count.keys(): class_count[vote] = 0 class_count[vote] += 1 sorted_class_count = sorted( class_count. items(), key=operator.itemgetter(1), reverse=True) return sorted_class_count[0][0]def CreateTree(data_set, feat_labels, method='ID3'): """ Create decision tree. Arguments: data_set: The object data set. labels: The feature labels in the data_set. method: The algorithm class. Returns: my_tree: A dict that represents the decision tree. """ # Arguments check if method not in ('ID3', 'C4.5'): raise ValueError('invalid value: %s' % method) labels = feat_labels.copy() class_list = [example[-1] for example in data_set] # print(class_list) # If the classes are fully same print('class_list', class_list) if class_list.count(class_list[0]) == len(class_list): return class_list[0] # If all feature is handled if len(data_set[0]) == 1: return majority_cnt(class_list) if method == 'ID3': # Get the best split-feature and the correspond label best_feat = ChooseBestFeatureToSplit(data_set) best_feat_label = labels[best_feat] # print(best_feat_label) # Build a recurrence dict my_tree = &#123;best_feat_label: &#123;&#125;&#125; # Next step start feat_values = [example[best_feat] for example in data_set] # Get the next step labels parameter del(labels[best_feat]) unique_vals = set(feat_values) for value in unique_vals: sub_labels = labels[:] # Recurrence calls my_tree[best_feat_label][value] = CreateTree( SplitDataSet(data_set, best_feat, value), sub_labels) return my_tree else: flag = 'ID3' # Get the best split-feature and the correspond label best_feat = ChooseBestFeatureToSplit(data_set, 'C4.5') best_feat_label = labels[best_feat] print(best_feat_label) # Build a recurrence dict my_tree = &#123;best_feat_label: &#123;&#125;&#125; # Next step start feat_values = [example[best_feat] for example in data_set] del(labels[best_feat]) unique_vals = set(feat_values) if len(unique_vals) &gt; 3: flag = 'C4.5' if flag == 'ID3': for value in unique_vals: sub_labels = labels[:] # Recurrence calls my_tree[best_feat_label][value] = CreateTree( SplitDataSet(data_set, best_feat, value), sub_labels, 'C4.5') return my_tree else: data_set = np.array(data_set) best_iv = 0.0 best_split_value = -1 sorted_feat = np.argsort(feat_values) for i in range(len(sorted_feat) - 1): pre_sorted_feat, post_sorted_feat = np.split( sorted_feat, [i + 1, ]) pre_data_set = data_set[pre_sorted_feat] post_data_set = data_set[post_sorted_feat] pre_coff = len(pre_sorted_feat) / len(sorted_feat) post_coff = len(post_sorted_feat) / len(sorted_feat) # Calucate the split info iv = pre_coff * CalcShannon(pre_data_set) + \ post_coff * CalcShannon(post_data_set) if iv &gt; best_iv: best_iv = iv best_split_value = feat_values[sorted_feat[i]] print(best_feat, best_split_value) # print(best_split_value) left_data_set = data_set[ data_set[:, best_feat] &lt;= best_split_value] left_data_set = np.delete(left_data_set, best_feat, axis=1) # if len(left_data_set) == 1: # return left_data_set[0][-1] right_data_set = data_set[ data_set[:, best_feat] &gt; best_split_value] right_data_set = np.delete(right_data_set, best_feat, axis=1) # if len(right_data_set) == 1: # return right_data_set[0][-1] sub_labels = labels[:] my_tree[best_feat_label][ '&lt;=' + str(best_split_value)] = CreateTree( left_data_set.tolist(), sub_labels, 'C4.5') my_tree[best_feat_label][ '&gt;' + str(best_split_value)] = CreateTree( right_data_set.tolist(), sub_labels, 'C4.5') # print('continious tree', my_tree) return my_treedef Classify(input_tree, feat_labels, test_vec): """ Classify that uses the given decision tree. Arguments: input_tree: The Given decision tree. feat_labels: The labels of correspond feature. test_vec: The test data. Returns: class_label: The class label that corresponds to the test data. """ # Get the start feature label to split first_str = list(input_tree.keys())[0] # Get the sub-tree that corresponds to the start feature to split second_dict = input_tree[first_str] # Get the feature index that the label is the start feature label feat_index = feat_labels.index(first_str) # Start recurrence search for key in second_dict.keys(): if test_vec[feat_index] == key: if type(second_dict[key]).__name__ == 'dict': # Recurrence calls class_label = Classify(second_dict[key], feat_labels, test_vec) else: class_label = second_dict[key] return class_labeldemo123456789101112131415161718192021222324252627282930313233In [108]: reload(trees)Out[108]: &lt;module 'trees' from 'C:\\Users\\Ewan\\Documents\\GitHub\\hexo\\public\\2017\\02\\15\\Decision-tree\\trees.py'&gt;In [109]: my_dat, labels = trees.CreateDataSet('C4.5')In [110]: my_tree_c = trees.CreateTree(my_dat, labels, 'C4.5')class_list [0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]outlookclass_list [0, 0, 0, 1, 1]humidity1 90class_list [0, 0, 1, 1]temperature0 69class_list [1]class_list [0, 0, 1]windyclass_list [0]class_list [0, 1]class_list [0]class_list [1, 1, 1, 1]class_list [1, 1, 0, 1, 0]windyclass_list [1, 1, 1]class_list [0, 0]In [111]: my_tree_cOut[111]:&#123;'outlook': &#123;1: &#123;'humidity': &#123;'&lt;=90': &#123;'temperature': &#123;'&lt;=69': 1, '&gt;69': &#123;'windy': &#123;0: 0, 1: 0&#125;&#125;&#125;&#125;, '&gt;90': 0&#125;&#125;, 2: 1, 3: &#123;'windy': &#123;0: 1, 1: 0&#125;&#125;&#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[kNN and kd-tree]]></title>
      <url>%2F2017%2F02%2F15%2FkNN-and-kd-tree%2F</url>
      <content type="text"><![CDATA[k-[1][2]kk[4]kk1from numpy import *1234def createDataset(): group = array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]]) labels = ['A', 'A', 'B', 'B'] return group, labels123456789101112131415def classify0(inX, dataSet, labels, k): dataSetSize = dataSet.shape[0] diffMat = tile(inX, (dataSetSize, 1)) - dataSet sqDiffMat = diffMat ** 2 sqDistances = sqDiffMat.sum(axis=1) distances = sqDistances**0.5 sortedDistIndices = distances.argsort() classCount = &#123;&#125; for i in range(k): voteIlabel = labels[sortedDistIndices[i]] classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1 # the return of sorted() is a list and its item is a tuple sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1),reverse=True) return sortedClassCount[0][0] # returns the predict class labelk-kkk=1k=N[3]naivekNNkkdkd6{(2, 3), (5, 4), (9, 6), (4, 7), (8, 1), (7, 2)}kd:kdkdkdkdkkdkkkd:Node-datakSplitLeftkdkdRightkdkdkdk-dcreateKDTreeData-setKdk-d tree1. If Data-setk-d tree2.  1splitSURF6464split 2Node-dataData-setsplitNode-dataData-set = Data-set\Node-dataNode-data3. dataleft = {dData-set &amp;&amp; d[split]  Node-data[split]} dataright = {dData-set &amp;&amp; d[split] &gt; Node-data[split]}4. left = dataleftk-d treecreateKDTreedataleftleftparentKd right = datarightk-d treecreateKDTreedataleftrightparentKd6splitxyxsplit0xNode-datax2,5,9,4,8,77Node-data = (7, 2)(7, 2)split = 0xx = 7x = 7x &lt; = 73{(2, 3), (5, 4), (4, 7)}2{(9, 6), (8, 1)}k-d5,49,61k-dxysplitkdsplitxxxyysplitWindows 10 Pro 64-bit x64-based(Ver. 10.0.14393), Python 3.5.2, Anaconda 4.1.1(64-bit), IPython 5.0.0, Windows CMD,kdTreeCreate.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import numpy as npfrom kdTreeNode import *def createDataSet(): """ Create the test dataset. Returns: A numpy array that contains the test data. """ dataSet = np.array([[2, 3], [5, 4], [9, 6], [4, 7], [8, 1], [7, 2]]) return dataSetdef split(dataSet): """ Split the given dataset. Returns: LeftDataSet: A kdTreeNode object. RightDataSet: A kdTreeNode object. NodeData: A tuple. """ # Ensure the dimension to split dimenIndex = np.var(dataSet, axis=0).argmax() partitionDataSet = dataSet[:, dimenIndex] # print(partitionDataSet) # Ensure the position to split partitionDataSetArgSort = partitionDataSet.argsort() # print(partitionDataSetArgSort) lenOfPartitionDataSetArgSort = len(partitionDataSetArgSort) if lenOfPartitionDataSetArgSort % 2 == 0: posIndex = lenOfPartitionDataSetArgSort // 2 splitIndex = partitionDataSetArgSort[posIndex] else: posIndex = (lenOfPartitionDataSetArgSort - 1) // 2 splitIndex = partitionDataSetArgSort[posIndex] # print(splitIndex) # Split nodeData = dataSet[splitIndex] leftIndeies = partitionDataSetArgSort[:posIndex] rightIndeies = partitionDataSetArgSort[posIndex + 1:] leftDataSet = dataSet[leftIndeies] rightDataSet = dataSet[rightIndeies] return nodeData, dimenIndex, leftDataSet, rightDataSetdef createKDTree(dataSet): """ Create the KD tree. Returns: A kdTreeNode object. """ if len(dataSet) == 0: return nodeData, dimenIndex, leftDataSet, rightDataSet = split(dataSet) # print(nodeData, dimenIndex, leftDataSet, rightDataSet) node = kdTreeNode(nodeData, dimenIndex) node.setLeft(createKDTree(leftDataSet)) node.setRight(createKDTree(rightDataSet)) return nodedef midTravel(node): if node is None: return midTravel(node.getLeft()) print(node.getData()) midTravel(node.getRight())if __name__ == "__main__": dataSet = createDataSet() node = createKDTree(dataSet) midTravel(node)kdTreeNode.py123456789101112131415161718192021222324252627282930313233class kdTreeNode(object): """ Class of k-d tree nodes """ def __init__(self, data=None, split=None, left=None, right=None): self.__data = data self.__split = split self.__left = left self.__right = right def getData(self): return self.__data def setData(self, data): self.__data = data def getSplit(self): return self.__split def setSplit(self, split): self.__split = split def getLeft(self): return self.__left def setLeft(self, left): self.__left = left def getRight(self): return self.__right def setRight(self, right): self.__right = right12345678In [1]: run kdTreeCreate.py-------------------------------------[2 3][5 4][4 7][7 2][8 1][9 6]NK $t=O(KN^{2})$kdkd(2.1, 3.1)(2, 3)(7, 2)(5, 4)(2, 3)&lt;(7, 2), (5, 4), (2, 3)&gt;(2, 3)(2.1, 3.1)0.1414(5, 4)(2.1, 3.1)0.14144y = 4(5, 4)(7, 2)(2.1, 3.1)0.1414x = 7(7, 2)(2, 3)0.1414(2, 4.5)(7, 2)(5, 4)y = 4y4.5(4, 7)&lt;(7, 2), (5, 4), (4, 7)&gt;(4, 7)3.202(5, 4)3.041(2, 4.5)3.041y = 4(5, 4)(2, 3)&lt;(7, 2), (2, 3)&gt;(2, 3)(2, 3)(2, 4.5)(5, 4)(2, 3)1.5(7, 2)(2, 4.5)1.5x = 7(2, 3)1.5k-d k-dKd //k-d treetarget //nearest //dist //123456789101112131415161718192021222324252627282930311. If KdNULLdistinfinite2. // Kd_point = &amp;Kd //Kd-pointk-d tree nearest = Kd_point -&gt; Node-data // whileKd_point pushKd_pointsearch_path //search_path /*** If Distnearesttarget &gt; DistKd_point -&gt; Node-datatarget nearest = Kd_point -&gt; Node-data // Max_dist = Dist(Kd_pointtarget // ***/ s = Kd_point -&gt; split // If target[s] &lt;= Kd_point -&gt; Node-data[s] // Kd_point = Kd_point -&gt; left else Kd_point = Kd_point -&gt;right nearest = search_path // Max_dist = Distnearesttarget // 3. // whilesearch_path != NULL back_point = search_path //search_path s = back_point -&gt; split // If Disttarget[s]back_point -&gt; Node-data[s] &lt; Max_dist // If target[s] &lt;= back_point -&gt; Node-data[s] Kd_point = back_point -&gt; right //target else Kd_point = back_point -&gt; left; //target Kd_pointsearch_path If Distnearesttarget &gt; DistKd_Point -&gt; Node-datatarget nearest = Kd_point -&gt; Node-data // Min_dist = DistKd_point -&gt; Node-data,target //kdTreeSearch.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import numpy as npdef cal_dist(node, target): """ Calculate the distance between the node and the target. Arguments: node: The kd-tree's one node. target: Search target. Returns: dist: The distance between the two nodes. """ node_data = np.array(node) target_data = np.array(target) square_dist_vector = (node_data - target_data) ** 2 square_dist = np.sum(square_dist_vector) dist = square_dist ** 0.5 return distdef search(root_node, target): """ Search the nearest node of the target node in the kd-tree that root node is the root_node Arguments: root_node: The kd-tree's root node. target: Search target. Returns: nearest: The nearest node of the target node in the kd-tree. min_dist: The nearest distance. """ if root_node is None: min_dist = float('inf') return min_dist # Two-fork search kd_point = root_node # Save the root node nearest = kd_point.getData() # Initial the nearest node search_path = [] # Initial the search stack while kd_point: search_path.append(kd_point) split_index = kd_point.getSplit() # Ensure the split path if target[split_index] &lt;= kd_point.getData()[split_index]: kd_point = kd_point.getLeft() else: kd_point = kd_point.getRight() nearest = search_path.pop().getData() min_dist = cal_dist(nearest, target) # Retrospect search while search_path: back_point = search_path.pop() # Ensure the back-split path back_split_index = back_point.getSplit() # Judge if needs to enter the subspace if cal_dist(target[back_split_index], back_point.getData()[back_split_index]) &lt; min_dist: # If the target is in the left subspace, then enter the right if target[back_split_index] &lt;= back_point.getData()[back_split_index]: kd_point = back_point.getRight() # Otherwise enter the left else: kd_point = back_point.getLeft() # Add the node to the search path if kd_point is not None: search_path.append(kd_point) if cal_dist(nearest, target) &gt; cal_dist(kd_point.getData(), target): # Update the nearest node nearest = kd_point.getData() # Update the maximum distance min_dist = cal_dist(kd_point.getData(), target) return nearest, min_dist12345678910111213141516171819202122232425262728293031323334In [1]: run kdTreeCreate.py-------------------------------------[2 3][5 4][4 7][7 2][8 1][9 6]In [2]: node-------------------------------------Out [2]: &lt;kdTreeNode.kdTreeNode at 0x26bff22f160&gt;In [3]: import kdTreeSearchIn [4]: nearest, min_dist = kdTreeSearch.search(node, [2.1, 3.1])In [5]: nearest-------------------------------------Out [5]: array([2, 3])In [6]: min_dist-------------------------------------Out [6]: 0.14142135623730964In [7]: nearest, min_dist = kdTreeSearch.search(node, [2, 4.5])In [8]: nearest-------------------------------------Out [8]: array([2, 3])In [9]: min_dist-------------------------------------Out [9]: 1.5NKkd $t_{worst}=O(KN^{1-1/k})$KN $N&gt;&gt;2^K$ K&lt;2020ball-treeBBFMVPMVPkdk-[1] k-k[2] [3] N[4] ]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2017%2F02%2F15%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.Quick StartCreate a new post1$ hexo new "My New Post"More info: WritingRun server1$ hexo serverMore info: ServerGenerate static files1$ hexo generateMore info: GeneratingDeploy to remote sites1$ hexo deployMore info: Deployment]]></content>
    </entry>

    
  
  
</search>
